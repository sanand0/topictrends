id,update_date,title,abstract
0704.2244,2010-08-30,"Proving Regularity of the Minimal Probability of Ruin via a Game of
  Stopping and Control","  We reveal an interesting convex duality relationship between two problems:
(a) minimizing the probability of lifetime ruin when the rate of consumption is
stochastic and when the individual can invest in a Black-Scholes financial
market; (b) a controller-and-stopper problem, in which the controller controls
the drift and volatility of a process in order to maximize a running reward
based on that process, and the stopper chooses the time to stop the running
reward and rewards the controller a final amount at that time. Our primary goal
is to show that the minimal probability of ruin, whose stochastic
representation does not have a classical form as does the utility maximization
problem (i.e., the objective's dependence on the initial values of the state
variables is implicit), is the unique classical solution of its
Hamilton-Jacobi-Bellman (HJB) equation, which is a non-linear boundary-value
problem. We establish our goal by exploiting the convex duality relationship
between (a) and (b).
"
0705.0053,2008-12-10,Mutual Fund Theorems when Minimizing the Probability of Lifetime Ruin,"  We show that the mutual fund theorems of Merton (1971) extend to the problem
of optimal investment to minimize the probability of lifetime ruin. We obtain
two such theorems by considering a financial market both with and without a
riskless asset for random consumption. The striking result is that we obtain
two-fund theorems despite the additional source of randomness from consumption.
"
0705.1949,2009-05-06,Correlated multi-asset portfolio optimisation with transaction cost,"  We employ perturbation analysis technique to study multi-asset portfolio
optimisation with transaction cost. We allow for correlations in risky assets
and obtain optimal trading methods for general utility functions. Our
analytical results are supported by numerical simulations in the context of the
Long Term Growth Model.
"
0705.2097,2008-12-10,A simple algorithm based on fluctuations to play the market,"  In Biology, all motor enzymes operate on the same principle: they trap
favourable brownian fluctuations in order to generate directed forces and to
move. Whether it is possible or not to copy one such strategy to play the
market was the starting point of our investigations. We found the answer is
yes. In this paper we describe one such strategy and appraise its performance
with historical data from the European Monetary System (EMS), the US Dow Jones,
the german Dax and the french Cac40.
"
0706.0051,2008-12-10,"Optimal consumption from investment and random endowment in incomplete
  semimartingale markets","  We consider the problem of maximizing expected utility from consumption in a
constrained incomplete semimartingale market with a random endowment process,
and establish a general existence and uniqueness result using techniques from
convex duality. The notion of asymptotic elasticity of Kramkov and
Schachermayer is extended to the time-dependent case. By imposing no smoothness
requirements on the utility function in the temporal argument, we can treat
both pure consumption and combined consumption/terminal wealth problems, in a
common framework. To make the duality approach possible, we provide a detailed
characterization of the enlarged dual domain which is reminiscent of the
enlargement of $L^1$ to its topological bidual $(L^{\infty})^*$, a space of
finitely-additive measures. As an application, we treat the case of a
constrained It\^ o-process market-model.
"
0706.0468,2008-12-10,On the semimartingale property via bounded logarithmic utility,"  This paper provides a new version of the condition of Di Nunno et al. (2003),
Ankirchner and Imkeller (2005) and Biagini and \{O}ksendal (2005) ensuring the
semimartingale property for a large class of continuous stochastic processes.
Unlike our predecessors, we base our modeling framework on the concept of
portfolio proportions which yields a short self-contained proof of the main
theorem, as well as a counterexample, showing that analogues of our results do
not hold in the discontinuous setting.
"
0706.0474,2008-12-10,Stability of utility-maximization in incomplete markets,"  The effectiveness of utility-maximization techniques for portfolio management
relies on our ability to estimate correctly the parameters of the dynamics of
the underlying financial assets. In the setting of complete or incomplete
financial markets, we investigate whether small perturbations of the market
coefficient processes lead to small changes in the agent's optimal behavior
derived from the solution of the related utility-maximization problems.
Specifically, we identify the topologies on the parameter process space and the
solution space under which utility-maximization is a continuous operation, and
we provide a counterexample showing that our results are best possible, in a
certain sense. A novel result about the structure of the solution of the
utility-maximization problem where prices are modeled by continuous
semimartingales is established as an offshoot of the proof of our central
theorem.
"
0706.0478,2008-12-10,"Optimal Investment with an Unbounded Random Endowment and Utility-Based
  Pricing","  This paper studies the problem of maximizing the expected utility of terminal
wealth for a financial agent with an unbounded random endowment, and with a
utility function which supports both positive and negative wealth. We prove the
existence of an optimal trading strategy within a class of permissible
strategies -- those strategies whose wealth process is a supermartingale under
all pricing measures with finite relative entropy. We give necessary and
sufficient conditions for the absence of utility-based arbitrage, and for the
existence of a solution to the primal problem.
  We consider two utility-based methods which can be used to price contingent
claims. Firstly we investigate marginal utility-based price processes
(MUBPP's). We show that such processes can be characterized as local
martingales under the normalized optimal dual measure for the utility
maximizing investor. Finally, we present some new results on utility
indifference prices, including continuity properties and volume asymptotics for
the case of a general utility function, unbounded endowment and unbounded
contingent claims.
"
0706.0480,2008-12-02,Maximizing the Growth Rate under Risk Constraints,"  We investigate the ergodic problem of growth-rate maximization under a class
of risk constraints in the context of incomplete, It\^{o}-process models of
financial markets with random ergodic coefficients. Including {\em
value-at-risk} (VaR), {\em tail-value-at-risk} (TVaR), and {\em limited
expected loss} (LEL), these constraints can be both wealth-dependent(relative)
and wealth-independent (absolute). The optimal policy is shown to exist in an
appropriate admissibility class, and can be obtained explicitly by uniform,
state-dependent scaling down of the unconstrained (Merton) optimal portfolio.
This implies that the risk-constrained wealth-growth optimizer locally behaves
like a CRRA-investor, with the relative risk-aversion coefficient depending on
the current values of the market coefficients.
"
0706.0482,2010-03-17,"Stability of the utility maximization problem with random endowment in
  incomplete markets","  We perform a stability analysis for the utility maximization problem in a
general semimartingale model where both liquid and illiquid assets (random
endowments) are present. Small misspecifications of preferences (as modeled via
expected utility), as well as views of the world or the market model (as
modeled via subjective probabilities) are considered. Simple sufficient
conditions are given for the problem to be well-posed, in the sense the optimal
wealth and the marginal utility-based prices are continuous functionals of
preferences and probabilistic views.
"
0707.3198,2008-12-02,Growth-optimal portfolios under transaction costs,"  This paper studies a portfolio optimization problem in a discrete-time
Markovian model of a financial market, in which asset price dynamics depend on
an external process of economic factors. There are transaction costs with a
structure that covers, in particular, the case of fixed plus proportional
costs. We prove that there exists a self-financing trading strategy maximizing
the average growth rate of the portfolio wealth. We show that this strategy has
a Markovian form. Our result is obtained by large deviations estimates on
empirical measures of the price process and by a generalization of the
vanishing discount method to discontinuous transition operators.
"
0708.0046,2013-01-01,Sparse and stable Markowitz portfolios,"  We consider the problem of portfolio selection within the classical Markowitz
mean-variance framework, reformulated as a constrained least-squares regression
problem. We propose to add to the objective function a penalty proportional to
the sum of the absolute values of the portfolio weights. This penalty
regularizes (stabilizes) the optimization problem, encourages sparse portfolios
(i.e. portfolios with only few active positions), and allows to account for
transaction costs. Our approach recovers as special cases the
no-short-positions portfolios, but does allow for short positions in limited
number. We implement this methodology on two benchmark data sets constructed by
Fama and French. Using only a modest amount of training data, we construct
portfolios whose out-of-sample performance, as measured by Sharpe ratio, is
consistently and significantly better than that of the naive evenly-weighted
portfolio which constitutes, as shown in recent literature, a very tough
benchmark.
"
0708.0588,2008-12-02,Investment and Consumption without Commitment,"  In this paper, we investigate the Merton portfolio management problem in the
context of non-exponential discounting. This gives rise to time-inconsistency
of the decision-maker. If the decision-maker at time t=0 can commit his/her
successors, he/she can choose the policy that is optimal from his/her point of
view, and constrain the others to abide by it, although they do not see it as
optimal for them. If there is no commitment mechanism, one must seek a
subgame-perfect equilibrium strategy between the successive decision-makers. In
the line of the earlier work by Ekeland and Lazrak we give a precise definition
of equilibrium strategies in the context of the portfolio management problem,
with finite horizon, we characterize it by a system of partial differential
equations, and we show existence in the case when the utility is CRRA and the
terminal time T is small. We also investigate the infinite-horizon case and we
give two different explicit solutions in the case when the utility is CRRA (in
contrast with the case of exponential discount, where there is only one). Some
of our results are proved under the assumption that the discount function h(t)
is a linear combination of two exponentials, or is the product of an
exponential by a linear function.
"
0708.1715,2017-07-25,On the Structure of General Mean-Variance Hedging Strategies,"  We provide a new characterization of mean-variance hedging strategies in a
general semimartingale market. The key point is the introduction of a new
probability measure $P^{\star}$ which turns the dynamic asset allocation
problem into a myopic one. The minimal martingale measure relative to
$P^{\star}$ coincides with the variance-optimal martingale measure relative to
the original probability measure $P$.
"
0708.2542,2008-12-02,"Capital Allocation to Business Units and Sub-Portfolios: the Euler
  Principle","  Despite the fact that the Euler allocation principle has been adopted by many
financial institutions for their internal capital allocation process, a
comprehensive description of Euler allocation seems still to be missing. We try
to fill this gap by presenting the theoretical background as well as practical
aspects. In particular, we discuss how Euler risk contributions can be
estimated for some important risk measures. We furthermore investigate the
analysis of CDO tranche expected losses by means of Euler's theorem and suggest
an approach to measure the impact of risk factors on non-linear portfolios.
"
0708.2805,2009-09-29,"The public goods game on homogeneous and heterogeneous networks:
  investment strategy according to the pool size","  We propose an extended public goods interaction model to study the evolution
of cooperation in heterogeneous population. The investors are arranged on the
well known scale-free type network, the Barab\'{a}si-Albert model. Each
investor is supposed to preferentially distribute capital to pools in its
portfolio based on the knowledge of pool sizes. The extent that investors
prefer larger pools is determined by investment strategy denoted by a tunable
parameter $\alpha$, with larger $\alpha$ corresponding to more preference to
larger pools. As comparison, we also study this interaction model on square
lattice, and find that the heterogeneity contacts favors cooperation.
Additionally, the influence of local topology to the game dynamics under
different $\alpha$ strategies are discussed. It is found that the system with
smaller $\alpha$ strategy can perform comparatively better than the larger
$\alpha$ ones.
"
0709.2830,2008-12-02,Behavioral Portfolio Selection in Continuous Time,"  This paper formulates and studies a general continuous-time behavioral
portfolio selection model under Kahneman and Tversky's (cumulative) prospect
theory, featuring S-shaped utility (value) functions and probability
distortions. Unlike the conventional expected utility maximization model, such
a behavioral model could be easily mis-formulated (a.k.a. ill-posed) if its
different components do not coordinate well with each other. Certain classes of
an ill-posed model are identified. A systematic approach, which is
fundamentally different from the ones employed for the utility model, is
developed to solve a well-posed model, assuming a complete market and general
It\^o processes for asset prices. The optimal terminal wealth positions,
derived in fairly explicit forms, possess surprisingly simple structure
reminiscent of a gambling policy betting on a good state of the world while
accepting a fixed, known loss in case of a bad one. An example with a two-piece
CRRA utility is presented to illustrate the general results obtained, and is
solved completely for all admissible parameters. The effect of the behavioral
criterion on the risky allocations is finally discussed.
"
0709.3630,2009-11-13,Investments in Random Environments,"  We present analytical investigations of a multiplicative stochastic process
that models a simple investor dynamics in a random environment. The dynamics of
the investor's budget, $x(t)$, depends on the stochasticity of the return on
investment, $r(t)$, for which different model assumptions are discussed. The
fat-tail distribution of the budget is investigated and compared with
theoretical predictions. Weare mainly interested in the most probable value
$x_mp$ of the budget that reaches a constant value over time. Based on an
analytical investigation of the dynamics, we are able to predict $x_mp^stat$.
We find a scaling law that relates the most probable value to the
characteristic parameters describing the stochastic process. Our analytical
results are confirmed by stochastic computer simulations that show a very good
agreement with the predictions.
"
0709.4358,2009-11-13,Projective Market Model Approach to AHP Decision-Making,"  In this paper we describe market in projective geometry language and give
definition of a matrix of market rate, which is related to the matrix rate of
return and the matrix of judgements in the Analytic Hierarchy Process (AHP). We
use these observations to extend the AHP model to projective geometry formalism
and generalise it to intransitive case. We give financial interpretations of
such generalised model and propose its simplification. The unification of the
AHP model and projective aspect of portfolio theory suggests a wide spectrum of
new applications such extended model.
"
0709.4467,2022-01-07,"A Convex Stochastic Optimization Problem Arising from Portfolio
  Selection","  A continuous-time financial portfolio selection model with expected utility
maximization typically boils down to solving a (static) convex stochastic
optimization problem in terms of the terminal wealth, with a budget constraint.
In literature the latter is solved by assuming {\it a priori} that the problem
is well-posed (i.e., the supremum value is finite) and a Lagrange multiplier
exists (and as a consequence the optimal solution is attainable). In this paper
it is first shown, via various counter-examples, neither of these two
assumptions needs to hold, and an optimal solution does not necessarily exist.
These anomalies in turn have important interpretations in and impacts on the
portfolio selection modeling and solutions. Relations among the non-existence
of the Lagrange multiplier, the ill-posedness of the problem, and the
non-attainability of an optimal solution are then investigated. Finally,
explicit and easily verifiable conditions are derived which lead to finding the
unique optimal solution.
"
0710.1855,2009-11-13,"Divergent estimation error in portfolio optimization and in linear
  regression","  The problem of estimation error in portfolio optimization is discussed, in
the limit where the portfolio size N and the sample size T go to infinity such
that their ratio is fixed. The estimation error strongly depends on the ratio
N/T and diverges for a critical value of this parameter. This divergence is the
manifestation of an algorithmic phase transition, it is accompanied by a number
of critical phenomena, and displays universality. As the structure of a large
number of multidimensional regression and modelling problems is very similar to
portfolio optimization, the scope of the above observations extends far beyond
finance, and covers a large number of problems in operations research, machine
learning, bioinformatics, medical science, economics, and technology.
"
0711.2718,2008-12-02,"A Risk-Sensitive Portfolio Optimization Problem with Fixed Incomes
  Securities","  We discuss a class of risk-sensitive portfolio optimization problems. We
consider the portfolio optimization model investigated by Nagai in 2003. The
model by its nature can include fixed income securities as well in the
portfolio. Under fairly general conditions, we prove the existence of optimal
portfolio in both finite and infinite horizon problems.
"
0712.2771,2011-04-08,Analysis of Kelly-optimal portfolios,"  We investigate the use of Kelly's strategy in the construction of an optimal
portfolio of assets. For lognormally distributed asset returns, we derive
approximate analytical results for the optimal investment fractions in various
settings. We show that when mean returns and volatilities of the assets are
small and there is no risk-free asset, the Kelly-optimal portfolio lies on
Markowitz Efficient Frontier. Since in the investigated case the Kelly approach
forbids short positions and borrowing, often only a small fraction of the
available assets is included in the Kelly-optimal portfolio. This phenomenon,
that we call condensation, is studied analytically in various model scenarios.
"
0801.0195,2011-05-03,"An optimal life insurance policy in the investment-consumption problem
  in an incomplete market","  This paper considers an optimal life insurance for a householder subject to
mortality risk. The household receives a wage income continuously, which is
terminated by unexpected (premature) loss of earning power or (planned and
intended) retirement, whichever happens first. In order to hedge the risk of
losing income stream by householder's unpredictable event, the household enters
a life insurance contract by paying a premium to an insurance company. The
household may also invest their wealth into a financial market. The problem is
to determine an optimal insurance/investment/consumption strategy in order to
maximize the expected total, discounted utility from consumption and terminal
wealth. To reflect a real-life situation better, we consider an incomplete
market where the householder cannot trade insurance contracts continuously. To
our best knowledge, such a model is new in the insurance and finance
literature. The case of exponential utilities is considered in detail to derive
an explicit solution. We also provide numerical experiments for that particular
case to illustrate our results.
"
0801.3560,2009-11-13,Trading Model with Pair Pattern Strategies,"  A simple trading model based on pair pattern strategy space with holding
periods is proposed. Power-law behaviors are observed for the return variance
$\sigma^2$, the price impact $H$ and the predictability $K$ for both models
with linear and square root impact functions. The sum of the traders' wealth
displays a positive value for the model with square root price impact function,
and a qualitative explanation is given based on the observation of the
conditional excess demand $<A|u>$. An evolutionary trading model is further
proposed, and the elimination mechanism effectively changes the behavior of the
traders highly performed in the model without evolution. The trading model with
other types of traders, e.g., traders with the MG's strategies and producers,
are also carefully studied.
"
0801.4305,2009-11-13,"Risk-Seeking versus Risk-Avoiding Investments in Noisy Periodic
  Environments","  We study the performance of various agent strategies in an artificial
investment scenario. Agents are equipped with a budget, $x(t)$, and at each
time step invest a particular fraction, $q(t)$, of their budget. The return on
investment (RoI), $r(t)$, is characterized by a periodic function with
different types and levels of noise. Risk-avoiding agents choose their fraction
$q(t)$ proportional to the expected positive RoI, while risk-seeking agents
always choose a maximum value $q_{max}$ if they predict the RoI to be positive
(""everything on red""). In addition to these different strategies, agents have
different capabilities to predict the future $r(t)$, dependent on their
internal complexity. Here, we compare 'zero-intelligent' agents using technical
analysis (such as moving least squares) with agents using reinforcement
learning or genetic algorithms to predict $r(t)$. The performance of agents is
measured by their average budget growth after a certain number of time steps.
We present results of extensive computer simulations, which show that, for our
given artificial environment, (i) the risk-seeking strategy outperforms the
risk-avoiding one, and (ii) the genetic algorithm was able to find this optimal
strategy itself, and thus outperforms other prediction approaches considered.
"
0801.4941,2008-12-10,"Hedging strategies and minimal variance portfolios for European and
  exotic options in a Levy market","  This paper presents hedging strategies for European and exotic options in a
Levy market. By applying Taylor's Theorem, dynamic hedging portfolios are con-
structed under different market assumptions, such as the existence of power
jump assets or moment swaps. In the case of European options or baskets of
European options, static hedging is implemented. It is shown that perfect
hedging can be achieved. Delta and gamma hedging strategies are extended to
higher moment hedging by investing in other traded derivatives depending on the
same underlying asset. This development is of practical importance as such
other derivatives might be readily available. Moment swaps or power jump assets
are not typically liquidly traded. It is shown how minimal variance portfolios
can be used to hedge the higher order terms in a Taylor expansion of the
pricing function, investing only in a risk-free bank account, the underlying
asset and potentially variance swaps. The numerical algorithms and performance
of the hedging strategies are presented, showing the practical utility of the
derived results.
"
0803.1364,2008-12-10,Diversification and limited information in the Kelly game,"  Financial markets, with their vast range of different investment
opportunities, can be seen as a system of many different simultaneous games
with diverse and often unknown levels of risk and reward. We introduce
generalizations to the classic Kelly investment game [Kelly (1956)] that
incorporates these features, and use them to investigate the influence of
diversification and limited information on Kelly-optimal portfolios. In
particular we present approximate formulas for optimizing diversified
portfolios and exact results for optimal investment in unknown games where the
only available information is past outcomes.
"
0803.3093,2008-12-10,Diversity and relative arbitrage in equity markets,"  A financial market is called ""diverse"" if no single stock is ever allowed to
dominate the entire market in terms of relative capitalization. In the context
of the standard Ito-process model initiated by Samuelson (1965) we formulate
this property (and the allied, successively weaker notions of ""weak diversity""
and ""asymptotic weak diversity"") in precise terms. We show that diversity is
possible to achieve, but delicate. Several illustrative examples are provided,
which demonstrate that weakly-diverse financial markets contain relative
arbitrage opportunities: it is possible to outperform (or underperform) such
markets over sufficiently long time-horizons, and to underperform them
significantly over arbitrary time-horizons. The existence of such relative
arbitrage does not interfere with the development of option pricing, and has
interesting consequences for the pricing of long-term warrants and for put-call
parity. Several open questions are suggested for further study.
"
0804.4522,2008-12-02,"Optimal solution of investment problems via linear parabolic equations
  generated by Kalman filter","  We consider optimal investment problems for a diffusion market model with
non-observable random drifts that evolve as an Ito's process. Admissible
strategies do not use direct observations of the market parameters, but rather
use historical stock prices. For a non-linear problem with a general
performance criterion, the optimal portfolio strategy is expressed via the
solution of a scalar minimization problem and a linear parabolic equation with
coefficients generated by the Kalman filter.
"
0805.0122,2008-12-10,Optimal Robust Mean-Variance Hedging in Incomplete Financial Markets,"  Optimal B-robust estimate is constructed for multidimensional parameter in
drift coefficient of diffusion type process with small noise. Optimal
mean-variance robust (optimal V -robust) trading strategy is find to hedge in
mean-variance sense the contingent claim in incomplete financial market with
arbitrary information structure and misspecified volatility of asset price,
which is modelled by multidimensional continuous semimartingale. Obtained
results are applied to stochastic volatility model, where the model of latent
volatility process contains unknown multidimensional parameter in drift
coefficient and small parameter in diffusion term.
"
0805.0618,2012-01-04,Risk Aversion and Portfolio Selection in a Continuous-Time Model,"  The comparative statics of the optimal portfolios across individuals is
carried out for a continuous-time complete market model, where the risky assets
price process follows a joint geometric Brownian motion with time-dependent and
deterministic coefficients. It turns out that the indirect utility functions
inherit the order of risk aversion (in the Arrow-Pratt sense) from the von
Neumann-Morgenstern utility functions, and therefore, a more risk-averse agent
would invest less wealth (in absolute value) in the risky assets.
"
0805.3397,2009-04-16,"How to quantify the influence of correlations on investment
  diversification","  When assets are correlated, benefits of investment diversification are
reduced. To measure the influence of correlations on investment performance, a
new quantity - the effective portfolio size - is proposed and investigated in
both artificial and real situations. We show that in most cases, the effective
portfolio size is much smaller than the actual number of assets in the
portfolio and that it lowers even further during financial crises.
"
0805.3981,2008-12-02,Optimal Investment Strategy to Minimize Occupation Time,"  We find the optimal investment strategy to minimize the expected time that an
individual's wealth stays below zero, the so-called {\it occupation time}. The
individual consumes at a constant rate and invests in a Black-Scholes financial
market consisting of one riskless and one risky asset, with the risky asset's
price process following a geometric Brownian motion. We also consider an
extension of this problem by penalizing the occupation time for the degree to
which wealth is negative.
"
0806.4026,2008-12-02,On a Non-Standard Stochastic Control Problem,"  This paper considers the Merton portfolio management problem. We are
concerned with non-exponential discounting of time and this leads to time
inconsistencies of the decision maker. Following Ekeland and Pirvu 2006, we
introduce the notion of equilibrium policies and we characterize them by an
integral equation. The main idea is to come up with the value function in this
context. If risk preferences are of CRRA type, the integral equation which
characterizes the value function is shown to have a solution which leads to an
equilibrium policy. This work is an extension of Ekeland and Pirvu 2006.
"
0806.4061,2008-12-10,"An explicit solution for an optimal stopping/optimal control problem
  which models an asset sale","  In this article we study an optimal stopping/optimal control problem which
models the decision facing a risk-averse agent over when to sell an asset. The
market is incomplete so that the asset exposure cannot be hedged. In addition
to the decision over when to sell, the agent has to choose a control strategy
which corresponds to a feasible wealth process. We formulate this problem as
one involving the choice of a stopping time and a martingale. We conjecture the
form of the solution and verify that the candidate solution is equal to the
value function. The interesting features of the solution are that it is
available in a very explicit form, that for some parameter values the optimal
strategy is more sophisticated than might originally be expected, and that
although the setup is based on continuous diffusions, the optimal martingale
may involve a jump process. One interpretation of the solution is that it is
optimal for the risk-averse agent to gamble.
"
0806.4834,2008-12-02,"Dual method for continuous-time Markowitz's Problems with nonlinear
  wealth equations","  Continuous-time mean-variance portfolio selection model with nonlinear wealth
equations and bankruptcy prohibition is investigated by the dual method. A
necessary and sufficient condition which the optimal terminal wealth satisfies
is obtained through a terminal perturbation technique. It is also shown that
the optimal wealth and portfolio is the solution of a forward-backward
stochastic differential equation with constraints.
"
0808.1710,2009-05-19,Dynamic modeling of mean-reverting spreads for statistical arbitrage,"  Statistical arbitrage strategies, such as pairs trading and its
generalizations, rely on the construction of mean-reverting spreads enjoying a
certain degree of predictability. Gaussian linear state-space processes have
recently been proposed as a model for such spreads under the assumption that
the observed process is a noisy realization of some hidden states. Real-time
estimation of the unobserved spread process can reveal temporary market
inefficiencies which can then be exploited to generate excess returns. Building
on previous work, we embrace the state-space framework for modeling spread
processes and extend this methodology along three different directions. First,
we introduce time-dependency in the model parameters, which allows for quick
adaptation to changes in the data generating process. Second, we provide an
on-line estimation algorithm that can be constantly run in real-time. Being
computationally fast, the algorithm is particularly suitable for building
aggressive trading strategies based on high-frequency data and may be used as a
monitoring device for mean-reversion. Finally, our framework naturally provides
informative uncertainty measures of all the estimated parameters. Experimental
results based on Monte Carlo simulations and historical equity data are
discussed, including a co-integration relationship involving two
exchange-traded funds.
"
0809.0739,2009-12-10,"A dual characterization of self-generation and exponential forward
  performances","  We propose a mathematical framework for the study of a family of random
fields--called forward performances--which arise as numerical representation of
certain rational preference relations in mathematical finance. Their spatial
structure corresponds to that of utility functions, while the temporal one
reflects a Nisio-type semigroup property, referred to as self-generation. In
the setting of semimartingale financial markets, we provide a dual formulation
of self-generation in addition to the original one, and show equivalence
between the two, thus giving a dual characterization of forward performances.
Then we focus on random fields with an exponential structure and provide
necessary and sufficient conditions for self-generation in that case. Finally,
we illustrate our methods in financial markets driven by It\^o-processes, where
we obtain an explicit parametrization of all exponential forward performances.
"
0809.4615,2010-08-25,"Correlation, hierarchies, and networks in financial markets","  We discuss some methods to quantitatively investigate the properties of
correlation matrices. Correlation matrices play an important role in portfolio
optimization and in several other quantitative descriptions of asset price
dynamics in financial markets. Specifically, we discuss how to define and
obtain hierarchical trees, correlation based trees and networks from a
correlation matrix. The hierarchical clustering and other procedures performed
on the correlation matrix to detect statistically reliable aspects of the
correlation matrix are seen as filtering procedures of the correlation matrix.
We also discuss a method to associate a hierarchically nested factor model to a
hierarchical tree obtained from a correlation matrix. The information retained
in filtering procedures and its stability with respect to statistical
fluctuations is quantified by using the Kullback-Leibler distance.
"
0810.0678,2008-12-02,Portfolio Optimization under Habit Formation,"  The ""standard"" Merton formulation of optimal investment and consumption
involves optimizing the integrated lifetime utility of consumption, suitably
discounted, together with the discounted future bequest. In this formulation
the utility of consumption at any given time depends only on the amount
consumed at that time. However, it is both theoretically and empirically
reasonable that an individuals utility of consumption would depend on past
consumption history. Economists term this ""Habit Formation"". We introduce a new
formulation of habit formation which allows non-addictive consumption patterns
for a wide variety of utility specification. In this paper we construct a
simple mathematical description of this habit formation and present numerical
solutions. We compare the results with the standard ones and draw insights
obtained from the habit formation. The consumption path tends to increase with
time and be less sensitive to the market fluctuations, which perfectly reflects
the existence of habit persistence of an investor. At the same time, his
decreasing risk aversion, which seems to be in contradiction with the empirical
evidence, can be explained within the limitations of the model.
"
0810.1922,2014-08-26,Look-Ahead Benchmark Bias in Portfolio Performance Evaluation,"  Performance of investment managers are evaluated in comparison with
benchmarks, such as financial indices. Due to the operational constraint that
most professional databases do not track the change of constitution of
benchmark portfolios, standard tests of performance suffer from the ""look-ahead
benchmark bias,"" when they use the assets constituting the benchmarks of
reference at the end of the testing period, rather than at the beginning of the
period. Here, we report that the ""look-ahead benchmark bias"" can exhibit a
surprisingly large amplitude for portfolios of common stocks (up to 8% annum
for the S&P500 taken as the benchmark) -- while most studies have emphasized
related survival biases in performance of mutual and hedge funds for which the
biases can be expected to be even larger. We use the CRSP database from 1926 to
2006 and analyze the running top 500 US capitalizations to demonstrate that
this bias can account for a gross overestimation of performance metrics such as
the Sharpe ratio as well as an underestimation of risk, as measured for
instance by peak-to-valley drawdowns. We demonstrate the presence of a
significant bias in the estimation of the survival and look-ahead biases
studied in the literature. A general methodology to test the properties of
investment strategies is advanced in terms of random strategies with similar
investment constraints.
"
0811.3889,2009-04-08,Multivariate utility maximization with proportional transaction costs,"  We present an optimal investment theorem for a currency exchange model with
random and possibly discontinuous proportional transaction costs. The
investor's preferences are represented by a multivariate utility function,
allowing for simultaneous consumption of any prescribed selection of the
currencies at a given terminal date. We prove the existence of an optimal
portfolio process under the assumption of asymptotic satiability of the value
function. Sufficient conditions for asymptotic satiability of the value
function include reasonable asymptotic elasticity of the utility function, or a
growth condition on its dual function. We show that the portfolio optimization
problem can be reformulated in terms of maximization of a terminal liquidation
utility function, and that both problems have a common optimizer.
"
0811.4715,2010-07-13,Utility maximization in incomplete markets with default,"  We adress the maximization problem of expected utility from terminal wealth.
The special feature of this paper is that we consider a financial market where
the price process of risky assets can have a default time. Using dynamic
programming, we characterize the value function with a backward stochastic
differential equation and the optimal portfolio policies. We separately treat
the cases of exponential, power and logarithmic utility.
"
0812.0033,2010-03-24,"Multiplicative approximation of wealth processes involving no-short-sale
  strategies via simple trading","  A financial market model with general semimartingale asset-price processes
and where agents can only trade using no-short-sales strategies is considered.
We show that wealth processes using continuous trading can be approximated very
closely by wealth processes using simple combinations of buy-and-hold trading.
This approximation is based on controlling the proportions of wealth invested
in the assets. As an application, the utility maximization problem is
considered and it is shown that optimal expected utilities and wealth processes
resulting from continuous trading can be approximated arbitrarily well by the
use of simple combinations of buy-and-hold strategies.
"
0812.0136,2008-12-08,"A mixed relaxed singular maximum principle for linear SDEs with random
  coefficients","  We study singular stochastic control of a two dimensional stochastic
differential equation, where the first component is linear with random and
unbounded coefficients. We derive existence of an optimal relaxed control and
necessary conditions for optimality in the form of a mixed relaxed-singular
maximum principle in a global form. A motivating example is given in the form
of an optimal investment and consumption problem with transaction costs, where
we consider a portfolio with a continuum of bonds and where the portfolio
weights are modeled as measure-valued processes on the set of times to
maturity.
"
0812.2604,2008-12-16,"Asset Allocation and Risk Assessment with Gross Exposure Constraints for
  Vast Portfolios","  Markowitz (1952, 1959) laid down the ground-breaking work on the
mean-variance analysis. Under his framework, the theoretical optimal allocation
vector can be very different from the estimated one for large portfolios due to
the intrinsic difficulty of estimating a vast covariance matrix and return
vector. This can result in adverse performance in portfolio selected based on
empirical data due to the accumulation of estimation errors. We address this
problem by introducing the gross-exposure constrained mean-variance portfolio
selection. We show that with gross-exposure constraint the theoretical optimal
portfolios have similar performance to the empirically selected ones based on
estimated covariance matrices and there is no error accumulation effect from
estimation of vast covariance matrices. This gives theoretical justification to
the empirical results in Jagannathan and Ma (2003). We also show that the
no-short-sale portfolio is not diversified enough and can be improved by
allowing some short positions. As the constraint on short sales relaxes, the
number of selected assets varies from a small number to the total number of
stocks, when tracking portfolios or selecting assets. This achieves the optimal
sparse portfolio selection, which has close performance to the theoretical
optimal one. Among 1000 stocks, for example, we are able to identify all
optimal subsets of portfolios of different sizes, their associated allocation
vectors, and their estimated risks. The utility of our new approach is
illustrated by simulation and empirical studies on the 100 Fama-French
industrial portfolios and the 400 stocks randomly selected from Russell 3000.
"
0901.0447,2009-01-06,"Evaluating the performance of adapting trading strategies with different
  memory lengths","  We propose a prediction model based on the minority game in which traders
continuously evaluate a complete set of trading strategies with different
memory lengths using the strategies' past performance. Based on the chosen
trading strategy they determine their prediction of the movement for the
following time period of a single asset. We find empirically using stocks from
the S&P500 that our prediction model yields a high success rate of over 51.5%
and produces higher returns than a buy-and-hold strategy. Even when taking into
account trading costs we find that using the predictions will generate superior
investment portfolios.
"
0901.2070,2009-01-15,State-dependent utility maximization in L\'evy markets,"  We revisit Merton's portfolio optimization problem under boun-ded
state-dependent utility functions, in a market driven by a L\'evy process $Z$
extending results by Karatzas et. al. (1991) and Kunita (2003). The problem is
solved using a dual variational problem as it is customarily done for
non-Markovian models. One of the main features here is that the domain of the
dual problem enjoys an explicit ""parametrization"", built on a multiplicative
optional decomposition for nonnegative supermartingales due to F\""ollmer and
Kramkov (1997). As a key step in obtaining the representation result we prove a
closure property for integrals with respect to Poisson random measures, a
result of interest on its own that extends the analog property for integrals
with respect to a fixed semimartingale due to M\'emin (1980). In the case that
(i) the L\'evy measure of $Z$ is atomic with a finite number of atoms or that
(ii) $\Delta S_{t}/S_{t^{-}}=\zeta_{t} \vartheta(\Delta Z_{t})$ for a process
$\zeta$ and a deterministic function $\vartheta$, we explicitly characterize
the admissible trading strategies and show that the dual solution is a
risk-neutral local martingale.
"
0901.2484,2009-03-27,Consumption and Portfolio Rules for Time-Inconsistent Investors,"  This paper extends the classical consumption and portfolio rules model in
continuous time (Merton 1969, 1971) to the framework of decision-makers with
time-inconsistent preferences. The model is solved for different utility
functions for both, naive and sophisticated agents, and the results are
compared. In order to solve the problem for sophisticated agents, we derive a
modified HJB (Hamilton-Jacobi-Bellman) equation. It is illustrated how for CRRA
functions within the family of HARA functions (logarithmic and potential cases)
the optimal portfolio rule does not depend on the discount rate, but this is
not the case for a general utility function, such as the exponential (CARA)
utility function.
"
0902.2965,2015-03-13,Optimal leverage from non-ergodicity,"  In modern portfolio theory, the balancing of expected returns on investments
against uncertainties in those returns is aided by the use of utility
functions. The Kelly criterion offers another approach, rooted in information
theory, that always implies logarithmic utility. The two approaches seem
incompatible, too loosely or too tightly constraining investors' risk
preferences, from their respective perspectives. The conflict can be understood
on the basis that the multiplicative models used in both approaches are
non-ergodic which leads to ensemble-average returns differing from time-average
returns in single realizations. The classic treatments, from the very beginning
of probability theory, use ensemble-averages, whereas the Kelly-result is
obtained by considering time-averages. Maximizing the time-average growth rates
for an investment defines an optimal leverage, whereas growth rates derived
from ensemble-average returns depend linearly on leverage. The latter measure
can thus incentivize investors to maximize leverage, which is detrimental to
time-average growth and overall market stability. The Sharpe ratio is
insensitive to leverage. Its relation to optimal leverage is discussed. A
better understanding of the significance of time-irreversibility and
non-ergodicity and the resulting bounds on leverage may help policy makers in
reshaping financial risk controls.
"
0902.3836,2009-02-24,"The Effects of Market Properties on Portfolio Diversification in the
  Korean and Japanese Stock Markets","  In this study, we have investigated empirically the effects of market
properties on the degree of diversification of investment weights among stocks
in a portfolio. The weights of stocks within a portfolio were determined on the
basis of Markowitz's portfolio theory. We identified that there was a negative
relationship between the influence of market properties and the degree of
diversification of the weights among stocks in a portfolio. Furthermore, we
noted that the random matrix theory method could control the properties of
correlation matrix between stocks; this may be useful in improving portfolio
management for practical application.
"
0903.1525,2009-03-10,The empirical properties of large covariance matrices,"  The salient properties of large empirical covariance and correlation matrices
are studied for three datasets of size 54, 55 and 330. The covariance is
defined as a simple cross product of the returns, with weights that decay
logarithmically slowly. The key general properties of the covariance matrices
are the following. The spectrum of the covariance is very static, except for
the top three to ten eigenvalues, and decay exponentially fast toward zero. The
mean spectrum and spectral density show no particular feature that would
separate ""meaningful"" from ""noisy"" eigenvalues. The spectrum of the correlation
is more static, with three to five eigenvalues that have distinct dynamics. The
mean projector of rank k on the leading subspace shows instead that most of the
dynamics occur in the eigenvectors, including deep in the spectrum. Together,
this implies that the reduction of the covariance to a few leading eigenmodes
misses most of the dynamics, and that a covariance estimator correctly
evaluates both volatilities and correlations.
"
0903.1531,2009-03-10,Inference on multivariate ARCH processes with large sizes,"  The covariance matrix is formulated in the framework of a linear multivariate
ARCH process with long memory, where the natural cross product structure of the
covariance is generalized by adding two linear terms with their respective
parameter. The residuals of the linear ARCH process are computed using
historical data and the (inverse square root of the) covariance matrix. Simple
measure of qualities assessing the independence and unit magnitude of the
residual distributions are proposed. The salient properties of the computed
residuals are studied for three data sets of size 54, 55 and 330. Both new
terms introduced in the covariance help in producing uncorrelated residuals,
but the residual magnitudes are very different from unity. The large sizes of
the inferred residuals are due to the limited information that can be extracted
from the empirical data when the number of time series is large, and denotes a
fundamental limitation to the inference that can be achieved.
"
0903.2243,2014-09-24,"Pragmatic Information Rates, Generalizations of the Kelly Criterion, and
  Financial Market Efficiency","  This paper is part of an ongoing investigation of ""pragmatic information"",
defined in Weinberger (2002) as ""the amount of information actually used in
making a decision"". Because a study of information rates led to the Noiseless
and Noisy Coding Theorems, two of the most important results of Shannon's
theory, we begin the paper by defining a pragmatic information rate, showing
that all of the relevant limits make sense, and interpreting them as the
improvement in compression obtained from using the correct distribution of
transmitted symbols.
  The first of two applications of the theory extends the information theoretic
analysis of the Kelly Criterion, and its generalization, the horse race, to a
series of races where the stochastic process of winning horses, payoffs, and
strategies depend on some stationary process, including, but not limited to the
history of previous races. If the bettor is receiving messages (side
information) about the probability distribution of winners, the doubling rate
of the bettor's winnings is bounded by the pragmatic information of the
messages.
  A second application is to the question of market efficiency. An efficient
market is, by definition, a market in which the pragmatic information of the
""tradable past"" with respect to current prices is zero. Under this definition,
markets whose returns are characterized by a GARCH(1,1) process cannot be
efficient.
  Finally, a pragmatic informational analogue to Shannon's Noisy Coding Theorem
suggests that a cause of market inefficiency is that the underlying
fundamentals are changing so fast that the price discovery mechanism simply
cannot keep up. This may happen most readily in the run-up to a financial
bubble, where investors' willful ignorance degrade the information processing
capabilities of the market.
"
0903.2910,2015-05-13,Application of the Kelly Criterion to Ornstein-Uhlenbeck Processes,"  In this paper, we study the Kelly criterion in the continuous time framework
building on the work of E.O. Thorp and others. The existence of an optimal
strategy is proven in a general setting and the corresponding optimal wealth
process is found. A simple formula is provided for calculating the optimal
portfolio for a set of price processes satisfying some simple conditions.
Properties of the optimal investment strategy for assets governed by multiple
Ornstein-Uhlenbeck processes are studied. The paper ends with a short
discussion of the implications of these ideas for financial markets.
"
0904.0870,2009-04-07,Risk Measures in Quantitative Finance,"  This paper was presented and written for two seminars: a national UK
University Risk Conference and a Risk Management industry workshop. The target
audience is therefore a cross section of Academics and industry professionals.
  The current ongoing global credit crunch has highlighted the importance of
risk measurement in Finance to companies and regulators alike. Despite risk
measurement's central importance to risk management, few papers exist reviewing
them or following their evolution from its foremost beginnings up to the
present day risk measures.
  This paper reviews the most important portfolio risk measures in Financial
Mathematics, from Bernoulli (1738) to Markowitz's Portfolio Theory, to the
presently preferred risk measures such as CVaR (conditional Value at Risk). We
provide a chronological review of the risk measures and survey less commonly
known risk measures e.g. Treynor ratio.
"
0904.1131,2009-04-08,"Optimisation of Stochastic Programming by Hidden Markov Modelling based
  Scenario Generation","  This paper formed part of a preliminary research report for a risk
consultancy and academic research. Stochastic Programming models provide a
powerful paradigm for decision making under uncertainty. In these models the
uncertainties are represented by a discrete scenario tree and the quality of
the solutions obtained is governed by the quality of the scenarios generated.
We propose a new technique to generate scenarios based on Gaussian Mixture
Hidden Markov Modelling. We show that our approach explicitly captures
important time varying dynamics of stochastic processes (such as autoregression
and jumps) as well as non-Gaussian distribution characteristics (such as
skewness and kurtosis). Our scenario generation method enables richer
robustness and scenario analysis through exploiting the tractable properties of
Markov models and Gaussian mixture distributions. We demonstrate the benefits
of our scenario generation method by conducting numerical experiments on
FTSE-100 data.
"
0904.1903,2009-04-14,Minimizing the expected market time to reach a certain wealth level,"  In a financial market model, we consider variations of the problem of
minimizing the expected time to upcross a certain wealth level. For exponential
Levy markets, we show the asymptotic optimality of the growth-optimal portfolio
for the above problem and obtain tight bounds for the value function for any
wealth level. In an Ito market, we employ the concept of market time, which is
a clock that runs according to the underlying market growth. We show the
optimality of the growth-optimal portfolio for minimizing the expected market
time to reach any wealth level. This reveals a general definition of market
time which can be useful from an investor's point of view. We utilize this last
definition to extend the previous results in a general semimartingale setting.
"
0904.4620,2009-04-30,Haar Wavelets-Based Approach for Quantifying Credit Portfolio Losses,"  This paper proposes a new methodology to compute Value at Risk (VaR) for
quantifying losses in credit portfolios. We approximate the cumulative
distribution of the loss function by a finite combination of Haar wavelets
basis functions and calculate the coefficients of the approximation by
inverting its Laplace transform. In fact, we demonstrate that only a few
coefficients of the approximation are needed, so VaR can be reached quickly. To
test the methodology we consider the Vasicek one-factor portfolio credit loss
model as our model framework. The Haar wavelets method is fast, accurate and
robust to deal with small or concentrated portfolios, when the hypothesis of
the Basel II formulas are violated.
"
0905.0155,2009-11-05,"Weakly nonlinear analysis of the Hamilton-Jacobi-Bellman equation
  arising from pension savings management","  The main purpose of this paper is to analyze solutions to a fully nonlinear
parabolic equation arising from the problem of optimal portfolio construction.
We show how the problem of optimal stock to bond proportion in the management
of pension fund portfolio can be formulated in terms of the solution to the
Hamilton-Jacobi-Bellman equation. We analyze the solution from qualitative as
well as quantitative point of view. We construct useful bounds of solution
yielding estimates for the optimal value of the stock to bond proportion in the
portfolio. Furthermore we construct asymptotic expansions of a solution in
terms of a small model parameter. Finally, we perform sensitivity analysis of
the optimal solution with respect to various model parameters and compare
analytical results of this paper with the corresponding known results arising
from time-discrete dynamic stochastic optimization model.
"
0905.0781,2009-09-28,"Variance-covariance based risk allocation in credit portfolios:
  analytical approximation","  High precision analytical approximation is proposed for variance-covariance
based risk allocation in a portfolio of risky assets. A general case of a
single-period multi-factor Merton-type model with stochastic recovery is
considered. The accuracy of the approximation as well as its speed are compared
to and shown to be superior to those of Monte Carlo simulation.
"
0905.2926,2010-02-10,One-Dimensional Pricing of CPPI,"  Constant Proportion Portfolio Insurance (CPPI) is an investment strategy
designed to give participation in the performance of a risky asset while
protecting the invested capital. This protection is however not perfect and the
gap risk must be quantified. CPPI strategies are path-dependent and may have
American exercise which makes their valuation complex. A naive description of
the state of the portfolio would involve three or even four variables. In this
paper we prove that the system can be described as a discrete-time Markov
process in one single variable if the underlying asset follows a homogeneous
process. This yields an efficient pricing scheme using transition
probabilities. Our framework is flexible enough to handle most features of
traded CPPIs including profit lock-in and other kinds of strategies with
discrete-time reallocation.
"
0905.3875,2009-06-02,"Are Stock Markets Integrated? Evidence from a Partially Segmented ICAPM
  with Asymmetric Effects","  In this paper, we test a partially segmented ICAPM for two developed markets,
two emerging markets and World market, using an asymmetric extension of the
multivariate GARCH process of De Santis and Gerard (1997,1998). We find that
this asymmetric process provides a significantly better fit of the data than a
standard symmetric process. The evidence obtained from the whole period and
sub-periods analysis supports the financial integration hypothesis and suggests
that domestic risk is not a priced factor.
"
0905.3891,2009-05-26,"La prime de risque dans un cadre international : le risque de change
  est-il appr\'eci\'e ?","  In this article, we investigate whether exchange rate risk is priced. We use
a multivariate GARCH-in-Mean specification and test alternative conditional
international CAPM versions. Our results support strongly the international
asset-pricing model that includes exchange rate risk for both developed and
emerging stock markets. However, there are important time and cross-country
variations in the relative size and dynamics of different risk premia.
"
0905.4740,2015-03-13,Jump-Diffusion Risk-Sensitive Asset Management,"  This paper considers a portfolio optimization problem in which asset prices
are represented by SDEs driven by Brownian motion and a Poisson random measure,
with drifts that are functions of an auxiliary diffusion 'factor' process. The
criterion, following earlier work by Bielecki, Pliska, Nagai and others, is
risk-sensitive optimization (equivalent to maximizing the expected growth rate
subject to a constraint on variance.) By using a change of measure technique
introduced by Kuroda and Nagai we show that the problem reduces to solving a
certain stochastic control problem in the factor process, which has no jumps.
The main result of the paper is that the Hamilton-Jacobi-Bellman equation for
this problem has a classical solution. The proof uses Bellman's ""policy
improvement"" method together with results on linear parabolic PDEs due to
Ladyzhenskaya et al.
"
0906.0678,2022-01-07,Continuous-Time Markowitz's Model with Transaction Costs,"  A continuous-time Markowitz's mean-variance portfolio selection problem is
studied in a market with one stock, one bond, and proportional transaction
costs. This is a singular stochastic control problem,inherently in a finite
time horizon. With a series of transformations, the problem is turned into a
so-called double obstacle problem, a well studied problem in physics and
partial differential equation literature, featuring two time-varying free
boundaries. The two boundaries, which define the buy, sell, and no-trade
regions, are proved to be smooth in time. This in turn characterizes the
optimal strategy, via a Skorokhod problem, as one that tries to keep a certain
adjusted bond-stock position within the no-trade region. Several features of
the optimal strategy are revealed that are remarkably different from its
no-transaction-cost counterpart. It is shown that there exists a critical
length in time, which is dependent on the stock excess return as well as the
transaction fees but independent of the investment target and the stock
volatility, so that an expected terminal return may not be achievable if the
planning horizon is shorter than that critical length (while in the absence of
transaction costs any expected return can be reached in an arbitrary period of
time). It is further demonstrated that anyone following the optimal strategy
should not buy the stock beyond the point when the time to maturity is shorter
than the aforementioned critical length. Moreover, the investor would be less
likely to buy the stock and more likely to sell the stock when the maturity
date is getting closer. These features, while consistent with the widely
accepted investment wisdom, suggest that the planning horizon is an integral
part of the investment opportunities.
"
0906.0999,2009-06-08,The premium of dynamic trading,"  It is well established that in a market with inclusion of a risk-free asset
the single-period mean-variance efficient frontier is a straight line tangent
to the risky region, a fact that is the very foundation of the classical CAPM.
In this paper, it is shown that in a continuous-time market where the risky
prices are described by Ito's processes and the investment opportunity set is
deterministic (albeit time-varying), any efficient portfolio must involve
allocation to the risk-free asset at any time. As a result, the dynamic
mean-variance efficient frontier, though still a straight line, is strictly
above the entire risky region. This in turn suggests a positive premium, in
terms of the Sharpe ratio of the efficient frontier, arising from the dynamic
trading. Another implication is that the inclusion of a risk-free asset boosts
the Sharpe ratio of the efficient frontier, which again contrasts sharply with
the single-period case.
"
0906.2271,2009-06-15,"Portfolio optimization when expected stock returns are determined by
  exposure to risk","  It is widely recognized that when classical optimal strategies are applied
with parameters estimated from data, the resulting portfolio weights are
remarkably volatile and unstable over time. The predominant explanation for
this is the difficulty of estimating expected returns accurately. In this
paper, we modify the $n$ stock Black--Scholes model by introducing a new
parametrization of the drift rates. We solve Markowitz' continuous time
portfolio problem in this framework. The optimal portfolio weights correspond
to keeping $1/n$ of the wealth invested in stocks in each of the $n$ Brownian
motions. The strategy is applied out-of-sample to a large data set. The
portfolio weights are stable over time and obtain a significantly higher Sharpe
ratio than the classical $1/n$ strategy.
"
0906.4838,2009-06-29,"Forecasting Model for Crude Oil Price Using Artificial Neural Networks
  and Commodity Futures Prices","  This paper presents a model based on multilayer feedforward neural network to
forecast crude oil spot price direction in the short-term, up to three days
ahead. A great deal of attention was paid on finding the optimal ANN model
structure. In addition, several methods of data pre-processing were tested. Our
approach is to create a benchmark based on lagged value of pre-processed spot
price, then add pre-processed futures prices for 1, 2, 3,and four months to
maturity, one by one and also altogether. The results on the benchmark suggest
that a dynamic model of 13 lags is the optimal to forecast spot price direction
for the short-term. Further, the forecast accuracy of the direction of the
market was 78%, 66%, and 53% for one, two, and three days in future
conclusively. For all the experiments, that include futures data as an input,
the results show that on the short-term, futures prices do hold new information
on the spot price direction. The results obtained will generate comprehensive
understanding of the crude oil dynamic which help investors and individuals for
risk managements.
"
0907.0941,2012-03-08,Differentiability of quadratic BSDEs generated by continuous martingales,"  In this paper we consider a class of BSDEs with drivers of quadratic growth,
on a stochastic basis generated by continuous local martingales. We first
derive the Markov property of a forward--backward system (FBSDE) if the
generating martingale is a strong Markov process. Then we establish the
differentiability of a FBSDE with respect to the initial value of its forward
component. This enables us to obtain the main result of this article, namely a
representation formula for the control component of its solution. The latter is
relevant in the context of securitization of random liabilities arising from
exogenous risk, which are optimally hedged by investment in a given financial
market with respect to exponential preferences. In a purely stochastic
formulation, the control process of the backward component of the FBSDE steers
the system into the random liability and describes its optimal derivative hedge
by investment in the capital market, the dynamics of which is given by the
forward component.
"
0907.1827,2009-07-13,The Chinese Equity Bubble: Ready to Burst,"  Amid the current financial crisis, there has been one equity index beating
all others: the Shanghai Composite. Our analysis of this main Chinese equity
index shows clear signatures of a bubble build up and we go on to predict its
most likely crash date: July 17-27, 2009 (20%/80% quantile confidence
interval).
"
0907.2203,2009-07-14,"Optimal investment on finite horizon with random discrete order flow in
  illiquid markets","  We study the problem of optimal portfolio selection in an illiquid market
with discrete order flow. In this market, bids and offers are not available at
any time but trading occurs more frequently near a terminal horizon. The
investor can observe and trade the risky asset only at exogenous random times
corresponding to the order flow given by an inhomogenous Poisson process. By
using a direct dynamic programming approach, we first derive and solve the
fixed point dynamic programming equation satisfied by the value function, and
then perform a verification argument which provides the existence and
characterization of optimal trading strategies. We prove the convergence of the
optimal performance, when the deterministic intensity of the order flow
approaches infinity at any time, to the optimal expected utility for an
investor trading continuously in a perfectly liquid market model with no-short
sale constraints.
"
0907.3301,2009-07-21,"A stochastic reachability approach to portfolio construction in finance
  industry","  In finance industry portfolio construction deals with how to divide the
investors' wealth across an asset-classes' menu in order to maximize the
investors' gain. Main approaches in use at the present are based on variations
of the classical Markowitz model. However, recent evolutions of the world
market showed limitations of this method and motivated many researchers and
practitioners to study alternative methodologies to portfolio construction. In
this paper we propose one approach to optimal portfolio construction based on
recent results on stochastic reachability, which overcome some of the limits of
current approaches. Given a sequence of target sets that the investors would
like their portfolio to stay within, the optimal portfolio allocation is
synthesized in order to maximize the joint probability for the portfolio value
to fulfill the target sets requirements. A case study in the US market is given
which shows benefits from the proposed methodology in portfolio construction. A
comparison with traditional approaches is included.
"
0907.5600,2009-08-03,"Macrostate Parameter, an Econophysics Approach for the Risk Analysis of
  the Stock Exchange Market Transactions","  In this paper we attempt to introduce an econophysics approach to evaluate
some aspects of the risks in financial markets. For this purpose, the
thermodynamical methods and statistical physics results about entropy and
equilibrium states in the physical systems are used. Some considerations on
economic value and financial information are made. Finally, on this basis, a
new index for the financial risk estimation of the stock-exchange market
transactions, named macrostate parameter, was introduced and discussed.
  Keywords: econophysics, stock-exchange markets, financial risk, informational
fascicle, entropy, macrostate parameter.
"
0908.0682,2009-08-06,Global risk minimization in financial markets,"  Recurring international financial crises have adverse socioeconomic effects
and demand novel regulatory instruments or strategies for risk management and
market stabilization. However, the complex web of market interactions often
impedes rational decisions that would absolutely minimize the risk. Here we
show that, for any given expected return, investors can overcome this
complexity and globally minimize their financial risk in portfolio selection
models, which is mathematically equivalent to computing the ground state of
spin glass models in physics, provided the margin requirement remains below a
critical, empirically measurable value. For markets with centrally regulated
margin requirements, this result suggests a potentially stabilizing
intervention strategy.
"
0908.1014,2009-08-10,Selling a stock at the ultimate maximum,"  Assuming that the stock price $Z=(Z_t)_{0\leq t\leq T}$ follows a geometric
Brownian motion with drift $\mu\in\mathbb{R}$ and volatility $\sigma>0$, and
letting $M_t=\max_{0\leq s\leq t}Z_s$ for $t\in[0,T]$, we consider the optimal
prediction problems \[V_1=\inf_{0\leq\tau\leq
T}\mathsf{E}\biggl(\frac{M_T}{Z_{\tau}}\biggr)\quadand\quad
V_2=\sup_{0\leq\tau\leq T}\mathsf{E}\biggl(\frac{Z_{\tau}}{M_T}\biggr),\] where
the infimum and supremum are taken over all stopping times $\tau$ of $Z$. We
show that the following strategy is optimal in the first problem: if $\mu\leq0$
stop immediately; if $\mu\in (0,\sigma^2)$ stop as soon as $M_t/Z_t$ hits a
specified function of time; and if $\mu\geq\sigma^2$ wait until the final time
$T$. By contrast we show that the following strategy is optimal in the second
problem: if $\mu\leq\sigma^2/2$ stop immediately, and if $\mu>\sigma^2/2$ wait
until the final time $T$. Both solutions support and reinforce the widely held
financial view that ``one should sell bad stocks and keep good ones.'' The
method of proof makes use of parabolic free-boundary problems and local
time--space calculus techniques. The resulting inequalities are unusual and
interesting in their own right as they involve the future and as such have a
predictive element.
"
0908.1211,2009-11-25,Optimal execution of Portfolio transactions with geometric price process,"  In this paper we derive the optimal execution trajectory for a trader who
wishes to buy or sell a large position of shares which evolve as a geometric
Brownian process in contrast to the arithmetic model which prevails in the
existing literature, and with a general temporary impact $h$. We provide a
couple of examples which illustrate the results. We would like to stress the
fact that in this paper we use understandable user-friendly techniques.
"
0908.1444,2009-09-21,Portfolio Optimization Under Uncertainty,"  Classical mean-variance portfolio theory tells us how to construct a
portfolio of assets which has the greatest expected return for a given level of
return volatility. Utility theory then allows an investor to choose the point
along this efficient frontier which optimally balances her desire for excess
expected return against her reluctance to bear risk. The means and covariances
of the distributions of future asset returns are assumed to be known, so the
only source of uncertainty is the stochastic piece of the price evolution.
  In the real world, we have another source of uncertainty - we estimate but
don't know with certainty the means and covariances of future asset returns.
This note explains how to construct mean-variance optimal portfolios of assets
whose future returns have uncertain means and covariances. The result is simple
in form, intuitive, and can easily be incorporated in an optimizer.
"
0908.2455,2009-08-19,Second Order Risk,"  Managing a portfolio to a risk model can tilt the portfolio toward weaknesses
of the model. As a result, the optimized portfolio acquires downside exposure
to uncertainty in the model itself, what we call ""second order risk."" We
propose a risk measure that accounts for this bias. Studies of real portfolios,
in asset-by-asset and factor model contexts, demonstrate that second order risk
contributes significantly to realized volatility, and that the proposed measure
accurately forecasts the out-of-sample behavior of optimized portfolios.
"
0908.3196,2009-08-25,"A policyholder's utility indifference valuation model for the guaranteed
  annuity option","  Insurance companies often include very long-term guarantees in participating
life insurance products, which can turn out to be very valuable. Under a
guaranteed annuity options (G.A.O), the insurer guarantees to convert a
policyholder's accumulated funds to a life annuity at a fixed rated when the
policy matures. Both financial and actuarial approaches have been used to
valuate of such options. In the present work, we present an indifference
valuation model for the guaranteed annuity option. We are interested in the
additional lump sum that the policyholder is willing to pay in order to have
the option to convert the accumulated funds into a lifelong annuity at a
guaranteed rate.
"
0908.4538,2009-09-01,Optimal reinsurance/investment problems for general insurance models,"  In this paper the utility optimization problem for a general insurance model
is studied. The reserve process of the insurance company is described by a
stochastic differential equation driven by a Brownian motion and a Poisson
random measure, representing the randomness from the financial market and the
insurance claims, respectively. The random safety loading and stochastic
interest rates are allowed in the model so that the reserve process is
non-Markovian in general. The insurance company can manage the reserves through
both portfolios of the investment and a reinsurance policy to optimize a
certain utility function, defined in a generic way. The main feature of the
problem lies in the intrinsic constraint on the part of reinsurance policy,
which is only proportional to the claim-size instead of the current level of
reserve, and hence it is quite different from the optimal
investment/consumption problem with constraints in finance. Necessary and
sufficient conditions for both well posedness and solvability will be given by
modifying the ``duality method'' in finance and with the help of the
solvability of a special type of backward stochastic differential equations.
"
0909.0065,2011-04-07,Hybrid Atlas models,"  We study Atlas-type models of equity markets with local characteristics that
depend on both name and rank, and in ways that induce a stable capital
distribution. Ergodic properties and rankings of processes are examined with
reference to the theory of reflected Brownian motions in polyhedral domains. In
the context of such models we discuss properties of various investment
strategies, including the so-called growth-optimal and universal portfolios.
"
0909.3891,2009-09-23,Stock Market Trading Via Stochastic Network Optimization,"  We consider the problem of dynamic buying and selling of shares from a
collection of $N$ stocks with random price fluctuations. To limit investment
risk, we place an upper bound on the total number of shares kept at any time.
Assuming that prices evolve according to an ergodic process with a mild
decaying memory property, and assuming constraints on the total number of
shares that can be bought and sold at any time, we develop a trading policy
that comes arbitrarily close to achieving the profit of an ideal policy that
has perfect knowledge of future events. Proximity to the optimal profit comes
with a corresponding tradeoff in the maximum required stock level and in the
timescales associated with convergence. We then consider arbitrary (possibly
non-ergodic) price processes, and show that the same algorithm comes close to
the profit of a frame based policy that can look a fixed number of slots into
the future. Our analysis uses techniques of Lyapunov Optimization that we
originally developed for stochastic network optimization problems.
"
0909.4730,2009-09-28,"Growth-optimal investments and numeraire portfolios under transaction
  costs: An analysis based on the von Neumann-Gale model","  The aim of this work is to extend the capital growth theory developed by
Kelly, Breiman, Cover and others to asset market models with transaction costs.
We define a natural generalization of the notion of a numeraire portfolio
proposed by Long and show how such portfolios can be used for constructing
growth-optimal investment strategies. The analysis is based on the classical
von Neumann-Gale model of economic dynamics, a stochastic version of which we
use as a framework for the modelling of financial markets with frictions.
"
0910.0545,2011-02-09,"A general ""bang-bang"" principle for predicting the maximum of a random
  walk","  Let $(B_t)_{0\leq t\leq T}$ be either a Bernoulli random walk or a Brownian
motion with drift, and let $M_t:=\max\{B_s: 0\leq s\leq t\}$, $0\leq t\leq T$.
This paper solves the general optimal prediction problem \sup_{0\leq\tau\leq
T}\sE[f(M_T-B_\tau)], where the supremum is over all stopping times $\tau$
adapted to the natural filtration of $(B_t)$, and $f$ is a nonincreasing convex
function. The optimal stopping time $\tau^*$ is shown to be of ""bang-bang""
type: $\tau^*\equiv 0$ if the drift of the underlying process $(B_t)$ is
negative, and $\tau^*\equiv T$ is the drift is positive. This result
generalizes recent findings by S. Yam, S. Yung and W. Zhou [{\em J. Appl.
Probab.} {\bf 46} (2009), 651--668] and J. Du Toit and G. Peskir [{\em Ann.
Appl. Probab.} {\bf 19} (2009), 983--1014], and provides additional
mathematical justification for the dictum in finance that one should sell bad
stocks immediately, but keep good ones as long as possible.
"
0910.2696,2009-10-15,"Implied Multi-Factor Model for Bespoke CDO Tranches and other Portfolio
  Credit Derivatives","  This paper introduces a new semi-parametric approach to the pricing and risk
management of bespoke CDO tranches, with a particular attention to bespokes
that need to be mapped onto more than one reference portfolio. The only user
input in our framework is a multi-factor model (a ""prior"" model hereafter) for
index portfolios, such as CDX.NA.IG or iTraxx Europe, that are chosen as
benchmark securities for the pricing of a given bespoke CDO. Parameters of the
prior model are fixed, and not tuned to match prices of benchmark index
tranches. Instead, our calibration procedure amounts to a proper reweightening
of the prior measure using the Minimum Cross Entropy method. As the latter
problem reduces to convex optimization in a low dimensional space, our model is
computationally efficient. Both the static (one-period) and dynamic versions of
the model are presented. The latter can be used for pricing and risk management
of more exotic instruments referencing bespoke portfolios, such as
forward-starting tranches or tranche options, and for calculation of credit
valuation adjustment (CVA) for bespoke tranches.
"
0910.3936,2017-07-25,Admissible Strategies in Semimartingale Portfolio Selection,"  The choice of admissible trading strategies in mathematical modelling of
financial markets is a delicate issue, going back to Harrison and Kreps (1979).
In the context of optimal portfolio selection with expected utility preferences
this question has been a focus of considerable attention over the last twenty
years. We propose a novel notion of admissibility that has many pleasant
features - admissibility is characterized purely under the objective measure;
each admissible strategy can be approximated by simple strategies using finite
number of trading dates; the wealth of any admissible strategy is a
supermartingale under all pricing measures; local boundedness of the price
process is not required; neither strict monotonicity, strict concavity nor
differentiability of the utility function are necessary; the definition
encompasses both the classical mean-variance preferences and the monotone
expected utility. For utility functions finite on the whole real line, our
class represents a minimal set containing simple strategies which also contains
the optimizer, under conditions that are milder than the celebrated reasonable
asymptotic elasticity condition on the utility function.
"
0911.0223,2011-07-14,Analytical Framework for Credit Portfolios. Part I: Systematic Risk,"  Analytical, free of time consuming Monte Carlo simulations, framework for
credit portfolio systematic risk metrics calculations is presented. Techniques
are described that allow calculation of portfolio-level systematic risk
measures (standard deviation, VaR and Expected Shortfall) as well as allocation
of risk down to individual transactions. The underlying model is the industry
standard multi-factor Merton-type model with arbitrary valuation function at
horizon (in contrast to the simplistic default-only case). High accuracy of the
proposed analytical technique is demonstrated by benchmarking against Monte
Carlo simulations.
"
0911.1694,2015-05-14,Regularizing Portfolio Optimization,"  The optimization of large portfolios displays an inherent instability to
estimation error. This poses a fundamental problem, because solutions that are
not stable under sample fluctuations may look optimal for a given sample, but
are, in effect, very far from optimal with respect to the average risk. In this
paper, we approach the problem from the point of view of statistical learning
theory. The occurrence of the instability is intimately related to over-fitting
which can be avoided using known regularization methods. We show how
regularized portfolio optimization with the expected shortfall as a risk
measure is related to support vector regression. The budget constraint dictates
a modification. We present the resulting optimization problem and discuss the
solution. The L2 norm of the weight vector is used as a regularizer, which
corresponds to a diversification ""pressure"". This means that diversification,
besides counteracting downward fluctuations in some assets by upward
fluctuations in others, is also crucial because it improves the stability of
the solution. The approach we provide here allows for the simultaneous
treatment of optimization and diversification in one framework that enables the
investor to trade-off between the two, depending on the size of the available
data set.
"
0911.3043,2009-11-17,"Robust utility maximization for diffusion market model with misspecified
  coefficients","  The paper studies the robust maximization of utility of terminal wealth in
the diffusion financial market model. The underlying model consists with risky
tradable asset, whose price is described by diffusion process with misspecified
trend and volatility coefficients, and non-tradable asset with a known
parameter. The robust utility functional is defined in terms of a HARA utility
function. We give explicit characterization of the solution of the problem by
means of a solution of the HJBI equation.
"
0911.3117,2010-02-09,Optimal investment with inside information and parameter uncertainty,"  This paper has been withdrawn by the authors pending corrections.
"
0911.3194,2014-04-01,Mutual Fund Theorem for continuous time markets with random coefficients,"  We study the optimal investment problem for a continuous time incomplete
market model such that the risk-free rate, the appreciation rates and the
volatility of the stocks are all random; they are assumed to be independent
from the driving Brownian motion, and they are supposed to be currently
observable. It is shown that some weakened version of Mutual Fund Theorem holds
for this market for general class of utilities; more precisely, it is shown
that the supremum of expected utilities can be achieved on a sequence of
strategies with a certain distribution of risky assets that does not depend on
risk preferences described by different utilities.
"
0911.3608,2009-11-22,Utility maximization in models with conditionally independent increments,"  We consider the problem of maximizing expected utility from terminal wealth
in models with stochastic factors. Using martingale methods and a conditioning
argument, we determine the optimal strategy for power utility under the
assumption that the increments of the asset price are independent conditionally
on the factor process.
"
0911.3802,2014-01-21,A Coupled Markov Chain Approach to Credit Risk Modeling,"  We propose a Markov chain model for credit rating changes. We do not use any
distributional assumptions on the asset values of the rated companies but
directly model the rating transitions process. The parameters of the model are
estimated by a maximum likelihood approach using historical rating transitions
and heuristic global optimization techniques.
  We benchmark the model against a GLMM model in the context of bond portfolio
risk management. The proposed model yields stronger dependencies and higher
risks than the GLMM model. As a result, the risk optimal portfolios are more
conservative than the decisions resulting from the benchmark model.
"
0911.4030,2009-11-23,The StressVaR: A New Risk Concept for Superior Fund Allocation,"  In this paper we introduce a novel approach to risk estimation based on
nonlinear factor models - the ""StressVaR"" (SVaR). Developed to evaluate the
risk of hedge funds, the SVaR appears to be applicable to a wide range of
investments. Its principle is to use the fairly short and sparse history of the
hedge fund returns to identify relevant risk factors among a very broad set of
possible risk sources. This risk profile is obtained by calibrating a
collection of nonlinear single-factor models as opposed to a single
multi-factor model. We then use the risk profile and the very long and rich
history of the factors to asses the possible impact of known past crises on the
funds, unveiling their hidden risks and so called ""black swans"".
  In backtests using data of 1060 hedge funds we demonstrate that the SVaR has
better or comparable properties than several common VaR measures - shows less
VaR exceptions and, perhaps even more importantly, in case of an exception, by
smaller amounts.
  The ultimate test of the StressVaR however, is in its usage as a fund
allocating tool. By simulating a realistic investment in a portfolio of hedge
funds, we show that the portfolio constructed using the StressVaR on average
outperforms both the market and the portfolios constructed using common VaR
measures.
  For the period from Feb. 2003 to June 2009, the StressVaR constructed
portfolio outperforms the market by about 6% annually, and on average the
competing VaR measures by around 3%. The performance numbers from Aug. 2007 to
June 2009 are even more impressive. The SVaR portfolio outperforms the market
by 20%, and the best competing measure by 4%.
"
0911.4801,2010-11-16,Existence of Shadow Prices in Finite Probability Spaces,"  A shadow price is a process lying within the bid/ask prices of a market with
proportional transaction costs, such that maximizing expected utility from
consumption in the frictionless market with this price process leads to the
same maximal utility as in the original market with transaction costs. For
finite probability spaces, this note provides an elementary proof for the
existence of such a shadow price.
"
0912.1534,2010-04-27,Evolutionary multi-stage financial scenario tree generation,"  Multi-stage financial decision optimization under uncertainty depends on a
careful numerical approximation of the underlying stochastic process, which
describes the future returns of the selected assets or asset categories.
Various approaches towards an optimal generation of discrete-time,
discrete-state approximations (represented as scenario trees) have been
suggested in the literature. In this paper, a new evolutionary algorithm to
create scenario trees for multi-stage financial optimization models will be
presented. Numerical results and implementation details conclude the paper.
"
0912.1879,2010-11-03,"The Opportunity Process for Optimal Consumption and Investment with
  Power Utility","  We study the utility maximization problem for power utility random fields in
a semimartingale financial market, with and without intermediate consumption.
The notion of an opportunity process is introduced as a reduced form of the
value process of the resulting stochastic control problem. We show how the
opportunity process describes the key objects: optimal strategy, value
function, and dual problem. The results are applied to obtain monotonicity
properties of the optimal consumption.
"
0912.1883,2012-03-09,The Bellman equation for power utility maximization with semimartingales,"  We study utility maximization for power utility random fields with and
without intermediate consumption in a general semimartingale model with closed
portfolio constraints. We show that any optimal strategy leads to a solution of
the corresponding Bellman equation. The optimal strategies are described
pointwise in terms of the opportunity process, which is characterized as the
minimal solution of the Bellman equation. We also give verification theorems
for this equation.
"
0912.1885,2012-12-21,Power Utility Maximization in Constrained Exponential L\'evy Models,"  We study power utility maximization for exponential L\'evy models with
portfolio constraints, where utility is obtained from consumption and/or
terminal wealth. For convex constraints, an explicit solution in terms of the
L\'evy triplet is constructed under minimal assumptions by solving the Bellman
equation. We use a novel transformation of the model to avoid technical
conditions. The consequences for q-optimal martingale measures are discussed as
well as extensions to non-convex constraints.
"
0912.3132,2009-12-17,Multiple defaults and contagion risks,"  We study multiple defaults where the global market information is modelled as
progressive enlargement of filtrations. We shall provide a general pricing
formula by establishing a relationship between the enlarged filtration and the
reference default-free filtration in the random measure framework. On each
default scenario, the formula can be interpreted as a Radon-Nikodym derivative
of random measures. The contagion risks are studied in the multi-defaults
setting where we consider the optimal investment problem in a contagion risk
model and show that the optimization can be effectuated in a recursive manner
with respect to the default-free filtration.
"
0912.3362,2013-01-09,Asymptotic Power Utility-Based Pricing and Hedging,"  Kramkov and Sirbu (2006, 2007) have shown that first-order approximations of
power utility-based prices and hedging strategies can be computed by solving a
mean-variance hedging problem under a specific equivalent martingale measure
and relative to a suitable numeraire. In order to avoid the introduction of an
additional state variable necessitated by the change of numeraire, we propose
an alternative representation in terms of the original numeraire. More
specifically, we characterize the relevant quantities using semimartingale
characteristics similarly as in Cerny and Kallsen (2007) for mean-variance
hedging. These results are illustrated by applying them to exponential L\'evy
processes and stochastic volatility models of Barndorff-Nielsen and Shephard
type.
"
0912.4723,2015-05-14,"Turnover, account value and diversification of real traders: evidence of
  collective portfolio optimizing behavior","  Despite the availability of very detailed data on financial market,
agent-based modeling is hindered by the lack of information about real trader
behavior. This makes it impossible to validate agent-based models, which are
thus reverse-engineering attempts. This work is a contribution to the building
of a set of stylized facts about the traders themselves. Using the client
database of Swissquote Bank SA, the largest on-line Swiss broker, we find
empirical relationships between turnover, account values and the number of
assets in which a trader is invested. A theory based on simple mean-variance
portfolio optimization that crucially includes variable transaction costs is
able to reproduce faithfully the observed behaviors. We finally argue that our
results bring into light the collective ability of a population to construct a
mean-variance portfolio that takes into account the structure of transaction
costs
"
1001.0497,2010-01-05,Multiscaled Cross-Correlation Dynamics in Financial Time-Series,"  The cross correlation matrix between equities comprises multiple interactions
between traders with varying strategies and time horizons. In this paper, we
use the Maximum Overlap Discrete Wavelet Transform to calculate correlation
matrices over different timescales and then explore the eigenvalue spectrum
over sliding time windows. The dynamics of the eigenvalue spectrum at different
times and scales provides insight into the interactions between the numerous
constituents involved.
  Eigenvalue dynamics are examined for both medium and high-frequency equity
returns, with the associated correlation structure shown to be dependent on
both time and scale. Additionally, the Epps effect is established using this
multivariate method and analyzed at longer scales than previously studied. A
partition of the eigenvalue time-series demonstrates, at very short scales, the
emergence of negative returns when the largest eigenvalue is greatest. Finally,
a portfolio optimization shows the importance of timescale information in the
context of risk management.
"
1001.1379,2010-11-16,Jump-Diffusion Risk-Sensitive Asset Management I: Diffusion Factor Model,"  This paper considers a portfolio optimization problem in which asset prices
are represented by SDEs driven by Brownian motion and a Poisson random measure,
with drifts that are functions of an auxiliary diffusion factor process. The
criterion, following earlier work by Bielecki, Pliska, Nagai and others, is
risk-sensitive optimization (equivalent to maximizing the expected growth rate
subject to a constraint on variance.) By using a change of measure technique
introduced by Kuroda and Nagai we show that the problem reduces to solving a
certain stochastic control problem in the factor process, which has no jumps.
The main result of the paper is to show that the risk-sensitive jump diffusion
problem can be fully characterized in terms of a parabolic
Hamilton-Jacobi-Bellman PDE rather than a PIDE, and that this PDE admits a
classical C^{1,2} solution.
"
1001.1446,2010-01-12,Using Financial Ratios to Identify Romanian Distressed Companies,"  In the context of the current financial crisis, when more companies are
facing bankruptcy or insolvency, the paper aims to find methods to identify
distressed firms by using financial ratios. The study will focus on identifying
a group of Romanian listed companies, for which financial data for the year
2008 were available. For each company a set of 14 financial indicators was
calculated and then used in a principal component analysis, followed by a
cluster analysis, a logit model, and a CHAID classification tree.
"
1001.1914,2010-01-13,Rentes en cours de service : un nouveau crit\`ere d'allocation d'actif,"  The aim of this paper is to compare two asset allocation methods for a
pension scheme during the decumulation phase in the simplified portfolio
selection between a risky asset following a geometric Brownian motion and a
riskless asset. The two asset allocation criteria are the ruin probability of
the insurance company and the optimization of the economic capital. We first
solve the asset allocation problem with deterministic pension payments then
with stochastic mortality risk. We analyze the part of mortality risk in the
global risk of the company. Then we show the impact of the indexation of the
pensions to the inflation on the asset allocation.
"
1001.2131,2010-01-14,"Asymptotics of the probability minimizing a ""down-side"" risk","  We consider a long-term optimal investment problem where an investor tries to
minimize the probability of falling below a target growth rate. From a
mathematical viewpoint, this is a large deviation control problem. This problem
will be shown to relate to a risk-sensitive stochastic control problem for a
sufficiently large time horizon. Indeed, in our theorem we state a duality in
the relation between the above two problems. Furthermore, under a
multidimensional linear Gaussian model we obtain explicit solutions for the
primal problem.
"
1001.3289,2010-01-25,"Optimal stopping of expected profit and cost yields in an investment
  under uncertainty","  We consider a finite horizon optimal stopping problem related to trade-off
strategies between expected profit and cost cash-flows of an investment under
uncertainty. The optimal problem is first formulated in terms of a system of
Snell envelopes for the profit and cost yields which act as obstacles to each
other. We then construct both a minimal and a maximal solutions using an
approximation scheme of the associated system of reflected backward SDEs. When
the dependence of the cash-flows on the sources of uncertainty, such as
fluctuation market prices, assumed to evolve according to a diffusion process,
is made explicit, we also obtain a connection between these solutions and
viscosity solutions of a system of variational inequalities (VI) with
interconnected obstacles. We also provide two counter-examples showing that
uniqueness of solutions of (VI) does not hold in general.
"
1001.5421,2014-01-21,"A note on evolutionary stochastic portfolio optimization and
  probabilistic constraints","  In this note, we extend an evolutionary stochastic portfolio optimization
framework to include probabilistic constraints. Both the stochastic
programming-based modeling environment as well as the evolutionary optimization
environment are ideally suited for an integration of various types of
probabilistic constraints. We show an approach on how to integrate these
constraints. Numerical results using recent financial data substantiate the
applicability of the presented approach.
"
1002.2282,2016-09-08,The Hazards of Propping Up: Bubbles and Chaos,"  In the current environment of financial distress, many governments are likely
to soon become major holders of financial assets, but the policy debate focuses
only on the likelihood and extent of short-term market stabilization. This
paper shows that government intervention and propping up are likely to lead to
long-term bubbles and even wildly chaotic behavior. The discontinuities occur
when the committed capital reaches a critical amount that depends on just two
parameters: the market impact of trading and the target exposure percentage.
"
1002.2486,2010-02-15,"Optimal consumption and investment with bounded downside risk measures
  for logarithmic utility functions","  We investigate optimal consumption problems for a Black-Scholes market under
uniform restrictions on Value-at-Risk and Expected Shortfall for logarithmic
utility functions. We find the solutions in terms of a dynamic strategy in
explicit form, which can be compared and interpreted. This paper continues our
previous work, where we solved similar problems for power utility functions.
"
1002.2487,2010-02-15,"Optimal consumption and investment with bounded downside risk for power
  utility functions","  We investigate optimal consumption and investment problems for a
Black-Scholes market under uniform restrictions on Value-at-Risk and Expected
Shortfall. We formulate various utility maximization problems, which can be
solved explicitly. We compare the optimal solutions in form of optimal value,
optimal control and optimal wealth to analogous problems under additional
uniform risk bounds. Our proofs are partly based on solutions to
Hamilton-Jacobi-Bellman equations, and we prove a corresponding verification
theorem. This work was supported by the European Science Foundation through the
AMaMeF programme.
"
1002.3681,2010-02-22,Optimal investment with bounded VaR for power utility functions,"  We consider the optimal investment problem for Black-Scholes type financial
market with bounded VaR measure on the whole investment interval $[0,T]$. The
explicit form for the optimal strategies is found.
"
1002.4744,2010-08-24,Market behavior and performance of different strategy evaluation schemes,"  Strategy evaluation schemes are a crucial factor in any agent-based market
model, as they determine the agents' strategy preferences and consequently
their behavioral pattern. This study investigates how the strategy evaluation
schemes adopted by agents affect their performance in conjunction with the
market circumstances. We observe the performance of three strategy evaluation
schemes, the history-dependent wealth game, the trend-opposing minority game,
and the trend-following majority game, in a stock market where the price is
exogenously determined. The price is either directly adopted from the real
stock market indices or generated with a Markov chain of order $\le 2$. Each
scheme's success is quantified by average wealth accumulated by the traders
equipped with the scheme. The wealth game, as it learns from the history, shows
relatively good performance unless the market is highly unpredictable. The
majority game is successful in a trendy market dominated by long periods of
sustained price increase or decrease. On the other hand, the minority game is
suitable for a market with persistent zig-zag price patterns. We also discuss
the consequence of implementing finite memory in the scoring processes of
strategies. Our findings suggest under which market circumstances each
evaluation scheme is appropriate for modeling the behavior of real market
traders.
"
1002.4817,2010-11-23,Accounting for risk of non linear portfolios: a novel Fourier approach,"  The presence of non linear instruments is responsible for the emergence of
non Gaussian features in the price changes distribution of realistic
portfolios, even for Normally distributed risk factors. This is especially true
for the benchmark Delta Gamma Normal model, which in general exhibits
exponentially damped power law tails. We show how the knowledge of the model
characteristic function leads to Fourier representations for two standard risk
measures, the Value at Risk and the Expected Shortfall, and for their
sensitivities with respect to the model parameters. We detail the numerical
implementation of our formulae and we emphasizes the reliability and efficiency
of our results in comparison with Monte Carlo simulation.
"
1003.2521,2010-03-15,"Risk Sensitive Investment Management with Affine Processes: a Viscosity
  Approach","  In this paper, we extend the jump-diffusion model proposed by Davis and Lleo
to include jumps in asset prices as well as valuation factors. The criterion,
following earlier work by Bielecki, Pliska, Nagai and others, is risk-sensitive
optimization (equivalent to maximizing the expected growth rate subject to a
constraint on variance.) In this setting, the Hamilton- Jacobi-Bellman equation
is a partial integro-differential PDE. The main result of the paper is to show
that the value function of the control problem is the unique viscosity solution
of the Hamilton-Jacobi-Bellman equation.
"
1003.2930,2010-03-16,Utility Maximization of an Indivisible Market with Transaction Costs,"  This work takes up the challenges of utility maximization problem when the
market is indivisible and the transaction costs are included. First there is a
so-called solvency region given by the minimum margin requirement in the
problem formulation. Then the associated utility maximization is formulated as
an optimal switching problem. The diffusion turns out to be degenerate and the
boundary of domain is an unbounded set. One no longer has the continuity of the
value function without posing further conditions due to the degeneracy and the
dependence of the random terminal time on the initial data. This paper provides
sufficient conditions under which the continuity of the value function is
obtained. The essence of our approach is to find a sequence of continuous
functions locally uniformly converging to the desired value function. Thanks to
continuity, the value function can be characterized by using the notion of
viscosity solution of certain quasi-variational inequality.
"
1003.3582,2012-08-13,Risk Aversion Asymptotics for Power Utility Maximization,"  We consider the economic problem of optimal consumption and investment with
power utility. We study the optimal strategy as the relative risk aversion
tends to infinity or to one. The convergence of the optimal consumption is
obtained for general semimartingale models while the convergence of the optimal
trading strategy is obtained for continuous models. The limits are related to
exponential and logarithmic utility. To derive these results, we combine
approaches from optimal control, convex analysis and backward stochastic
differential equations (BSDEs).
"
1003.4216,2011-05-06,Minimizing the Probability of Lifetime Ruin under Stochastic Volatility,"  We assume that an individual invests in a financial market with one riskless
and one risky asset, with the latter's price following a diffusion with
stochastic volatility. In the current financial market especially, it is
important to include stochastic volatility in the risky asset's price process.
Given the rate of consumption, we find the optimal investment strategy for the
individual who wishes to minimize the probability of going bankrupt. To solve
this minimization problem, we use techniques from stochastic optimal control.
"
1003.6002,2015-10-21,Portfolio optimization in a default model under full/partial information,"  In this paper, we consider a financial market with assets exposed to some
risks inducing jumps in the asset prices, and which can still be traded after
default times. We use a default-intensity modeling approach, and address in
this incomplete market context the problem of maximization of expected utility
from terminal wealth for logarithmic, power and exponential utility functions.
We study this problem as a stochastic control problem both under full and
partial information. Our contribution consists in showing that the optimal
strategy can be obtained by a direct approach for the logarithmic utility
function, and the value function for the power utility function can be
determined as the minimal solution of a backward stochastic differential
equation. For the partial information case, we show how the problem can be
divided into two problems: a filtering problem and an optimization problem. We
also study the indifference pricing approach to evaluate the price of a
contingent claim in an incomplete market and the information price for an agent
with insider information.
"
1004.1053,2010-04-08,Managing Derivative Exposure,"  We present an approach to derivative exposure management based on subjective
and implied probabilities. We suggest to maximize the valuation difference
subject to risk constraints and propose a class of risk measures derived from
the subjective distribution. We illustrate this process with specific examples
for the two and three dimensional case. In these cases the optimization can be
performed graphically.
"
1004.1489,2010-09-30,Illiquidity Effects in Optimal Consumption-Investment Problems,"  We study the effect of liquidity freezes on an economic agent optimizing her
utility of consumption in a perturbed Black-Scholes-Merton model. The single
risky asset follows a geometric Brownian motion but is subject to liquidity
shocks, during which no trading is possible and stock dynamics are modified.
The liquidity regime is governed by a two-state Markov chain. We derive the
asymptotic effect of such freezes on optimal consumption and investment
schedules in the two cases of (i) small probability of liquidity shock; (ii)
fast-scale liquidity regime switching. Explicit formulas are obtained for
logarithmic and hyperbolic utility maximizers on infinite horizon. We also
derive the corresponding loss in utility and compare with a recent related
finite-horizon model of Diesinger, Kraft and Seifried (2009).
"
1004.1670,2012-04-23,Any Regulation of Risk Increases Risk,"  We show that any objective risk measurement algorithm mandated by central
banks for regulated financial entities will result in more risk being taken on
by those financial entities than would otherwise be the case. Furthermore, the
risks taken on by the regulated financial entities are far more systemically
concentrated than they would have been otherwise, making the entire financial
system more fragile. This result leaves three directions for the future of
financial regulation: continue regulating by enforcing risk measurement
algorithms at the cost of occasional severe crises, regulate more severely and
subjectively by fully nationalizing all financial entities, or abolish all
central banking regulations including deposit insurance to let risk be
determined by the entities themselves and, ultimately, by their depositors
through voluntary market transactions rather than by the taxpayers through
enforced government participation.
"
1004.2947,2013-07-16,Optimal closing of a pair trade with a model containing jumps,"  A pair trade is a portfolio consisting of a long position in one asset and a
short position in another, and it is a widely applied investment strategy in
the financial industry. Recently, Ekstr\""om, Lindberg and Tysk studied the
problem of optimally closing a pair trading strategy when the difference of the
two assets is modelled by an Ornstein-Uhlenbeck process. In this paper we study
the same problem, but the model is generalized to also include jumps. More
precisely we assume that the above difference is an Ornstein-Uhlenbeck type
process, driven by a L\'evy process of finite activity. We prove a verification
theorem and analyze a numerical method for the associated free boundary
problem. We prove rigorous error estimates, which are used to draw some
conclusions from numerical simulations.
"
1004.3310,2011-10-19,"Dividend problem with Parisian delay for a spectrally negative L\'evy
  risk process","  In this paper we consider dividend problem for an insurance company whose
risk evolves as a spectrally negative L\'{e}vy process (in the absence of
dividend payments) when Parisian delay is applied. The objective function is
given by the cumulative discounted dividends received until the moment of ruin
when so-called barrier strategy is applied. Additionally we will consider two
possibilities of delay. In the first scenario ruin happens when the surplus
process stays below zero longer than fixed amount of time $\zeta>0$. In the
second case there is a time lag $d$ between decision of paying dividends and
its implementation.
"
1004.3525,2018-03-14,"$F$-divergence minimal equivalent martingale measures and optimal
  portfolios for exponential Levy models with a change-point","  We study exponential Levy models with change-point which is a random
variable, independent from initial Levy processes. On canonical space with
initially enlarged filtration we describe all equivalent martingale measures
for change-point model and we give the conditions for the existence of
f-divergence minimal equivalent martingale measure. Using the connection
between utility maximisation and $f$-divergence minimisation, we obtain a
general formula for optimal strategy in change-point case for initially
enlarged filtration and also for progressively enlarged filtration in the case
of exponential utility. We illustrate our results considering the Black-Scholes
model with change-point.
"
1004.3830,2010-04-23,"Model Selection and Adaptive Markov chain Monte Carlo for Bayesian
  Cointegrated VAR model","  This paper develops a matrix-variate adaptive Markov chain Monte Carlo (MCMC)
methodology for Bayesian Cointegrated Vector Auto Regressions (CVAR). We
replace the popular approach to sampling Bayesian CVAR models, involving griddy
Gibbs, with an automated efficient alternative, based on the Adaptive
Metropolis algorithm of Roberts and Rosenthal, (2009). Developing the adaptive
MCMC framework for Bayesian CVAR models allows for efficient estimation of
posterior parameters in significantly higher dimensional CVAR series than
previously possible with existing griddy Gibbs samplers. For a n-dimensional
CVAR series, the matrix-variate posterior is in dimension $3n^2 + n$, with
significant correlation present between the blocks of matrix random variables.
We also treat the rank of the CVAR model as a random variable and perform joint
inference on the rank and model parameters. This is achieved with a Bayesian
posterior distribution defined over both the rank and the CVAR model
parameters, and inference is made via Bayes Factor analysis of rank.
Practically the adaptive sampler also aids in the development of automated
Bayesian cointegration models for algorithmic trading systems considering
instruments made up of several assets, such as currency baskets. Previously the
literature on financial applications of CVAR trading models typically only
considers pairs trading (n=2) due to the computational cost of the griddy
Gibbs. We are able to extend under our adaptive framework to $n >> 2$ and
demonstrate an example with n = 10, resulting in a posterior distribution with
parameters up to dimension 310. By also considering the rank as a random
quantity we can ensure our resulting trading models are able to adjust to
potentially time varying market conditions in a coherent statistical framework.
"
1004.3939,2010-07-05,Price Trackers Inspired by Immune Memory,"  In this paper we outline initial concepts for an immune inspired algorithm to
evaluate price time series data. The proposed solution evolves a short term
pool of trackers dynamically through a process of proliferation and mutation,
with each member attempting to map to trends in price movements. Successful
trackers feed into a long term memory pool that can generalise across repeating
trend patterns. Tests are performed to examine the algorithm's ability to
successfully identify trends in a small data set. The influence of the long
term memory pool is then examined. We find the algorithm is able to identify
price trends presented successfully and efficiently.
"
1004.4169,2011-02-22,Optimal Liquidation Strategies Regularize Portfolio Selection,"  We consider the problem of portfolio optimization in the presence of market
impact, and derive optimal liquidation strategies. We discuss in detail the
problem of finding the optimal portfolio under Expected Shortfall (ES) in the
case of linear market impact. We show that, once market impact is taken into
account, a regularized version of the usual optimization problem naturally
emerges. We characterize the typical behavior of the optimal liquidation
strategies, in the limit of large portfolio sizes, and show how the market
impact removes the instability of ES in this context.
"
1004.4272,2010-04-27,"When do improved covariance matrix estimators enhance portfolio
  optimization? An empirical comparative study of nine estimators","  The use of improved covariance matrix estimators as an alternative to the
sample estimator is considered an important approach for enhancing portfolio
optimization. Here we empirically compare the performance of 9 improved
covariance estimation procedures by using daily returns of 90 highly
capitalized US stocks for the period 1997-2007. We find that the usefulness of
covariance matrix estimators strongly depends on the ratio between estimation
period T and number of stocks N, on the presence or absence of short selling,
and on the performance metric considered. When short selling is allowed,
several estimation methods achieve a realized risk that is significantly
smaller than the one obtained with the sample covariance method. This is
particularly true when T/N is close to one. Moreover many estimators reduce the
fraction of negative portfolio weights, while little improvement is achieved in
the degree of diversification. On the contrary when short selling is not
allowed and T>N, the considered methods are unable to outperform the sample
covariance in terms of realized risk but can give much more diversified
portfolios than the one obtained with the sample covariance. When T<N the use
of the sample covariance matrix and of the pseudoinverse gives portfolios with
very poor performance.
"
1004.4956,2010-04-29,"Vast Volatility Matrix Estimation using High Frequency Data for
  Portfolio Selection","  Portfolio allocation with gross-exposure constraint is an effective method to
increase the efficiency and stability of selected portfolios among a vast pool
of assets, as demonstrated in Fan et al (2008). The required high-dimensional
volatility matrix can be estimated by using high frequency financial data. This
enables us to better adapt to the local volatilities and local correlations
among vast number of assets and to increase significantly the sample size for
estimating the volatility matrix. This paper studies the volatility matrix
estimation using high-dimensional high-frequency data from the perspective of
portfolio selection. Specifically, we propose the use of ""pairwise-refresh
time"" and ""all-refresh time"" methods proposed by Barndorff-Nielsen et al (2008)
for estimation of vast covariance matrix and compare their merits in the
portfolio selection. We also establish the concentration inequalities of the
estimates, which guarantee desirable properties of the estimated volatility
matrix in vast asset allocation with gross exposure constraints. Extensive
numerical studies are made via carefully designed simulations. Comparing with
the methods based on low frequency daily data, our methods can capture the most
recent trend of the time varying volatility and correlation, hence provide more
accurate guidance for the portfolio allocation in the next time period. The
advantage of using high-frequency data is significant in our simulation and
empirical studies, which consist of 50 simulated assets and 30 constituent
stocks of Dow Jones Industrial Average index.
"
1005.0194,2010-05-31,Delta Hedging in Financial Engineering: Towards a Model-Free Approach,"  Delta hedging, which plays a crucial r\^ole in modern financial engineering,
is a tracking control design for a ""risk-free"" management. We utilize the
existence of trends in financial time series (Fliess M., Join C.: A
mathematical proof of the existence of trends in financial time series, Proc.
Int. Conf. Systems Theory: Modelling, Analysis and Control, Fes, 2009. Online:
http://hal.inria.fr/inria-00352834/en/) in order to propose a model-free
setting for delta hedging. It avoids most of the shortcomings encountered with
the now classic Black-Scholes-Merton framework. Several convincing computer
simulations are presented. Some of them are dealing with abrupt changes, i.e.,
jumps.
"
1005.0313,2010-05-04,An Econophysics Model for the Currency Exchange with Commission,"  In this paper an econophysics model for the currency exchange operations with
commission is proposed. With this purpose some analogies and similarities of
the processes that take place in the frame of the electrochemical system made
from electrodes sunk into a solution of electrolytes and the process of the
currency exchange and determination of the international currency purchasing
power have been used. Some contact phenomena at the electrode/electrolyte
separation surface, the physical principles of an electrochemical source
operation and the determination of the sale attractiveness or the ""potential""
of the currency that is to be exchanged are also introduced and analyzed.
"
1005.0877,2010-08-03,Detrending moving average algorithm for multifractals,"  The detrending moving average (DMA) algorithm is a widely used technique to
quantify the long-term correlations of non-stationary time series and the
long-range correlations of fractal surfaces, which contains a parameter
$\theta$ determining the position of the detrending window. We develop
multifractal detrending moving average (MFDMA) algorithms for the analysis of
one-dimensional multifractal measures and higher-dimensional multifractals,
which is a generalization of the DMA method. The performance of the
one-dimensional and two-dimensional MFDMA methods is investigated using
synthetic multifractal measures with analytical solutions for backward
($\theta=0$), centered ($\theta=0.5$), and forward ($\theta=1$) detrending
windows. We find that the estimated multifractal scaling exponent $\tau(q)$ and
the singularity spectrum $f(\alpha)$ are in good agreement with the theoretical
values. In addition, the backward MFDMA method has the best performance, which
provides the most accurate estimates of the scaling exponents with lowest error
bars, while the centered MFDMA method has the worse performance. It is found
that the backward MFDMA algorithm also outperforms the multifractal detrended
fluctuation analysis (MFDFA). The one-dimensional backward MFDMA method is
applied to analyzing the time series of Shanghai Stock Exchange Composite Index
and its multifractal nature is confirmed.
"
1005.2661,2010-05-18,"Statistically Optimal Strategy Analysis of a Competing Portfolio Market
  with a Polyvariant Profit Function","  A competing market model with a polyvariant profit function that assumes
""zeitnot"" stock behavior of clients is formulated within the banking portfolio
medium and then analyzed from the perspective of devising optimal strategies.
An associated Markov process method for finding an optimal choice strategy for
monovariant and bivariant profit functions is developed. Under certain
conditions on the bank ""promotional"" parameter with respect to the ""fee"" for a
missed share package transaction and at an asymptotically large enough
portfolio volume, universal transcendental equations - determining the optimal
share package choice among competing strategies with monovariant and bivariant
profit functions - are obtained.
"
1005.2979,2010-05-20,Robust and Adaptive Algorithms for Online Portfolio Selection,"  We present an online approach to portfolio selection. The motivation is
within the context of algorithmic trading, which demands fast and recursive
updates of portfolio allocations, as new data arrives. In particular, we look
at two online algorithms: Robust-Exponentially Weighted Least Squares (R-EWRLS)
and a regularized Online minimum Variance algorithm (O-VAR). Our methods use
simple ideas from signal processing and statistics, which are sometimes
overlooked in the empirical financial literature. The two approaches are
evaluated against benchmark allocation techniques using 4 real datasets. Our
methods outperform the benchmark allocation techniques in these datasets, in
terms of both computational demand and financial performance.
"
1005.3454,2012-08-22,Robust maximization of asymptotic growth,"  This paper addresses the question of how to invest in a robust growth-optimal
way in a market where the instantaneous expected return of the underlying
process is unknown. The optimal investment strategy is identified using a
generalized version of the principal eigenfunction for an elliptic second-order
differential operator, which depends on the covariance structure of the
underlying process used for investing. The robust growth-optimal strategy can
also be seen as a limit, as the terminal date goes to infinity, of optimal
arbitrages in the terminology of Fernholz and Karatzas [Ann. Appl. Probab. 20
(2010) 1179-1204].
"
1005.4456,2010-05-26,Some Remarks on T-copulas,"  We examine three methods of constructing correlated Student-$t$ random
variables. Our motivation arises from simulations that utilise heavy-tailed
distributions for the purposes of stress testing and economic capital
calculations for financial institutions. We make several observations regarding
the suitability of the three methods for this purpose.
"
1005.5021,2010-05-28,Random Matrix Theory and Fund of Funds Portfolio Optimisation,"  The proprietary nature of Hedge Fund investing means that it is common
practise for managers to release minimal information about their returns. The
construction of a Fund of Hedge Funds portfolio requires a correlation matrix
which often has to be estimated using a relatively small sample of monthly
returns data which induces noise. In this paper random matrix theory (RMT) is
applied to a cross-correlation matrix C, constructed using hedge fund returns
data. The analysis reveals a number of eigenvalues that deviate from the
spectrum suggested by RMT. The components of the deviating eigenvectors are
found to correspond to distinct groups of strategies that are applied by hedge
fund managers. The Inverse Participation ratio is used to quantify the number
of components that participate in each eigenvector. Finally, the correlation
matrix is cleaned by separating the noisy part from the non-noisy part of C.
This technique is found to greatly reduce the difference between the predicted
and realised risk of a portfolio, leading to an improved risk profile for a
fund of hedge funds.
"
1005.5082,2013-09-17,"A Note on Sparse Minimum Variance Portfolios and Coordinate-Wise Descent
  Algorithms","  In this short report, we discuss how coordinate-wise descent algorithms can
be used to solve minimum variance portfolio (MVP) problems in which the
portfolio weights are constrained by $l_{q}$ norms, where $1\leq q \leq 2$. A
portfolio which weights are regularised by such norms is called a sparse
portfolio (Brodie et al.), since these constraints facilitate sparsity (zero
components) of the weight vector. We first consider a case when the portfolio
weights are regularised by a weighted $l_{1}$ and squared $l_{2}$ norm. Then
two benchmark data sets (Fama and French 48 industries and 100 size and BM
ratio portfolios) are used to examine performances of the sparse portfolios.
When the sample size is not relatively large to the number of assets, sparse
portfolios tend to have lower out-of-sample portfolio variances, turnover
rates, active assets, short-sale positions, but higher Sharpe ratios than the
unregularised MVP. We then show some possible extensions; particularly we
derive an efficient algorithm for solving an MVP problem in which assets are
allowed to be chosen grouply.
"
1005.5105,2010-10-12,"The dual optimizer for the growth-optimal portfolio under transaction
  costs","  We consider the maximization of the long-term growth rate in the
Black-Scholes model under proportional transaction costs as in Taksar, Klass
and Assaf [Math. Oper. Res. 13, 1988]. Similarly as in Kallsen and Muhle-Karbe
[Ann. Appl. Probab., 20, 2010] for optimal consumption over an infinite
horizon, we tackle this problem by determining a shadow price, which is the
solution of the dual problem. It can be calculated explicitly up to determining
the root of a deterministic function. This in turn allows to explicitly compute
fractional Taylor expansions, both for the no-trade region of the optimal
strategy and for the optimal growth rate.
"
1006.1791,2010-06-14,"Investigating Causal Relationships in Stock Returns with Temporal Logic
  Based Methods","  We describe a new framework for causal inference and its application to
return time series. In this system, causal relationships are represented as
logical formulas, allowing us to test arbitrarily complex hypotheses in a
computationally efficient way. We simulate return time series using a common
factor model, and show that on this data the method described significantly
outperforms Granger causality (a primary approach to this type of problem).
Finally we apply the method to real return data, showing that the method can
discover novel relationships between stocks. The approach described is a
general one that will allow combination of price and volume data with
qualitative information at varying time scales (from interest rate
announcements, to earnings reports to news stories) shedding light on some of
the previously invisible common causes of seemingly correlated price movements.
"
1006.2555,2011-03-22,Price as a matter of choice and nonstochastic randomness,"  A version of indifference valuation of a European call option is proposed
that includes statistical regularities of nonstochastic randomness. Classical
relations (forward contract value and Black-Scholes formula) are obtained as
particular cases. We show that in the general case of nonstochastic randomness
the minimal expected profit of uncovered European option position is always
negative. A version of delta hedge is proposed.
"
1006.3224,2012-08-22,Outperforming the market portfolio with a given probability,"  Our goal is to resolve a problem proposed by Fernholz and Karatzas [On
optimal arbitrage (2008) Columbia Univ.]: to characterize the minimum amount of
initial capital with which an investor can beat the market portfolio with a
certain probability, as a function of the market configuration and time to
maturity. We show that this value function is the smallest nonnegative
viscosity supersolution of a nonlinear PDE. As in Fernholz and Karatzas [On
optimal arbitrage (2008) Columbia Univ.], we do not assume the existence of an
equivalent local martingale measure, but merely the existence of a local
martingale deflator.
"
1006.4070,2010-06-22,"Computation of vector sublattices and minimal lattice-subspaces of R^k.
  Applications in finance","  In this article we perform a computational study of Polyrakis algorithms
presented in [12,13]. These algorithms are used for the determination of the
vector sublattice and the minimal lattice-subspace generated by a finite set of
positive vectors of R^k. The study demonstrates that our findings can be very
useful in the field of Economics, especially in completion by options of
security markets and portfolio insurance.
"
1006.5057,2010-10-04,Horizon dependence of utility optimizers in incomplete models,"  This paper studies the utility maximization problem with changing time
horizons in the incomplete Brownian setting. We first show that the primal
value function and the optimal terminal wealth are continuous with respect to
the time horizon $T$. Secondly, we exemplify that the expected utility stemming
from applying the $T$-horizon optimizer on a shorter time horizon $S$, $S < T$,
may not converge as $S\uparrow T$ to the $T$-horizon value. Finally, we provide
necessary and sufficient conditions preventing the existence of this
phenomenon.
"
1006.5847,2010-07-01,"Estimating correlation and covariance matrices by weighting of market
  similarity","  We discuss a weighted estimation of correlation and covariance matrices from
historical financial data. To this end, we introduce a weighting scheme that
accounts for similarity of previous market conditions to the present one. The
resulting estimators are less biased and show lower variance than either
unweighted or exponentially weighted estimators. The weighting scheme is based
on a similarity measure which compares the current correlation structure of the
market to the structures at past times. Similarity is then measured by the
matrix 2-norm of the difference of probe correlation matrices estimated for two
different times. The method is validated in a simulation study and tested
empirically in the context of mean-variance portfolio optimization. In the
latter case we find an enhanced realized portfolio return as well as a reduced
portfolio volatility compared to alternative approaches based on different
strategies and estimators.
"
1007.3601,2015-05-19,Strategic Insights From Playing the Quantum Tic-Tac-Toe,"  In this paper, we perform a minimalistic quantization of the classical game
of tic-tac-toe, by allowing superpositions of classical moves. In order for the
quantum game to reduce properly to the classical game, we require legal quantum
moves to be orthogonal to all previous moves. We also admit interference
effects, by squaring the sum of amplitudes over all moves by a player to
compute his or her occupation level of a given site. A player wins when the
sums of occupations along any of the eight straight lines we can draw in the $3
\times 3$ grid is greater than three. We play the quantum tic-tac-toe first
randomly, and then deterministically, to explore the impact different opening
moves, end games, and different combinations of offensive and defensive
strategies have on the outcome of the game. In contrast to the classical
tic-tac-toe, the deterministic quantum game does not always end in a draw. In
contrast also to most classical two-player games of no chance, it is possible
for Player 2 to win. More interestingly, we find that Player 1 enjoys an
overwhelming quantum advantage when he opens with a quantum move, but loses
this advantage when he opens with a classical move. We also find the quantum
blocking move, which consists of a weighted superposition of moves that the
opponent could use to win the game, to be very effective in denying the
opponent his or her victory. We then speculate what implications these results
might have on quantum information transfer and portfolio optimization.
"
1007.5433,2010-08-02,Analytical Framework for Credit Portfolios,"  Analytical, free of time consuming Monte Carlo simulations, framework for
credit portfolio systematic risk metrics calculations is presented. Techniques
are described that allow calculation of portfolio-level systematic risk
measures (standard deviation, VaR and Expected Shortfall) as well as allocation
of risk down to individual transactions. The underlying model is the industry
standard multi-factor Merton-type model with arbitrary valuation function at
horizon (in contrast to the simplistic default-only case). High accuracy of the
proposed analytical technique is demonstrated by benchmarking against Monte
Carlo simulations.
"
1008.3718,2010-08-24,"Monte Carlo Portfolio Optimization for General Investor Risk-Return
  Objectives and Arbitrary Return Distributions: a Solution for Long-only
  Portfolios","  We develop the idea of using Monte Carlo sampling of random portfolios to
solve portfolio investment problems. In this first paper we explore the need
for more general optimization tools, and consider the means by which
constrained random portfolios may be generated. A practical scheme for the
long-only fully-invested problem is developed and tested for the classic QP
application. The advantage of Monte Carlo methods is that they may be extended
to risk functions that are more complicated functions of the return
distribution, and that the underlying return distribution may be computed
without the classical Gaussian limitations. The optimization of quadratic
risk-return functions, VaR, CVaR, may be handled in a similar manner to
variability ratios such as Sortino and Omega, or mathematical constructions
such as expected utility and its behavioural finance extensions.
Robustification is also possible. Grid computing technology is an excellent
platform for the development of such computations due to the intrinsically
parallel nature of the computation, coupled to the requirement to transmit only
small packets of data over the grid. We give some examples deploying
GridMathematica, in which various investor risk preferences are optimized with
differing multivariate distributions. Good comparisons with established results
in Mean-Variance and CVaR optimization are obtained when ``edge-vertex-biased''
sampling methods are employed to create random portfolios. We also give an
application to Omega optimization.
"
1008.3746,2016-12-15,Belief Propagation Algorithm for Portfolio Optimization Problems,"  The typical behavior of optimal solutions to portfolio optimization problems
with absolute deviation and expected shortfall models using replica analysis
was pioneeringly estimated by S. Ciliberti and M. M\'ezard [Eur. Phys. B. 57,
175 (2007)]; however, they have not yet developed an approximate derivation
method for finding the optimal portfolio with respect to a given return set. In
this study, an approximation algorithm based on belief propagation for the
portfolio optimization problem is presented using the Bethe free energy
formalism, and the consistency of the numerical experimental results of the
proposed algorithm with those of replica analysis is confirmed. Furthermore,
the conjecture of H. Konno and H. Yamazaki, that the optimal solutions with the
absolute deviation model and with the mean-variance model have the same typical
behavior, is verified using replica analysis and the belief propagation
algorithm.
"
1008.5058,2010-08-31,"Optimal insurance demand under marked point processes shocks: a dynamic
  programming duality approach","  We study the stochastic control problem of maximizing expected utility from
terminal wealth under a non-bankruptcy constraint. The wealth process is
subject to shocks produced by a general marked point process. The problem of
the agent is to derive the optimal insurance strategy which allows ""lowering""
the level of the shocks. This optimization problem is related to a suitable
dual stochastic control problem in which the delicate boundary constraints
disappear. We characterize the dual value function as the unique viscosity
solution of the corresponding a Hamilton Jacobi Bellman Variational Inequality
(HJBVI in short).
"
1009.2896,2012-06-06,On the nature of financial leverage,"  The article presents a translation of some widespread financial terminology
into the language of decision theory. For instance, financial leverage can be
regarded as an object of choice or a decision. We show how the optics of
decision theory allows perceiving the recently introduced metrics of
see-through-leverage, which proved to be very useful in understanding the
phenomenology of the recent economic crisis. The importance for practical
decision making of specification of the statistical regularity of the random
phenomena at hand as well as of the rationality class of the decision maker is
discussed.
"
1009.3638,2011-11-30,"Scaling portfolio volatility and calculating risk contributions in the
  presence of serial cross-correlations","  In practice daily volatility of portfolio returns is transformed to longer
holding periods by multiplying by the square-root of time which assumes that
returns are not serially correlated. Under this assumption this procedure of
scaling can also be applied to contributions to volatility of the assets in the
portfolio. Close prices are often used to calculate the profit and loss of a
portfolio. Trading at exchanges located in distant time zones this can lead to
significant serial cross-correlations of the closing-time returns of the assets
in the portfolio. These serial correlations cause the square-root-of-time rule
to fail. Moreover volatility contributions in this setting turn out to be
misleading due to non-synchronous correlations. We address this issue and
provide alternative procedures for scaling volatility and calculating risk
contributions for arbitrary holding periods.
"
1009.3753,2011-04-08,Transaction fees and optimal rebalancing in the growth-optimal portfolio,"  The growth-optimal portfolio optimization strategy pioneered by Kelly is
based on constant portfolio rebalancing which makes it sensitive to transaction
fees. We examine the effect of fees on an example of a risky asset with a
binary return distribution and show that the fees may give rise to an optimal
period of portfolio rebalancing. The optimal period is found analytically in
the case of lognormal returns. This result is consequently generalized and
numerically verified for broad return distributions and returns generated by a
GARCH process. Finally we study the case when investment is rebalanced only
partially and show that this strategy can improve the investment long-term
growth rate more than optimization of the rebalancing period.
"
1009.5806,2010-09-30,"Density quantization method in the optimal portfolio choice with partial
  observation of stochastic volatility","  Computational aspects of the optimal consumption and investment with the
partially observed stochastic volatility of the asset prices are considered.
The new quantization approach to filtering - density quantization - is
introduced which reduces the original infinite dimensional state space of the
problem to the finite quantization set. The density quantization is embedded
into the numerical algorithm to solve the dynamic programming equation related
to the portfolio optimization.
"
1010.0080,2010-12-07,"Optimal consumption and investment in incomplete markets with general
  constraints","  We study an optimal consumption and investment problem in a possibly
incomplete market with general, not necessarily convex, stochastic constraints.
We give explicit solutions for investors with exponential, logarithmic and
power utility. Our approach is based on martingale methods which rely on recent
results on the existence and uniqueness of solutions to BSDEs with drivers of
quadratic growth.
"
1010.0627,2011-08-29,Asymptotics and Duality for the Davis and Norman Problem,"  We revisit the problem of maximizing expected logarithmic utility from
consumption over an infinite horizon in the Black-Scholes model with
proportional transaction costs, as studied in the seminal paper of Davis and
Norman [Math. Operation Research, 15, 1990]. Similarly to Kallsen and
Muhle-Karbe [Ann. Appl. Probab., 20, 2010], we tackle this problem by
determining a shadow price, that is, a frictionless price process with values
in the bid-ask spread which leads to the same optimization problem. However, we
use a different parametrization, which facilitates computation and
verification. Moreover, for small transaction costs, we determine fractional
Taylor expansions of arbitrary order for the boundaries of the no-trade region
and the value function. This extends work of Janecek and Shreve [Finance
Stoch., 8, 2004], who determined the leading terms of these power series.
"
1010.1961,2010-12-24,A time before which insiders would not undertake risk,"  A continuous-path semimartingale market model with wealth processes
discounted by a riskless asset is considered. The numeraire portfolio is the
unique strictly positive wealth process that, when used as a benchmark to
denominate all other wealth, makes all wealth processes local martingales. It
is assumed that the numeraire portfolio exists and that its wealth increases to
infinity as time goes to infinity. Under this setting, an initial enlargement
of the filtration is performed, by including the overall minimum of the
numeraire portfolio. It is established that all nonnegative wealth processes,
when stopped at the time of the overall minimum of the numeraire portfolio,
become local martingales in the enlarged filtration. This implies that
risk-averse insider traders would refrain from investing in the risky assets
before that time. A partial converse to the previous result is also established
in the case of complete markets, showing that the time of the overall minimum
of the numeraire portfolio is in a certain sense unique in rendering
undesirable the act of undertaking risky positions before it. The
aforementioned results shed light to the importance of the numeraire portfolio
as an indicator of overall market performance.
"
1010.2110,2010-10-12,Stock loans in incomplete markets,"  A stock loan is a contract whereby a stockholder uses shares as collateral to
borrow money from a bank or financial institution. In Xia and Zhou (2007), this
contract is modeled as a perpetual American option with a time varying strike
and analyzed in detail within a risk--neutral framework. In this paper, we
extend the valuation of such loans to an incomplete market setting, which takes
into account the natural trading restrictions faced by the client. When the
maturity of the loan is infinite, we use a time--homogeneous utility
maximization problem to obtain an exact formula for the value of the loan fee
to be charged by the bank. For loans of finite maturity, we characterize the
fee using variational inequality techniques. In both cases we show analytically
how the fee varies with the model parameters and illustrate the results
numerically.
"
1010.4322,2011-03-28,On the Stability of Utility Maximization Problems,"  In this paper we extend the stability results of [4]}. Our utility
maximization problem is defined as an essential supremum of conditional
expectations of the terminal values of wealth processes, conditioned on the
filtration at the stopping time $\tau$. To establish our results, we extend the
classical results of convex analysis to maps from $L^0$ to $L^0$. The notion of
convex compactness introduced in [7] plays an important role in our analysis.
"
1010.4987,2010-10-26,On optimal arbitrage,"  In a Markovian model for a financial market, we characterize the best
arbitrage with respect to the market portfolio that can be achieved using
nonanticipative investment strategies, in terms of the smallest positive
solution to a parabolic partial differential inequality; this is determined
entirely on the basis of the covariance structure of the model. The solution is
intimately related to properties of strict local martingales and is used to
generate the investment strategy which realizes the best possible arbitrage.
Some extensions to non-Markovian situations are also presented.
"
1010.4988,2010-10-26,"Optimal investment policy and dividend payment strategy in an insurance
  company","  We consider in this paper the optimal dividend problem for an insurance
company whose uncontrolled reserve process evolves as a classical
Cram\'{e}r--Lundberg process. The firm has the option of investing part of the
surplus in a Black--Scholes financial market. The objective is to find a
strategy consisting of both investment and dividend payment policies which
maximizes the cumulative expected discounted dividend pay-outs until the time
of bankruptcy. We show that the optimal value function is the smallest
viscosity solution of the associated second-order integro-differential
Hamilton--Jacobi--Bellman equation. We study the regularity of the optimal
value function. We show that the optimal dividend payment strategy has a band
structure. We find a method to construct a candidate solution and obtain a
verification result to check optimality. Finally, we give an example where the
optimal dividend strategy is not barrier and the optimal value function is not
twice continuously differentiable.
"
1010.4989,2010-10-26,On using shadow prices in portfolio optimization with transaction costs,"  In frictionless markets, utility maximization problems are typically solved
either by stochastic control or by martingale methods. Beginning with the
seminal paper of Davis and Norman [Math. Oper. Res. 15 (1990) 676--713],
stochastic control theory has also been used to solve various problems of this
type in the presence of proportional transaction costs. Martingale methods, on
the other hand, have so far only been used to derive general structural
results. These apply the duality theory for frictionless markets typically to a
fictitious shadow price process lying within the bid-ask bounds of the real
price process. In this paper, we show that this dual approach can actually be
used for both deriving a candidate solution and verification in Merton's
problem with logarithmic utility and proportional transaction costs. In
particular, we determine the shadow price process.
"
1011.3246,2010-11-16,Reduced form models of bond portfolios,"  We derive simple return models for several classes of bond portfolios. With
only one or two risk factors our models are able to explain most of the return
variations in portfolios of fixed rate government bonds, inflation linked
government bonds and investment grade corporate bonds. The underlying risk
factors have natural interpretations which make the models well suited for risk
management and portfolio design.
"
1011.4499,2010-11-22,"A Functional Approach to FBSDEs and Its Application in Optimal
  Portfolios","  In Liang et al (2009), the current authors demonstrated that BSDEs can be
reformulated as functional differential equations, and as an application, they
solved BSDEs on general filtered probability spaces. In this paper the authors
continue the study of functional differential equations and demonstrate how
such approach can be used to solve FBSDEs. By this approach the equations can
be solved in one direction altogether rather than in a forward and backward
way. The solutions of FBSDEs are then employed to construct the weak solutions
to a class of BSDE systems (not necessarily scalar) with quadratic growth, by a
nonlinear version of Girsanov's transformation. As the solving procedure is
constructive, the authors not only obtain the existence and uniqueness theorem,
but also really work out the solutions to such class of BSDE systems with
quadratic growth. Finally an optimal portfolio problem in incomplete markets is
solved based on the functional differential equation approach and the nonlinear
Girsanov's transformation.
"
1011.4991,2010-11-24,"Optimal mean-variance investment strategy under value-at-risk
  constraints","  This paper is devoted to study the effects arising from imposing a
value-at-risk (VaR) constraint in mean-variance portfolio selection problem for
an investor who receives a stochastic cash flow which he/she must then invest
in a continuous-time financial market. For simplicity, we assume that there is
only one investment opportunity available for the investor, a risky stock.
Using techniques of stochastic linear-quadratic (LQ) control, the optimal
mean-variance investment strategy with and without VaR constraint are derived
explicitly in closed forms, based on solution of corresponding
Hamilton-Jacobi-Bellman (HJB) equation. Furthermore, some numerical examples
are proposed to show how the addition of the VaR constraint affects the optimal
strategy.
"
1011.6097,2010-11-30,"Currency Forecasting using Multiple Kernel Learning with Financially
  Motivated Features","  Multiple Kernel Learning (MKL) is used to replicate the signal combination
process that trading rules embody when they aggregate multiple sources of
financial information when predicting an asset's price movements. A set of
financially motivated kernels is constructed for the EURUSD currency pair and
is used to predict the direction of price movement for the currency over
multiple time horizons. MKL is shown to outperform each of the kernels
individually in terms of predictive accuracy. Furthermore, the kernel
weightings selected by MKL highlights which of the financial features
represented by the kernels are the most informative for predictive tasks.
"
1012.2848,2011-01-03,Fully Flexible Views: Theory and Practice,"  We propose a unified methodology to input non-linear views from any number of
users in fully general non-normal markets, and perform, among others,
stress-testing, scenario analysis, and ranking allocation. We walk the reader
through the theory and we detail an extremely efficient algorithm to easily
implement this methodology under fully general assumptions. As it turns out, no
repricing is ever necessary, hence the methodology can be readily applied to
books with complex derivatives. We also present an analytical solution, useful
for benchmarking, which per se generalizes notable previous results. Code
illustrating this methodology in practice is available at
http://www.mathworks.com/matlabcentral/fileexchange/21307
"
1101.0945,2012-02-09,"Abstract, Classic, and Explicit Turnpikes","  Portfolio turnpikes state that, as the investment horizon increases, optimal
portfolios for generic utilities converge to those of isoelastic utilities.
This paper proves three kinds of turnpikes. In a general semimartingale
setting, the abstract turnpike states that optimal final payoffs and portfolios
converge under their myopic probabilities. In diffusion models with several
assets and a single state variable, the classic turnpike demonstrates that
optimal portfolios converge under the physical probability; meanwhile the
explicit turnpike identifies the limit of finite-horizon optimal portfolios as
a long-run myopic portfolio defined in terms of the solution of an ergodic HJB
equation.
"
1101.1148,2011-01-07,A Mispricing Model of Stocks Under Asymmetric Information,"  We extend the theory of asymmetric information in mispricing models for
stocks following geometric Brownian motion to constant relative risk averse
investors. Mispricing follows a continuous mean--reverting Ornstein--Uhlenbeck
process. Optimal portfolios and maximum expected log--linear utilities from
terminal wealth for informed and uninformed investors are derived. We obtain
analogous but more general results which nests those of Guasoni (2006) as a
special case of the relative risk aversion approaching one.
"
1101.2968,2015-03-17,"Duality in Robust Utility Maximization with Unbounded Claim via a Robust
  Extension of Rockafellar's Theorem","  We study the convex duality method for robust utility maximization in the
presence of a random endowment. When the underlying price process is a locally
bounded semimartingale, we show that the fundamental duality relation holds
true for a wide class of utility functions on the whole real line and unbounded
random endowment. To obtain this duality, we prove a robust version of
Rockafellar's theorem on convex integral functionals and apply Fenchel's
general duality theorem.
"
1101.3572,2015-03-17,Utility theory front to back - inferring utility from agents' choices,"  We pursue an inverse approach to utility theory and consumption & investment
problems. Instead of specifying an agent's utility function and deriving her
actions, we assume we observe her actions (i.e. her consumption and investment
strategies) and ask if it is possible to derive a utility function for which
the observed behaviour is optimal. We work in continuous time both in a
deterministic and stochastic setting. In the deterministic setup, we find that
there are infinitely many utility functions generating a given consumption
pattern. In the stochastic setting of the Black-Scholes complete market it
turns out that the consumption and investment strategies have to satisfy a
consistency condition (PDE) if they are to come from a classical utility
maximisation problem. We show further that important characteristics of the
agent such as her attitude towards risk (e.g. DARA) can be deduced directly
from her consumption/investment choices.
"
1102.0346,2013-02-25,On utility maximization under convex portfolio constraints,"  We consider a utility-maximization problem in a general semimartingale
financial model, subject to constraints on the number of shares held in each
risky asset. These constraints are modeled by predictable convex-set-valued
processes whose values do not necessarily contain the origin; that is, it may
be inadmissible for an investor to hold no risky investment at all. Such a
setup subsumes the classical constrained utility-maximization problem, as well
as the problem where illiquid assets or a random endowment are present. Our
main result establishes the existence of optimal trading strategies in such
models under no smoothness requirements on the utility function. The result
also shows that, up to attainment, the dual optimization problem can be posed
over a set of countably-additive probability measures, thus eschewing the need
for the usual finitely-additive enlargement.
"
1102.0938,2013-07-02,Minimizing Shortfall,"  This paper describes an empirical study of shortfall optimization with Barra
Extreme Risk. We compare minimum shortfall to minimum variance portfolios in
the US, UK, and Japanese equity markets using Barra Style Factors (Value,
Growth, Momentum, etc.). We show that minimizing shortfall generally improves
performance over minimizing variance, especially during down-markets, over the
period 1985-2010. The outperformance of shortfall is due to intuitive tilts
towards protective factors like Value, and away from aggressive factors like
Growth and Momentum. The outperformance is largest for the shortfall that
measures overall asymmetry rather than the extreme losses.
"
1102.1186,2011-12-12,Optimal consumption and investment for markets with random coefficients,"  We consider an optimal investment and consumption problem for a Black-Scholes
financial market with stochastic coefficients driven by a diffusion process. We
assume that an agent makes consumption and investment decisions based on CRRA
utility functions. The dynamical programming approach leads to an investigation
of the Hamilton Jacobi Bellman (HJB) equation which is a highly non linear
partial differential equation (PDE) of the second oder. By using the Feynman -
Kac representation we prove uniqueness and smoothness of the solution.
Moreover, we study the optimal convergence rate of the iterative numerical
schemes for both the value function and the optimal portfolio. We show, that in
this case, the optimal convergence rate is super geometrical, i.e. is more
rapid than any geometrical one. We apply our results to a stochastic volatility
financial market.
"
1102.2263,2011-02-14,"Optimal Life Insurance Purchase, Consumption and Investment on a
  financial market with multi-dimensional diffusive terms","  We introduce an extension to Merton's famous continuous time model of optimal
consumption and investment, in the spirit of previous works by Pliska and Ye,
to allow for a wage earner to have a random lifetime and to use a portion of
the income to purchase life insurance in order to provide for his estate, while
investing his savings in a financial market comprised of one risk-free security
and an arbitrary number of risky securities driven by multi-dimensional
Brownian motion. We then provide a detailed analysis of the optimal
consumption, investment, and insurance purchase strategies for the wage earner
whose goal is to maximize the expected utility obtained from his family
consumption, from the size of the estate in the event of premature death, and
from the size of the estate at the time of retirement. We use dynamic
programming methods to obtain explicit solutions for the case of discounted
constant relative risk aversion utility functions and describe new analytical
results which are presented together with the corresponding economic
interpretations.
"
1102.4722,2011-02-24,Measuring Portfolio Diversification,"  In the market place, diversification reduces risk and provides protection
against extreme events by ensuring that one is not overly exposed to individual
occurrences. We argue that diversification is best measured by characteristics
of the combined portfolio of assets and introduce a measure based on the
information entropy of the probability distribution for the final portfolio
asset value. For Gaussian assets the measure is a logarithmic function of the
variance and combining independent Gaussian assets of equal variance adds an
amount to the diversification. The advantages of this measure include that it
naturally extends to any type of distribution and that it takes all moments
into account. Furthermore, it can be used in cases of undefined weights
(zero-cost assets) or moments. We present examples which apply this measure to
derivative overlays.
"
1102.5078,2011-11-08,On Mean-Variance Analysis,"  This paper considers the mean variance portfolio management problem. We
examine portfolios which contain both primary and derivative securities. The
challenge in this context is due to portfolio's nonlinearities. The delta-gamma
approximation is employed to overcome it. Thus, the optimization problem is
reduced to a well posed quadratic program. The methodology developed in this
paper can be also applied to pricing and hedging in incomplete markets.
"
1102.5126,2012-09-12,"Jump-Diffusion Risk-Sensitive Asset Management II: Jump-Diffusion Factor
  Model","  In this article we extend earlier work on the jump-diffusion risk-sensitive
asset management problem [SIAM J. Fin. Math. (2011) 22-54] by allowing jumps in
both the factor process and the asset prices, as well as stochastic volatility
and investment constraints. In this case, the HJB equation is a partial
integro-differential equation (PIDE). By combining viscosity solutions with a
change of notation, a policy improvement argument and classical results on
parabolic PDEs we prove that the HJB PIDE admits a unique smooth solution. A
verification theorem concludes the resolution of this problem.
"
1102.5665,2011-03-01,"Risk, VaR, CVaR and their associated Portfolio Optimizations when Asset
  Returns have a Multivariate Student T Distribution","  We show how to reduce the problem of computing VaR and CVaR with Student T
return distributions to evaluation of analytical functions of the moments. This
allows an analysis of the risk properties of systems to be carefully attributed
between choices of risk function (e.g. VaR vs CVaR); choice of return
distribution (power law tail vs Gaussian) and choice of event frequency, for
risk assessment. We exploit this to provide a simple method for portfolio
optimization when the asset returns follow a standard multivariate T
distribution. This may be used as a semi-analytical verification tool for more
general optimizers, and for practical assessment of the impact of fat tails on
asset allocation for shorter time horizons.
"
1103.1165,2012-03-12,Hedging of Game Options With the Presence of Transaction Costs,"  We study the problem of super-replication for game options under proportional
transaction costs. We consider a multidimensional continuous time model, in
which the discounted stock price process satisfies the conditional full support
property. We show that the super-replication price is the cheapest cost of a
trivial super-replication strategy. This result is an extension of previous
papers (see [3] and [7]) which considered only European options. In these
papers the authors showed that with the presence of proportional transaction
costs the super--replication price of a European option is given in terms of
the concave envelope of the payoff function. In the present work we prove that
for game options the super-replication price is given by a game variant analog
of the standard concave envelope term. The treatment of game options is more
complicated and requires additional tools. We combine the theory of consistent
price systems together with the theory of extended weak convergence which was
developed in [1]. The second theory is essential in dealing with hedging which
involves stopping times, like in the case of game options.
"
1103.1729,2011-03-10,"Optimal Investment and Premium Policies under Risk Shifting and Solvency
  Regulation","  Limited liability creates a conflict of interests between policyholders and
shareholders of insurance companies. It provides shareholders with incentives
to increase the risk of the insurer's assets and liabilities which, in turn,
might reduce the value policyholders attach to and premiums they are willing to
pay for insurance coverage. We characterize Pareto optimal investment and
premium policies in this context and provide necessary and sufficient
conditions for their existence and uniqueness. We then identify investment and
premium policies under the risk shifting problem if shareholders cannot
credibly commit to an investment strategy before policies are sold and premiums
are paid. Last, we analyze the effect of solvency regulation, such as Solvency
II or the Swiss Solvency Test, on the agency cost of the risk shifting problem
and calibrate our model to a non-life insurer average portfolio.
"
1103.1755,2022-01-07,Optimal stopping under probability distortion,"  We formulate an optimal stopping problem for a geometric Brownian motion
where the probability scale is distorted by a general nonlinear function. The
problem is inherently time inconsistent due to the Choquet integration
involved. We develop a new approach, based on a reformulation of the problem
where one optimally chooses the probability distribution or quantile function
of the stopped state. An optimal stopping time can then be recovered from the
obtained distribution/quantile function, either in a straightforward way for
several important cases or in general via the Skorokhod embedding. This
approach enables us to solve the problem in a fairly general manner with
different shapes of the payoff and probability distortion functions. We also
discuss economical interpretations of the results. In particular, we justify
several liquidation strategies widely adopted in stock trading, including those
of ""buy and hold"", ""cut loss or take profit"", ""cut loss and let profit run"" and
""sell on a percentage of historical high"".
"
1103.4934,2011-03-28,"Mean Reversion Pays, but Costs","  A mean-reverting financial instrument is optimally traded by buying it when
it is sufficiently below the estimated `mean level' and selling it when it is
above. In the presence of linear transaction costs, a large amount of value is
paid away crossing bid-offers unless one devises a `buffer' through which the
price must move before a trade is done. In this paper, Richard Martin and
Torsten Sch\""oneborn derive the optimal strategy and conclude that for low
costs the buffer width is proportional to the cube root of the transaction
cost, determining the proportionality constant explicitly.
"
1103.4943,2011-03-28,"An Empirical Analysis of Dynamic Multiscale Hedging using Wavelet
  Decomposition","  This paper investigates the hedging effectiveness of a dynamic moving window
OLS hedging model, formed using wavelet decomposed time-series. The wavelet
transform is applied to calculate the appropriate dynamic minimum-variance
hedge ratio for various hedging horizons for a number of assets. The
effectiveness of the dynamic multiscale hedging strategy is then tested, both
in- and out-of-sample, using standard variance reduction and expanded to
include a downside risk metric, the time horizon dependent Value-at-Risk.
Measured using variance reduction, the effectiveness converges to one at longer
scales, while a measure of VaR reduction indicates a portion of residual risk
remains at all scales. Analysis of the hedge portfolio distributions indicate
that this unhedged tail risk is related to excess portfolio kurtosis found at
all scales.
"
1103.5575,2012-04-27,"Power Utility Maximization in Discrete-Time and Continuous-Time
  Exponential Levy Models","  Consider power utility maximization of terminal wealth in a 1-dimensional
continuous-time exponential Levy model with finite time horizon. We discretize
the model by restricting portfolio adjustments to an equidistant discrete time
grid. Under minimal assumptions we prove convergence of the optimal
discrete-time strategies to the continuous-time counterpart. In addition, we
provide and compare qualitative properties of the discrete-time and
continuous-time optimizers.
"
1103.5971,2011-03-31,Housing risk and return: Evidence from a housing asset-pricing model,"  This paper investigates the risk-return relationship in determination of
housing asset pricing. In so doing, the paper evaluates behavioral hypotheses
advanced by Case and Shiller (1988, 2002, 2009) in studies of boom and
post-boom housing markets. The paper specifies and tests a multi-factor housing
asset pricing model. In that model, we evaluate whether the market factor as
well as other measures of risk, including idiosyncratic risk, momentum, and MSA
size effects, have explanatory power for metropolitan-specific housing returns.
Further, we test the robustness of the asset pricing results to inclusion of
controls for socioeconomic variables commonly represented in the house price
literature, including changes in employment, affordability, and foreclosure
incidence. We find a sizable and statistically significant influence of the
market factor on MSA house price returns. Moreover we show that market betas
have varied substantially over time. Also, results are largely robust to the
inclusion of other explanatory variables, including standard measures of risk
and other housing market fundamentals. Additional tests of model validity using
the Fama-MacBeth framework offer further strong support of a positive risk and
return relationship in housing. Our findings are supportive of the application
of a housing investment risk-return framework in explanation of variation in
metro-area cross-section and time-series US house price returns. Further,
results strongly corroborate Case-Shiller survey research indicating the
importance of speculative forces in the determination of U.S. housing returns.
"
1103.5972,2011-03-31,"A Comparative Anatomy of REITs and Residential Real Estate Indexes:
  Returns, Risks and Distributional Characteristics","  Real Estate Investment Trusts (REITs) are the only truly liquid assets
related to real estate investments. We study the behavior of U.S. REITs over
the past three decades and document their return characteristics. REITs have
somewhat less market risk than equity; their betas against a broad market index
average about .65. Decomposing their covariances into principal components
reveals several strong factors. REIT characteristics differ to some extent from
those of the S&P/Case-Shiller (SCS) residential real estate indexes. This is
partly attributable to methods of index construction. Our examination of REITs
suggests that investment in real estate is far more risky than what might be
inferred from the widely-followed SCS series. REITs, unlike SCS series are
forward looking, and this helps them in the prediction of SCS returns. REIT
forecasts of SCS returns are reasonably precise over a number of periods.
"
1103.5978,2011-03-31,Financial Risks and the Pension Protection Fund: Can it Survive Them?,"  This paper discusses the financial risks faced by the UK Pension Protection
Fund (PPF) and what, if anything, it can do about them. It draws lessons from
the regulatory regimes under which other financial institutions, such as banks
and insurance companies, operate and asks why pension funds are treated
differently. It also reviews the experience with other government-sponsored
insurance schemes, such as the US Pension Benefit Guaranty Corporation, upon
which the PPF is modelled. We conclude that the PPF will live under the
permanent risk of insolvency as a consequence of the moral hazard, adverse
selection, and, especially, systemic risks that it faces.
"
1104.0761,2011-09-15,"Utility Maximization, Risk Aversion, and Stochastic Dominance","  Consider an investor trading dynamically to maximize expected utility from
terminal wealth. Our aim is to study the dependence between her risk aversion
and the distribution of the optimal terminal payoff.
  Economic intuition suggests that high risk aversion leads to a rather
concentrated distribution, whereas lower risk aversion results in a higher
average payoff at the expense of a more widespread distribution.
  Dybvig and Wang [J. Econ. Theory, 2011, to appear] find that this idea can
indeed be turned into a rigorous mathematical statement in one-period models.
More specifically, they show that lower risk aversion leads to a payoff which
is larger in terms of second order stochastic dominance.
  In the present study, we extend their results to (weakly) complete
continuous-time models. We also complement an ad-hoc counterexample of Dybvig
and Wang, by showing that these results are ""fragile"", in the sense that they
fail in essentially any model, if the latter is perturbed on a set of
arbitrarily small probability. On the other hand, we establish that they hold
for power investors in models with (conditionally) independent increments.
"
1104.2124,2011-05-11,"Is a probabilistic modeling really useful in financial engineering? -
  A-t-on vraiment besoin d'un mod\`ele probabiliste en ing\'enierie
  financi\`ere ?","  A new standpoint on financial time series, without the use of any
mathematical model and of probabilistic tools, yields not only a rigorous
approach of trends and volatility, but also efficient calculations which were
already successfully applied in automatic control and in signal processing. It
is based on a theorem due to P. Cartier and Y. Perrin, which was published in
1995. The above results are employed for sketching a dynamical portfolio and
strategy management, without any global optimization technique. Numerous
computer simulations are presented.
"
1104.5393,2011-04-29,Notional portfolios and normalized linear returns,"  The vector of periodic, compound returns of a typical investment portfolio is
almost never a convex combination of the return vectors of the securities in
the portfolio. As a result the ex post version of Harry Markowitz's ""standard
mean-variance portfolio selection model"" does not apply to compound return
data. We propose using notional portfolios and normalized linear returns to
remedy this problem.
"
1105.0042,2011-09-07,"Dynamic Portfolio Optimization with a Defaultable Security and Regime
  Switching","  We consider a portfolio optimization problem in a defaultable market with
finitely-many economical regimes, where the investor can dynamically allocate
her wealth among a defaultable bond, a stock, and a money market account. The
market coefficients are assumed to depend on the market regime in place, which
is modeled by a finite state continuous time Markov process. We rigorously
deduce the dynamics of the defaultable bond price process in terms of a Markov
modulated stochastic differential equation. Then, by separating the utility
maximization problem into the pre-default and post-default scenarios, we deduce
two coupled Hamilton-Jacobi-Bellman equations for the post and pre-default
optimal value functions and show a novel verification theorem for their
solutions. We obtain explicit optimal investment strategies and value functions
for an investor with logarithmic utility. We finish with an economic analysis
in the case of a market with two regimes and homogenous transition rates, and
show the impact of the default intensities and loss rates on the optimal
strategies and value functions.
"
1105.1488,2014-04-15,"The structure of optimal portfolio strategies for continuous time
  markets","  The paper studies problem of continuous time optimal portfolio selection for
a incom- plete market diffusion model. It is shown that, under some mild
conditions, near optimal strategies for investors with different performance
criteria can be constructed using a limited number of fixed processes (mutual
funds), for a market with a larger number of available risky stocks. In other
words, a dimension reduction is achieved via a relaxed version of the Mutual
Fund Theorem.
"
1105.2956,2011-05-17,Adjusted Closing Prices,"  Historical returns depend on historical closing prices and distributions. We
describe how to compute adjusted closing prices from closing price/distribution
data with an emphasis on spreadsheet implementation. Then the growth of a
security from one date to another (1 + total return) is just the ratio of the
corresponding adjusted closing prices.
"
1105.3594,2019-05-08,"Portfolio selection problems in practice: a comparison between linear
  and quadratic optimization models","  Several portfolio selection models take into account practical limitations on
the number of assets to include and on their weights in the portfolio. We
present here a study of the Limited Asset Markowitz (LAM), of the Limited Asset
Mean Absolute Deviation (LAMAD) and of the Limited Asset Conditional
Value-at-Risk (LACVaR) models, where the assets are limited with the
introduction of quantity and cardinality constraints. We propose a completely
new approach for solving the LAM model, based on reformulation as a Standard
Quadratic Program and on some recent theoretical results. With this approach we
obtain optimal solutions both for some well-known financial data sets used by
several other authors, and for some unsolved large size portfolio problems. We
also test our method on five new data sets involving real-world capital market
indices from major stock markets. Our computational experience shows that,
rather unexpectedly, it is easier to solve the quadratic LAM model with our
algorithm, than to solve the linear LACVaR and LAMAD models with CPLEX, one of
the best commercial codes for mixed integer linear programming (MILP) problems.
Finally, on the new data sets we have also compared, using out-of-sample
analysis, the performance of the portfolios obtained by the Limited Asset
models with the performance provided by the unconstrained models and with that
of the official capital market indices.
"
1106.1702,2012-03-19,CRRA Utility Maximization under Risk Constraints,"  This paper studies the problem of optimal investment with CRRA (constant,
relative risk aversion) preferences, subject to dynamic risk constraints on
trading strategies. The market model considered is continuous in time and
incomplete. the prices of financial assets are modeled by It\^o processes. The
dynamic risk constraints, which are time and state dependent, are generated by
risk measures. Optimal trading strategies are characterized by a quadratic
BSDE. Within the class of \textit{time consistent distortion risk measures}, a
three-fund separation result is established. Numerical results emphasize the
effects of imposing risk constraints on trading.
"
1106.2980,2012-01-11,"Additive habit formation: Consumption in incomplete markets with random
  endowments","  We provide a detailed characterization of the optimal consumption stream for
the additive habit-forming utility maximization problem, in a framework of
general discrete-time incomplete markets and random endowments. This
characterization allows us to derive the monotonicity and concavity of the
optimal consumption as a function of wealth, for several important classes of
incomplete markets and preferences. These results yield a deeper understanding
of the fine structure of the optimal consumption and provide a further
theoretical support for the classical conjectures of Keynes (1936).
"
1106.3006,2019-06-27,Exponential utility with non-negative consumption,"  We offer mathematical tractability and new insights for a framework of
exponential utility with non-negative consumption, a constraint often omitted
in the literature giving rise to economically unviable solutions. Specifically,
using the Kuhn-Tucker theorem and the notion of aggregate state price density
(Malamud and Trubowitz (2007)), we provide a solution to this problem in the
setting of both complete and incomplete markets (with random endowments). Then,
we exploit this result to provide an explicit characterization of complete
market heterogeneous equilibria. Furthermore, we construct concrete examples of
models admitting multiple (including infinitely many) equilibria. By using
Cramer's large deviation theorem, we study the asymptotics of equilibrium zero
coupon bonds. Lastly, we conduct a study of the precautionary savings motive in
incomplete markets.
"
1106.3025,2012-01-17,Market selection with learning and catching up with the Joneses,"  We study the market selection hypothesis in complete financial markets,
populated by heterogeneous agents. We allow for a rich structure of
heterogeneity: individuals may differ in their beliefs concerning the economy,
information and learning mechanism, risk aversion, impatience and 'catching up
with Joneses' preferences. We develop new techniques for studying the long-run
behavior of such economies, based on the Strassen's functional law of iterated
logarithm. In particular, we explicitly determine an agent's survival index and
show how the latter depends on the agent's characteristics. We use these
results to study the long-run behavior of the equilibrium interest rate and the
market price of risk.
"
1107.0183,2012-05-10,BSDEs in Utility Maximization with BMO Market Price of Risk,"  This article studies quadratic semimartingale BSDEs arising in power utility
maximization when the market price of risk is of BMO type. In a Brownian
setting we provide a necessary and sufficient condition for the existence of a
solution but show that uniqueness fails to hold in the sense that there exists
a continuum of distinct square-integrable solutions. This feature occurs since,
contrary to the classical Ito representation theorem, a representation of
random variables in terms of stochastic exponentials is not unique. We study in
detail when the BSDE has a bounded solution and derive a new dynamic
exponential moments condition which is shown to be the minimal sufficient
condition in a general filtration. The main results are complemented by several
interesting examples which illustrate their sharpness as well as important
properties of the utility maximization BSDE.
"
1107.0190,2011-07-04,"The Stability of the Constrained Utility Maximization Problem - A BSDE
  Approach","  This article studies the sensitivity of the power utility maximization
problem with respect to the investor's relative risk aversion, the statistical
probability measure, the investment constraints and the market price of risk.
We extend previous descriptions of the dual domain then exploit the link
between the constrained utility maximization problem and continuous
semimartingale quadratic BSDEs to reduce questions on sensitivity to results on
stability for such equations. This then allows us to prove appropriate
convergence of the primal and dual optimizers in the semimartingale topology.
"
1107.1617,2012-10-03,"On optimal investment for a behavioural investor in multiperiod
  incomplete market models","  We provide easily verifiable conditions for the well-posedness of the optimal
investment problem for a behavioral investor in an incomplete discrete-time
multiperiod financial market model, for the first time in the literature. Under
two different sets of assumptions we also establish the existence of optimal
strategies.
"
1107.1895,2011-07-12,On Investment-Consumption with Regime-Switching,"  In a continuous time stochastic economy, this paper considers the problem of
consumption and investment in a financial market in which the representative
investor exhibits a change in the discount rate. The investment opportunities
are a stock and a riskless account. The market coefficients and discount factor
switches according to a finite state Markov chain. The change in the discount
rate leads to time inconsistencies of the investor's decisions. The randomness
in our model is driven by a Brownian motion and Markov chain. Following Ekeland
etc (2008) we introduce and characterize the equilibrium policies for power
utility functions. Moreover, they are computed in closed form for logarithmic
utility function. We show that a higher discount rate leads to a higher
equilibrium consumption rate. Numerical experiments show the effect of both
time preference and risk aversion on the equilibrium policies.
"
1107.2164,2011-07-13,KISS approach to credit portfolio modeling,"  A simple, yet reasonably accurate, analytical technique is proposed for
multi-factor structural credit portfolio models. The accuracy of the technique
is demonstrated by benchmarking against Monte Carlo simulations. The approach
presented here may be of high interest to practitioners looking for
transparent, intuitive, easy to implement and high performance credit portfolio
model.
"
1107.2716,2012-12-13,"Stability of exponential utility maximization with respect to market
  perturbations","  We investigate the continuity of expected exponential utility maximization
with respect to perturbation of the Sharpe ratio of markets. By focusing only
on continuity, we impose weaker regularity conditions than those found in the
literature. Specifically, we require, in addition to the $V$-compactness
hypothesis of Larsen and \v{Z}itkovi\'c (2007) (ArXiv: 0706.0474), a local
$bmo$ hypothesis, a condition which is seen to always be trivially satisfied in
the setting of Larsen and \v{Z}itkovi\'c (2007). For markets of the form $S = M
+ \int \lambda d<M>$, these conditions are simultaneously implied by the
existence of a uniform bound on the norm of $\lambda \cdot M$ in a suitable
$bmo$ space.
"
1107.2988,2013-09-09,Robust maximization of asymptotic growth under covariance uncertainty,"  This paper resolves a question proposed in Kardaras and Robertson [Ann. Appl.
Probab. 22 (2012) 1576-1610]: how to invest in a robust growth-optimal way in a
market where precise knowledge of the covariance structure of the underlying
assets is unavailable. Among an appropriate class of admissible covariance
structures, we characterize the optimal trading strategy in terms of a
generalized version of the principal eigenvalue of a fully nonlinear elliptic
operator and its associated eigenfunction, by slightly restricting the
collection of nondominated probability measures.
"
1107.4210,2012-04-26,Investment/consumption problem in illiquid markets with regime-switching,"  We consider an illiquid financial market with different regimes modeled by a
continuous-time finite-state Markov chain. The investor can trade a stock only
at the discrete arrival times of a Cox process with intensity depending on the
market regime. Moreover, the risky asset price is subject to liquidity shocks,
which change its rate of return and volatility, and induce jumps on its
dynamics. In this setting, we study the problem of an economic agent optimizing
her expected utility from consumption under a non-bankruptcy constraint. By
using the dynamic programming method, we provide the characterization of the
value function of this stochastic control problem in terms of the unique
viscosity solution to a system of integro-partial differential equations. We
next focus on the popular case of CRRA utility functions, for which we can
prove smoothness $C^2$ results for the value function. As an important
byproduct, this allows us to get the existence of optimal
investment/consumption strategies characterized in feedback forms. We analyze a
convergent numerical scheme for the resolution to our stochastic control
problem, and we illustrate finally with some numerical experiments the effects
of liquidity regimes in the investor's optimal decision.
"
1107.5122,2012-04-20,Spontaneous symmetry breaking of arbitrage,"  We introduce the concept of spontaneous symmetry breaking to arbitrage
modeling. In the model, the arbitrage strategy is considered as being in the
symmetry breaking phase and the phase transition between arbitrage mode and
no-arbitrage mode is triggered by a control parameter. We estimate the control
parameter for momentum strategy with real historical data. The momentum
strategy aided by symmetry breaking shows stronger performance and has a better
risk measure than the naive momentum strategy in U.S. and South Korean markets.
"
1107.5852,2012-07-17,"Necessary and sufficient conditions in the problem of optimal investment
  with intermediate consumption","  We consider a problem of optimal investment with intermediate consumption in
the framework of an incomplete semimartingale model of a financial market. We
show that a necessary and sufficient condition for the validity of key
assertions of the theory is that the value functions of the primal and dual
problems are finite
"
1108.0837,2011-08-04,Constructing the Best Trading Strategy: A New General Framework,"  We introduce a new general framework for constructing the best trading
strategy for a given historical indicator. We construct the unique trading
strategy with the highest expected return. This optimal strategy may be
implemented directly, or its expected return may be used as a benchmark to
evaluate how far away from the optimal other proposed strategies for the given
indicators are. Separately, we also construct the unique trading strategy with
the highest information ratio. In the normal case, when the traded security
return is near zero, and for reasonable correlations, the performance
differences are economically insignificant. However, when the correlation
approaches one, the trading strategy with the highest expected return
approaches its maximum information ratio of 1.32 while the trading strategy
with the highest information ratio goes to infinity.
"
1108.0945,2013-07-23,"On the closure in the Emery topology of semimartingale wealth-process
  sets","  A wealth-process set is abstractly defined to consist of nonnegative
c\`{a}dl\`{a}g processes containing a strictly positive semimartingale and
satisfying an intuitive re-balancing property. Under the condition of absence
of arbitrage of the first kind, it is established that all wealth processes are
semimartingales and that the closure of the wealth-process set in the Emery
topology contains all ""optimal"" wealth processes.
"
1108.0996,2011-08-05,"Mean--variance portfolio optimization when means and covariances are
  unknown","  Markowitz's celebrated mean--variance portfolio optimization theory assumes
that the means and covariances of the underlying asset returns are known. In
practice, they are unknown and have to be estimated from historical data.
Plugging the estimates into the efficient frontier that assumes known
parameters has led to portfolios that may perform poorly and have
counter-intuitive asset allocation weights; this has been referred to as the
""Markowitz optimization enigma."" After reviewing different approaches in the
literature to address these difficulties, we explain the root cause of the
enigma and propose a new approach to resolve it. Not only is the new approach
shown to provide substantial improvements over previous methods, but it also
allows flexible modeling to incorporate dynamic features and fundamental
analysis of the training sample of historical data, as illustrated in
simulation and empirical studies.
"
1108.1035,2012-05-25,"On traveling wave solutions to Hamilton-Jacobi-Bellman equation with
  inequality constraints","  The aim of this paper is to construct and analyze solutions to a class of
Hamilton-Jacobi-Bellman equations with range bounds on the optimal response
variable. Using the Riccati transformation we derive and analyze a fully
nonlinear parabolic partial differential equation for the optimal response
function. We construct monotone traveling wave solutions and identify
parametric regions for which the traveling wave solution has a positive or
negative wave speed.
"
1108.1167,2013-01-15,"Transaction Costs, Trading Volume, and the Liquidity Premium","  In a market with one safe and one risky asset, an investor with a long
horizon, constant investment opportunities, and constant relative risk aversion
trades with small proportional transaction costs. We derive explicit formulas
for the optimal investment policy, its implied welfare, liquidity premium, and
trading volume. At the first order, the liquidity premium equals the spread,
times share turnover, times a universal constant. Results are robust to
consumption and finite horizons. We exploit the equivalence of the transaction
cost market to another frictionless market, with a shadow risky asset, in which
investment opportunities are stochastic. The shadow price is also found
explicitly.
"
1108.2889,2011-08-16,"Additive habits with power utility: Estimates, asymptotics and
  equilibrium","  We consider a power utility maximization problem with additive habits in a
framework of discrete-time markets and random endowments. For certain classes
of incomplete markets, we establish estimates for the optimal consumption
stream in terms of the aggregate state price density, investigate the
asymptotic behaviour of the propensity to consume (ratio of the consumption to
the wealth), as the initial endowment tends to infinity, and show that the
limit is the corresponding quantity in an artificial market. For complete
markets, we concentrate on proving the existence of an Arrow-Debreu equilibrium
in an economy inhabited by heterogeneous individuals who differ with respect to
their risk-aversion coefficient, impatience rate and endowments stream, but
possess the same degree of habit-formation. Finally, in a representative agent
equilibrium, we compute explicitly the price of a zero coupon bond and the
Lucas tree equity, and study its dependence on the habit-formation parameter.
"
1108.4102,2011-08-23,Portfolios and the market geometry,"  A geometric analysis of the time series of returns has been performed in the
past and it implied that the most of the systematic information of the market
is contained in a space of small dimension. Here we have explored subspaces of
this space to find out the relative performance of portfolios formed from the
companies that have the largest projections in each one of the subspaces. It
was found that the best performance portfolios are associated to some of the
small eigenvalue subspaces and not to the dominant directions in the distances
matrix. This occurs in such a systematic fashion over an extended period
(1990-2008) that it may not be a statistical accident.
"
1108.4886,2013-12-03,"Identifying the Free Boundary of a Stochastic, Irreversible Investment
  Problem via the Bank-El Karoui Representation Theorem","  We study a stochastic, continuous time model on a finite horizon for a firm
that produces a single good. We model the production capacity as an Ito
diffusion controlled by a nondecreasing process representing the cumulative
investment. The firm aims to maximize its expected total net profit by choosing
the optimal investment process. That is a singular stochastic control problem.
We derive some first order conditions for optimality and we characterize the
optimal solution in terms of the base capacity process, i.e. the unique
solution of a representation problem in the spirit of Bank and El Karoui
(2004). We show that the base capacity is deterministic and it is identified
with the free boundary of the associated optimal stopping problem, when the
coefficients of the controlled diffusion are deterministic functions of time.
This is a novelty in the literature on finite horizon singular stochastic
control problems. As a subproduct this result allows us to obtain an integral
equation for the free boundary, which we explicitly solve in the infinite
horizon case for a Cobb-Douglas production function and constant coefficients
in the controlled capacity process.
"
1109.1256,2011-09-07,"Diversification Return, Portfolio Rebalancing, and the Commodity Return
  Puzzle","  Diversification return is an incremental return earned by a rebalanced
portfolio of assets. The diversification return of a rebalanced portfolio is
often incorrectly ascribed to a reduction in variance. We argue that the
underlying source of the diversification return is the rebalancing, which
forces the investor to sell assets that have appreciated in relative value and
buy assets that have declined in relative value, as measured by their weights
in the portfolio. In contrast, the incremental return of a buy-and-hold
portfolio is driven by the fact that the assets that perform the best become a
greater fraction of the portfolio. We use these results to resolve two puzzles
associated with the Gorton and Rouwenhorst index of commodity futures, and
thereby obtain a clear understanding of the source of the return of that index.
Diversification return can be a significant source of return for any rebalanced
portfolio of volatile assets.
"
1109.2945,2015-02-24,Portfolio Optimization under Convex Incentive Schemes,"  We consider the terminal wealth utility maximization problem from the point
of view of a portfolio manager who is paid by an incentive scheme, which is
given as a convex function $g$ of the terminal wealth. The manager's own
utility function $U$ is assumed to be smooth and strictly concave, however the
resulting utility function $U \circ g$ fails to be concave. As a consequence,
the problem considered here does not fit into the classical portfolio
optimization theory. Using duality theory, we prove wealth-independent
existence and uniqueness of the optimal portfolio in general (incomplete)
semimartingale markets as long as the unique optimizer of the dual problem has
a continuous law. In many cases, this existence and uniqueness result is
independent of the incentive scheme and depends only on the structure of the
set of equivalent local martingale measures. As examples, we discuss (complete)
one-dimensional models as well as (incomplete) lognormal mixture and popular
stochastic volatility models. We also provide a detailed analysis of the case
where the unique optimizer of the dual problem does not have a continuous law,
leading to optimization problems whose solvability by duality methods depends
on the initial wealth of the investor.
"
1109.3069,2015-03-19,"Directional Variance Adjustment: improving covariance estimates for
  high-dimensional portfolio optimization","  Robust and reliable covariance estimates play a decisive role in financial
and many other applications. An important class of estimators is based on
Factor models. Here, we show by extensive Monte Carlo simulations that
covariance matrices derived from the statistical Factor Analysis model exhibit
a systematic error, which is similar to the well-known systematic error of the
spectrum of the sample covariance matrix. Moreover, we introduce the
Directional Variance Adjustment (DVA) algorithm, which diminishes the
systematic error. In a thorough empirical study for the US, European, and Hong
Kong market we show that our proposed method leads to improved portfolio
allocation.
"
1109.3488,2012-01-04,"Using MOEAs To Outperform Stock Benchmarks In The Presence of Typical
  Investment Constraints","  Portfolio managers are typically constrained by turnover limits, minimum and
maximum stock positions, cardinality, a target market capitalization and
sometimes the need to hew to a style (such as growth or value). In addition,
portfolio managers often use multifactor stock models to choose stocks based
upon their respective fundamental data.
  We use multiobjective evolutionary algorithms (MOEAs) to satisfy the above
real-world constraints. The portfolios generated consistently outperform
typical performance benchmarks and have statistically significant asset
selection.
"
1109.3908,2016-11-26,Forward Exponential Performances: Pricing and Optimal Risk Sharing,"  In a Markovian stochastic volatility model, we consider financial agents
whose investment criteria are modelled by forward exponential performance
processes. The problem of contingent claim indifference valuation is first
addressed and a number of properties are proved and discussed. Special
attention is given to the comparison between the forward exponential and the
backward exponential utility indifference valuation. In addition, we construct
the problem of optimal risk sharing in this forward setting and solve it when
the agents' forward performance criteria are exponential.
"
1109.4422,2011-09-22,"Investment Volatility: A Critique of Standard Beta Estimation and a
  Simple Way Forward","  Beta is a widely used quantity in investment analysis. We review the common
interpretations that are applied to beta in finance and show that the standard
method of estimation - least squares regression - is inconsistent with these
interpretations. We present the case for an alternative beta estimator which is
more appropriate, as well as being easier to understand and to calculate.
Unlike regression, the line fit we propose treats both variables in the same
way. Remarkably, it provides a slope that is precisely the ratio of the
volatility of the investment's rate of return to the volatility of the market
index rate of return (or the equivalent excess rates of returns). Hence, this
line fitting method gives an alternative beta, which corresponds exactly to the
relative volatility of an investment - which is one of the usual
interpretations attached to beta.
"
1109.5144,2011-09-26,"The Capital Asset Pricing Model as a corollary of the Black-Scholes
  model","  We consider a financial market in which two securities are traded: a stock
and an index. Their prices are assumed to satisfy the Black-Scholes model.
Besides assuming that the index is a tradable security, we also assume that it
is efficient, in the following sense: we do not expect a prespecified
self-financing trading strategy whose wealth is almost surely nonnegative at
all times to outperform the index greatly. We show that, for a long investment
horizon, the appreciation rate of the stock has to be close to the interest
rate (assumed constant) plus the covariance between the volatility vectors of
the stock and the index. This contains both a version of the Capital Asset
Pricing Model and our earlier result that the equity premium is close to the
squared volatility of the index.
"
1109.5316,2015-03-19,"Outperformance Portfolio Optimization via the Equivalence of Pure and
  Randomized Hypothesis Testing","  We study the portfolio problem of maximizing the outperformance probability
over a random benchmark through dynamic trading with a fixed initial capital.
Under a general incomplete market framework, this stochastic control problem
can be formulated as a composite pure hypothesis testing problem. We analyze
the connection between this pure testing problem and its randomized
counterpart, and from latter we derive a dual representation for the maximal
outperformance probability. Moreover, in a complete market setting, we provide
a closed-form solution to the problem of beating a leveraged exchange traded
fund. For a general benchmark under an incomplete stochastic factor model, we
provide the Hamilton-Jacobi-Bellman PDE characterization for the maximal
outperformance probability.
"
1109.5512,2012-10-16,On Admissible Strategies in Robust Utility Maximization,"  The existence of optimal strategy in robust utility maximization is addressed
when the utility function is finite on the entire real line. A delicate problem
in this case is to find a ""good definition"" of admissible strategies, so that
an optimizer is obtained. Under suitable assumptions, especially a
time-consistency property of the set of probabilities which describes the model
uncertainty, we show that an optimal strategy is obtained in the class of
strategies whose wealths are supermartingales under all local martingale
measures having a finite generalized entropy with at least one of candidate
models (probabilities).
"
1110.0403,2017-01-09,"Pricing and Semimartingale Representations of Vulnerable Contingent
  Claims in Regime-Switching Markets","  Using a suitable change of probability measure, we obtain a novel Poisson
series representation for the arbitrage- free price process of vulnerable
contingent claims in a regime-switching market driven by an underlying
continuous- time Markov process. As a result of this representation, along with
a short-time asymptotic expansion of the claim's price process, we develop an
efficient method for pricing claims whose payoffs may depend on the full path
of the underlying Markov chain. The proposed approach is applied to price not
only simple European claims such as defaultable bonds, but also a new type of
path-dependent claims that we term self-decomposable, as well as the important
class of vulnerable call and put options on a stock. We provide a detailed
error analysis and illustrate the accuracy and computational complexity of our
method on several market traded instruments, such as defaultable bond prices,
barrier options, and vulnerable call options. Using again our Poisson series
representation, we show differentiability in time of the pre-default price
function of European vulnerable claims, which enables us to rigorously deduce
Feynman-Kac representations for the pre-default pricing function and new
semimartingale representations for the price process of the vulnerable claim
under both risk-neutral and objective probability measures.
"
1110.1214,2012-08-01,"Long Horizons, High Risk Aversion, and Endogeneous Spreads","  For an investor with constant absolute risk aversion and a long horizon, who
trades in a market with constant investment opportunities and small
proportional transaction costs, we obtain explicitly the optimal investment
policy, its implied welfare, liquidity premium, and trading volume. We identify
these quantities as the limits of their isoelastic counterparts for high levels
of risk aversion. The results are robust with respect to finite horizons, and
extend to multiple uncorrelated risky assets.
  In this setting, we study a Stackelberg equilibrium, led by a risk-neutral,
monopolistic market maker who sets the spread as to maximize profits. The
resulting endogenous spread depends on investment opportunities only, and is of
the order of a few percentage points for realistic parameter values.
"
1110.1436,2014-03-26,Loss-Based Risk Measures,"  Starting from the requirement that risk measures of financial portfolios
should be based on their losses, not their gains, we define the notion of
loss-based risk measure and study the properties of this class of risk
measures. We characterize loss-based risk measures by a representation theorem
and give examples of such risk measures. We then discuss the statistical
robustness of estimators of loss-based risk measures: we provide a general
criterion for qualitative robustness of risk estimators and compare this
criterion with sensitivity analysis of estimators based on influence functions.
Finally, we provide examples of statistically robust estimators for loss-based
risk measures.
"
1110.2573,2012-10-12,Optimal investment with intermediate consumption and random endowment,"  We consider a problem of optimal investment with intermediate consumption and
random endowment in an incomplete semimartingale model of a financial market.
We establish the key assertions of the utility maximization theory assuming
that both primal and dual value functions are finite in the interiors of their
domains as well as that random endowment at maturity can be dominated by the
terminal value of a self-financing wealth process. In order to facilitate
verification of these conditions, we present alternative, but equivalent
conditions, under which the conclusions of the theory hold.
"
1110.3383,2011-10-18,"Suitability of using technical indicators as potential strategies within
  intelligent trading systems","  The potential of machine learning to automate and control nonlinear, complex
systems is well established. These same techniques have always presented
potential for use in the investment arena, specifically for the managing of
equity portfolios. In this paper, the opportunity for such exploitation is
investigated through analysis of potential simple trading strategies that can
then be meshed together for the machine learning system to switch between. It
is the eligibility of these strategies that is being investigated in this
paper, rather than application. In order to accomplish this, the underlying
assumptions of each trading system are explored, and data is created in order
to evaluate the efficacy of these systems when trading on data with the
underlying patterns that they expect. The strategies are tested against a
buy-and-hold strategy to determine if the act of trading has actually produced
any worthwhile results, or are simply facets of the underlying prices. These
results are then used to produce targeted returns based upon either a desired
return or a desired risk, as both are required within the portfolio-management
industry. Results show a very viable opportunity for exploitation within the
aforementioned industry, with the Strategies performing well within their
narrow assumptions, and the intelligent system combining them to perform
without assumptions.
"
1110.3460,2015-05-30,"Performance analysis and optimal selection of large mean-variance
  portfolios under estimation risk","  We study the consistency of sample mean-variance portfolios of arbitrarily
high dimension that are based on Bayesian or shrinkage estimation of the input
parameters as well as weighted sampling. In an asymptotic setting where the
number of assets remains comparable in magnitude to the sample size, we provide
a characterization of the estimation risk by providing deterministic
equivalents of the portfolio out-of-sample performance in terms of the
underlying investment scenario. The previous estimates represent a means of
quantifying the amount of risk underestimation and return overestimation of
improved portfolio constructions beyond standard ones. Well-known for the
latter, if not corrected, these deviations lead to inaccurate and overly
optimistic Sharpe-based investment decisions. Our results are based on recent
contributions in the field of random matrix theory. Along with the asymptotic
analysis, the analytical framework allows us to find bias corrections improving
on the achieved out-of-sample performance of typical portfolio constructions.
Some numerical simulations validate our theoretical findings.
"
1110.3897,2015-03-19,Optimal decision under ambiguity for diffusion processes,"  In this paper we consider stochastic optimization problems for an ambiguity
averse decision maker who is uncertain about the parameters of the underlying
process. In a first part we consider problems of optimal stopping under drift
ambiguity for one-dimensional diffusion processes. Analogously to the case of
ordinary optimal stopping problems for one-dimensional Brownian motions we
reduce the problem to the geometric problem of finding the smallest majorant of
the reward function in a two-parameter function space. In a second part we
solve optimal stopping problems when the underlying process may crash down.
These problems are reduced to one optimal stopping problem and one Dynkin game.
Examples are discussed.
"
1110.5446,2017-05-08,"Optimizing expected utility of dividend payments for a Cram\'er-Lundberg
  risk proces","  We consider the problem of maximizing the discounted utility of dividend
payments of an insurance company whose reserves are modeled as a classical
Cram\'er-Lundberg risk process. We investigate this optimization problem under
the constraint that dividend rate is bounded. We prove that the value function
fulfills the Hamilton-Jacobi-Bellman equation and we identify the optimal
dividend strategy.
"
1110.6289,2013-04-23,"Portfolio optimisation under non-linear drawdown constraints in a
  semimartingale financial model","  A drawdown constraint forces the current wealth to remain above a given
function of its maximum to date. We consider the portfolio optimisation problem
of maximising the long-term growth rate of the expected utility of wealth
subject to a drawdown constraint, as in the original setup of Grossman and Zhou
(1993). We work in an abstract semimartingale financial market model with a
general class of utility functions and drawdown constraints. We solve the
problem by showing that it is in fact equivalent to an unconstrained problem
with a suitably modified utility function. Both the value function and the
optimal investment policy for the drawdown problem are given explicitly in
terms of their counterparts in the unconstrained problem.
"
1111.0389,2011-11-03,"An analytical performance comparison of exchanged traded funds with
  index funds: 2002-2010","  Exchange Traded Funds (ETFs) have been gaining increasing popularity in the
investment community as is evidenced by the high growth both in the number of
ETFs and their net assets since 2000. As ETFs are in nature similar to index
mutual funds, in this paper we examined if this growing demand for ETFs can be
explained through their outperformance as compared to index mutual funds. We
considered the population of all ETFs with inception dates prior to 2002 and
then for each ETF found all the passive index mutual funds that had the same
investment style as the selected ETF and had inception date prior to 2002.
Within each investment style we matched every ETF with all the passive index
funds in that investment style and compared the performances of the matched
pairs in terms of Sharp Ratios and risk adjusted buy and hold total returns for
the period 2002-2010. We then applied the Wilcoxon signed rank test to examine
if ETFs had better performances than index mutual funds during the sample
period. Out of the 230 paired matches of all the styles, ETFs outperformed
index mutual funds in 134 of the times in terms of Sharpe Ratio, however, the
test of the hypothesis showed no statistically significant difference between
ETFs and index funds performances in terms of Sharpe ratio. Out of the 230
paired matches of all the styles, ETFs outperformed index mutual funds in 125
of the times in terms of risk adjusted buy and hold total return, however, the
test of hypothesis showed no statistically significant difference between ETFs
and index funds performances in terms of risk adjusted buy and hold total
return. These findings indicate there is statistically no significant
difference between ETFs and passive index mutual funds performances at the fund
level and investors' choice between the two is related to product
characteristics and tax advantages.
"
1111.0818,2011-11-04,Time-Inconsistent Stochastic Linear--Quadratic Control,"  In this paper, we formulate a general time-inconsistent stochastic
linear--quadratic (LQ) control problem. The time-inconsistency arises from the
presence of a quadratic term of the expected state as well as a state-dependent
term in the objective functional. We define an equilibrium, instead of optimal,
solution within the class of open-loop controls, and derive a sufficient
condition for equilibrium controls via a flow of forward--backward stochastic
differential equations. When the state is one dimensional and the coefficients
in the problem are all deterministic, we find an explicit equilibrium control.
As an application, we then consider a mean-variance portfolio selection model
in a complete financial market where the risk-free rate is a deterministic
function of time but all the other market parameters are possibly stochastic
processes. Applying the general sufficient condition, we obtain explicit
equilibrium strategies when the risk premium is both deterministic and
stochastic.
"
1111.1113,2011-11-11,"Copula-based Hierarchical Aggregation of Correlated Risks. The behaviour
  of the diversification benefit in Gaussian and Lognormal Trees","  The benefits of diversifying risks are difficult to estimate quantitatively
because of the uncertainties in the dependence structure between the risks.
Also, the modelling of multidimensional dependencies is a non-trivial task.
This paper focuses on one such technique for portfolio aggregation, namely the
aggregation of risks within trees, where dependencies are set at each step of
the aggregation with the help of some copulas. We define rigorously this
procedure and then study extensively the Gaussian Tree of quite arbitrary size
and shape, where individual risks are normal, and where the Gaussian copula is
used. We derive exact analytical results for the diversification benefit of the
Gaussian tree as a function of its shape and of the dependency parameters.
  Such a ""toy-model"" of an aggregation tree enables one to understand the basic
phenomena's at play while aggregating risks in this way. In particular, it is
shown that, for a fixed number of individual risks, ""thin"" trees diversify
better than ""fat"" trees. Related to this, it is shown that hierarchical trees
have the natural tendency to lower the overall dependency with respect to the
dependency parameter chosen at each step of the aggregation. We also show that
these results hold in more general cases outside the gaussian world, and apply
notably to more realistic portfolios (LogNormal trees). We believe that any
insurer or reinsurer using such a tool should be aware of these systematic
effects, and that this awareness should strongly call for designing trees that
adequately fit the business.
  We finally address the issue of specifying the full joint distribution
between the risks. We show that the hierarchical mechanism does not require nor
specify the joint distribution, but that the latter can be determined exactly
(in the Gaussian case) by adding conditional independence hypotheses between
the risks and their sums.
"
1111.1133,2015-03-19,"Recovering Model Structures from Large Low Rank and Sparse Covariance
  Matrix Estimation","  Many popular statistical models, such as factor and random effects models,
give arise a certain type of covariance structures that is a summation of low
rank and sparse matrices. This paper introduces a penalized approximation
framework to recover such model structures from large covariance matrix
estimation. We propose an estimator based on minimizing a non-likelihood loss
with separable non-smooth penalty functions. This estimator is shown to recover
exactly the rank and sparsity patterns of these two components, and thus
partially recovers the model structures. Convergence rates under various matrix
norms are also presented. To compute this estimator, we further develop a
first-order iterative algorithm to solve a convex optimization problem that
contains separa- ble non-smooth functions, and the algorithm is shown to
produce a solution within O(1/t^2) of the optimal, after any finite t
iterations. Numerical performance is illustrated using simulated data and stock
portfolio selection on S&P 100.
"
1111.2091,2012-03-28,Performance-based regularization in mean-CVaR portfolio optimization,"  We introduce performance-based regularization (PBR), a new approach to
addressing estimation risk in data-driven optimization, to mean-CVaR portfolio
optimization. We assume the available log-return data is iid, and detail the
approach for two cases: nonparametric and parametric (the log-return
distribution belongs in the elliptical family). The nonparametric PBR method
penalizes portfolios with large variability in mean and CVaR estimations. The
parametric PBR method solves the empirical Markowitz problem instead of the
empirical mean-CVaR problem, as the solutions of the Markowitz and mean-CVaR
problems are equivalent when the log-return distribution is elliptical. We
derive the asymptotic behavior of the nonparametric PBR solution, which leads
to insight into the effect of penalization, and justification of the parametric
PBR method. We also show via simulations that the PBR methods produce efficient
frontiers that are, on average, closer to the population efficient frontier
than the empirical approach to the mean-CVaR problem, with less variability.
"
1111.2846,2011-11-14,A simplified Capital Asset Pricing Model,"  We consider a Black-Scholes market in which a number of stocks and an index
are traded. The simplified Capital Asset Pricing Model is the conjunction of
the usual Capital Asset Pricing Model, or CAPM, and the statement that the
appreciation rate of the index is equal to its squared volatility plus the
interest rate. (The mathematical statement of the conjunction is simpler than
that of the usual CAPM.) Our main result is that either we can outperform the
index or the simplified CAPM holds.
"
1111.5726,2011-11-28,"Multicurrency advisor based on the NSW model. Detailed description and
  perspectives","  Flexible algorithm of multicurrency trade on Forex market has been built on
the grounds of non-linear stochastic wavelets (NSW) model. Probability of the
loss-free trade has been evaluated. Results of the algorithm's real-time
testing and issues of the algorithm's development are discussed.
"
1111.6633,2013-01-09,On the Existence of Shadow Prices,"  For utility maximization problems under proportional transaction costs, it
has been observed that the original market with transaction costs can sometimes
be replaced by a frictionless ""shadow market"" that yields the same optimal
strategy and utility. However, the question of whether or not this indeed holds
in generality has remained elusive so far. In this paper we present a
counterexample which shows that shadow prices may fail to exist. On the other
hand, we prove that short selling constraints are a sufficient condition to
warrant their existence, even in very general multi-currency market models with
possibly discontinuous bid-ask-spreads.
"
1112.1114,2011-12-07,The Nature of Alpha,"  We suggest an empirical model of investment strategy returns which elucidates
the importance of non-Gaussian features, such as time-varying volatility,
asymmetry and fat tails, in explaining the level of expected returns.
Estimating the model on the (former) Lehman Brothers Hedge Fund Index data, we
demonstrate that the volatility compensation is a significant component of the
expected returns for most strategy styles, suggesting that many of these
strategies should be thought of as being `short vol'. We present some
fundamental and technical reasons why this should indeed be the case, and
suggest explanation for exception cases exhibiting `long vol' characteristics.
We conclude by drawing some lessons for hedge fund portfolio construction.
"
1112.1363,2011-12-07,Common persistence in conditional variance: A reconsideration,"  This paper demonstrates the flaws of co-persistence theory proposed by
Bollerslev and Engle (1993) which cause the theory can hardly be applied. With
the introduction of the half-life of decay coefficient as the measure of the
persistence, and both the weak definition of persistence and co-persistence in
variance, this study attempts to solve the problems by using exhaustive search
algorithm for obtaining co-persistent vector. In addition, this method is
illustrated to research the co-persistence of stock return volatility in 10
European countries.
"
1112.2406,2011-12-20,"On the game interpretation of a shadow price process in utility
  maximization problems under transaction costs","  To any utility maximization problem under transaction costs one can assign a
frictionless model with a price process $S^*$, lying in the bid/ask price
interval $[\underline S, \bar{S}]$. Such process $S^*$ is called a \emph{shadow
price} if it provides the same optimal utility value as in the original model
with bid-ask spread.
  We call $S^*$ a \emph{generalized shadow price} if the above property is true
for the \emph{relaxed} utility function in the frictionless model. This
relaxation is defined as the lower semicontinuous envelope of the original
utility, considered as a function on the set $[\underline S, \bar{S}]$,
equipped with some natural weak topology. We prove the existence of a
generalized shadow price under rather weak assumptions and mark its relation to
a saddle point of the trader/market zero-sum game, determined by the relaxed
utility function. The relation of the notion of a shadow price to its
generalization is illustrated by several examples. Also, we briefly discuss the
interpretation of shadow prices via Lagrange duality.
"
1112.2749,2011-12-14,"Asymptotic Analysis for Optimal Investment in Finite Time with
  Transaction Costs","  We consider an agent who invests in a stock and a money market account with
the goal of maximizing the utility of his investment at the final time T in the
presence of a proportional transaction cost. The utility function considered is
power utility. We provide a heuristic and a rigorous derivation of the
asymptotic expansion of the value function in powers of transaction cost
parameter. We also obtain a ""nearly optimal"" strategy, whose utility
asymptotically matches the leading terms in the value function.
"
1112.2939,2014-08-12,"An Explicit Example Of Optimal Portfolio-Consumption Choices With Habit
  Formation And Partial Observations","  We consider a model of optimal investment and consumption with both habit
formation and partial observations in incomplete It\^{o} processes market. The
investor chooses his consumption under the addictive habits constraint while
only observing the market stock prices but not the instantaneous rate of
return. Applying the Kalman-Bucy filtering theorem and the Dynamic Programming
arguments, we solve the associated Hamilton-Jacobi-Bellman (HJB) equation
explicitly for the path dependent stochastic control problem in the case of
power utilities. We provide the optimal investment and consumption policies in
explicit feedback forms using rigorous verification arguments.
"
1112.2940,2015-05-29,"Utility maximization with addictive consumption habit formation in
  incomplete semimartingale markets","  This paper studies the continuous time utility maximization problem on
consumption with addictive habit formation in incomplete semimartingale
markets. Introducing the set of auxiliary state processes and the modified dual
space, we embed our original problem into a time-separable utility maximization
problem with a shadow random endowment on the product space
$\mathbb{L}_+^0(\Omega\times [0,T],\mathcal{O},\overline{\mathbb{P}})$.
Existence and uniqueness of the optimal solution are established using convex
duality approach, where the primal value function is defined on two variables,
that is, the initial wealth and the initial standard of living. We also provide
sufficient conditions on the stochastic discounting processes and on the
utility function for the well-posedness of the original optimization problem.
Under the same assumptions, classical proofs in the approach of convex duality
analysis can be modified when the auxiliary dual process is not necessarily
integrable.
"
1112.3012,2011-12-14,"Pricing a Contingent Claim Liability with Transaction Costs Using
  Asymptotic Analysis for Optimal Investment","  We price a contingent claim liability using the utility indifference
argument. We consider an agent with exponential utility, who invests in a stock
and a money market account with the goal of maximizing the utility of his
investment at the final time T in the presence of positive proportional
transaction cost in two cases with and without a contingent claim liability.
Using the computations from the heuristic argument in Whalley & Wilmott we
provide a rigorous derivation of the asymptotic expansion of the value function
in powers of the transaction cost parameter around the known value function for
the case of zero transaction cost in both cases with and without a contingent
claim liability. Additionally, using utility indifference method we derive an
asymptotic expansion of the price of the contingent claim liability. In both
cases, we also obtain a ""nearly optimal"" strategy, whose expected utility
asymptotically matches the leading terms of the value function.
"
1112.4007,2011-12-20,Optimal Constrained Investment in the Cramer-Lundberg model,"  We consider an insurance company whose surplus is represented by the
classical Cramer-Lundberg process. The company can invest its surplus in a risk
free asset and in a risky asset, governed by the Black-Scholes equation. There
is a constraint that the insurance company can only invest in the risky asset
at a limited leveraging level; more precisely, when purchasing, the ratio of
the investment amount in the risky asset to the surplus level is no more than
a; and when shortselling, the proportion of the proceeds from the short-selling
to the surplus level is no more than b. The objective is to find an optimal
investment policy that minimizes the probability of ruin. The minimal ruin
probability as a function of the initial surplus is characterized by a
classical solution to the corresponding Hamilton-Jacobi-Bellman (HJB) equation.
We study the optimal control policy and its properties. The interrelation
between the parameters of the model plays a crucial role in the qualitative
behavior of the optimal policy. E.g., for some ratios between a and b, quite
unusual and at first ostensibly counterintuitive policies may appear, like
short-selling a stock with a higher rate of return to earn lower interest, or
borrowing at a higher rate to invest in a stock with lower rate of return. This
is in sharp contrast with the unrestricted case, first studied in Hipp and Plum
(2000), or with the case of no shortselling and no borrowing studied in Azcue
and Muler (2009).
"
1112.4027,2013-10-22,Analysis of hedging based on co-persistence theory,"  This article analyzes the relationship between co-persistence and hedging
which indicates co-persistence ratio is just the long-term hedging ratio. The
new method of exhaustive search algorithm for deriving co-persistence ratio is
derived in the article. And we also develop a new hedging strategy of combining
co-persistence with dynamic hedging which can enhance the hedging effectiveness
and reduce the persistence of the hedged portfolio. Finally our strategy is
illustrated to study the hedge of JIASHI300 index and HS300 stock index future .
"
1112.4385,2015-09-10,Shadow price in the power utility case,"  We consider the problem of maximizing expected power utility from consumption
over an infinite horizon in the Black-Scholes model with proportional
transaction costs, as studied in Shreve and Soner [Ann. Appl. Probab. 4 (1994)
609-692]. Similar to Kallsen and Muhle-Karbe [Ann. Appl. Probab. 20 (2010)
1341-1358], we derive a shadow price, that is, a frictionless price process
with values in the bid-ask spread which leads to the same optimal policy.
"
1112.6169,2011-12-30,Measuring market liquidity: An introductory survey,"  Asset liquidity in modern financial markets is a key but elusive concept. A
market is often said to be liquid when the prevailing structure of transactions
provides a prompt and secure link between the demand and supply of assets, thus
delivering low costs of transaction. Providing a rigorous and empirically
relevant definition of market liquidity has, however, provided to be a
difficult task. This paper provides a critical review of the frameworks
currently available for modelling and estimating the market liquidity of
assets. We consider definitions that stress the role of the bid-ask spread and
the estimation of its components that arise from alternative sources of market
friction. In this case, intra-daily measures of liquidity appear relevant for
capturing the core features of a market, and for their ability to describe the
arrival of new information to market participants.
"
1201.0106,2012-01-04,Saddlepoint methods in portfolio theory,"  We discuss the use of saddlepoint methods in the analysis of portfolios, with
particular reference to credit portfolios. The objective is to proceed from a
model of the loss distribution, given through probabilities, correlations and
the like, to an analytical approximation of the distribution. Once this is done
we show how to derive the so-called risk contributions which are the
derivatives of risk measures, such as a given quantile (VaR) or expected
shortfall, to the allocations in the underlying assets. These show, informally,
where the risk is coming from, and also indicate how to go about optimising the
portfolio.
"
1201.0625,2014-08-11,"Building portfolios of stocks in the S\~ao Paulo Stock Exchange using
  Random Matrix Theory","  By using Random Matrix Theory, we build covariance matrices between stocks of
the BM&F-Bovespa (Bolsa de Valores, Mercadorias e Futuros de S\~ao Paulo) which
are cleaned of some of the noise due to the complex interactions between the
many stocks and the finiteness of available data. We also use a regression
model in order to remove the market effect due to the common movement of all
stocks. These two procedures are then used to build stock portfolios based on
Markowitz's theory, trying to obtain better predictions of future risk based on
past data. This is done for years of both low and high volatility of the
Brazilian stock market, from 2004 to 2010. The results show that the use of
regression to subtract the market effect on returns greatly increases the
accuracy of the prediction of risk, and that, although the cleaning of the
correlation matrix often leads to portfolios that better predict risks, in
periods of high volatility of the market this procedure may fail to do so.
"
1202.0628,2013-04-30,"Optimal Portfolio Choice for a Behavioural Investor in Continuous-Time
  Markets","  The aim of this work consists in the study of the optimal investment strategy
for a behavioural investor, whose preference towards risk is described by both
a probability distortion and an S-shaped utility function. Within a
continuous-time financial market framework and assuming that asset prices are
modelled by semimartingales, we derive sufficient and necessary conditions for
the well-posedness of the optimisation problem in the case of piecewise-power
probability distortion and utility functions. Finally, under straightforwardly
verifiable conditions, we further demonstrate the existence of an optimal
strategy.
"
1202.2999,2012-02-15,Optimal arbitrage under model uncertainty,"  In an equity market model with ""Knightian"" uncertainty regarding the relative
risk and covariance structure of its assets, we characterize in several ways
the highest return relative to the market that can be achieved using
nonanticipative investment rules over a given time horizon, and under any
admissible configuration of model parameters that might materialize. One
characterization is in terms of the smallest positive supersolution to a fully
nonlinear parabolic partial differential equation of the
Hamilton--Jacobi--Bellman type. Under appropriate conditions, this smallest
supersolution is the value function of an associated stochastic control
problem, namely, the maximal probability with which an auxiliary
multidimensional diffusion process, controlled in a manner which affects both
its drift and covariance structures, stays in the interior of the positive
orthant through the end of the time-horizon. This value function is also
characterized in terms of a stochastic game, and can be used to generate an
investment rule that realizes such best possible outperformance of the market.
"
1202.6131,2013-06-18,Homogenization and asymptotics for small transaction costs,"  We consider the classical Merton problem of lifetime consumption-portfolio
optimization problem with small proportional transaction costs. The first order
term in the asymptotic expansion is explicitly calculated through a singular
ergodic control problem which can be solved in closed form in the
one-dimensional case. Unlike the existing literature, we consider a general
utility function and general dynamics for the underlying assets. Our arguments
are based on ideas from the homogenization theory and use the convergence tools
from the theory of viscosity solutions. The multidimensional case is studied in
our accompanying paper using the same approach.
"
1203.0643,2012-03-06,"Incorporating fat tails in financial models using entropic divergence
  measures","  In the existing financial literature, entropy based ideas have been proposed
in portfolio optimization, in model calibration for options pricing as well as
in ascertaining a pricing measure in incomplete markets. The abstracted problem
corresponds to finding a probability measure that minimizes the relative
entropy (also called $I$-divergence) with respect to a known measure while it
satisfies certain moment constraints on functions of underlying assets. In this
paper, we show that under $I$-divergence, the optimal solution may not exist
when the underlying assets have fat tailed distributions, ubiquitous in
financial practice. We note that this drawback may be corrected if
`polynomial-divergence' is used. This divergence can be seen to be equivalent
to the well known (relative) Tsallis or (relative) Renyi entropy. We discuss
existence and uniqueness issues related to this new optimization problem as
well as the nature of the optimal solution under different objectives. We also
identify the optimal solution structure under $I$-divergence as well as
polynomial-divergence when the associated constraints include those on marginal
distribution of functions of underlying assets. These results are applied to a
simple problem of model calibration to options prices as well as to portfolio
modeling in Markowitz framework, where we note that a reasonable view that a
particular portfolio of assets has heavy tailed losses may lead to fatter and
more reasonable tail distributions of all assets.
"
1203.1399,2012-03-08,Portfolios and risk premia for the long run,"  This paper develops a method to derive optimal portfolios and risk premia
explicitly in a general diffusion model for an investor with power utility and
a long horizon. The market has several risky assets and is potentially
incomplete. Investment opportunities are driven by, and partially correlated
with, state variables which follow an autonomous diffusion. The framework nests
models of stochastic interest rates, return predictability, stochastic
volatility and correlation risk. In models with several assets and a single
state variable, long-run portfolios and risk premia admit explicit formulas up
the solution of an ordinary differential equation which characterizes the
principal eigenvalue of an elliptic operator. Multiple state variables lead to
a quasilinear partial differential equation which is solvable for many models
of interest. The paper derives the long-run optimal portfolio and the long-run
optimal pricing measures depending on relative risk aversion, as well as their
finite-horizon performance.
"
1203.3757,2013-08-20,"Generalized Kuhn-Tucker Conditions for N-Firm Stochastic Irreversible
  Investment under Limited Resources","  In this paper we study a continuous time, optimal stochastic investment
problem under limited resources in a market with N firms. The investment
processes are subject to a time-dependent stochastic constraint. Rather than
using a dynamic programming approach, we exploit the concavity of the profit
functional to derive some necessary and sufficient first order conditions for
the corresponding Social Planner optimal policy. Our conditions are a
stochastic infinite-dimensional generalization of the Kuhn-Tucker Theorem. The
Lagrange multiplier takes the form of a nonnegative optional random measure on
[0,T] which is flat off the set of times for which the constraint is binding,
i.e. when all the fuel is spent. As a subproduct we obtain an enlightening
interpretation of the first order conditions for a single firm in Bank (2005).
In the infinite-horizon case, with operating profit functions of Cobb-Douglas
type, our method allows the explicit calculation of the optimal policy in terms
of the `base capacity' process, i.e. the unique solution of the Bank and El
Karoui representation problem (2004).
"
1203.4153,2012-07-18,Optimal Investment Under Transaction Costs,"  We investigate how and when to diversify capital over assets, i.e., the
portfolio selection problem, from a signal processing perspective. To this end,
we first construct portfolios that achieve the optimal expected growth in
i.i.d. discrete-time two-asset markets under proportional transaction costs. We
then extend our analysis to cover markets having more than two stocks. The
market is modeled by a sequence of price relative vectors with arbitrary
discrete distributions, which can also be used to approximate a wide class of
continuous distributions. To achieve the optimal growth, we use threshold
portfolios, where we introduce a recursive update to calculate the expected
wealth. We then demonstrate that under the threshold rebalancing framework, the
achievable set of portfolios elegantly form an irreducible Markov chain under
mild technical conditions. We evaluate the corresponding stationary
distribution of this Markov chain, which provides a natural and efficient
method to calculate the cumulative expected wealth. Subsequently, the
corresponding parameters are optimized yielding the growth optimal portfolio
under proportional transaction costs in i.i.d. discrete-time two-asset markets.
As a widely known financial problem, we next solve optimal portfolio selection
in discrete-time markets constructed by sampling continuous-time Brownian
markets. For the case that the underlying discrete distributions of the price
relative vectors are unknown, we provide a maximum likelihood estimator that is
also incorporated in the optimization framework in our simulations.
"
1203.4156,2015-06-04,"Optimal Investment Under Transaction Costs: A Threshold Rebalanced
  Portfolio Approach","  We study optimal investment in a financial market having a finite number of
assets from a signal processing perspective. We investigate how an investor
should distribute capital over these assets and when he should reallocate the
distribution of the funds over these assets to maximize the cumulative wealth
over any investment period. In particular, we introduce a portfolio selection
algorithm that maximizes the expected cumulative wealth in i.i.d. two-asset
discrete-time markets where the market levies proportional transaction costs in
buying and selling stocks. We achieve this using ""threshold rebalanced
portfolios"", where trading occurs only if the portfolio breaches certain
thresholds. Under the assumption that the relative price sequences have
log-normal distribution from the Black-Scholes model, we evaluate the expected
wealth under proportional transaction costs and find the threshold rebalanced
portfolio that achieves the maximal expected cumulative wealth over any
investment period. Our derivations can be readily extended to markets having
more than two stocks, where these extensions are pointed out in the paper. As
predicted from our derivations, we significantly improve the achieved wealth
over portfolio selection algorithms from the literature on historical data
sets.
"
1203.5957,2012-03-28,Optimal Trading with Linear Costs,"  We consider the problem of the optimal trading strategy in the presence of
linear costs, and with a strict cap on the allowed position in the market.
Using Bellman's backward recursion method, we show that the optimal strategy is
to switch between the maximum allowed long position and the maximum allowed
short position, whenever the predictor exceeds a threshold value, for which we
establish an exact equation. This equation can be solved explicitely in the
case of a discrete Ornstein-Uhlenbeck predictor. We discuss in detail the
dependence of this threshold value on the transaction costs. Finally, we
establish a strong connection between our problem and the case of a quadratic
risk penalty, where our threshold becomes the size of the optimal non-trading
band.
"
1204.0305,2012-06-18,"Shadow prices and well-posedness in the problem of optimal investment
  and consumption with transaction costs","  We revisit the optimal investment and consumption model of Davis and Norman
(1990) and Shreve and Soner (1994), following a shadow-price approach similar
to that of Kallsen and Muhle-Karbe (2010). Making use of the completeness of
the model without transaction costs, we reformulate and reduce the
Hamilton-Jacobi-Bellman equation for this singular stochastic control problem
to a non-standard free-boundary problem for a first-order ODE with an integral
constraint. Having shown that the free boundary problem has a smooth solution,
we use it to construct the solution of the original optimal
investment/consumption problem in a self-contained manner and without any
recourse to the dynamic programming principle. Furthermore, we provide an
explicit characterization of model parameters for which the value function is
finite.
"
1204.0637,2012-04-04,Efficient Discretization of Stochastic Integrals,"  Sharp asymptotic lower bounds of the expected quadratic variation of
discretization error in stochastic integration are given. The theory relies on
inequalities for the kurtosis and skewness of a general random variable which
are themselves seemingly new. Asymptotically efficient schemes which attain the
lower bounds are constructed explicitly. The result is directly applicable to
practical hedging problem in mathematical finance; it gives an asymptotically
optimal way to choose rebalancing dates and portofolios with respect to
transaction costs. The asymptotically efficient strategies in fact reflect the
structure of transaction costs. In particular a specific biased rebalancing
scheme is shown to be superior to unbiased schemes if transaction costs follow
a convex model. The problem is discussed also in terms of the exponential
utility maximization.
"
1204.2667,2012-04-13,Optimal portfolios in commodity futures markets,"  We consider portfolio optimization in futures markets. We model the entire
futures price curve at once as a solution of a stochastic partial differential
equation. The agents objective is to maximize her utility from the final wealth
when investing in futures contracts. We study a class of futures price curve
models which admit a finite-dimensional realization. Using this, we recast the
portfolio optimization problem as a finite-dimensional control problem and
study its solvability.
"
1205.0505,2012-05-04,Fractal Profit Landscape of the Stock Market,"  We investigate the structure of the profit landscape obtained from the most
basic, fluctuation based, trading strategy applied for the daily stock price
data. The strategy is parameterized by only two variables, p and q. Stocks are
sold and bought if the log return is bigger than p and less than -q,
respectively. Repetition of this simple strategy for a long time gives the
profit defined in the underlying two-dimensional parameter space of p and q. It
is revealed that the local maxima in the profit landscape are spread in the
form of a fractal structure. The fractal structure implies that successful
strategies are not localized to any region of the profit landscape and are
neither spaced evenly throughout the profit landscape, which makes the
optimization notoriously hard and hypersensitive for partial or limited
information. The concrete implication of this property is demonstrated by
showing that optimization of one stock for future values or other stocks
renders worse profit than a strategy that ignores fluctuations, i.e., a
long-term buy-and-hold strategy.
"
1205.0877,2012-07-27,"On the non-stationarity of financial time series: impact on optimal
  portfolio selection","  We investigate the possible drawbacks of employing the standard Pearson
estimator to measure correlation coefficients between financial stocks in the
presence of non-stationary behavior, and we provide empirical evidence against
the well-established common knowledge that using longer price time series
provides better, more accurate, correlation estimates. Then, we investigate the
possible consequences of instabilities in empirical correlation coefficient
measurements on optimal portfolio selection. We rely on previously published
works which provide a framework allowing to take into account possible risk
underestimations due to the non-optimality of the portfolio weights being used
in order to distinguish such non-optimality effects from risk underestimations
genuinely due to non-stationarities. We interpret such results in terms of
instabilities in some spectral properties of portfolio correlation matrices.
"
1205.3767,2014-11-05,"Universal Algorithm for Online Trading Based on the Method of
  Calibration","  We present a universal algorithm for online trading in Stock Market which
performs asymptotically at least as good as any stationary trading strategy
that computes the investment at each step using a fixed function of the side
information that belongs to a given RKHS (Reproducing Kernel Hilbert Space).
Using a universal kernel, we extend this result for any continuous stationary
strategy. In this learning process, a trader rationally chooses his gambles
using predictions made by a randomized well-calibrated algorithm. Our strategy
is based on Dawid's notion of calibration with more general checking rules and
on some modification of Kakade and Foster's randomized rounding algorithm for
computing the well-calibrated forecasts. We combine the method of randomized
calibration with Vovk's method of defensive forecasting in RKHS. Unlike the
statistical theory, no stochastic assumptions are made about the stock prices.
Our empirical results on historical markets provide strong evidence that this
type of technical trading can ""beat the market"" if transaction costs are
ignored.
"
1205.4588,2013-01-09,"Portfolio Selection with Small Transaction Costs and Binding Portfolio
  Constraints","  An investor with constant relative risk aversion and an infinite planning
horizon trades a risky and a safe asset with constant investment opportunities,
in the presence of small transaction costs and a binding exogenous portfolio
constraint. We explicitly derive the optimal trading policy, its welfare, and
implied trading volume. As an application, we study the problem of selecting a
prime broker among alternatives with different lending rates and margin
requirements. Moreover, we discuss how changing regulatory constraints affect
the deposit rates offered for illiquid loans.
"
1205.4643,2014-01-17,"Transaction Costs, Shadow Prices, and Duality in Discrete Time","  For portfolio choice problems with proportional transaction costs, we discuss
whether or not there exists a ""shadow price"", i.e., a least favorable
frictionless market extension leading to the same optimal strategy and utility.
  By means of an explicit counter-example, we show that shadow prices may fail
to exist even in seemingly perfectly benign situations, i.e., for a
log-investor trading in an arbitrage-free market with bounded prices and
arbitrarily small transaction costs.
  We also clarify the connection between shadow prices and duality theory.
Whereas dual minimizers need not lead to shadow prices in the above ""global""
sense, we show that they always correspond to a ""local"" version.
"
1205.4748,2012-05-23,"Time-Consistent Mean-Variance Portfolio Selection in Discrete and
  Continuous Time","  It is well known that mean-variance portfolio selection is a
time-inconsistent optimal control problem in the sense that it does not satisfy
Bellman's optimality principle and therefore the usual dynamic programming
approach fails. We develop a time- consistent formulation of this problem,
which is based on a local notion of optimality called local mean-variance
efficiency, in a general semimartingale setting. We start in discrete time,
where the formulation is straightforward, and then find the natural extension
to continuous time. This complements and generalises the formulation by Basak
and Chabakauri (2010) and the corresponding example in Bj\""ork and Murgoci
(2010), where the treatment and the notion of optimality rely on an underlying
Markovian framework. We justify the continuous-time formulation by showing that
it coincides with the continuous-time limit of the discrete-time formulation.
The proof of this convergence is based on a global description of the locally
optimal strategy in terms of the structure condition and the
F\""ollmer-Schweizer decomposition of the mean-variance tradeoff. As a
byproduct, this also gives new convergence results for the F\""ollmer-Schweizer
decomposition, i.e. for locally risk minimising strategies.
"
1205.5958,2013-06-28,Life Insurance Purchasing to Maximize Utility of Household Consumption,"  We determine the optimal amount of life insurance for a household of two wage
earners. We consider the simple case of exponential utility, thereby removing
wealth as a factor in buying life insurance, while retaining the relationship
among life insurance, income, and the probability of dying and thus losing that
income. For insurance purchased via a single premium or premium payable
continuously, we explicitly determine the optimal death benefit. We show that
if the premium is determined to target a specific probability of loss per
policy, then the rates of consumption are identical under single premium or
continuously payable premium. Thus, not only is equivalence of consumption
achieved for the households under the two premium schemes, it is also obtained
for the insurance company in the sense of equivalence of loss probabilities.
"
1205.6160,2013-09-04,"Stability of the exponential utility maximization problem with respect
  to preferences","  This paper studies stability of the exponential utility maximization when
there are small variations on agent's utility function. Two settings are
considered. First, in a general semimartingale model where random endowments
are present, a sequence of utilities defined on R converges to the exponential
utility. Under a uniform condition on their marginal utilities, convergence of
value functions, optimal payoffs and optimal investment strategies are
obtained, their rate of convergence are also determined. Stability of
utility-based pricing is studied as an application. Second, a sequence of
utilities defined on R_+ converges to the exponential utility after shifting
and scaling. Their associated optimal strategies, after appropriate scaling,
converge to the optimal strategy for the exponential hedging problem. This
complements Theorem 3.2 in \textit{M. Nutz, Probab. Theory Relat. Fields, 152,
2012}, which establishes the convergence for a sequence of power utilities.
"
1206.0243,2012-06-04,Cone-Constrained Continuous-Time Markowitz Problems,"  The Markowitz problem consists of finding in a financial market a
self-financing trading strategy whose final wealth has maximal mean and minimal
variance. We study this in continuous time in a general semimartingale model
and under cone constraints: Trading strategies must take values in a (possibly
random and time-dependent) closed cone. We first prove existence of a solution
for convex constraints by showing that the space of constrained terminal gains,
which is a space of stochastic integrals, is closed in L^2. Then we use
stochastic control methods to describe the local structure of the optimal
strategy, as follows. The value process of a naturally associated constrained
linear-quadratic optimal control problem is decomposed into a sum with two
opportunity processes L^{\pm} appearing as coefficients. The martingale
optimality principle translates into a drift condition for the semimartingale
characteristics of L^{\pm} or equivalently into a coupled system of backward
stochastic differential equations for L^{\pm}. We show how this can be used to
both characterise and construct optimal strategies. Our results explain and
generalise all the results available in the literature so far. Moreover, we
even obtain new sharp results in the unconstrained case.
"
1206.0715,2012-06-05,"Robust utility maximization for L\'evy processes: Penalization and
  solvability","  In this paper the robust utility maximization problem for a market model
based on L\'evy processes is analyzed. The interplay between the form of the
utility function and the penalization function required to have a well posed
problem is studied, and for a large class of utility functions it is proved
that the dual problem is solvable as well as the existence of optimal
solutions. The class of equivalent local martingale measures is characterized
in terms of the parameters of the price process, and the connection with convex
risk measures is also presented.
"
1206.2305,2012-11-21,"The numeraire property and long-term growth optimality for
  drawdown-constrained investments","  We consider the portfolio choice problem for a long-run investor in a general
continuous semimartingale model. We suggest to use path-wise growth optimality
as the decision criterion and encode preferences through restrictions on the
class of admissible wealth processes. Specifically, the investor is only
interested in strategies which satisfy a given linear drawdown constraint. The
paper introduces the numeraire property through the notion of expected relative
return and shows that drawdown-constrained strategies with the numeraire
property exist and are unique, but may depend on the financial planning
horizon. However, when sampled at the times of its maximum and asymptotically
as the time-horizon becomes distant, the drawdown-constrained numeraire
portfolio is given explicitly through a model-independent transformation of the
unconstrained numeraire portfolio. Further, it is established that the
asymptotically growth-optimal strategy is obtained as limit of numeraire
strategies on finite horizons.
"
1206.2333,2014-11-19,An algorithm for the orthogonal decomposition of financial return data,"  We present an algorithm for the decomposition of periodic financial return
data into orthogonal factors of expected return and ""systemic"", ""productive"",
and ""nonproductive"" risk. Generally, when the number of funds does not exceed
the number of periods, the expected return of a portfolio is an affine function
of its productive risk.
"
1206.2662,2012-06-21,"Alpha Representation For Active Portfolio Management and High Frequency
  Trading In Seemingly Efficient Markets","  We introduce a trade strategy representation theorem for performance
measurement and portable alpha in high frequency trading, by embedding a robust
trading algorithm that describe portfolio manager market timing behavior, in a
canonical multifactor asset pricing model. First, we present a spectral test
for market timing based on behavioral transformation of the hedge factors
design matrix. Second, we find that the typical trade strategy process is a
local martingale with a background driving Brownian bridge that mimics
portfolio manager price reversal strategies. Third, we show that equilibrium
asset pricing models like the CAPM exists on a set with P-measure zero. So that
excess returns, i.e. positive alpha, relative to a benchmark index is robust to
no arbitrage pricing in turbulent capital markets. Fourth, the path properties
of alpha are such that it is positive between suitably chosen stopping times
for trading. Fifth, we demonstrate how, and why, econometric tests of portfolio
performance tend to under report positive alpha.
"
1206.4562,2012-06-21,"Active Portfolio Management, Positive Jensen-Jarrow Alpha, and Zero Sets
  of CAPM","  We present conditions under which positive alpha exists in the realm of
active portfolio management- in contrast to the controversial result in Jarrow
(2010, pg. 20) which implicates delegated portfolio management by surmising
that positive alphas are illusionary. Specifically, we show that the critical
assumption used in Jarrow (2010, pg. 20), to derive the illusionary alpha
result, is based on a zero set for CAPM with Lebesgue measure zero. So
conclusions based on that assumption may well have probability measure zero of
occurrence as well. Technically, the existence of [Tanaka] local time on a zero
set for CAPM implies existence of positive alphas. In fact, we show that
positive alpha exists under the same scenarios of ""perpetual event swap"" and
""market systemic event"" Jarrow (2010) used to formulate the illusionary
positive alpha result. First, we prove that as long as asset price volatility
is greater than zero, systemic events like market crash will occur in finite
time almost surely. Thus creating an opportunity to hedge against that event.
Second, we find that Jarrow's ""false positive alpha"" variable constitutes
portfolio manager reward for trading strategy. For instance, we show that
positive alpha exists if portfolio managers develop hedging strategies based on
either (1) an exotic [barrier] option on the underlying asset - with barrier
hitting time motivated by the ""market systemic"" event, or (2) a swaption
strategy for the implied interest rate risk inherent in Jarrow's triumvirate of
riskless rate of return, factor sensitivity exposure, and constant risk premium
for a perpetual event swap.
"
1206.4626,2012-06-22,On-Line Portfolio Selection with Moving Average Reversion,"  On-line portfolio selection has attracted increasing interests in machine
learning and AI communities recently. Empirical evidences show that stock's
high and low prices are temporary and stock price relatives are likely to
follow the mean reversion phenomenon. While the existing mean reversion
strategies are shown to achieve good empirical performance on many real
datasets, they often make the single-period mean reversion assumption, which is
not always satisfied in some real datasets, leading to poor performance when
the assumption does not hold. To overcome the limitation, this article proposes
a multiple-period mean reversion, or so-called Moving Average Reversion (MAR),
and a new on-line portfolio selection strategy named ""On-Line Moving Average
Reversion"" (OLMAR), which exploits MAR by applying powerful online learning
techniques. From our empirical results, we found that OLMAR can overcome the
drawback of existing mean reversion algorithms and achieve significantly better
results, especially on the datasets where the existing mean reversion
algorithms failed. In addition to superior trading performance, OLMAR also runs
extremely fast, further supporting its practical applicability to a wide range
of applications.
"
1206.5324,2012-06-26,Effective Trade Execution,"  This paper examines the role of algorithmic trading in modern financial
markets. Additionally, order types, characteristics, and special features of
algorithmic trading are described under the lens provided by the large
development of high frequency trading technology. Special order types are
examined together with an intuitive description of the implied dynamics of the
order book conditional to special orders (iceberg and hidden). The chapter
provides an analysis of the transaction costs associated with trading activity
and examines the most common trading strategy employed in the market. It also
examines optimal execution strategy with the description of the Efficient
Trading Frontier. These concepts represent the tools needed to understand the
most recent innovations in financial markets and the most recent advances in
microstructures research.
"
1206.5756,2012-06-27,"On free lunches in random walk markets with short-sale constraints and
  small transaction costs, and weak convergence to Gaussian continuous-time
  processes","  This paper considers a sequence of discrete-time random walk markets with a
safe and a single risky investment opportunity, and gives conditions for the
existence of arbitrages or free lunches with vanishing risk, of the form of
waiting to buy and selling the next period, with no shorting, and furthermore
for weak convergence of the random walk to a Gaussian continuous-time
stochastic process. The conditions are given in terms of the kernel
representation with respect to ordinary Brownian motion and the discretisation
chosen. Arbitrage and free lunch with vanishing risk examples are established
where the continuous-time analogue is arbitrage-free under small transaction
costs - including for the semimartingale modifications of fractional Brownian
motion suggested in the seminal Rogers (1997) article proving arbitrage in fBm
models.
"
1206.6268,2012-06-28,"Maximizing Utility of Consumption Subject to a Constraint on the
  Probability of Lifetime Ruin","  In this note, we explicitly solve the problem of maximizing utility of
consumption (until the minimum of bankruptcy and the time of death) with a
constraint on the probability of lifetime ruin, which can be interpreted as a
risk measure on the whole path of the wealth process.
"
1207.1003,2023-04-19,"A Closed-Form Solution of the Multi-Period Portfolio Choice Problem for
  a Quadratic Utility Function","  In the present paper, we derive a closed-form solution of the multi-period
portfolio choice problem for a quadratic utility function with and without a
riskless asset. All results are derived under weak conditions on the asset
returns. No assumption on the correlation structure between different time
points is needed and no assumption on the distribution is imposed. All
expressions are presented in terms of the conditional mean vectors and the
conditional covariance matrices. If the multivariate process of the asset
returns is independent it is shown that in the case without a riskless asset
the solution is presented as a sequence of optimal portfolio weights obtained
by solving the single-period Markowitz optimization problem. The process
dynamics are included only in the shape parameter of the utility function. If a
riskless asset is present then the multi-period optimal portfolio weights are
proportional to the single-period solutions multiplied by time-varying
constants which are depending on the process dynamics. Remarkably, in the case
of a portfolio selection with the tangency portfolio the multi-period solution
coincides with the sequence of the simple-period solutions. Finally, we compare
the suggested strategies with existing multi-period portfolio allocation
methods for real data.
"
1207.1029,2013-05-13,"On the Equivalence of Quadratic Optimization Problems Commonly Used in
  Portfolio Theory","  In the paper, we consider three quadratic optimization problems which are
frequently applied in portfolio theory, i.e, the Markowitz mean-variance
problem as well as the problems based on the mean-variance utility function and
the quadratic utility.Conditions are derived under which the solutions of these
three optimization procedures coincide and are lying on the efficient frontier,
the set of mean-variance optimal portfolios. It is shown that the solutions of
the Markowitz optimization problem and the quadratic utility problem are not
always mean-variance efficient. The conditions for the mean-variance efficiency
of the solutions depend on the unknown parameters of the asset returns. We deal
with the problem of parameter uncertainty in detail and derive the
probabilities that the estimated solutions of the Markowitz problem and the
quadratic utility problem are mean-variance efficient. Because these
probabilities deviate from one the above mentioned quadratic optimization
problems are not stochastically equivalent. The obtained results are
illustrated by an empirical study.
"
1207.1037,2023-04-19,"On the Exact Solution of the Multi-Period Portfolio Choice Problem for
  an Exponential Utility under Return Predictability","  In this paper we derive the exact solution of the multi-period portfolio
choice problem for an exponential utility function under return predictability.
It is assumed that the asset returns depend on predictable variables and that
the joint random process of the asset returns and the predictable variables
follow a vector autoregressive process. We prove that the optimal portfolio
weights depend on the covariance matrices of the next two periods and the
conditional mean vector of the next period. The case without predictable
variables and the case of independent asset returns are partial cases of our
solution. Furthermore, we provide an empirical study where the cumulative
empirical distribution function of the investor's wealth is calculated using
the exact solution. It is compared with the investment strategy obtained under
the additional assumption that the asset returns are independently distributed.
"
1207.1759,2015-08-14,On arbitrages arising from honest times,"  In the context of a general continuous financial market model, we study
whether the additional information associated with an honest time gives rise to
arbitrage profits. By relying on the theory of progressive enlargement of
filtrations, we explicitly show that no kind of arbitrage profit can ever be
realised strictly before an honest time, while classical arbitrage
opportunities can be realised exactly at an honest time as well as after an
honest time. Moreover, stronger arbitrages of the first kind can only be
obtained by trading as soon as an honest time occurs. We carefully study the
behavior of local martingale deflators and consider no-arbitrage-type
conditions weaker than NFLVR.
"
1207.1932,2012-07-10,"Optimization Method for Interval Portfolio Selection Based on
  Satisfaction Index of Interval inequality Relation","  In this paper we consider an interval portfolio selection problem with
uncertain returns and introduce an inclusive concept of satisfaction index for
interval inequality relation. Based on the satisfaction index, we propose an
approach to reduce the interval programming problem with uncertain objective
and constraints into a standard linear programming problem with two parameters.
We showed by simulation experiment that our method is capable of helping
investors to find efficient portfolios according to their preference.
"
1207.3118,2012-07-16,The Long Neglected Critically Leveraged Portfolio,"  We show that the efficient frontier for a portfolio in which short positions
precisely offset the long ones is composed of a pair of straight lines through
the origin of the risk-return plane. This unique but important case has been
overlooked because the original formulation of the mean-variance model by
Markowitz as well as all its subsequent elaborations have implicitly excluded
it by using portfolio weights rather than actual amounts allocated to
individual assets. We also elucidate the properties of portfolios where short
positions dominate the long ones, a case which has similarly been obscured by
the adoption of portfolio weights.
"
1207.4749,2013-10-23,Do arbitrage-free prices come from utility maximization?,"  In this paper we ask whether, given a stock market and an illiquid
derivative, there exists arbitrage-free prices at which an utility-maximizing
agent would always want to buy the derivative, irrespectively of his own
initial endowment of derivatives and cash. We prove that this is false for any
given investor if one considers all initial endowments with finite utility, and
that it can instead be true if one restricts to the endowments in the interior.
  We show however how the endowments on the boundary can give rise to very odd
phenomena; for example, an investor with such an endowment would choose not to
trade in the derivative even at prices arbitrarily close to some arbitrage
price.
"
1207.7330,2012-08-01,Portfolio Choice with Transaction Costs: a User's Guide,"  Recent progress in portfolio choice has made a wide class of problems
involving transaction costs tractable. We review the basic approach to these
problems, and outline some directions for future research.
"
1208.0371,2012-08-03,"Can Metropolitan Housing Risk be Diversified? A Cautionary Tale from the
  Recent Boom and Bust","  Geographic diversification is fundamental to risk mitigation among investors
and insurers of housing, mortgages, and mortgage-related derivatives. To
characterize diversification potential, we provide estimates of integration,
spatial correlation, and contagion among US metropolitan housing markets.
Results reveal a high and increasing level of integration among US markets over
the decade of the 2000s, especially in California. We apply integration results
to assess the risk of alternative housing investment portfolios. Portfolio
simulation indicates reduced diversification potential and increased risk in
the wake of estimated increases in metropolitan housing market integration.
Research findings provide new insights regarding the synchronous
non-performance of geographically-disparate MBS investments during the late
2000s.
"
1208.0763,2014-05-28,"Second Order BSDEs with Jumps: Existence and probabilistic
  representation for fully-nonlinear PIDEs","  In this paper, we pursue the study of second order BSDEs with jumps (2BSDEJs
for short) started in our accompanying paper [15]. We prove existence of these
equations by a direct method, thus providing complete wellposedness for
2BSDEJs. These equations are a natural candidate for the probabilistic
interpretation of some fully non-linear partial integro-differential equations,
which is the point of the second part of this work. We prove a non-linear
Feynman-Kac formula and show that solutions to 2BSDEJs provide viscosity
solutions of the associated PIDEs.
"
1208.2068,2012-08-13,"Risk minimizing of derivatives via dynamic g-expectation and related
  topics","  In this paper, we investigate risk minimization problem of derivatives based
on non-tradable underlyings by means of dynamic g-expectations which are slight
different from conditional g-expectations. In this framework, inspired by [1]
and [16], we introduce risk indifference price, marginal risk price and
derivative hedge and obtain their corresponding explicit expressions. The
interesting thing is that their expressions have nothing to do with nonlinear
generator g, and one deep reason for this is due to the completeness of
financial market. By giving three useful special risk minimization problems, we
obtain the explicit optimal strategies with initial wealth involved,
demonstrate some qualitative analysis among optimal strategies, risk aversion
parameter and market price of risk, together with some economic
interpretations.
"
1208.2775,2014-08-21,"Physical approach to price momentum and its application to momentum
  strategy","  We introduce various quantitative and mathematical definitions for price
momentum of financial instruments. The price momentum is quantified with
velocity and mass concepts originated from the momentum in physics. By using
the physical momentum of price as a selection criterion, the weekly contrarian
strategies are implemented in South Korea KOSPI 200 and US S&P 500 universes.
The alternative strategies constructed by the physical momentum achieve the
better expected returns and reward-risk measures than those of the traditional
contrarian strategy in weekly scale. The portfolio performance is not
understood by the Fama-French three-factor model.
"
1208.4799,2014-10-28,Hedge and Mutual Funds' Fees and the Separation of Private Investments,"  A fund manager invests both the fund's assets and own private wealth in
separate but potentially correlated risky assets, aiming to maximize expected
utility from private wealth in the long run. If relative risk aversion and
investment opportunities are constant, we find that the fund's portfolio
depends only on the fund's investment opportunities, and the private portfolio
only on private opportunities. This conclusion is valid both for a hedge fund
manager, who is paid performance fees with a high-water mark provision, and for
a mutual fund manager, who is paid management fees proportional to the fund's
assets. The manager invests earned fees in the safe asset, allocating remaining
private wealth in a constant-proportion portfolio, while the fund is managed as
another constant-proportion portfolio. The optimal welfare is the maximum
between the optimal welfare of each investment opportunity, with no
diversification gain. In particular, the manager does not use private
investments to hedge future income from fees.
"
1208.5382,2012-08-28,Wrong-way risk in credit and funding valuation adjustments,"  Wrong-way risk in counterparty and funding exposures is most dramatic in the
situations of systemic crises and tails events. A consistent model of wrong-way
risk (WWR) is developed here with the probability-weighted addition of tail
events to the calculation of credit valuation and funding valuation adjustments
(CVA and FVA). This new practical model quantifies the tail risks in the
pricing of CVA and FVA of derivatives and does not rely on a limited concept of
linear correlation frequently used in many models. The application of the model
is illustrated with practical examples of WWR arising in the case of a
sovereign default for the most common interest-rate and foreign exchange
derivatives.
"
1209.0305,2013-06-10,"Optimal relaxed portfolio strategies for growth rate maximization
  problems with transaction costs","  In this paper we investigate a new class of growth rate maximization problems
based on impulse control strategies such that the average number of trades per
time unit does not exceed a fixed level. Moreover, we include proportional
transaction costs to make the portfolio problem more realistic. We provide a
Verification Theorem to compute the optimal growth rate as well as an optimal
trading strategy. Furthermore, we prove the existence of a constant boundary
strategy which is optimal. At the end, we compare our approach to other
discrete-time growth rate maximization problems in numerical examples. It turns
out that constant boundary strategies with a small average number of trades per
unit perform nearly as good as the classical optimal solutions with infinite
activity.
"
1209.2555,2012-12-13,Option Pricing and Hedging with Small Transaction Costs,"  An investor with constant absolute risk aversion trades a risky asset with
general It\^o-dynamics, in the presence of small proportional transaction
costs. In this setting, we formally derive a leading-order optimal trading
policy and the associated welfare, expressed in terms of the local dynamics of
the frictionless optimizer. By applying these results in the presence of a
random endowment, we obtain asymptotic formulas for utility indifference prices
and hedging strategies in the presence of small transaction costs.
"
1209.4449,2013-02-12,Diffusion-based models for financial markets without martingale measures,"  We consider a general class of diffusion-based models and show that, even in
the absence of an Equivalent Local Martingale Measure, the financial market may
still be viable, in the sense that strong forms of arbitrage are excluded and
portfolio optimisation problems can be meaningfully solved. Relying partly on
the recent literature, we provide necessary and sufficient conditions for
market viability in terms of the market price of risk process and martingale
deflators. Regardless of the existence of a martingale measure, we show that
the financial market may still be complete and contingent claims can be valued
under the original (real-world) probability measure, provided we use as
numeraire the Growth-Optimal Portfolio.
"
1209.5175,2012-09-25,"Utility Maximization in a Binomial Model with transaction costs: a
  Duality Approach Based on the Shadow Price Process","  We consider the problem of optimizing the expected logarithmic utility of the
value of a portfolio in a binomial model with proportional transaction costs
with a long time horizon. By duality methods, we can find expressions for the
boundaries of the no-trade-region and the asymptotic optimal growth rate, which
can be made explicit for small transaction costs. Here we find that, contrary
to the classical results in continuous time, the size of the no-trade-region as
well as the asymptotic growth rate depend analytically on the level of
transaction costs, implying a linear first order effect of perturbations of
(small) transaction costs. We obtain the asymptotic expansion by an almost
explicit construction of the shadow price process.
"
1209.6385,2012-10-01,"Maximising Survival, Growth, and Goal Reaching Under Borrowing
  Constraints","  In this paper, we consider three problems related to survival, growth, and
goal reaching maximization of an investment portfolio with proportional net
cash flow. We solve the problems in a market constrained due to borrowing
prohibition. To solve the problems, we first construct an auxiliary market and
then apply the dynamic programming approach. Via our solutions, an alternative
approach is introduced in order to solve the problems defined under an
auxiliary market.
"
1209.6439,2015-03-13,The best gain-loss ratio is a poor performance measure,"  The gain-loss ratio is known to enjoy very good properties from a normative
point of view. As a confirmation, we show that the best market gain-loss ratio
in the presence of a random endowment is an acceptability index and we provide
its dual representation for general probability spaces. However, the gain-loss
ratio was designed for finite $\Omega$, and works best in that case. For
general $\Omega$ and in most continuous time models, the best gain-loss is
either infinite or fails to be attained. In addition, it displays an odd
behaviour due to the scale invariance property, which does not seem desirable
in this context. Such weaknesses definitely prove that the (best) gain-loss is
a poor performance measure.
"
1210.1598,2012-10-08,Portfolio Choice in Markets with Contagion,"  We consider the problem of optimal investment and consumption in a class of
multidimensional jump-diffusion models in which asset prices are subject to
mutually exciting jump processes. This captures a type of contagion where each
downward jump in an asset's price results in increased likelihood of further
jumps, both in that asset and in the other assets. We solve in closed-form the
dynamic consumption-investment problem of a log-utility investor in such a
contagion model, prove a theorem verifying its optimality and discuss features
of the solution, including flight-to-quality. The exponential and power utility
investors are also considered: in these cases, the optimal strategy can be
characterized as a distortion of the strategy of a corresponding non-contagion
investor.
"
1210.1625,2014-11-25,Optimal order placement in limit order markets,"  To execute a trade, participants in electronic equity markets may choose to
submit limit orders or market orders across various exchanges where a stock is
traded. This decision is influenced by the characteristics of the order flow
and queue sizes in each limit order book, as well as the structure of
transaction fees and rebates across exchanges. We propose a quantitative
framework for studying this order placement problem by formulating it as a
convex optimization problem. This formulation allows to study how the interplay
between the state of order books, the fee structure, order flow properties and
preferences of a trader determine the optimal placement decision. In the case
of a single exchange, we derive an explicit solution for the optimal split
between limit and market orders. For the general problem of order placement
across multiple exchanges, we propose a stochastic algorithm for computing the
optimal policy and study the sensitivity of the solution to various parameters
using a numerical implementation of the algorithm.
"
1210.3800,2013-07-16,"A Note on Applications of Stochastic Ordering to Control Problems in
  Insurance and Finance","  We consider a controlled diffusion process $(X_t)_{t\ge 0}$ where the
controller is allowed to choose the drift $\mu_t$ and the volatility $\sigma_t$
from a set $\K(x) \subset \R\times (0,\infty)$ when $X_t=x$. By choosing the
largest $\frac{\mu}{\sigma^2}$ at every point in time an extremal process is
constructed which is under suitable time changes stochastically larger than any
other admissible process. This observation immediately leads to a very simple
solution of problems where ruin or hitting probabilities have to be minimized.
Under further conditions this extremal process also minimizes ""drawdown""
probabilities.
"
1210.4901,2012-10-19,"An Approximate Solution Method for Large Risk-Averse Markov Decision
  Processes","  Stochastic domains often involve risk-averse decision makers. While recent
work has focused on how to model risk in Markov decision processes using risk
measures, it has not addressed the problem of solving large risk-averse
formulations. In this paper, we propose and analyze a new method for solving
large risk-averse MDPs with hybrid continuous-discrete state spaces and
continuous action spaces. The proposed method iteratively improves a bound on
the value function using a linearity structure of the MDP. We demonstrate the
utility and properties of the method on a portfolio optimization problem.
"
1210.5111,2015-05-15,"Sequential $\delta$-optimal consumption and investment for stochastic
  volatility markets with unknown parameters","  We consider an optimal investment and consumption problem for a Black-Scholes
financial market with stochastic volatility and unknown stock appreciation
rate. The volatility parameter is driven by an external economic factor modeled
as a diffusion process of Ornstein-Uhlenbeck type with unknown drift. We use
the dynamical programming approach and find an optimal financial strategy which
depends on the drift parameter. To estimate the drift coefficient we observe
the economic factor $Y$ in an interval $[0,T_0]$ for fixed $T_0>0$, and use
sequential estimation. We show, that the consumption and investment strategy
calculated through this sequential procedure is $\delta$-optimal.
"
1210.5205,2012-10-19,The Merton Problem with a Drawdown Constraint on Consumption,"  In this paper, we work in the framework of the Merton problem but we impose a
drawdown constraint on the consumption process. This means that consumption can
never fall below a fixed proportion of the running maximum of past consumption.
In terms of economic motivation, this constraint represents a type of habit
formation where the investor is reluctant to let his standard of living fall
too far from the maximum standard achieved to date. We use techniques from
stochastic optimal control and duality theory to obtain our candidate value
function and optimal controls, which are then verified.
"
1210.5466,2013-10-09,Optimal Investment with Stocks and Derivatives,"  This paper studies the problem of maximizing expected utility from terminal
wealth combining a static position in derivative securities, which we assume
can be traded only at time zero, with a traditional dynamic trading strategy in
stocks. We work in the framework of a general semi-martingale model and
consider a utility function defined on the positive real line.
"
1210.5859,2012-10-23,Determination the Parameters of Markowitz Portfolio Optimization Model,"  The main purpose of this study is the determination of the optimal length of
the historical data for the estimation of statistical parameters in Markowitz
Portfolio Optimization. We present a trading simulation using Markowitz method,
for a portfolio consisting of foreign currency exchange rates and selected
assets from the Istanbul Stock Exchange ISE 30, over the period 2001-2009. In
the simulation, the expected returns and the covariance matrix are computed
from historical data observed for past n days and the target returns are chosen
as multiples of the return of the market index. The trading strategy is to buy
a stock if the simulation resulted in a feasible solution and sell the stock
after exactly m days, independently from the market conditions. The actual
returns are computed for n and m being equal to 21, 42, 63, 84 and 105 days and
we have seen that the best return is obtained when the observation period is 2
or 3 times the investment period.
"
1211.0412,2015-01-21,"On an integral equation for the free-boundary of stochastic,
  irreversible investment problems","  In this paper, we derive a new handy integral equation for the free-boundary
of infinite time horizon, continuous time, stochastic, irreversible investment
problems with uncertainty modeled as a one-dimensional, regular diffusion $X$.
The new integral equation allows to explicitly find the free-boundary
$b(\cdot)$ in some so far unsolved cases, as when the operating profit function
is not multiplicatively separable and $X$ is a three-dimensional Bessel process
or a CEV process. Our result follows from purely probabilistic arguments.
Indeed, we first show that $b(X(t))=l^*(t)$, with $l^*$ the unique optional
solution of a representation problem in the spirit of Bank-El Karoui [Ann.
Probab. 32 (2004) 1030-1067]; then, thanks to such an identification and the
fact that $l^*$ uniquely solves a backward stochastic equation, we find the
integral problem for the free-boundary.
"
1211.1285,2015-03-20,Impact of time illiquidity in a mixed market without full observation,"  We study a problem of optimal investment/consumption over an infinite horizon
in a market consisting of two possibly correlated assets: one liquid and one
illiquid. The liquid asset is observed and can be traded continuously, while
the illiquid one can be traded only at discrete random times corresponding to
the jumps of a Poisson process with intensity $\lambda$, is observed at the
trading dates, and is partially observed between two different trading dates.
The problem is a nonstandard mixed discrete/continuous optimal control problem
which we face by the dynamic programming approach. When the utility has a
general form we prove that the value function is the unique viscosity solution
of the HJB equation and, assuming sufficient regularity of the value function,
we give a verification theorem that describes the optimal investment strategies
for the illiquid asset. In the case of power utility, we prove the regularity
of the value function needed to apply the verification theorem, providing the
complete theoretical solution of the problem. This allows us to perform
numerical simulation, so to analyze the impact of time illiquidity in this
mixed market and how this impact is affected by the degree of observation.
"
1211.1286,2012-11-07,"Viscosity characterization of the value function of an
  investment-consumption problem in presence of illiquid assets","  We study a problem of optimal investment/consumption over an infinite horizon
in a market consisting of a liquid and an illiquid asset. The liquid asset is
observed and can be traded continuously, while the illiquid one can only be
traded and observed at discrete random times corresponding to the jumps of a
Poisson process. The problem is a nonstandard mixed discrete/continuous optimal
control problem which we face by the dynamic programming approach. The main aim
of the paper is to prove that the value function is the unique viscosity
solution of an associated HJB equation. We then use such result to build a
numerical algorithm allowing to approximate the value function and so to
measure the cost of illiquidity.
"
1211.2754,2012-11-13,Coal Enterprise Management and Asynchronism of Return,"  For researching the association between coal enterprise management and return
in financial market, this paper applies the method of time difference relevance
and PageRank method to seek the leader-index of a stock set containing 21 coal
enterprises in A-share market and score those stocks. Based on the return in
2011, the asynchronism of the return series is revealed and presents a
hierarchical structure of our stock set. Finally, we compare the result with
the firm-level variables and discuss the relation between them. The results
show that those large coal enterprises with a good management condition always
present an antecedence of stock return; there is a significant positive
association between company scale and the score given by PageRank method.
"
1211.4598,2014-06-20,"How Non-Arbitrage, Viability and Num\'eraire Portfolio are Related","  This paper proposes two approaches that quantify the exact relationship among
the viability, the absence of arbitrage, and/or the existence of the
num\'eraire portfolio under minimal assumptions and for general continuous-time
market models. Precisely, our first and principal contribution proves the
equivalence among the No-Unbounded-Profit-with-Bounded-Risk condition (NUPBR
hereafter), the existence of the num\'eraire portfolio, and the existence of
the optimal portfolio under an equivalent probability measure for any ""nice""
utility and positive initial capital. Herein, a 'nice"" utility is any smooth
von Neumann-Morgenstern utility satisfying Inada's conditions and the
elasticity assumptions of Kramkov and Schachermayer. Furthermore, the
equivalent probability measure ---under which the utility maximization problems
have solutions--- can be chosen as close to the real-world probability measure
as we want (but might not be equal). Without changing the underlying
probability measure and under mild assumptions, our second contribution proves
that the NUPBR is equivalent to the ""{\it local}"" existence of the optimal
portfolio. This constitutes an alternative to the first contribution, if one
insists on working under the real-world probability. These two contributions
lead naturally to new types of viability that we call weak and local
viabilities.
"
1211.4946,2013-10-03,"The Calculus of Expected Loss: Backtesting Parameter-Based Expected Loss
  in a Basel II Framework","  The dependency structure of credit risk parameters is a key driver for
capital consumption and receives regulatory and scientific attention. The
impact of parameter imperfections on the quality of expected loss (EL) in the
sense of a fair, unbiased estimate of risk expenses however is barely covered.
So far there are no established backtesting procedures for EL, quantifying its
impact with regards to pricing or risk adjusted profitability measures. In this
paper, a practically oriented, top-down approach to assess the quality of EL by
backtesting with a properly defined risk measure is introduced. In a first
step, the concept of risk expenses (Cost of Risk) has to be extended beyond the
classical provisioning view, towards a more adequate capital consumption
approach (Impact of Risk, IoR). On this basis, the difference between
parameter-based EL and actually reported Impact of Risk is decomposed into its
key components. The proposed method will deepen the understanding of practical
properties of EL, reconciles the EL with a clearly defined and observable risk
measure and provides a link between upcoming IFRS 9 accounting standards for
loan loss provisioning with IRBA regulatory capital requirements. The method is
robust irrespective whether parameters are simple, expert based values or
highly predictive and perfectly calibrated IRBA compliant methods, as long as
parameters and default identification procedures are stable.
"
1211.5816,2024-07-16,"Relaxing the Differentiability Assumption in Taylor Theorem and
  Optimization: Applications to the HJB PDE and Finance","  We introduce Taylor expansions that do not require the differentiability. We
also provide new solutions to partial differential equations. We apply our
methods to finance.
"
1211.5819,2012-11-27,New stochastic calculus,"  We present new stochastic differential equations, that are more general and
simpler than the existing Ito-based stochastic differential equations. As an
example, we apply our approach to the investment (portfolio) model.
"
1211.5858,2014-05-26,"Degenerate backward SPDEs in domains: non-local boundary conditions and
  applications to finance","  Backward stochastic partial differential equations of parabolic type in
bounded domains are studied in the setting where the coercivity condition is
not necessary satisfied and the equation can be degenerate. Some generalized
solutions based on the representation theorem are suggested. In addition to
problems with a standard Cauchy condition at the terminal time, problems with
special non-local boundary conditions are considered. These non-local
conditions connect the terminal value of the solution with a functional over
the entire past solution. Uniqueness, solvability and regularity results are
obtained. Some applications to portfolio selection problem are considered.
"
1211.7365,2023-06-22,On optimal dividends in the dual model,"  We revisit the dividend payment problem in the dual model of Avanzi et al.
([2], [1], and [3]). Using the fluctuation theory of spectrally positive
L\'{e}vy processes, we give a short exposition in which we show the optimality
of barrier strategies for all such L\'{e}vy processes. Moreover, we
characterize the optimal barrier using the functional inverse of a scale
function. We also consider the capital injection problem of [3] and show that
its value function has a very similar form to the one in which the horizon is
the time of ruin.
"
1212.1877,2013-10-29,"Generalizations of Functionally Generated Portfolios with Applications
  to Statistical Arbitrage","  The theory of functionally generated portfolios (FGPs) is an aspect of the
continuous-time, continuous-path Stochastic Portfolio Theory of Robert
Fernholz. FGPs have been formulated to yield a master equation - a description
of their return relative to a passive (buy-and-hold) benchmark portfolio
serving as the num\'eraire. This description has proven to be analytically very
useful, as it is both pathwise and free of stochastic integrals. Here we
generalize the class of FGPs in several ways: (1) the num\'eraire may be any
strictly positive wealth process, not necessarily the market portfolio or even
a passive portfolio; (2) generating functions may be stochastically dynamic,
adjusting to changing market conditions through an auxiliary continuous-path
stochastic argument of finite variation. These generalizations do not forfeit
the important tractability properties of the associated master equation. We
show how these generalizations can be usefully applied to scenario analysis,
statistical arbitrage, portfolio risk immunization, and the theory of mirror
portfolios.
"
1212.2129,2013-05-21,Online Portfolio Selection: A Survey,"  Online portfolio selection is a fundamental problem in computational finance,
which has been extensively studied across several research communities,
including finance, statistics, artificial intelligence, machine learning, and
data mining, etc. This article aims to provide a comprehensive survey and a
structural understanding of published online portfolio selection techniques.
From an online machine learning perspective, we first formulate online
portfolio selection as a sequential decision problem, and then survey a variety
of state-of-the-art approaches, which are grouped into several major
categories, including benchmarks, ""Follow-the-Winner"" approaches,
""Follow-the-Loser"" approaches, ""Pattern-Matching"" based approaches, and
""Meta-Learning Algorithms"". In addition to the problem formulation and related
algorithms, we also discuss the relationship of these algorithms with the
Capital Growth theory in order to better understand the similarities and
differences of their underlying trading ideas. This article aims to provide a
timely and comprehensive survey for both machine learning and data mining
researchers in academia and quantitative portfolio managers in the financial
industry to help them understand the state-of-the-art and facilitate their
research and practical applications. We also discuss some open issues and
evaluate some emerging new trends for future research directions.
"
1212.3137,2012-12-14,"Smooth Value Function with Applications in Wealth-CVaR Efficient
  Portfolio and Turnpike Property","  In this paper we continue the study of Bian-Miao-Zheng (2011) and extend the
results there to a more general class of utility functions which may be bounded
and non-strictly-concave and show that there is a classical solution to the HJB
equation with the dual control method. We then apply the results to study the
efficient frontier of wealth and conditional VaR (CVaR) problem and the
turnpike property problem. For the former we construct explicitly the optimal
control and discuss the choice of the optimal threadshold level and illustrate
that the wealth and the CVaR are positively correlated. For the latter we give
a simple proof to the turnpike property of the optimal policy of long-run
investors and generalize the results of Huang-Zariphopoulou (1999).
"
1212.3145,2014-10-02,"Optimal Liquidation in a Finite Time Regime Switching Model with
  Permanent and Temporary Pricing Impact","  In this paper we discuss the optimal liquidation over a finite time horizon
until the exit time. The drift and diffusion terms of the asset price are
general functions depending on all variables including control and market
regime. There is also a local nonlinear transaction cost associated to the
liquidation. The model deals with both the permanent impact and the temporary
impact in a regime switching framework. The problem can be solved with the
dynamic programming principle. The optimal value function is the unique
continuous viscosity solution to the HJB equation and can be computed with the
finite difference method.
"
1212.3958,2012-12-18,Dynamic quasi-concave performance measures,"  We define Conditional quasi concave Performance Measures (CPMs), on random
variables bounded from below, to accommodate for additional information. Our
notion encompasses a wide variety of cases, from conditional expected utility
and certainty equivalent to conditional acceptability indexes. We provide the
characterization of a CPM in terms of an induced family of conditional convex
risk measures. In the case of indexes these risk measures are coherent. Then,
Dynamic Performance Measures (DPMs) are introduced and the problem of time
consistency is addressed. The definition of time consistency chosen here
ensures that the positions which are considered good tomorrow are already
considered good today. We prove the equivalence between time consistency for a
DPM and weak acceptance consistency for the induced families of risk measures.
Finally, we extend CPMs and DPMs to dividend processes.
"
1212.6275,2013-01-23,"Homogenization and asymptotics for small transaction costs: the
  multidimensional case","  In the context of the multi-dimensional infinite horizon optimal
consumption-investment problem with proportional transaction costs, we provide
the first order expansion in small transact costs. Similar to the
one-dimensional derivation in our accompanying paper [42], the asymptotic
expansion is expressed in terms of a singular ergodic control problem, and our
arguments are based on the theory of viscosity solutions, and the techniques of
homogenization which leads to a system of corrector equations. In contrast with
the one-dimensional case, no explicit solution of the first corrector equation
is available anymore. Finally, we provide some numerical results which
illustrate the structure of the first order optimal controls.
"
1301.0280,2015-02-10,"Utility maximization with current utility on the wealth: regularity of
  solutions to the HJB equation","  We consider a utility maximization problem for an investment-consumption
portfolio when the current utility depends also on the wealth process. Such
kind of problems arise, e.g., in portfolio optimization with random horizon or
with random trading times. To overcome the difficulties of the problem we use
the dual approach. We define a dual problem and treat it by means of dynamic
programming, showing that the viscosity solutions of the associated
Hamilton-Jacobi-Bellman equation belong to a suitable class of smooth
functions. This allows to define a smooth solution of the primal
Hamilton-Jacobi-Bellman equation, proving that this solution is indeed unique
in a suitable class and coincides with the value function of the primal
problem. Some financial applications of the results are provided.
"
1301.0381,2013-08-01,"Optimal replication of random claims by ordinary integrals with
  applications in finance","  By the classical Martingale Representation Theorem, replication of random
vectors can be achieved via stochastic integrals or solutions of stochastic
differential equations. We introduce a new approach to replication of random
vectors via adapted differentiable processes generated by a controlled ordinary
differential equation. We found that the solution of this replication problem
exists and is not unique. This leads to a new optimal control problem: find a
replicating process that is minimal in an integral norm. We found an explicit
solution of this problem. Possible applications to portfolio selection problems
and to bond pricing models are suggested.
"
1301.0719,2013-01-07,Gambling in contests with regret,"  This paper discusses the gambling contest introduced in Seel & Strack
(Gambling in contests, Discussion Paper Series of SFB/TR 15 Governance and the
Efficiency of Economic Systems 375, Mar 2012.) and considers the impact of
adding a penalty associated with failure to follow a winning strategy.
  The Seel & Strack model consists of $n$-agents each of whom privately
observes a transient diffusion process and chooses when to stop it. The player
with the highest stopped value wins the contest, and each player's objective is
to maximise their probability of winning the contest. We give a new derivation
of the results of Seel & Strack based on a Lagrangian approach. Moreover, we
consider an extension of the problem in which in the case when an agent is
penalised when their strategy is suboptimal, in the sense that they do not win
the contest, but there existed an alternative strategy which would have
resulted in victory.
"
1301.0907,2013-01-08,"On a dynamic adaptation of the Distribution Builder approach to
  investment decisions","  Sharpe et al. proposed the idea of having an expected utility maximizer
choose a probability distribution for future wealth as an input to her
investment problem instead of a utility function. They developed a computer
program, called The Distribution Builder, as one way to elicit such a
distribution. In a single-period model, they then showed how this desired
distribution for terminal wealth can be used to infer the investor's risk
preferences. We adapt their idea, namely that a risk-averse investor can choose
a desired distribution for future wealth as an alternative input attribute for
investment decisions, to continuous time. In a variety of scenarios, we show
how the investor's desired distribution combines with her initial wealth and
market-related input to determine the feasibility of her distribution, her
implied risk preferences, and her optimal policies throughout her investment
horizon. We then provide several examples.
"
1301.3823,2013-01-17,Portfolio Management Approach in Trade Credit Decision Making,"  The basic financial purpose of an enterprise is maximization of its value.
Trade credit management should also contribute to realization of this
fundamental aim. Many of the current asset management models that are found in
financial management literature assume book profit maximization as the basic
financial purpose. These book profitbased models could be lacking in what
relates to another aim (i.e., maximization of enterprise value). The enterprise
value maximization strategy is executed with a focus on risk and uncertainty.
This article presents the consequences that can result from operating risk that
is related to purchasers using payment postponement for goods and/or services.
The present article offers a method that uses portfolio management theory to
determine the level of accounts receivable in a firm. An increase in the level
of accounts receivables in a firm increases both net working capital and the
costs of holding and managing accounts receivables. Both of these decrease the
value of the firm, but a liberal policy in accounts receivable coupled with the
portfolio management approach could increase the value. Efforts to assign ways
to manage these risks were also undertaken; among them, special attention was
paid to adapting assumptions from portfolio theory as well as gauging the
potential effect on the firm value.
"
1301.3824,2013-01-17,"Planning Optimal From the Firm Value Creation Perspective Levels of
  Operating Cash Investments","  The basic financial purpose of corporation is creation of its value.
Liquidity management should also contribute to realization of this fundamental
aim. Many of the current asset management models that are found in financial
management literature assume book profit maximization as the basic financial
purpose. These book profit based models could be lacking in what relates to
another aim like maximization of enterprise value. The corporate value creation
strategy is executed with a focus on risk and uncertainty. Firms hold cash for
a variety of reasons. Generally, cash balances held in a firm can be called
considered, precautionary, speculative, transactional and intentional. The
first are the result of management anxieties. Managers fear the negative part
of the risk and hold cash to hedge against it. Second, cash balances are held
to use chances that are created by the positive part of the risk equation.
Next, cash balances are the result of the operating needs of the firm. In this
article, we analyze the relation between these types of cash balances and risk.
This article presents the discussion about relations between firm net working
investment policy and as result operating cash balances and firm value. This
article also contains propositions for marking levels of precautionary cash
balances and speculative cash balances. Application of these propositions
should help managers to make better decisions to maximize the value of a firm.
"
1301.3826,2013-02-25,Value-Based Inventory Management,"  The basic financial purpose of a firm is to maximize its value. An inventory
management system should also contribute to realization of this basic aim. Many
current asset management models currently found in financial management
literature were constructed with the assumption of book profit maximization as
basic aim. However these models could lack what relates to another aim, i.e.,
maximization of enterprise value. This article presents a modified value-based
inventory management model.
"
1301.4173,2014-08-26,Diversity and no arbitrage,"  A stock market is called diverse if no stock can dominate the market in terms
of relative capitalization. On one hand, this natural property leads to
arbitrage in diffusion models under mild assumptions. On the other hand, it is
also easy to construct diffusion models which are both diverse and free of
arbitrage. Can one tell whether an observed diverse market admits arbitrage?
  In the present paper we argue that this may well be impossible by proving
that the known examples of diverse markets in the literature (which do admit
arbitrage) can be approximated uniformly (on the logarithmic scale) by models
which are both diverse and arbitrage-free.
"
1301.4194,2013-01-21,"Financial Portfolio Optimization: Computationally guided agents to
  investigate, analyse and invest!?","  Financial portfolio optimization is a widely studied problem in mathematics,
statistics, financial and computational literature. It adheres to determining
an optimal combination of weights associated with financial assets held in a
portfolio. In practice, it faces challenges by virtue of varying math.
formulations, parameters, business constraints and complex financial
instruments. Empirical nature of data is no longer one-sided; thereby
reflecting upside and downside trends with repeated yet unidentifiable cyclic
behaviours potentially caused due to high frequency volatile movements in asset
trades. Portfolio optimization under such circumstances is theoretically and
computationally challenging. This work presents a novel mechanism to reach an
optimal solution by encoding a variety of optimal solutions in a solution bank
to guide the search process for the global investment objective formulation. It
conceptualizes the role of individual solver agents that contribute optimal
solutions to a bank of solutions, a super-agent solver that learns from the
solution bank, and, thus reflects a knowledge-based computationally guided
agents approach to investigate, analyse and reach to optimal solution for
informed investment decisions.
  Conceptual understanding of classes of solver agents that represent varying
problem formulations and, mathematically oriented deterministic solvers along
with stochastic-search driven evolutionary and swarm-intelligence based
techniques for optimal weights are discussed. Algorithmic implementation is
presented by an enhanced neighbourhood generation mechanism in Simulated
Annealing algorithm. A framework for inclusion of heuristic knowledge and human
expertise from financial literature related to investment decision making
process is reflected via introduction of controlled perturbation strategies
using a decision matrix for neighbourhood generation.
"
1301.4881,2013-02-05,"On the optimal allocation of assets in investment portfolio with
  application of modern portfolio and nonlinear dynamic chaos theories in
  investment, commercial and central banks","  The investment economy is a main characteristic of prosperous society. The
investment portfolio management is a main financial problem, which has to be
solved by the investment, commercial and central banks with the application of
modern portfolio theory in the investment economy. We use the learning
analytics together with the integrative creative imperative intelligent
conceptual co-lateral adaptive thinking with the purpose to advance our
scientific knowledge on the diversified investment portfolio management in the
nonlinear dynamic financial system. We apply the econophysics principles and
the econometrics methods with the aim to find the solution to the problem of
the optimal allocation of assets in the investment portfolio, using the
advanced risk management techniques with the efficient frontier modeling in
agreement with the modern portfolio theory and using the stability management
techniques with the dynamic regimes modeling on the bifurcation diagram in
agreement with the dynamic chaos theory. We show that the bifurcation diagram,
created with the use of the logistic function in Matlab, can provide some
valuable information on the stability of combining risky investments in the
investment portfolio, solving the problem of optimization of assets allocation
in the investment portfolio. We propose the Ledenyov investment portfolio
theorem, based on the Lyapunov stability criteria, with the aim to create the
optimized investment portfolio with the uncorrelated diversified assets, which
can deliver the increased expected returns to the institutional and private
investors in the nonlinear dynamic financial system in the frames of investment
economy.
"
1301.5129,2018-05-10,"A Bayesian Non-Parametric Approach to Asymmetric Dynamic Conditional
  Correlation Model With Application to Portfolio Selection","  We propose a Bayesian non-parametric approach for modeling the distribution
of multiple returns. In particular, we use an asymmetric dynamic conditional
correlation (ADCC) model to estimate the time-varying correlations of financial
returns where the individual volatilities are driven by GJR-GARCH models. The
ADCC-GJR-GARCH model takes into consideration the asymmetries in individual
assets' volatilities, as well as in the correlations. The errors are modeled
using a Dirichlet location-scale mixture of multivariate Gaussian distributions
allowing for a great flexibility in the return distribution in terms of
skewness and kurtosis. Model estimation and prediction are developed using MCMC
methods based on slice sampling techniques. We carry out a simulation study to
illustrate the flexibility of the proposed approach. We find that the proposed
DPM model is able to adapt to several frequently used distribution models and
also accurately estimates the posterior distribution of the volatilities of the
returns, without assuming any underlying distribution. Finally, we present a
financial application using Apple and NASDAQ Industrial index data to solve a
portfolio allocation problem. We find that imposing a restrictive parametric
distribution can result into underestimation of the portfolio variance, whereas
DPM model is able to overcome this problem.
"
1301.5497,2014-07-15,Suitability of Capital Allocations for Performance Measurement,"  Capital allocation principles are used in various contexts in which a risk
capital or a cost of an aggregate position has to be allocated among its
constituent parts. We study capital allocation principles in a performance
measurement framework. We introduce the notation of suitability of allocations
for performance measurement and show under different assumptions on the
involved reward and risk measures that there exist suitable allocation methods.
The existence of certain suitable allocation principles generally is given
under rather strict assumptions on the underlying risk measure. Therefore we
show, with a reformulated definition of suitability and in a slightly modified
setting, that there is a known suitable allocation principle that does not
require any properties of the underlying risk measure. Additionally we extend a
previous characterization result from the literature from a mean-risk to a
reward-risk setting. Formulations of this theory are also possible in a game
theoretic setting.
"
1301.7413,2013-02-01,Switching Portfolios,"  A constant rebalanced portfolio is an asset allocation algorithm which keeps
the same distribution of wealth among a set of assets along a period of time.
Recently, there has been work on on-line portfolio selection algorithms which
are competitive with the best constant rebalanced portfolio determined in
hindsight. By their nature, these algorithms employ the assumption that high
returns can be achieved using a fixed asset allocation strategy. However, stock
markets are far from being stationary and in many cases the wealth achieved by
a constant rebalanced portfolio is much smaller than the wealth achieved by an
ad-hoc investment strategy that adapts to changes in the market. In this paper
we present an efficient Bayesian portfolio selection algorithm that is able to
track a changing market. We also describe a simple extension of the algorithm
for the case of a general transaction cost, including the transactions cost
models recently investigated by Blum and kalai. We provide a simple analysis of
the competitiveness of the algorithm and check its performance on real stock
data from the New York Stock Exchange accumulated during a 22-year period.
"
1302.0134,2014-09-04,"Maximization of Non-Concave Utility Functions in Discrete-Time Financial
  Market Models","  This paper investigates the problem of maximizing expected terminal utility
in a (generically incomplete) discrete-time financial market model with finite
time horizon. In contrast to the standard setting, a possibly non-concave
utility function $U$ is considered, with domain of definition $\mathbb{R}$.
Simple conditions are presented which guarantee the existence of an optimal
strategy for the problem. In particular, the asymptotic elasticity of $U$ plays
a decisive role: existence can be shown when it is strictly greater at
$-\infty$ than at $+\infty$.
"
1302.0590,2013-08-30,Robust Hedging with Proportional Transaction Costs,"  Duality for robust hedging with proportional transaction costs of path
dependent European options is obtained in a discrete time financial market with
one risky asset. Investor's portfolio consists of a dynamically traded stock
and a static position in vanilla options which can be exercised at maturity.
Both the stock and the option trading is subject to proportional transaction
costs. The main theorem is duality between hedging and a Monge-Kantorovich type
optimization problem. In this dual transport problem the optimization is over
all the probability measures which satisfy an approximate martingale condition
related to consistent price systems in addition to the usual marginal
constraints.
"
1302.0926,2013-02-06,Risks of Large Portfolios,"  Estimating and assessing the risk of a large portfolio is an important topic
in financial econometrics and risk management. The risk is often estimated by a
substitution of a good estimator of the volatility matrix. However, the
accuracy of such a risk estimator for large portfolios is largely unknown, and
a simple inequality in the previous literature gives an infeasible upper bound
for the estimation error. In addition, numerical studies illustrate that this
upper bound is very crude. In this paper, we propose factor-based risk
estimators under a large amount of assets, and introduce a high-confidence
level upper bound (H-CLUB) to assess the accuracy of the risk estimation. The
H-CLUB is constructed based on three different estimates of the volatility
matrix: sample covariance, approximate factor model with known factors, and
unknown factors (POET, Fan, Liao and Mincheva, 2013). For the first time in the
literature, we derive the limiting distribution of the estimated risks in high
dimensionality. Our numerical results demonstrate that the proposed upper
bounds significantly outperform the traditional crude bounds, and provide
insightful assessment of the estimation of the portfolio risks. In addition,
our simulated results quantify the relative error in the risk estimation, which
is usually negligible using 3-month daily data. Finally, the proposed methods
are applied to an empirical study.
"
1302.2231,2014-03-11,On the optimal dividend problem for a spectrally positive Levy process,"  In this paper we study the optimal dividend problem for a company whose
surplus process evolves as a spectrally positive Levy process. This model
including the dual model of the classical risk model and the dual model with
diffusion as special cases. We assume that dividends are paid to the
shareholders according to admissible strategy whose dividend rate is bounded by
a constant. The objective is to find a dividend policy so as to maximize the
expected discounted value of dividends which are paid to the shareholders until
the company is ruined. We show that the optimal dividend strategy is formed by
a threshold strategy.
"
1302.4254,2015-08-14,Market viability and martingale measures under partial information,"  We consider a financial market model with a single risky asset whose price
process evolves according to a general jump-diffusion with locally bounded
coefficients and where market participants have only access to a partial
information flow. For any utility function, we prove that the partial
information financial market is locally viable, in the sense that the optimal
portfolio problem has a solution up to a stopping time, if and only if the
(normalised) marginal utility of the terminal wealth generates a partial
information equivalent martingale measure (PIEMM). This equivalence result is
proved in a constructive way by relying on maximum principles for stochastic
control problems under partial information. We then characterize a global
notion of market viability in terms of partial information local martingale
deflators (PILMDs). We illustrate our results by means of a simple example.
"
1302.4679,2014-02-03,Rationalizing Investors Choice,"  Assuming that agents' preferences satisfy first-order stochastic dominance,
we show how the Expected Utility paradigm can rationalize all optimal
investment choices: the optimal investment strategy in any behavioral
law-invariant (state-independent) setting corresponds to the optimum for an
expected utility maximizer with an explicitly derived concave non-decreasing
utility function. This result enables us to infer the utility and risk aversion
of agents from their investment choice in a non-parametric way. We relate the
property of decreasing absolute risk aversion (DARA) to distributional
properties of the terminal wealth and of the financial market. Specifically, we
show that DARA is equivalent to a demand for a terminal wealth that has more
spread than the opposite of the log pricing kernel at the investment horizon.
"
1302.5339,2013-02-22,Theory of Performance Participation Strategies,"  The purpose of this article is to introduce, analyze and compare two
performance participation methods based on a portfolio consisting of two risky
assets: Option-Based Performance Participation (OBPP) and Constant Proportion
Performance Participation (CPPP). By generalizing the provided guarantee to a
participation in the performance of a second risky underlying, the new
strategies allow to cope with well-known problems associated with standard
portfolio insurance methods, like e.g. the CPPI cash lock-in. This is
especially an issue in times of market crisis. However, the minimum guaranteed
portfolio value at the end of the investment horizon is not deterministic
anymore, but subject to systematic risk instead. With respect to the comparison
of the two strategies, various criteria are applied such as comparison of
terminal payoffs and payoff distributions. General analytical expressions for
all moments of both performance participation strategies as well as standard
OBPI and CPPI are derived. Furthermore, dynamic hedging properties are
examined, in particular classical delta hedging.
"
1302.6669,2013-02-28,"Continuous-time Mean-Variance Portfolio Selection with Stochastic
  Parameters","  This paper studies a continuous-time market {under stochastic environment}
where an agent, having specified an investment horizon and a target terminal
mean return, seeks to minimize the variance of the return with multiple stocks
and a bond. In the considered model firstly proposed by [3], the mean returns
of individual assets are explicitly affected by underlying Gaussian economic
factors. Using past and present information of the asset prices, a
partial-information stochastic optimal control problem with random coefficients
is formulated. Here, the partial information is due to the fact that the
economic factors can not be directly observed. Via dynamic programming theory,
the optimal portfolio strategy can be constructed by solving a deterministic
forward Riccati-type ordinary differential equation and two linear
deterministic backward ordinary differential equations.
"
1303.0237,2013-10-09,Optimal investment and price dependence in a semi-static market,"  This paper studies the problem of maximizing expected utility from terminal
wealth in a semi-static market composed of derivative securities, which we
assume can be traded only at time zero, and of stocks, which can be traded
continuously in time and are modeled as locally-bounded semi-martingales.
  Using a general utility function defined on the positive real line, we first
study existence and uniqueness of the solution, and then we consider the
dependence of the outputs of the utility maximization problem on the price of
the derivatives, investigating not only stability but also differentiability,
monotonicity, convexity and limiting properties.
"
1303.1064,2013-03-06,"Unified Framework of Mean-Field Formulations for Optimal Multi-period
  Mean-Variance Portfolio Selection","  The classical dynamic programming-based optimal stochastic control methods
fail to cope with nonseparable dynamic optimization problems as the principle
of optimality no longer applies in such situations. Among these notorious
nonseparable problems, the dynamic mean-variance portfolio selection
formulation had posted a great challenge to our research community until
recently. A few solution methods, including the embedding scheme, have been
developed in the last decade to solve the dynamic mean-variance portfolio
selection formulation successfully. We propose in this paper a novel mean-field
framework that offers a more efficient modeling tool and a more accurate
solution scheme in tackling directly the issue of nonseparability and deriving
the optimal policies analytically for the multi-period mean-variance-type
portfolio selection problems.
"
1303.1248,2013-03-07,Investment and Consumption with Regime-Switching Discount Rates,"  This paper considers the problem of consumption and investment in a financial
market within a continuous time stochastic economy. The investor exhibits a
change in the discount rate. The investment opportunities are a stock and a
riskless account. The market coefficients and discount factor switch according
to a finite state Markov chain. The change in the discount rate leads to time
inconsistencies of the investor's decisions. The randomness in our model is
driven by a Brownian motion and a Markov chain. Following Ekeland and Pirvu we
introduce and characterize the subgame perfect strategies. Numerical
experiments show the effect of time preference on subgame perfect strategies
and the pre-commitment strategies.
"
1303.2513,2016-02-03,"Portfolio Optimization under Partial Information with Expert Opinions: a
  Dynamic Programming Approach","  This paper investigates optimal portfolio strategies in a market where the
drift is driven by an unobserved Markov chain. Information on the state of this
chain is obtained from stock prices and expert opinions in the form of signals
at random discrete time points. As in Frey et al. (2012), Int. J. Theor. Appl.
Finance, 15, No. 1, we use stochastic filtering to transform the original
problem into an optimization problem under full information where the state
variable is the filter for the Markov chain. The dynamic programming equation
for this problem is studied with viscosity-solution techniques and with
regularization arguments.
"
1303.2950,2014-06-04,Dynamic Credit Investment in Partially Observed Markets,"  We consider the problem of maximizing expected utility for a power investor
who can allocate his wealth in a stock, a defaultable security, and a money
market account. The dynamics of these security prices are governed by geometric
Brownian motions modulated by a hidden continuous time finite state Markov
chain. We reduce the partially observed stochastic control problem to a
complete observation risk sensitive control problem via the filtered regime
switching probabilities. We separate the latter into pre-default and
post-default dynamic optimization subproblems, and obtain two coupled
Hamilton-Jacobi-Bellman (HJB) partial differential equations. We prove
existence and uniqueness of a globally bounded classical solution to each HJB
equation, and give the corresponding verification theorem. We provide a
numerical analysis showing that the investor increases his holdings in stock as
the filter probability of being in high growth regimes increases, and decreases
his credit risk exposure when the filter probability of being in high default
risk regimes gets larger.
"
1303.3148,2015-05-18,"The General Structure of Optimal Investment and Consumption with Small
  Transaction Costs","  We investigate the general structure of optimal investment and consumption
with small proportional transaction costs. For a safe asset and a risky asset
with general continuous dynamics, traded with random and time-varying but small
transaction costs, we derive simple formal asymptotics for the optimal policy
and welfare. These reveal the roles of the investors' preferences as well as
the market and cost dynamics, and also lead to a fully dynamic model for the
implied trading volume. In frictionless models that can be solved in closed
form, explicit formulas for the leading-order corrections due to small
transaction costs are obtained.
"
1303.3956,2013-03-19,A liability tracking approach to long term management of pension funds,"  We propose a long term portfolio management method which takes into account a
liability. Our approach is based on the LQG (Linear, Quadratic cost, Gaussian)
control problem framework and then the optimal portfolio strategy hedges the
liability by directly tracking a benchmark process which represents the
liability. Two numerical results using empirical data published by Japanese
organizations are served: simulations tracking an artificial liability and an
estimated liability of Japanese organization. The latter one demonstrates that
our optimal portfolio strategy can hedge his or her liability.
"
1303.4314,2014-01-14,"Reinvestigating the Uncovered Interest Rate Parity Puzzle via Analysis
  of Multivariate Tail Dependence in Currency Carry Trades","  The currency carry trade is the investment strategy that involves selling low
interest rate currencies in order to purchase higher interest rate currencies,
thus profiting from the interest rate differentials. This is a well known
financial puzzle to explain, since assuming foreign exchange risk is
uninhibited and the markets have rational risk-neutral investors, then one
would not expect profits from such strategies. That is uncovered interest rate
parity (UIP), the parity condition in which exposure to foreign exchange risk,
with unanticipated changes in exchange rates, should result in an outcome that
changes in the exchange rate should offset the potential to profit from such
interest rate differentials. The two primary assumptions required for interest
rate parity are related to capital mobility and perfect substitutability of
domestic and foreign assets. Given foreign exchange market equilibrium, the
interest rate parity condition implies that the expected return on domestic
assets will equal the exchange rate-adjusted expected return on foreign
currency assets.
  However, it has been shown empirically, that investors can actually earn
arbitrage profits by borrowing in a country with a lower interest rate,
exchanging for foreign currency, and investing in a foreign country with a
higher interest rate, whilst allowing for any losses (or gains) from exchanging
back to their domestic currency at maturity. Therefore trading strategies that
aim to exploit the interest rate differentials can be profitable on average.
The intention of this paper is therefore to reinterpret the currency carry
trade puzzle in light of heavy tailed marginal models coupled with multivariate
tail dependence features in the analysis of the risk-reward for the currency
portfolios with high interest rate differentials and low interest rate
differentials.
"
1304.1420,2015-02-20,Fluctuation Analysis for the Loss From Default,"  We analyze the fluctuation of the loss from default around its large
portfolio limit in a class of reduced-form models of correlated firm-by-firm
default timing. We prove a weak convergence result for the fluctuation process
and use it for developing a conditionally Gaussian approximation to the loss
distribution. Numerical results illustrate the accuracy and computational
efficiency of the approximation.
"
1304.1821,2018-11-27,"Optimal initiation of a GLWB in a variable annuity: no arbitrage
  approach","  This paper offers a financial economic perspective on the optimal time (and
age) at which the owner of a Variable Annuity (VA) policy with a Guaranteed
Living Withdrawal Benefit (GLWB) rider should initiate guaranteed lifetime
income payments. We abstract from utility, bequest and consumption preference
issues by treating the VA as liquid and tradable. This allows us to use an
American option pricing framework to derive a so-called optimal initiation
region. Our main practical finding is that given current design parameters in
which volatility (asset allocation) is restricted to less than 20%, while
guaranteed payout rates (GPR) as well as bonus (roll-up) rates are less than
5%, GLWBs that are in-the-money should be turned on by the late 50s and
certainly the early 60s. The exception to the rule is when a non-constant GPR
is about to increase (soon) to a higher age band, in which case the optimal
policy is to wait until the new GPR is hit and then initiate immediately. Also,
to offer a different perspective, we invert the model and solve for the bonus
(roll-up) rate that is required to justify delaying initiation at any age. We
find that the required bonus is quite high and more than what is currently
promised by existing products. Our methodology and results should be of
interest to researchers as well as to the individuals that collectively have
over \$1 USD trillion in aggregate invested in these products. We conclude by
suggesting that much of the non-initiation at older age is irrational (which
obviously benefits the insurance industry.)
"
1304.1999,2013-10-21,Mirror and Synchronous Couplings of Geometric Brownian Motions,"  The paper studies the question of whether the classical mirror and
synchronous couplings of two Brownian motions minimise and maximise,
respectively, the coupling time of the corresponding geometric Brownian
motions. We establish a characterisation of the optimality of the two couplings
over any finite time horizon and show that, unlike in the case of Brownian
motion, the optimality fails in general even if the geometric Brownian motions
are martingales. On the other hand, we prove that in the cases of the ergodic
average and the infinite time horizon criteria, the mirror coupling and the
synchronous coupling are always optimal for general (possibly non-martingale)
geometric Brownian motions. We show that the two couplings are efficient if and
only if they are optimal over a finite time horizon and give a conjectural
answer for the efficient couplings when they are suboptimal.
"
1304.3284,2017-01-31,"Existence and uniqueness of Arrow-Debreu equilibria with consumptions in
  $\mathbf{L}^0_+$","  We consider an economy where agents' consumption sets are given by the cone
$\mathbf{L}^0_+$ of non-negative measurable functions and whose preferences are
defined by additive utilities satisfying the Inada conditions. We extend to
this setting the results in \citet{Dana:93} on the existence and uniqueness of
Arrow-Debreu equilibria. In the case of existence, our conditions are necessary
and sufficient.
"
1304.4590,2013-04-18,"Double Whammy - How ICT Projects are Fooled by Randomness and Screwed by
  Political Intent","  The cost-benefit analysis formulates the holy trinity of objectives of
project management - cost, schedule, and benefits. As our previous research has
shown, ICT projects deviate from their initial cost estimate by more than 10%
in 8 out of 10 cases. Academic research has argued that Optimism Bias and Black
Swan Blindness cause forecasts to fall short of actual costs. Firstly, optimism
bias has been linked to effects of deception and delusion, which is caused by
taking the inside-view and ignoring distributional information when making
decisions. Secondly, we argued before that Black Swan Blindness makes
decision-makers ignore outlying events even if decisions and judgements are
based on the outside view. Using a sample of 1,471 ICT projects with a total
value of USD 241 billion - we answer the question: Can we show the different
effects of Normal Performance, Delusion, and Deception? We calculated the
cumulative distribution function (CDF) of (actual-forecast)/forecast. Our
results show that the CDF changes at two tipping points - the first one
transforms an exponential function into a Gaussian bell curve. The second
tipping point transforms the bell curve into a power law distribution with the
power of 2. We argue that these results show that project performance up to the
first tipping point is politically motivated and project performance above the
second tipping point indicates that project managers and decision-makers are
fooled by random outliers, because they are blind to thick tails. We then show
that Black Swan ICT projects are a significant source of uncertainty to an
organisation and that management needs to be aware of.
"
1304.5040,2015-09-08,Dynamic robust duality in utility maximization,"  A celebrated financial application of convex duality theory gives an explicit
relation between the following two quantities:
  (i) The optimal terminal wealth $X^*(T) : = X_{\varphi^*}(T)$ of the problem
to maximize the expected $U$-utility of the terminal wealth $X_{\varphi}(T)$
generated by admissible portfolios $\varphi(t), 0 \leq t \leq T$ in a market
with the risky asset price process modeled as a semimartingale;
  (ii) The optimal scenario $\frac{dQ^*}{dP}$ of the dual problem to minimize
the expected $V$-value of $\frac{dQ}{dP}$ over a family of equivalent local
martingale measures $Q$, where $V$ is the convex conjugate function of the
concave function $U$.
  In this paper we consider markets modeled by It\^o-L\'evy processes. In the
first part we use the maximum principle in stochastic control theory to extend
the above relation to a \emph{dynamic} relation, valid for all $t \in [0,T]$.
We prove in particular that the optimal adjoint process for the primal problem
coincides with the optimal density process, and that the optimal adjoint
process for the dual problem coincides with the optimal wealth process, $0 \leq
t \leq T$. In the terminal time case $t=T$ we recover the classical duality
connection above. We get moreover an explicit relation between the optimal
portfolio $\varphi^*$ and the optimal measure $Q^*$. We also obtain that the
existence of an optimal scenario is equivalent to the replicability of a
related $T$-claim.
  In the second part we present robust (model uncertainty) versions of the
optimization problems in (i) and (ii), and we prove a similar dynamic relation
between them. In particular, we show how to get from the solution of one of the
problems to the other. We illustrate the results with explicit examples.
"
1304.7562,2013-04-30,"Balancing small fixed and proportional transaction cost in trading
  strategies","  Transaction costs appear in financial markets in more than one form. There
are several results in the literature on small proportional transaction cost
and not that many on fixed transaction cost. In the present work, we
heuristically study the effect of both types of transaction cost by focusing on
a portfolio optimization. Here we assume the presence of fixed transaction cost
and that there is a balance between fixed and proportional transaction cost,
such that none of them dominates the other, asymptotically. We find out that
the deviation of value function, when the fixed transaction cost is
$\varepsilon$, from the Merton value function, without transaction cost, is of
order $\varepsilon^1/2$ which is different from the pure proportional cost of
$\varepsilon^2/3$. Based on this, we propose an expansion for the value
function in terms of powers of $\varepsilon^1/2$.
"
1304.7878,2013-11-06,On the Dividend Strategies with Non-Exponential Discounting,"  In this paper, we study the dividend strategies for a shareholder with
non-constant discount rate in a diffusion risk model. We assume that the
dividends can only be paid at a bounded rate and restrict ourselves to the
Markov strategies. This is a time inconsistent control problem. The extended
HJB equation is given and the verification theorem is proved for a general
discount function. Considering the pseudo-exponential discount functions (Type
I and Type II), we get the equilibrium dividend strategies and the equilibrium
value functions by solving the extended HJB equations.
"
1305.0144,2013-05-14,Relative Robust Portfolio Optimization,"  Considering mean-variance portfolio problems with uncertain model parameters,
we contrast the classical absolute robust optimization approach with the
relative robust approach based on a maximum regret function. Although the
latter problems are NP-hard in general, we show that tractable inner and outer
approximations exist in several cases that are of central interest in asset
management.
"
1305.5915,2014-01-17,Model-free CPPI,"  We consider Constant Proportion Portfolio Insurance (CPPI) and its dynamic
extension, which may be called Dynamic Proportion Portfolio Insurance (DPPI).
It is shown that these investment strategies work within the setting of
F\""ollmer's pathwise It\^o calculus, which makes no probabilistic assumptions
whatsoever. This shows, on the one hand, that CPPI and DPPI are completely
independent of any choice of a particular model for the dynamics of asset
prices. They even make sense beyond the class of semimartingale sample paths
and can be successfully defined for models admitting arbitrage, including some
models based on fractional Brownian motion. On the other hand, the result can
be seen as a case study for the general issue of robustness in the face of
model uncertainty in finance.
"
1305.6831,2013-05-30,"Optimal portfolios of a long-term investor with floor or drawdown
  constraints","  We study the portfolio selection problem of a long-run investor who is
maximising the asymptotic growth rate of her expected utility. We show that,
somewhat surprisingly, it is essentially not affected by introduction of a
floor constraint which requires the wealth process to dominate a given
benchmark at all times. We further study the notion of long-run optimality of
wealth processes via convergence of finite horizon value functions to the
asymptotic optimal value. We characterise long-run optimality under floor and
drawdown constraints.
"
1305.7309,2013-06-03,Optimization problem under change of regime of interest rate,"  In this paper, we study the classical problem of maximization of the sum of
the utility of the terminal wealth and the utility of the consumption, in a
case where a sudden jump in the risk-free interest rate creates incompleteness.
The value function of the dual problem is proved to be solution of a BSDE and
the duality between the primal and the dual value functions is exploited to
study the BSDE associated to the primal problem.
"
1306.0938,2013-06-06,"The Dirichlet Portfolio Model: Uncovering the Hidden Composition of
  Hedge Fund Investments","  Hedge funds have long been viewed as a veritable ""black box"" of investing
since outsiders may never view the exact composition of portfolio holdings.
Therefore, the ability to estimate an informative set of asset weights is
highly desirable for analysis. We present a compositional state space model for
estimation of an investment portfolio's unobserved asset allocation weightings
on a set of candidate assets when the only observed information is the time
series of portfolio returns and the candidate asset returns. In this paper, we
exhibit both sequential Monte Carlo numerical and conditionally Normal
analytical approaches to solve for estimates of the unobserved asset weight
time series. This methodology is motivated by the estimation of monthly asset
class weights on the aggregate hedge fund industry from 1996 to 2012.
Furthermore, we show how to implement the results as predictive investment
weightings in order to construct hedge fund replicating portfolios.
"
1306.2508,2016-09-20,Phase Transition in the S&P Stock Market,"  We analyze the stock prices of the S&P market from 1987 until 2012 with the
covariance matrix of the firm returns determined in time windows of several
years. The eigenvector belonging to the leading eigenvalue (market) exhibits in
its long term time dependence a phase transition with an order parameter which
can be interpreted within an agent-based model. From 1995 to 2005 the market is
in an ordered state and after 2005 in a disordered state.
"
1306.2751,2014-08-19,Robust Portfolios and Weak Incentives in Long-Run Investments,"  When the planning horizon is long, and the safe asset grows indefinitely,
isoelastic portfolios are nearly optimal for investors who are close to
isoelastic for high wealth, and not too risk averse for low wealth. We prove
this result in a general arbitrage-free, frictionless, semimartingale model. As
a consequence, optimal portfolios are robust to the perturbations in
preferences induced by common option compensation schemes, and such incentives
are weaker when their horizon is longer. Robust option incentives are possible,
but require several, arbitrarily large exercise prices, and are not always
convex.
"
1306.2802,2013-10-23,Asymptotics for Fixed Transaction Costs,"  An investor with constant relative risk aversion trades a safe and several
risky assets with constant investment opportunities. For a small fixed
transaction cost, levied on each trade regardless of its size, we explicitly
determine the leading-order corrections to the frictionless value function and
optimal policy.
"
1306.3359,2013-11-26,"Making Mean-Variance Hedging Implementable in a Partially Observable
  Market","  The mean-variance hedging (MVH) problem is studied in a partially observable
market where the drift processes can only be inferred through the observation
of asset or index processes. Although most of the literatures treat the MVH
problem by the duality method, here we study a system consisting of three BSDEs
derived by Mania and Tevzadze (2003) and Mania et.al.(2008) and try to provide
more explicit expressions directly implementable by practitioners. Under the
Bayesian and Kalman-Bucy frameworks, we find that a relevant BSDE yields a
semi-closed solution via a simple set of ODEs which allow a quick numerical
evaluation. This renders remaining problems equivalent to solving European
contingent claims under a new forward measure, and it is straightforward to
obtain a forward looking non-sequential Monte Carlo simulation scheme. We also
give a special example where the hedging position is available in a semi-closed
form. For more generic setups, we provide explicit expressions of approximate
hedging portfolio by an asymptotic expansion. These analytic expressions not
only allow the hedgers to update the hedging positions in real time but also
make a direct analysis of the terminal distribution of the hedged portfolio
feasible by standard Monte Carlo simulation.
"
1306.3437,2014-08-14,"A cutting surface algorithm for semi-infinite convex programming with an
  application to moment robust optimization","  We present and analyze a central cutting surface algorithm for general
semi-infinite convex optimization problems, and use it to develop a novel
algorithm for distributionally robust optimization problems in which the
uncertainty set consists of probability distributions with given bounds on
their moments. Moments of arbitrary order, as well as non-polynomial moments
can be included in the formulation. We show that this gives rise to a hierarchy
of optimization problems with decreasing levels of risk-aversion, with classic
robust optimization at one end of the spectrum, and stochastic programming at
the other. Although our primary motivation is to solve distributionally robust
optimization problems with moment uncertainty, the cutting surface method for
general semi-infinite convex programs is also of independent interest. The
proposed method is applicable to problems with non-differentiable semi-infinite
constraints indexed by an infinite-dimensional index set. Examples comparing
the cutting surface algorithm to the central cutting plane algorithm of
Kortanek and No demonstrate the potential of our algorithm even in the solution
of traditional semi-infinite convex programming problems whose constraints are
differentiable and are indexed by an index set of low dimension. After the rate
of convergence analysis of the cutting surface algorithm, we extend the
authors' moment matching scenario generation algorithm to a probabilistic
algorithm that finds optimal probability distributions subject to moment
constraints. The combination of this distribution optimization method and the
central cutting surface algorithm yields a solution to a family of
distributionally robust optimization problems that are considerably more
general than the ones proposed to date.
"
1306.4958,2013-06-21,"Hedging and Leveraging: Principal Portfolios of the Capital Asset
  Pricing Model","  The principal portfolios of the standard Capital Asset Pricing Model (CAPM)
are analyzed and found to have remarkable hedging and leveraging properties.
Principal portfolios implement a recasting of any correlated asset set of N
risky securities into an equivalent but uncorrelated set when short sales are
allowed. While a determination of principal portfolios in general requires a
detailed knowledge of the covariance matrix for the asset set, the rather
simple structure of CAPM permits an accurate solution for any reasonably large
asset set that reveals interesting universal properties. Thus for an asset set
of size N, we find a market-aligned portfolio, corresponding to the market
portfolio of CAPM, as well as N-1 market-orthogonal portfolios which are market
neutral and strongly leveraged. These results provide new insight into the
return-volatility structure of CAPM, and demonstrate the effect of unbridled
leveraging on volatility.
"
1306.5510,2013-06-25,"Compound Wishart Matrices and Noisy Covariance Matrices: Risk
  Underestimation","  In this paper, we obtain a property of the expectation of the inverse of
compound Wishart matrices which results from their orthogonal invariance. Using
this property as well as results from random matrix theory (RMT), we derive the
asymptotic effect of the noise induced by estimating the covariance matrix on
computing the risk of the optimal portfolio. This in turn enables us to get an
asymptotically unbiased estimator of the risk of the optimal portfolio not only
for the case of independent observations but also in the case of correlated
observations. This improvement provides a new approach to estimate the risk of
a portfolio based on covariance matrices estimated from exponentially weighted
moving averages of stock returns.
"
1307.0114,2013-09-03,Risk Without Return,"  Risk-only investment strategies have been growing in popularity as
traditional in- vestment strategies have fallen short of return targets over
the last decade. However, risk-based investors should be aware of four things.
First, theoretical considerations and empirical studies show that apparently
dictinct risk-based investment strategies are manifestations of a single
effect. Second, turnover and associated transaction costs can be a substantial
drag on return. Third, capital diversification benefits may be reduced. Fourth,
there is an apparent connection between performance and risk diversification.
To analyze risk diversification benefits in a consistent way, we introduce the
Risk Diversification Index (RDI) which measures risk concentrations and
complements the Herfindahl-Herschman Index (HHI) for capital concentrations.
"
1307.0450,2013-11-12,Portfolio Optimization in R,"  We consider the problem of finding the efficient frontier associated with the
risk-return portfolio optimization model. We derive the analytical expression
of the efficient frontier for a portfolio of N risky assets, and for the case
when a risk-free asset is added to the model. Also, we provide an R
implementation, and we discuss in detail a numerical example of a portfolio of
several risky common stocks.
"
1307.0785,2013-07-03,"Explicit Description of HARA Forward Utilities and Their Optimal
  Portfolios","  This paper deals with forward performances of HARA type. Precisely, for a
market model in which stock price processes are modeled by a locally bounded
$d$-dimensional semimartingale, we elaborate a complete and explicit
characterization for this type of forward utilities. Furthermore, the optimal
portfolios for each of these forward utilities are explicitly described. Our
approach is based on the minimal Hellinger martingale densities that are
obtained from the important statistical concept of Hellinger process. These
martingale densities were introduced recently, and appeared herein tailor-made
for these forward utilities. After outlining our parametrization method for the
HARA forward, we provide illustrations on discrete-time market models. Finally,
we conclude our paper by pointing out a number of related open questions.
"
1307.0872,2014-09-23,Maximization of recursive utilities under convex portfolio constraints,"  We study a robust maximization problem from terminal wealth and consumption
under a convex constraints on the portfolio. We state the existence and the
uniqueness of the consumption-investment strategy by studying the associated
quadratic backward stochastic differential equation (BSDE in short). We
characterize the optimal control by using the duality method and deriving a
dynamic maximum principle.
"
1307.2824,2016-11-02,"Optimal Retirement Tontines for the 21st Century: With Reference to
  Mortality Derivatives in 1693","  Historical tontines promised enormous rewards to the last survivors at the
expense of those who died early. While this design appealed to the gambling
instinct, it is a suboptimal way to manage longevity risk during retirement.
This is why fair life annuities making constant payments -- where the insurance
company is exposed to the longevity risk -- induces greater lifetime utility.
However, tontines do not have to be designed using a winner-take-all approach
and insurance companies do not actually sell fair life annuities, partially due
to aggregate longevity risk.
  In this paper we derive the tontine structure that maximizes lifetime
utility, but doesn't expose the sponsor to any longevity risk. We examine its
sensitivity to the size of the tontine pool; individual longevity risk
aversion; and subjective health status. The optimal tontine varies with the
individual's longevity risk aversion $\gamma$ and the number of participants
$n$, which is problematic for product design. That said, we introduce a
structure called a natural tontine whose payout declines in exact proportion to
the (expected) survival probabilities, which is near-optimal for all $\gamma$
and $n$. We compare the utility of optimal tontines to the utility of loaded
life annuities under reasonable demographic and economic conditions and find
that the life annuity's advantage over tontines, is minimal.
  We also review and analyze the first-ever mortality-derivative issued by the
British government, known as King Williams's tontine of 1693. We shed light on
the preferences and beliefs of those who invested in the tontines vs. the
annuities and argue that tontines should be re-introduced and allowed to
co-exist with life annuities. Individuals would likely select a portfolio of
tontines and annuities that suit their personal preferences for consumption and
longevity risk, as they did over 320 years ago.
"
1307.2849,2018-05-23,"Continuous-Time Public Good Contribution under Uncertainty: A Stochastic
  Control Approach","  In this paper we study continuous-time stochastic control problems with both
monotone and classical controls motivated by the so-called public good
contribution problem. That is the problem of n economic agents aiming to
maximize their expected utility allocating initial wealth over a given time
period between private consumption and irreversible contributions to increase
the level of some public good. We investigate the corresponding social planner
problem and the case of strategic interaction between the agents, i.e. the
public good contribution game. We show existence and uniqueness of the social
planner's optimal policy, we characterize it by necessary and sufficient
stochastic Kuhn-Tucker conditions and we provide its expression in terms of the
unique optional solution of a stochastic backward equation. Similar stochastic
first order conditions prove to be very useful for studying any Nash equilibria
of the public good contribution game. In the symmetric case they allow us to
prove (qualitative) uniqueness of the Nash equilibrium, which we again
construct as the unique optional solution of a stochastic backward equation. We
finally also provide a detailed analysis of the so-called free rider effect.
"
1307.3597,2013-07-16,Utility Maximization under Model Uncertainty in Discrete Time,"  We give a general formulation of the utility maximization problem under
nondominated model uncertainty in discrete time and show that an optimal
portfolio exists for any utility function that is bounded from above. In the
unbounded case, integrability conditions are needed as nonexistence may arise
even if the value function is finite.
"
1307.3672,2013-07-25,"Transformation Method for Solving Hamilton-Jacobi-Bellman Equation for
  Constrained Dynamic Stochastic Optimal Allocation Problem","  In this paper we propose and analyze a method based on the Riccati
transformation for solving the evolutionary Hamilton-Jacobi-Bellman equation
arising from the stochastic dynamic optimal allocation problem. We show how the
fully nonlinear Hamilton-Jacobi-Bellman equation can be transformed into a
quasi-linear parabolic equation whose diffusion function is obtained as the
value function of certain parametric convex optimization problem. Although the
diffusion function need not be sufficiently smooth, we are able to prove
existence, uniqueness and derive useful bounds of classical H\""older smooth
solutions. We furthermore construct a fully implicit iterative numerical scheme
based on finite volume approximation of the governing equation. A numerical
solution is compared to a semi-explicit traveling wave solution by means of the
convergence ratio of the method. We compute optimal strategies for a portfolio
investment problem motivated by the German DAX 30 Index as an example of
application of the method.
"
1307.4813,2013-07-19,On utility maximization with derivatives under model uncertainty,"  We consider the robust utility maximization using a static holding in
derivatives and a dynamic holding in the stock. There is no fixed model for the
price of the stock but we consider a set of probability measures (models) which
are not necessarily dominated by a fixed probability measure. By assuming that
the set of physical probability measures is convex and weakly compact, we
obtain the duality result and the existence of an optimizer.
"
1307.5163,2014-03-18,"Dynamic Programming for controlled Markov families: abstractly and over
  Martingale Measures","  We describe an abstract control-theoretic framework in which the validity of
the dynamic programming principle can be established in continuous time by a
verification of a small number of structural properties. As an application we
treat several cases of interest, most notably the lower-hedging and
utility-maximization problems of financial mathematics both of which are
naturally posed over ``sets of martingale measures''.
"
1307.5981,2015-02-11,"Are benefits from oil - stocks diversification gone? New evidence from a
  dynamic copula and high frequency data","  Oil is perceived as a good diversification tool for stock markets. To fully
understand this potential, we propose a new empirical methodology that combines
generalized autoregressive score copula functions with high frequency data and
allows us to capture and forecast the conditional time-varying joint
distribution of the oil -- stocks pair accurately. Our realized GARCH with
time-varying copula yields statistically better forecasts of the dependence and
quantiles of the distribution relative to competing models. Employing a
recently proposed conditional diversification benefits measure that considers
higher-order moments and nonlinear dependence from tail events, we document
decreasing benefits from diversification over the past ten years. The
diversification benefits implied by our empirical model are, moreover, strongly
varied over time. These findings have important implications for asset
allocation, as the benefits of including oil in stock portfolios may not be as
large as perceived.
"
1307.6036,2014-02-07,A Benchmark Approach to Risk-Minimization under Partial Information,"  In this paper we study a risk-minimizing hedging problem for a semimartingale
incomplete financial market where d+1 assets are traded continuously and whose
price is expressed in units of the num\'{e}raire portfolio. According to the
so-called benchmark approach, we investigate the (benchmarked) risk-minimizing
strategy in the case where there are restrictions on the available information.
More precisely, we characterize the optimal strategy as the integrand appearing
in the Galtchouk-Kunita-Watanabe decomposition of the benchmarked claim under
partial information and provide its description in terms of the integrands in
the classical Galtchouk-Kunita-Watanabe decomposition under full information
via dual predictable projections. Finally, we apply the results in the case of
a Markovian jump-diffusion driven market model where the assets prices dynamics
depend on a stochastic factor which is not observable by investors.
"
1308.1321,2013-08-07,Asset Allocation under the Basel Accord Risk Measures,"  Financial institutions are currently required to meet more stringent capital
requirements than they were before the recent financial crisis; in particular,
the capital requirement for a large bank's trading book under the Basel 2.5
Accord more than doubles that under the Basel II Accord. The significant
increase in capital requirements renders it necessary for banks to take into
account the constraint of capital requirement when they make asset allocation
decisions. In this paper, we propose a new asset allocation model that
incorporates the regulatory capital requirements under both the Basel 2.5
Accord, which is currently in effect, and the Basel III Accord, which was
recently proposed and is currently under discussion. We propose an unified
algorithm based on the alternating direction augmented Lagrangian method to
solve the model; we also establish the first-order optimality of the limit
points of the sequence generated by the algorithm under some mild conditions.
The algorithm is simple and easy to implement; each step of the algorithm
consists of solving convex quadratic programming or one-dimensional
subproblems. Numerical experiments on simulated and real market data show that
the algorithm compares favorably with other existing methods, especially in
cases in which the model is non-convex.
"
1308.2254,2014-02-03,"Optimal investment for all time horizons and Martin boundary of
  space-time diffusions","  This paper is concerned with the axiomatic foundation and explicit
construction of a general class of optimality criteria that can be used for
investment problems with multiple time horizons, or when the time horizon is
not known in advance. Both the investment criterion and the optimal strategy
are characterized by the Hamilton-Jacobi-Bellman equation on a semi-infinite
time interval. In the case when this equation can be linearized, the problem
reduces to a time-reversed parabolic equation, which cannot be analyzed via the
standard methods of partial differential equations. Under the additional
uniform ellipticity condition, we make use of the available description of all
minimal solutions to such equations, along with some basic facts from potential
theory and convex analysis, to obtain an explicit integral representation of
all positive solutions. These results allow us to construct a large family of
the aforementioned optimality criteria, including some closed form examples in
relevant financial models.
"
1308.2324,2013-08-19,Optimal Dynamic Portfolio with Mean-CVaR Criterion,"  Value-at-Risk (VaR) and Conditional Value-at-Risk (CVaR) are popular risk
measures from academic, industrial and regulatory perspectives. The problem of
minimizing CVaR is theoretically known to be of Neyman-Pearson type binary
solution. We add a constraint on expected return to investigate the Mean-CVaR
portfolio selection problem in a dynamic setting: the investor is faced with a
Markowitz type of risk reward problem at final horizon where variance as a
measure of risk is replaced by CVaR. Based on the complete market assumption,
we give an analytical solution in general. The novelty of our solution is that
it is no longer Neyman-Pearson type where the final optimal portfolio takes
only two values. Instead, in the case where the portfolio value is required to
be bounded from above, the optimal solution takes three values; while in the
case where there is no upper bound, the optimal investment portfolio does not
exist, though a three-level portfolio still provides a sub-optimal solution.
"
1308.4276,2013-08-21,"Semiparametric Conditional Quantile Models for Financial Returns and
  Realized Volatility","  This paper investigates how the conditional quantiles of future returns and
volatility of financial assets vary with various measures of ex-post variation
in asset prices as well as option-implied volatility. We work in the flexible
quantile regression framework and rely on recently developed model-free
measures of integrated variance, upside and downside semivariance, and jump
variation. Our results for the S&P 500 and WTI Crude Oil futures contracts show
that simple linear quantile regressions for returns and heterogenous quantile
autoregressions for realized volatility perform very well in capturing the
dynamics of the respective conditional distributions, both in absolute terms as
well as relative to a couple of well-established benchmark models. The models
can therefore serve as useful risk management tools for investors trading the
futures contracts themselves or various derivative contracts written on
realized volatility.
"
1308.5376,2016-01-05,"Energy, entropy, and arbitrage","  We introduce a pathwise approach to analyze the relative performance of an
equity portfolio with respect to a benchmark market portfolio. In this
energy-entropy framework, the relative performance is decomposed into three
components: a volatility term, a relative entropy term measuring the distance
between the portfolio weights and the market capital distribution, and another
entropy term that can be controlled by the investor by adopting a suitable
rebalancing strategy. This framework leads to a class of portfolio strategies
that allows one to outperform, in the long run, a market that is diverse and
sufficiently volatile in the sense of stochastic portfolio theory. The
framework is illustrated with several empirical examples.
"
1308.6120,2013-09-27,"Can we still benefit from international diversification? The case of the
  Czech and German stock markets","  One of the findings of the recent literature is that the 2008 financial
crisis caused reduction in international diversification benefits. To fully
understand the possible potential from diversification, we build an empirical
model which combines generalised autoregressive score copula functions with
high frequency data, and allows us to capture and forecast the conditional
time-varying joint distribution of stock returns. Using this novel methodology
and fresh data covering five years after the crisis, we compute the conditional
diversification benefits to answer the question, whether it is still
interesting for an international investor to diversify. As diversification
tools, we consider the Czech PX and the German DAX broad stock indices, and we
find that the diversification benefits strongly vary over the 2008--2013 crisis
years.
"
1308.6465,2014-07-03,Optimal Payoffs under State-dependent Preferences,"  Most decision theories, including expected utility theory, rank dependent
utility theory and cumulative prospect theory, assume that investors are only
interested in the distribution of returns and not in the states of the economy
in which income is received. Optimal payoffs have their lowest outcomes when
the economy is in a downturn, and this feature is often at odds with the needs
of many investors. We introduce a framework for portfolio selection within
which state-dependent preferences can be accommodated. Specifically, we assume
that investors care about the distribution of final wealth and its interaction
with some benchmark. In this context, we are able to characterize optimal
payoffs in explicit form. Furthermore, we extend the classical expected utility
optimization problem of Merton to the state-dependent situation. Some
applications in security design are discussed in detail and we also solve some
stochastic extensions of the target probability optimization problem.
"
1309.0362,2014-03-18,"Continuous-Time Portfolio Optimisation for a Behavioural Investor with
  Bounded Utility on Gains","  This paper examines an optimal investment problem in a continuous-time
(essentially) complete financial market with a finite horizon. We deal with an
investor who behaves consistently with principles of Cumulative Prospect
Theory, and whose utility function on gains is bounded above. The
well-posedness of the optimisation problem is trivial, and a necessary
condition for the existence of an optimal trading strategy is derived. This
condition requires that the investor's probability distortion function on
losses does not tend to 0 near 0 faster than a given rate, which is determined
by the utility function. Under additional assumptions, we show that this
condition is indeed the borderline for attainability, in the sense that for
slower convergence of the distortion function there does exist an optimal
portfolio.
"
1309.0474,2017-07-07,"Smooth solutions to portfolio liquidation problems under price-sensitive
  market impact","  We consider the stochastic control problem of a financial trader that needs
to unwind a large asset portfolio within a short period of time. The trader can
simultaneously submit active orders to a primary market and passive orders to a
dark pool. Our framework is flexible enough to allow for price-dependent impact
functions describing the trading costs in the primary market and
price-dependent adverse selection costs associated with dark pool trading. We
prove that the value function can be characterized in terms of the unique
smooth solution to a PDE with singular terminal value, establish its explicit
asymptotic behavior at the terminal time, and give the optimal trading strategy
in feedback form.
"
1309.1844,2014-02-04,"Investment under uncertainty, competition and regulation","  We investigate a randomization procedure undertaken in real option games
which can serve as a basic model of regulation in a duopoly model of preemptive
investment. We recall the rigorous framework of [M. Grasselli, V. Lecl\`ere and
M. Ludkovsky, Priority Option: the value of being a leader, International
Journal of Theoretical and Applied Finance, 16, 2013], and extend it to a
random regulator. This model generalizes and unifies the different competitive
frameworks proposed in the literature, and creates a new one similar to a
Stackelberg leadership. We fully characterize strategic interactions in the
several situations following from the parametrization of the regulator.
Finally, we study the effect of the coordination game and uncertainty of
outcome when agents are risk-averse, providing new intuitions for the standard
case.
"
1309.3102,2015-01-15,A nested factor model for non-linear dependences in stock returns,"  The aim of our work is to propose a natural framework to account for all the
empirically known properties of the multivariate distribution of stock returns.
We define and study a ""nested factor model"", where the linear factors part is
standard, but where the log-volatility of the linear factors and of the
residuals are themselves endowed with a factor structure and residuals. We
propose a calibration procedure to estimate these log-vol factors and the
residuals. We find that whereas the number of relevant linear factors is
relatively large (10 or more), only two or three log-vol factors emerge in our
analysis of the data. In fact, a minimal model where only one log-vol factor is
considered is already very satisfactory, as it accurately reproduces the
properties of bivariate copulas, in particular the dependence of the
medial-point on the linear correlation coefficient, as reported in
Chicheportiche and Bouchaud (2012). We have tested the ability of the model to
predict Out-of-Sample the risk of non-linear portfolios, and found that it
performs significantly better than other schemes.
"
1309.3479,2013-09-16,"Portfolio Optimization under Small Transaction Costs: a Convex Duality
  Approach","  We consider an investor with constant absolute risk aversion who trades a
risky asset with general Ito dynamics, in the presence of small proportional
transaction costs. Kallsen and Muhle-Karbe (2012) formally derived the
leading-order optimal trading policy and the associated welfare impact of
transaction costs. In the present paper, we carry out a convex duality approach
facilitated by the concept of shadow price processes in order to verify the
main results of Kallsen and Muhle-Karbe under well-defined regularity
conditions.
"
1309.3721,2013-09-19,"Asymptotic analysis for Merton's problem with transaction costs in power
  utility case","  We revisit the optimal investment and consumption problem with proportional
transaction costs. We prove that both the value function and the slopes of the
lines demarcating the no-trading region are analytic functions of cube root of
the transaction cost parameter. Also, we can explicitly calculate the
coefficients of the fractional power series expansions of the value function
and the no-trading region.
"
1309.4916,2014-09-12,Hedging under an expected loss constraint with small transaction costs,"  We consider the problem of option hedging in a market with proportional
transaction costs. Since super-replication is very costly in such markets, we
replace perfect hedging with an expected loss constraint. Asymptotic analysis
for small transactions is used to obtain a tractable model. A general expansion
theory is developed using the dynamic programming approach. Explicit formulae
are also obtained in the special cases of an exponential or power loss
function. As a corollary, we retrieve the asymptotics for the exponential
utility indifference price.
"
1309.5235,2015-02-27,Optimal Liquidity Provision,"  A small investor provides liquidity at the best bid and ask prices of a limit
order market. For small spreads and frequent orders of other market
participants, we explicitly determine the investor's optimal policy and
welfare. In doing so, we allow for general dynamics of the mid price, the
spread, and the order flow, as well as for arbitrary preferences of the
liquidity provider under consideration.
"
1309.7368,2015-07-01,"Modeling capital gains taxes for trading strategies of infinite
  variation","  In this article we show that the payment flow of a linear tax on trading
gains from a security with a semimartingale price process can be constructed
for all c\`agl\`ad and adapted trading strategies. It is characterized as the
unique continuous extension of the tax payments for elementary strategies
w.r.t. the convergence ""uniformly in probability"". In this framework we prove
that under quite mild assumptions dividend payoffs have almost surely a
negative effect on investor's after-tax wealth if the riskless interest rate is
always positive.
"
1310.1444,2013-10-08,Can Google Trends search queries contribute to risk diversification?,"  Portfolio diversification and active risk management are essential parts of
financial analysis which became even more crucial (and questioned) during and
after the years of the Global Financial Crisis. We propose a novel approach to
portfolio diversification using the information of searched items on Google
Trends. The diversification is based on an idea that popularity of a stock
measured by search queries is correlated with the stock riskiness. We penalize
the popular stocks by assigning them lower portfolio weights and we bring
forward the less popular, or peripheral, stocks to decrease the total riskiness
of the portfolio. Our results indicate that such strategy dominates both the
benchmark index and the uniformly weighted portfolio both in-sample and
out-of-sample.
"
1310.2964,2013-10-14,"Optimistic versus Pessimistic--Optimal Judgemental Bias with Reference
  Point","  This paper develops a model of reference-dependent assessment of subjective
beliefs in which loss-averse people optimally choose the expectation as the
reference point to balance the current felicity from the optimistic
anticipation and the future disappointment from the realisation. The choice of
over-optimism or over-pessimism depends on the real chance of success and
optimistic decision makers prefer receiving early information. In the portfolio
choice problem, pessimistic investors tend to trade conservatively, however,
they might trade aggressively if they are sophisticated enough to recognise the
biases since low expectation can reduce their fear of loss.
"
1310.2973,2014-09-30,Taylor approximation of incomplete Radner equilibrium models,"  In the setting of exponential investors and uncertainty governed by Brownian
motions we first prove the existence of an incomplete equilibrium for a general
class of models. We then introduce a tractable class of exponential-quadratic
models and prove that the corresponding incomplete equilibrium is characterized
by a coupled set of Riccati equations. Finally, we prove that these
exponential-quadratic models can be used to approximate the incomplete models
we studied in the first part.
"
1310.3396,2013-10-15,Seven Sins in Portfolio Optimization,"  Although modern portfolio theory has been in existence for over 60 years,
fund managers often struggle to get its models to produce reliable portfolio
allocations without strongly constraining the decision vector by tight bands of
strategic allocation targets. The two main root causes to this problem are
inadequate parameter estimation and numerical artifacts. When both obstacles
are overcome, portfolio models yield excellent allocations. In this paper,
which is primarily aimed at practitioners, we discuss the most common mistakes
in setting up portfolio models and in solving them algorithmically.
"
1310.3397,2013-10-16,Regression techniques for Portfolio Optimisation using MOSEK,"  Regression is widely used by practioners across many disciplines. We
reformulate the underlying optimisation problem as a second-order conic program
providing the flexibility often needed in applications. Using examples from
portfolio management and quantitative trading we solve regression problems with
and without constraints. Several Python code fragments are given. The code and
data are available online at http://www.github.com/tschm/MosekRegression.
"
1310.6822,2013-10-28,"Optimal Choice under Short Sell Limit with Sharpe Ratio as Criterion
  among Multiple Assets","  This article is the term paper of the course Investments. We mainly focus on
modeling long-term investment decisions of a typical utility-maximizing
individual, with features of Chinese stock market in perspective. We adopt an
OR based methodology with market information as input parameters to carry out
the solution. Two main features of this article are: first, we take the no
short-sell constraint in Chinese stock market into consideration and use an
approach otherwise identical to Markowitz to work out the optimal portfolio
choice; this method has critical and practical implication to Chinese
investors. Second, we incorporate the benefits of multiple assets into one
single well-defined utility function and use a MIQP procedure to derive the
optimal allocation of funds upon each of them along the time-line.
"
1311.0498,2015-02-20,Default Clustering in Large Pools: Large Deviations,"  We study large deviations and rare default clustering events in a dynamic
large heterogeneous portfolio of interconnected components. Defaults come as
Poisson events and the default intensities of the different components in the
system interact through the empirical default rate and via systematic effects
that are common to all components. We establish the large deviations principle
for the empirical default rate for such an interacting particle system. The
rate function is derived in an explicit form that is amenable to numerical
computations and derivation of the most likely path to failure for the system
itself. Numerical studies illustrate the theoretical findings. An understanding
of the role of the preferred paths to large default rates and the most likely
ways in which contagion and systematic risk combine to lead to large default
rates would give useful insights into how to optimally safeguard against such
events.
"
1311.1715,2013-11-08,"Portfolio Choice with Stochastic Investment Opportunities: a User's
  Guide","  This survey reviews portfolio choice in settings where investment
opportunities are stochastic due to, e.g., stochastic volatility or return
predictability. It is explained how to heuristically compute candidate optimal
portfolios using tools from stochastic control, and how to rigorously verify
their optimality by means of convex duality. Special emphasis is placed on
long-horizon asymptotics, that lead to particularly tractable results.
"
1311.1924,2015-04-21,Community detection for correlation matrices,"  A challenging problem in the study of complex systems is that of resolving,
without prior information, the emergent, mesoscopic organization determined by
groups of units whose dynamical activity is more strongly correlated internally
than with the rest of the system. The existing techniques to filter
correlations are not explicitly oriented towards identifying such modules and
can suffer from an unavoidable information loss. A promising alternative is
that of employing community detection techniques developed in network theory.
Unfortunately, this approach has focused predominantly on replacing network
data with correlation matrices, a procedure that tends to be intrinsically
biased due to its inconsistency with the null hypotheses underlying the
existing algorithms. Here we introduce, via a consistent redefinition of null
models based on random matrix theory, the appropriate correlation-based
counterparts of the most popular community detection techniques. Our methods
can filter out both unit-specific noise and system-wide dependencies, and the
resulting communities are internally correlated and mutually anti-correlated.
We also implement multiresolution and multifrequency approaches revealing
hierarchically nested sub-communities with `hard' cores and `soft' peripheries.
We apply our techniques to several financial time series and identify
mesoscopic groups of stocks which are irreducible to a standard, sectorial
taxonomy, detect `soft stocks' that alternate between communities, and discuss
implications for portfolio optimization and risk management.
"
1311.2511,2015-06-17,Spin Glasses and Nonlinear Constraints in Portfolio Optimization,"  We discuss the portfolio optimization problem with the obligatory deposits
constraint. Recently it has been shown that as a consequence of this nonlinear
constraint, the solution consists of an exponentially large number of optimal
portfolios, completely different from each other, and extremely sensitive to
any changes in the input parameters of the problem, making the concept of
rational decision making questionable. Here we reformulate the problem using a
quadratic obligatory deposits constraint, and we show that from the physics
point of view, finding an optimal portfolio amounts to calculating the
mean-field magnetizations of a random Ising model with the constraint of a
constant magnetization norm. We show that the model reduces to an eigenproblem,
with 2N solutions, where N is the number of assets defining the portfolio.
Also, in order to illustrate our results, we present a detailed numerical
example of a portfolio of several risky common stocks traded on the Nasdaq
Market.
"
1311.2550,2013-11-20,The Kelly growth optimal strategy with a stop-loss rule,"  From the Hamilton-Jacobi-Bellman equation for the value function we derive a
non-linear partial differential equation for the optimal portfolio strategy
(the dynamic control). The equation is general in the sense that it does not
depend on the terminal utility and provides additional analytical insight for
some optimal investment problems with known solutions. Furthermore, when
boundary conditions for the optimal strategy can be established independently,
it is considerably simpler than the HJB to solve numerically. Using this method
we calculate the Kelly growth optimal strategy subject to a periodically reset
stop-loss rule.
"
1311.3529,2014-11-17,"Time--consistent investment under model uncertainty: the robust forward
  criteria","  We combine forward investment performance processes and ambiguity averse
portfolio selection. We introduce the notion of robust forward criteria which
addresses the issues of ambiguity in model specification and in preferences and
investment horizon specification. It describes the evolution of time-consistent
ambiguity averse preferences.
  We first focus on establishing dual characterizations of the robust forward
criteria. This offers various advantages as the dual problem amounts to a
search for an infimum whereas the primal problem features a saddle-point. Our
approach is based on ideas developed in Schied (2007) and Zitkovic (2009). We
then study in detail non-volatile criteria. In particular, we solve explicitly
the example of an investor who starts with a logarithmic utility and applies a
quadratic penalty function. The investor builds a dynamical estimate of the
market price of risk $\hat \lambda$ and updates her stochastic utility in
accordance with the so-perceived elapsed market opportunities. We show that
this leads to a time-consistent optimal investment policy given by a fractional
Kelly strategy associated with $\hat \lambda$. The leverage is proportional to
the investor's confidence in her estimate $\hat \lambda$.
"
1311.4057,2013-11-19,A Fast Algorithm for Computing High-dimensional Risk Parity Portfolios,"  In this paper we propose a cyclical coordinate descent (CCD) algorithm for
solving high dimensional risk parity problems. We show that this algorithm
converges and is very fast even with large covariance matrices (n > 500).
Comparison with existing algorithms also shows that it is one of the most
efficient algorithms.
"
1311.5120,2014-07-23,Actuarial fairness and solidarity in pooled annuity funds,"  Various types of structures that enable a group of individuals to pool their
mortality risk have been proposed in the literature. Collectively, the
structures are called pooled annuity funds. Since the pooled annuity funds
propose different methods of pooling mortality risk, we investigate the
connections between them and find that they are genuinely different for a
finite heterogeneous membership profile.
  We discuss the importance of actuarial fairness, defined as the expected
benefits equalling the contributions for each member, in the context of pooling
mortality risk and comment on whether actuarial unfairness can be seen as
solidarity between members. We show that, with a finite number of members in
the fund, the group self-annuitization scheme is not actuarially fair: some
members subsidize the other members. The implication is that the members who
are subsidizing the others may obtain a higher expected benefit by joining a
fund with a more favourable membership profile. However, we find that the
subsidies are financially significant only for very small or highly
heterogeneous membership profiles.
"
1311.6080,2022-01-07,"A New Characterization of Comonotonicity and its Application in
  Behavioral Finance","  It is well-known that an $\mathbb{R}$-valued random vector $(X_1, X_2,
\cdots, X_n)$ is comonotonic if and only if $(X_1, X_2, \cdots, X_n)$ and
$(Q_1(U), Q_2(U),\cdots, Q_n(U))$ coincide \emph{in distribution}, for
\emph{any} random variable $U$ uniformly distributed on the unit interval
$(0,1)$, where $Q_k(\cdot)$ are the quantile functions of $X_k$, $k=1,2,\cdots,
n$. It is natural to ask whether $(X_1, X_2, \cdots, X_n)$ and $(Q_1(U),
Q_2(U),\cdots, Q_n(U))$ can coincide \emph{almost surely} for \emph{some}
special $U$. In this paper, we give a positive answer to this question by
construction. We then apply this result to a general behavioral investment
model with a law-invariant preference measure and develop a universal framework
to link the problem to its quantile formulation. We show that any optimal
investment output should be anti-comonotonic with the market pricing kernel.
Unlike previous studies, our approach avoids making the assumption that the
pricing kernel is atomless, and consequently, we overcome one of the major
difficulties encountered when one considers behavioral economic equilibrium
models in which the pricing kernel is a yet-to-be-determined unknown random
variable. The method is applicable to many other models such as risk sharing
model.
"
1311.6179,2014-10-16,Optimal Strategies for a Long-Term Static Investor,"  The optimal strategies for a long-term static investor are studied. Given a
portfolio of a stock and a bond, we derive the optimal allocation of the
capitols to maximize the expected long-term growth rate of a utility function
of the wealth. When the bond has constant interest rate, three models for the
underlying stock price processes are studied: Heston model, 3/2 model and jump
diffusion model. We also study the optimal strategies for a portfolio in which
the stock price process follows a Black-Scholes model and the bond process has
a Vasicek interest rate that is correlated to the stock price.
"
1311.7419,2013-12-02,"Risk- and ambiguity-averse portfolio optimization with quasiconcave
  utility functionals","  Motivated by recent axiomatic developments, we study the risk- and
ambiguity-averse investment problem where trading takes place over a fixed
finite horizon and terminal payoffs are evaluated according to a criterion
defined in terms of a quasiconcave utility functional. We extend to the present
setting certain existence and duality results established for the so-called
variational preferences by Schied (2007). The results are proven by building on
existing results for the classical utility maximization problem.
"
1312.0557,2020-03-09,Asymptotic distribution of the Markowitz portfolio,"  The asymptotic distribution of the Markowitz portfolio is derived, for the
general case (assuming fourth moments of returns exist), and for the case of
multivariate normal returns. The derivation allows for inference which is
robust to heteroskedasticity and autocorrelation of moments up to order four.
As a side effect, one can estimate the proportion of error in the Markowitz
portfolio due to mis-estimation of the covariance matrix. A likelihood ratio
test is given which generalizes Dempster's Covariance Selection test to allow
inference on linear combinations of the precision matrix and the Markowitz
portfolio. Extensions of the main method to deal with hedged portfolios,
conditional heteroskedasticity, conditional expectation, and constrained
estimation are given. It is shown that the Hotelling-Lawley statistic
generalizes the (squared) Sharpe ratio under the conditional expectation model.
Asymptotic distributions of all four of the common `MGLH' statistics are found,
assuming random covariates. Examples are given demonstrating the possible uses
of these results.
"
1312.1578,2013-12-06,Credit Portfolio Management in a Turning Rates Environment,"  We give a detailed account of correlations between credit sector/quality and
treasury curve factors, using the robust framework of the Barclays POINT Global
Risk Model. Consistent with earlier studies, we find a strong negative
correlation between sector spreads and rate shifts. However, we also observe
that the correlations between spreads and Treasury twists reversed recently,
which is likely attributable to the Fed's ongoing quantitative easing. We also
find that short-term effective durations in the banking industry are now
significantly lower than historical patterns would indicate. Our findings are
relevant for credit portfolio managers contemplating the impact of rising
interest rates and steepening Treasury curve on corporate bond portfolios.
"
1312.2754,2015-02-13,Liquidation of an indivisible asset with independent investment,"  We provide an extension of the explicit solution of a mixed optimal
stopping-optimal stochastic control problem introduced by Henderson and Hobson.
The problem examines wether the optimal investment problem on a local
martingale financial market is affected by the optimal liquidation of an
independent indivisible asset. The indivisible asset process is defined by a
homogeneous scalar stochastic differential equation, and the investor's
preferences are defined by a general expected utility function. The value
function is obtained in explicit form, and we prove the existence of an optimal
stopping-investment strategy characterized as the limit of an explicit
maximizing strategy. Our approach is based on the standard dynamic programming
approach.
"
1312.3917,2017-02-02,On the Market Viability under Proportional Transaction Costs,"  This paper studies the market viability with proportional transaction costs.
Instead of requiring the existence of strictly consistent price systems (SCPS)
as in the literature, we show that strictly consistent local martingale systems
(SCLMS) can successfully serve as the dual elements such that the market
viability can be verified. We introduce two weaker notions of no arbitrage
conditions on market models named no unbounded profit with bounded risk (NUPBR)
and no local arbitrage with bounded portfolios (NLABP). In particular, we show
that the NUPBR and NLABP conditions in the robust sense for the smaller bid-ask
spreads is the equivalent characterization of the existence of SCLMS for
general market models. We also discuss the implications for the utility
maximization problem.
"
1312.4385,2014-11-20,Local risk-minimization under restricted information to asset prices,"  In this paper we investigate the local risk-minimization approach for a
semimartingale financial market where there are restrictions on the available
information to agents who can observe at least the asset prices. We
characterize the optimal strategy in terms of suitable decompositions of a
given contingent claim, with respect to a filtration representing the
information level, even in presence of jumps. Finally, we discuss some
practical examples in a Markovian framework and show that the computation of
the optimal strategy leads to filtering problems under the real-world
probability measure and under the minimalmartingale measure.
"
1312.5660,2014-08-21,"Capital distribution and portfolio performance in the mean-field Atlas
  model","  We study a mean-field version of rank-based models of equity markets such as
the Atlas model introduced by Fernholz in the framework of Stochastic Portfolio
Theory. We obtain an asymptotic description of the market when the number of
companies grows to infinity. Then, we discuss the long-term capital
distribution. We recover the Pareto-like shape of capital distribution curves
usually derived from empirical studies, and provide a new description of the
phase transition phenomenon observed by Chatterjee and Pal. Finally, we address
the performance of simple portfolio rules and highlight the influence of the
volatility structure on the growth of portfolios.
"
1312.6350,2013-12-24,Sparse Portfolio Selection via Quasi-Norm Regularization,"  In this paper, we propose $\ell_p$-norm regularized models to seek
near-optimal sparse portfolios. These sparse solutions reduce the complexity of
portfolio implementation and management. Theoretical results are established to
guarantee the sparsity of the second-order KKT points of the $\ell_p$-norm
regularized models. More interestingly, we present a theory that relates
sparsity of the KKT points with Projected correlation and Projected Sharpe
ratio. We also design an interior point algorithm to obtain an approximate
second-order KKT solution of the $\ell_p$-norm models in polynomial time with a
fixed error tolerance, and then test our $\ell_p$-norm modes on S&P 500
(2008-2012) data and international market data.\ The computational results
illustrate that the $\ell_p$-norm regularized models can generate portfolios of
any desired sparsity with portfolio variance and portfolio return comparable to
those of the unregularized Markowitz model with cardinality constraint. Our
analysis of a combined model lead us to conclude that sparsity is not directly
related to overfitting at all. Instead, we find that sparsity moderates
overfitting only indirectly. A combined $\ell_1$-$\ell_p$ model shows that the
proper choose of leverage, which is the amount of additional buying-power
generated by selling short can mitigate overfitting; A combined
$\ell_2$-$\ell_p$ model is able to produce extremely high performing portfolios
that exceeded the 1/N strategy and all $\ell_1$ and $\ell_2$ regularized
portfolios.
"
1312.6841,2016-11-25,"Hedging Against the Interest-rate Risk by Measuring the Yield-curve
  Movement","  By adopting the polynomial interpolation method, we propose an approach to
hedge against the interest-rate risk of the default-free bonds by measuring the
nonparallel movement of the yield-curve, such as the translation, the rotation
and the twist. The empirical analysis shows that our hedging strategies are
comparable to traditional duration-convexity strategy, or even better when we
have more suitable hedging instruments on hand. The article shows that this
strategy is flexible and robust to cope with the interest-rate risk and can
help fine-tune a position as time changes.
"
1401.0562,2014-08-28,Optimal Investment with Transaction Costs and Stochastic Volatility,"  Two major financial market complexities are transaction costs and uncertain
volatility, and we analyze their joint impact on the problem of portfolio
optimization. When volatility is constant, the transaction costs optimal
investment problem has a long history, especially in the use of asymptotic
approximations when the cost is small. Under stochastic volatility, but with no
transaction costs, the Merton problem under general utility functions can also
be analyzed with asymptotic methods. Here, we look at the long-run growth rate
problem when both complexities are present, using separation of time scales
approximations. This leads to perturbation analysis of an eigenvalue problem.
We find the first term in the asymptotic expansion in the time scale parameter,
of the optimal long-term growth rate, and of the optimal strategy, for fixed
small transaction costs.
"
1401.1639,2014-01-09,Optimal consumption and portfolio choice with ambiguity,"  We consider optimal consumption and portfolio choice in the presence of
Knightian uncertainty in continuous-time. We embed the problem into the new
framework of stochastic calculus for such settings, dealing in particular with
the issue of non-equivalent multiple priors. We solve the problem completely by
identifying the worst--case measure. Our setup also allows to consider interest
rate uncertainty; we show that under some robust parameter constellations, the
investor optimally puts all his wealth into the asset market, and does not save
or borrow at all.
"
1401.2314,2014-07-29,"Optimal Hedging for Fund & Insurance Managers with Partially Observable
  Investment Flows","  All the financial practitioners are working in incomplete markets full of
unhedgeable risk-factors. Making the situation worse, they are only equipped
with the imperfect information on the relevant processes. In addition to the
market risk, fund and insurance managers have to be prepared for sudden and
possibly contagious changes in the investment flows from their clients so that
they can avoid the over- as well as under-hedging. In this work, the prices of
securities, the occurrences of insured events and (possibly a network of) the
investment flows are used to infer their drifts and intensities by a stochastic
filtering technique. We utilize the inferred information to provide the optimal
hedging strategy based on the mean-variance (or quadratic) risk criterion. A
BSDE approach allows a systematic derivation of the optimal strategy, which is
shown to be implementable by a set of simple ODEs and the standard Monte Carlo
simulation. The presented framework may also be useful for manufactures and
energy firms to install an efficient overlay of dynamic hedging by financial
derivatives to minimize the costs.
"
1401.2531,2014-01-14,"Optimal control of uncertain stochastic systems with Markovian switching
  and its applications to portfolio decisions","  This paper first describes a class of uncertain stochastic control systems
with Markovian switching, and derives an It\^o-Liu formula for Markov-modulated
processes. And we characterize an optimal control law, which satisfies the
generalized Hamilton-Jacobi-Bellman (HJB) equation with Markovian switching.
Then, by using the generalized HJB equation, we deduce the optimal consumption
and portfolio policies under uncertain stochastic financial markets with
Markovian switching. Finally, for constant relative risk-aversion (CRRA)
felicity functions, we explicitly obtain the optimal consumption and portfolio
policies. Moreover, we also make an economic analysis through numerical
examples.
"
1401.3261,2015-04-07,General indifference pricing with small transaction costs,"  We study the utility indifference price of a European option in the context
of small transaction costs. Considering the general setup allowing consumption
and a general utility function at final time T, we obtain an asymptotic
expansion of the utility indifference price as a function of the asymptotic
expansions of the utility maximization problems with and without the European
contingent claim. We use the tools developed in [54] and [48] based on
homogenization and viscosity solutions to characterize these expansions.
Finally we study more precisely the example of exponential utilities, in
particular recovering under weaker assumptions the results of [6].
"
1401.7198,2015-05-20,"Arbitrage of the first kind and filtration enlargements in
  semimartingale financial models","  In a general semimartingale financial model, we study the stability of the No
Arbitrage of the First Kind (NA1) (or, equivalently, No Unbounded Profit with
Bounded Risk) condition under initial and under progressive filtration
enlargements. In both cases, we provide a simple and general condition which is
sufficient to ensure this stability for any fixed semimartingale model.
Furthermore, we give a characterisation of the NA1 stability for all
semimartingale models.
"
1402.1052,2019-01-03,Optimal Sharing Rule for a Household with a Portfolio Management Problem,"  We study the Merton problem of optimal consumption-investment for the case of
two investors sharing a final wealth. The typical example would be a husband
and wife sharing a portfolio looking to optimize the expected utility of
consumption and final wealth. Each agent has different utility function and
discount factor. An explicit formulation for the optimal consumptions and
portfolio can be obtained in the case of a complete market. The problem is
shown to be equivalent to maximizing three different utilities separately with
separate initial wealths. We study a numerical example where the market price
of risk is assumed to be mean reverting, and provide insights on the influence
of risk aversion or discount rates on the initial optimal allocation.
"
1402.1809,2014-11-04,Minimizing the Probability of Lifetime Ruin Under Ambiguity Aversion,"  We determine the optimal robust investment strategy of an individual who
targets at a given rate of consumption and seeks to minimize the probability of
lifetime ruin when she does not have perfect confidence in the drift of the
risky asset. Using stochastic control, we characterize the value function as
the unique classical solution of an associated Hamilton-Jacobi-Bellman (HJB)
equation, obtain feedback forms for the optimal investment and drift
distortion, and discuss their dependence on various model parameters. In
analyzing the HJB equation, we establish the existence and uniqueness of
viscosity solution using Perron's method, and then upgrade regularity by
working with an equivalent convex problem obtained via the Cole-Hopf
transformation. We show the original value function may lose convexity for a
class of parameters and the Isaacs condition may fail. Numerical examples are
also included to illustrate our results.
"
1402.3464,2014-02-17,Dynamic Mean-LPM and Mean-CVaR Portfolio Optimization in Continuous-time,"  Instead of controlling ""symmetric"" risks measured by central moments of
investment return or terminal wealth, more and more portfolio models have
shifted their focus to manage ""asymmetric"" downside risks that the investment
return is below certain threshold. Among the existing downside risk measures,
the lower-partial moments (LPM) and conditional value-at-risk (CVaR) are
probably most promising. In this paper we investigate the dynamic mean-LPM and
mean-CVaR portfolio optimization problems in continuous-time, while the current
literature has only witnessed their static versions. Our contributions are
two-fold, in both building up tractable formulations and deriving corresponding
analytical solutions. By imposing a limit funding level on the terminal wealth,
we conquer the ill-posedness exhibited in the class of mean-downside risk
portfolio models. The limit funding level not only enables us to solve both
dynamic mean-LPM and mean-CVaR portfolio optimization problems, but also offers
a flexibility to tame the aggressiveness of the portfolio policies generated
from such mean - downside risk models. More specifically, for a general market
setting, we prove the existence and uniqueness of the Lagrangian multiplies,
which is a key step in applying the martingale approach, and establish a
theoretical foundation for developing efficient numerical solution approaches.
Moreover, for situations where the opportunity set of the market setting is
deterministic, we derive analytical portfolio policies for both dynamic
mean-LPM and mean-CVaR formulations.
"
1402.3560,2014-03-10,"Optimal Investment and Risk Control Problem for an Insurer: Expected
  Utility Maximization","  Motivated by the AIG bailout case in the financial crisis of 2007-2008, we
consider an insurer who wants to maximize the expected utility of the terminal
wealth by selecting optimal investment and risk control strategies. The
insurer's risk process is modelled by a jump-diffusion process and is
negatively correlated with the capital gains in the financial market. We obtain
explicit solution to optimal strategies for various utility functions.
"
1402.3562,2014-06-25,"Explicit Solutions of Optimal Consumption, Investment and Insurance
  Problem with Regime Switching","  We consider an investor who wants to select her/his optimal consumption,
investment and insurance policies. Motivated by new insurance products, we
allow not only the financial marke but also the insurable loss to depend on the
regime of the economy. The objective of the investor is to maximize her/his
expected total discounted utility of consumption over an infinite time horizon.
For the case of hyperbolic absolute risk aversion (HARA) utility functions, we
obtain the first explicit solutions for simultaneous optimal consumption,
investment, and insurance problems when there is regime switching. We determine
that the optimal insurance contract is either no-insurance or deductible
insurance, and calculate when it is optimal to buy insurance. The optimal
policy depends strongly on the regime of the economy. Through an economic
analysis, we calculate the advantage of buying insurance.
"
1402.3720,2015-07-29,The geometry of relative arbitrage,"  Consider an equity market with $n$ stocks. The vector of proportions of the
total market capitalizations that belong to each stock is called the market
weight. The market weight defines the market portfolio which is a buy-and-hold
portfolio representing the performance of the entire stock market. Consider a
function that assigns a portfolio vector to each possible value of the market
weight, and we perform self-financing trading using this portfolio function. We
study the problem of characterizing functions such that the resulting portfolio
will outperform the market portfolio in the long run under the conditions of
diversity and sufficient volatility. No other assumption on the future behavior
of stock prices is made. We prove that the only solutions are functionally
generated portfolios in the sense of Fernholz. A second characterization is
given as the optimal maps of a remarkable optimal transport problem. Both
characterizations follow from a novel property of portfolios called
multiplicative cyclical monotonicity.
"
1402.5300,2014-07-25,Purchasing Life Insurance to Reach a Bequest Goal,"  We determine how an individual can use life insurance to meet a bequest goal.
We assume that the individual's consumption is met by an income, such as a
pension, life annuity, or Social Security. Then, we consider the wealth that
the individual wants to devote towards heirs (separate from any wealth related
to the afore-mentioned income) and find the optimal strategy for buying life
insurance to maximize the probability of reaching a given bequest goal. We
consider life insurance purchased by a single premium, with and without cash
value available. We also consider irreversible and reversible life insurance
purchased by a continuously paid premium; one can view the latter as
(instantaneous) term life insurance.
"
1402.5304,2015-03-31,Trading with Small Price Impact,"  An investor trades a safe and several risky assets with linear price impact
to maximize expected utility from terminal wealth. In the limit for small
impact costs, we explicitly determine the optimal policy and welfare, in a
general Markovian setting allowing for stochastic market, cost, and preference
parameters. These results shed light on the general structure of the problem at
hand, and also unveil close connections to optimal execution problems and to
other market frictions such as proportional and fixed transaction costs.
"
1402.5306,2017-09-05,Rebalancing with Linear and Quadratic Costs,"  We consider a market consisting of one safe and one risky asset, which offer
constant investment opportunities. Taking into account both proportional
transaction costs and linear price impact, we derive optimal rebalancing
policies for representative investors with constant relative risk aversion and
a long horizon.
"
1402.6313,2016-03-15,"Expert Opinions and Logarithmic Utility Maximization in a Market with
  Gaussian Drift","  This paper investigates optimal portfolio strategies in a financial market
where the drift of the stock returns is driven by an unobserved Gaussian mean
reverting process. Information on this process is obtained from observing stock
returns and expert opinions. The latter provide at discrete time points an
unbiased estimate of the current state of the drift. Nevertheless, the drift
can only be observed partially and the best estimate is given by the
conditional expectation given the available information, i.e., by the filter.
We provide the filter equations in the model with expert opinion and derive in
detail properties of the conditional variance. For an investor who maximizes
expected logarithmic utility of his portfolio, we derive the optimal strategy
explicitly in different settings for the available information. The optimal
expected utility, the value function of the control problem, depends on the
conditional variance. The bounds and asymptotic results for the conditional
variances are used to derive bounds and asymptotic properties for the value
functions. The results are illustrated with numerical examples.
"
1402.6760,2014-02-28,Time-Inconsistent Mean-Utility Portfolio Selection with Moving Target,"  In this paper, we solve the time inconsistent portfolio selection problem by
using different utility functions with a moving target as our constraint. We
solve this problem by finding an equilibrium control under the given definition
as our optimal control. We firstly derive a sufficient equilibrium condition
for second-order continuously differentiable utility funtions. Then we use
power functions of order two, three and four in our problem and find the
respective condtions for obtaining an equilibrium for our different problems.
In the last part of the paper, we consider using another definition of
equilibrium to solve our problem when the utility function that we use in our
problem is the negative part of x and also find the condtions for obtaining an
equilibrium.
"
1403.0202,2014-03-04,Investing and Stopping,"  In this paper we solve the hedge fund manager's optimization problem in a
model that allows for investors to enter and leave the fund over time depending
on its performance. The manager's payoff at the end of the year will then
depend not just on the terminal value of the fund level, but also on the lowest
and the highest value reached over that time. We establish equivalence to an
optimal stopping problem for Brownian motion; by approximating this problem
with the corresponding optimal stopping problem for a random walk we are led to
a simple and efficient numerical scheme to find the solution, which we then
illustrate with some examples.
"
1403.0718,2014-03-05,"Mean-Variance Policy for Discrete-time Cone Constrained Markets: The
  Consistency in Efficiency and Minimum-Variance Signed Supermartingale Measure","  The discrete-time mean-variance portfolio selection formulation, a
representative of general dynamic mean-risk portfolio selection problems, does
not satisfy time consistency in efficiency (TCIE) in general, i.e., a truncated
pre-committed efficient policy may become inefficient when considering the
corresponding truncated problem, thus stimulating investors' irrational
investment behavior. We investigate analytically effects of portfolio
constraints on time consistency of efficiency for convex cone constrained
markets. More specifically, we derive the semi-analytical expressions for the
pre-committed efficient mean-variance policy and the minimum-variance signed
supermartingale measure (VSSM) and reveal their close relationship. Our
analysis shows that the pre-committed discrete-time efficient mean-variance
policy satisfies TCIE if and only if the conditional expectation of VSSM's
density (with respect to the original probability measure) is nonnegative, or
once the conditional expectation becomes negative, it remains at the same
negative value until the terminal time. Our findings indicate that the property
of time consistency in efficiency only depends on the basic market setting,
including portfolio constraints, and this fact motivates us to establish a
general solution framework in constructing TCIE dynamic portfolio selection
problem formulations by introducing suitable portfolio constraints.
"
1403.1889,2014-03-11,Introduction to Risk Parity and Budgeting,"  Although portfolio management didn't change much during the 40 years after
the seminal works of Markowitz and Sharpe, the development of risk budgeting
techniques marked an important milestone in the deepening of the relationship
between risk and asset management. Risk parity then became a popular financial
model of investment after the global financial crisis in 2008. Today, pension
funds and institutional investors are using this approach in the development of
smart indexing and the redefinition of long-term investment policies.
  Introduction to Risk Parity and Budgeting provides an up-to-date treatment of
this alternative method to Markowitz optimization. It builds financial exposure
to equities and commodities, considers credit risk in the management of bond
portfolios, and designs long-term investment policy.
  This book contains the solutions of tutorial exercices which are included in
Introduction to Risk Parity and Budgeting.
"
1403.3212,2023-04-25,"Continuous-Time Portfolio Choice Under Monotone Mean-Variance
  Preferences-Stochastic Factor Case","  We consider an incomplete market with a nontradable stochastic factor and a
continuous time investment problem with an optimality criterion based on
monotone mean-variance preferences. We formulate it as a stochastic
differential game problem and use Hamilton-Jacobi-Bellman-Isaacs equations to
find an optimal investment strategy and the value function. What is more, we
show that our solution is also optimal for the classical Markowitz problem and
every optimal solution for the classical Markowitz problem is optimal also for
the monotone mean-variance preferences. These results are interesting because
the original Markowitz functional is not monotone, and it was observed that in
the case of a static one-period optimization problem the solutions for those
two functionals are different. In addition, we determine explicit Markowitz
strategies in the square root factor models.
"
1403.3223,2015-12-15,Merton problem with one additional indivisible asset,"  In this paper we consider a modification of the classical Merton portfolio
optimization problem. Namely, an investor can trade in financial asset and
consume his capital. He is additionally endowed with a one unit of an
indivisible asset which he can sell at any time. We give a numerical example of
calculating the optimal time to sale the indivisible asset, the optimal
consumption rate and the value function.
"
1403.4069,2014-09-18,Momentum Strategies with L1 Filter,"  In this article, we discuss various implementation of L1 filtering in order
to detect some properties of noisy signals. This filter consists of using a L1
penalty condition in order to obtain the filtered signal composed by a set of
straight trends or steps. This penalty condition, which determines the number
of breaks, is implemented in a constrained least square problem and is
represented by a regularization parameter ? which is estimated by a
cross-validation procedure. Financial time series are usually characterized by
a long-term trend (called the global trend) and some short-term trends (which
are named local trends). A combination of these two time scales can form a
simple model describing the process of a global trend process with some
mean-reverting properties. Explicit applications to momentum strategies are
also discussed in detail with appropriate uses of the trend configurations.
"
1403.4329,2014-11-26,"On asymptotic optimality of Merton's myopic portfolio strategies for
  discrete time market","  This paper studies the properties of discrete time stochastic optimal control
problems associated with portfolio selection. We investigate if optimal
continuous time strategies can be used effectively for a discrete time market
after a straightforward discretization. We found that Merton's strategy
approximates the performance of the optimal strategy in a discrete time model
with the sufficiently small time steps
"
1403.5247,2014-03-21,Portfolio Optimization in Affine Models with Markov Switching,"  We consider a stochastic factor financial model where the asset price process
and the process for the stochastic factor depend on an observable Markov chain
and exhibit an affine structure. We are faced with a finite time investment
horizon and derive optimal dynamic investment strategies that maximize the
investor's expected utility from terminal wealth. To this aim we apply Merton's
approach, as we are dealing with an incomplete market. Based on the
semimartingale characterization of Markov chains we first derive the HJB
equations, which in our case correspond to a system of coupled non-linear PDEs.
Exploiting the affine structure of the model, we derive simple expressions for
the solution in the case with no leverage, i.e. no correlation between the
Brownian motions driving the asset price and the stochastic factor. In the
presence of leverage we propose a separable ansatz, which leads to explicit
solutions in this case as well. General verification results are also proved.
The results are illustrated for the special case of a Markov modulated Heston
model.
"
1403.6093,2015-06-09,"Reward-risk momentum strategies using classical tempered stable
  distribution","  We implement momentum strategies using reward-risk measures as ranking
criteria based on classical tempered stable distribution. Performances and risk
characteristics for the alternative portfolios are obtained in various asset
classes and markets. The reward-risk momentum strategies with lower volatility
levels outperform the traditional momentum strategy regardless of asset class
and market. Additionally, the alternative portfolios are not only less riskier
in risk measures such as VaR, CVaR and maximum drawdown but also characterized
by thinner downside tails. Similar patterns in performance and risk profile are
also found at the level of each ranking basket in the reward-risk portfolios.
Higher factor-neutral returns achieved by the reward-risk momentum strategies
are statistically significant and large portions of the performances are not
explained by the Carhart four-factor model.
"
1403.6175,2014-10-21,Utility maximization in the large markets,"  In the large financial market, which is described by a model with countably
many traded assets, we formulate the problem of the expected utility
maximization. Assuming that the preferences of an economic agent are modeled
with a stochastic utility and that the consumption occurs according to a
stochastic clock, we obtain the ""usual"" conclusions of the utility maximization
theory. We also give a characterization of the value function in the large
market in terms of a sequence of the value functions in the finite-dimensional
models.
"
1403.6531,2014-03-27,"Credit acceptance process strategy case studies - the power of Credit
  Scoring","  The paper is aware of the importance of certain figures that are essential to
an understanding of Credit Scoring models in credit acceptance process
optimization, namely if the power of discrimination measured by Gini value is
increased by 5% then the profit of the process can be increased monthly by
about 1 500 kPLN (300 kGBP, 500 kUSD, 350 kEUR). Simple business models of
credit loans are also presented: acquisition - installment loan (low price) and
cross-sell - cash loans (high price). Scoring models are used to optimize
process, to become profitable. Various acceptance strategies with different
cutoffs are presented, some are profitable and some are not. Moreover, in a
time of prosperity some are preferable whilst the inverse is true during a
period of high risk or crisis. To optimize the process four models are
employed: three risk models, to predict the probability of default and one
typical propensity model to predict the probability of response. It is a simple
but very important example of the Customer Lifetime Value (CLTV or CLV) model
business, where risk and response models are working together to become a
profitable process.
"
1403.7269,2022-01-07,A Note on the Quantile Formulation,"  Many investment models in discrete or continuous-time settings boil down to
maximizing an objective of the quantile function of the decision variable. This
quantile optimization problem is known as the quantile formulation of the
original investment problem. Under certain monotonicity assumptions, several
schemes to solve such quantile optimization problems have been proposed in the
literature. In this paper, we propose a change-of-variable and relaxation
method to solve the quantile optimization problems without using the calculus
of variations or making any monotonicity assumptions. The method is
demonstrated through a portfolio choice problem under rank-dependent utility
theory (RDUT). We show that this problem is equivalent to a classical Merton's
portfolio choice problem under expected utility theory with the same utility
function but a different pricing kernel explicitly determined by the given
pricing kernel and probability weighting function. With this result, the
feasibility, well-posedness, attainability and uniqueness issues for the
portfolio choice problem under RDUT are solved. It is also shown that solving
functional optimization problems may reduce to solving probabilistic
optimization problems. The method is applicable to general models with
law-invariant preference measures including portfolio choice models under
cumulative prospect theory (CPT) or RDUT, Yaari's dual model, Lopes' SP/A
model, and optimal stopping models under CPT or RDUT.
"
1403.7830,2014-04-01,Pseudo Linear Pricing Rule for Utility Indifference Valuation,"  This paper considers exponential utility indifference pricing for a
multidimensional non-traded assets model, and provides two linear
approximations for the utility indifference price. The key tool is a
probabilistic representation for the utility indifference price by the solution
of a functional differential equation, which is termed \emph{pseudo linear
pricing rule}. We also provide an alternative derivation of the quadratic BSDE
representation for the utility indifference price.
"
1403.8125,2024-05-24,"Maximum drawdown, recovery, and momentum","  We empirically test predictability on asset price by using stock selection
rules based on maximum drawdown and its consecutive recovery. In various equity
markets, monthly momentum- and weekly contrarian-style portfolios constructed
from these alternative selection criteria are superior not only in forecasting
directions of asset prices but also in capturing cross-sectional return
differentials. In monthly periods, the alternative portfolios ranked by maximum
drawdown measures exhibit outperformance over other alternative momentum
portfolios including traditional cumulative return-based momentum portfolios.
In weekly time scales, recovery-related stock selection rules are the best
ranking criteria for detecting mean-reversion. For the alternative portfolios
and their ranking baskets, improved risk profiles in various reward-risk
measures also imply more consistent prediction on the direction of assets in
future. In the Carhart four-factor analysis, higher factor-neutral intercepts
for the alternative strategies are another evidence for the robust prediction
by the alternative stock selection rules.
"
1404.0746,2018-11-15,Is It Possible to OD on Alpha?,"  It is well known that combining multiple hedge fund alpha streams yields
diversification benefits to the resultant portfolio. Additionally, crossing
trades between different alpha streams reduces transaction costs. As the number
of alpha streams increases, the relative turnover of the portfolio decreases as
more trades are crossed. However, we argue, under reasonable assumptions, that
as the number of alphas increases, the turnover does not decrease indefinitely;
instead, the turnover approaches a non-vanishing limit related to the
correlation structure of the portfolio's alphas. We also point out that, more
generally, computational simplifications can arise when the number of alphas is
large.
"
1404.0879,2014-04-04,"Utility indifference pricing of derivatives written on industrial loss
  indexes","  We consider the problem of pricing derivatives written on some industrial
loss index via utility indifference pricing. The industrial loss index is
modelled by a compound Poisson process and the insurer can adjust her portfolio
by choosing the risk loading, which in turn determines the demand. We compute
the price of a CAT(spread) option written on that index using utility
indifference pricing.
"
1404.2227,2014-04-09,Facelifting in Utility Maximization,"  We establish the existence and characterization of a primal and a dual
facelift - discontinuity of the value function at the terminal time - for
utility-maximization in incomplete semimartingale-driven financial markets.
Unlike in the lower- and upper-hedging problems, and somewhat unexpectedly, a
facelift turns out to exist in utility-maximization despite strict convexity in
the objective function. In addition to discussing our results in their natural,
Markovian environment, we also use them to show that the dual optimizer cannot
be found in the set of countably-additive (martingale) measures in a wide
variety of situations.
"
1404.3274,2014-04-15,Two centuries of trend following,"  We establish the existence of anomalous excess returns based on trend
following strategies across four asset classes (commodities, currencies, stock
indices, bonds) and over very long time scales. We use for our studies both
futures time series, that exist since 1960, and spot time series that allow us
to go back to 1800 on commodities and indices. The overall t-stat of the excess
returns is $\approx 5$ since 1960 and $\approx 10$ since 1800, after accounting
for the overall upward drift of these markets. The effect is very stable, both
across time and asset classes. It makes the existence of trends one of the most
statistically significant anomalies in financial markets. When analyzing the
trend following signal further, we find a clear saturation effect for large
signals, suggesting that fundamentalist traders do not attempt to resist ""weak
trends"", but step in when their own signal becomes strong enough. Finally, we
study the performance of trend following in the recent period. We find no sign
of a statistical degradation of long trends, whereas shorter trends have
significantly withered.
"
1404.4040,2014-04-16,$L_p$ regularized portfolio optimization,"  Investors who optimize their portfolios under any of the coherent risk
measures are naturally led to regularized portfolio optimization when they take
into account the impact their trades make on the market. We show here that the
impact function determines which regularizer is used. We also show that any
regularizer based on the norm $L_p$ with $p>1$ makes the sensitivity of
coherent risk measures to estimation error disappear, while regularizers with
$p<1$ do not. The $L_1$ norm represents a border case: its ""soft""
implementation does not remove the instability, but rather shifts its locus,
whereas its ""hard"" implementation (equivalent to a ban on short selling)
eliminates it. We demonstrate these effects on the important special case of
Expected Shortfall (ES) that is on its way to becoming the next global
regulatory market risk measure.
"
1404.4798,2014-08-08,"Signal-wise performance attribution for constrained portfolio
  optimisation","  Performance analysis, from the external point of view of a client who would
only have access to returns and holdings of a fund, evolved towards exact
attribution made in the context of portfolio optimisation, which is the
internal point of view of a manager controlling all the parameters of this
optimisation. Attribution is exact, that-is-to-say no residual ""interaction""
term remains, and various contributions to the optimal portfolio can be
identified: predictive signals, constraints, benchmark. However constraints are
identified as a separate portfolio and attribution for each signal that are
used to predict future returns thus corresponds to unconstrained signal
portfolios. We propose a novel attribution method that put predictive signals
at the core of attribution and allows to include the effect of constraints in
portfolios attributed to every signal. We show how this can be applied to
various trading models and portfolio optimisation frameworks and explain what
kind of insights such an attribution provides.
"
1404.5222,2016-12-15,"Self-Averaging Property of Minimal Investment Risk of Mean-Variance
  Model","  In portfolio optimization problems, the minimum expected investment risk is
not always smaller than the expected minimal investment risk. That is, using a
well-known approach from operations research, it is possible to derive a
strategy that minimizes the expected investment risk, but this strategy does
not always result in the best rate of return on assets. Prior to making
investment decisions, it is important to an investor to know the potential
minimal investment risk (or the expected minimal investment risk) and to
determine the strategy that will maximize the return on assets. We use the
self-averaging property to analyze the potential minimal investment risk and
the concentrated investment level for the strategy that gives the best rate of
return. We compare the results from our method with the results obtained by the
operations research approach and with those obtained by a numerical simulation
using the optimal portfolio. The results of our method and the numerical
simulation are in agreement, but they differ from that of the operations
research approach.
"
1404.5408,2014-04-23,"Continuous time portfolio choice under monotone preferences with
  quadratic penalty - stochastic interest rate case","  This is a follow up of our previous paper - Trybu{\l}a and Zawisza
\cite{TryZaw}, where we considered a modification of a monotone mean-variance
functional in continuous time in stochastic factor model. In this article we
address the problem of optimizing the mentioned functional in a market with a
stochastic interest rate. We formulate it as a stochastic differential game
problem and use Hamilton-Jacobi-Bellman-Isaacs equations to derive the optimal
investment strategy and the value function.
"
1404.7406,2014-11-04,"Stochastic Perron's Method for the Probability of lifetime ruin problem
  under transaction costs","  We apply stochastic Perron's method to a singular control problem where an
individual targets at a given consumption rate, invests in a risky financial
market in which trading is subject to proportional transaction costs, and seeks
to minimize her probability of lifetime ruin. Without relying on the dynamic
programming principle (DPP), we characterize the value function as the unique
viscosity solution of an associated Hamilton-Jacobi-Bellman (HJB) variational
inequality. We also provide a complete proof of the comparison principle which
is the main assumption of stochastic Perron's method.
"
1404.7493,2016-09-22,Drawdown: From Practice to Theory and Back Again,"  Maximum drawdown, the largest cumulative loss from peak to trough, is one of
the most widely used indicators of risk in the fund management industry, but
one of the least developed in the context of measures of risk. We formalize
drawdown risk as Conditional Expected Drawdown (CED), which is the tail mean of
maximum drawdown distributions. We show that CED is a degree one positive
homogenous risk measure, so that it can be linearly attributed to factors; and
convex, so that it can be used in quantitative optimization. We empirically
explore the differences in risk attributions based on CED, Expected Shortfall
(ES) and volatility. An important feature of CED is its sensitivity to serial
correlation. In an empirical study that fits AR(1) models to US Equity and US
Bonds, we find substantially higher correlation between the autoregressive
parameter and CED than with ES or with volatility.
"
1404.7698,2022-01-06,An Optimal Consumption-Investment Model with Constraint on Consumption,"  A continuous-time consumption-investment model with constraint is considered
for a small investor whose decisions are the consumption rate and the
allocation of wealth to a risk-free and a risky asset with logarithmic Brownian
motion fluctuations. The consumption rate is subject to an upper bound
constraint which linearly depends on the investor's wealth and bankruptcy is
prohibited. The investor's objective is to maximize total expected discounted
utility of consumption over an infinite trading horizon. It is shown that the
value function is (second order) smooth everywhere but a unique possibility of
(known) exception point and the optimal consumption-investment strategy is
provided in a closed feedback form of wealth, which in contrast to the existing
work does not involve the value function. According to this model, an investor
should take the same optimal investment strategy as in Merton's model
regardless his financial situation. By contrast, the optimal consumption
strategy does depend on the investor's financial situation: he should use a
similar consumption strategy as in Merton's model when he is in a bad
situation, and consume as much as possible when he is in a good situation.
"
1405.1266,2014-05-07,"The super-replication theorem under proportional transaction costs
  revisited","  We consider a financial market with one riskless and one risky asset. The
super-replication theorem states that there is no duality gap in the problem of
super-replicating a contingent claim under transaction costs and the associated
dual problem. We give two versions of this theorem. The first theorem relates a
num\'eraire-based admissibility condition in the primal problem to the notion
of a local martingale in the dual problem. The second theorem relates a
num\'eraire -free admissibility condition in the primal problem to the notion
of a uniformly integrable martingale in the dual problem.
"
1405.2384,2014-05-13,A Multi-factor Adaptive Statistical Arbitrage Model,"  This paper examines the implementation of a statistical arbitrage trading
strategy based on co-integration relationships where we discover candidate
portfolios using multiple factors rather than just price data. The portfolio
selection methodologies include K-means clustering, graphical lasso and a
combination of the two. Our results show that clustering appears to yield
better candidate portfolios on average than naively using graphical lasso over
the entire equity pool. A hybrid approach of using the combination of graphical
lasso and clustering yields better results still. We also examine the effects
of an adaptive approach during the trading period, by re-computing potential
portfolios once to account for change in relationships with passage of time.
However, the adaptive approach does not produce better results than the one
without re-learning. Our results managed to pass the test for the presence of
statistical arbitrage test at a statistically significant level. Additionally
we were able to validate our findings over a separate dataset for formation and
trading periods.
"
1405.2442,2014-11-13,"A Non Convex Singular Stochastic Control Problem and its Related Optimal
  Stopping Boundaries","  Equivalences are known between problems of singular stochastic control (SSC)
with convex performance criteria and related questions of optimal stopping, see
for example Karatzas and Shreve [SIAM J. Control Optim. 22 (1984)]. The aim of
this paper is to investigate how far connections of this type generalise to a
non convex problem of purchasing electricity. Where the classical equivalence
breaks down we provide alternative connections to optimal stopping problems.
  We consider a non convex infinite time horizon SSC problem whose state
consists of an uncontrolled diffusion representing a real-valued commodity
price, and a controlled increasing bounded process representing an inventory.
We analyse the geometry of the action and inaction regions by characterising
their (optimal) boundaries. Unlike the case of convex SSC problems we find that
the optimal boundaries may be both reflecting and repelling and it is natural
to interpret the problem as one of SSC with discretionary stopping.
"
1405.3812,2014-06-23,Optimal investment under behavioural criteria -- a dual approach,"  We consider a discrete-time, generically incomplete market model and a
behavioural investor with power-like utility and distortion functions. The
existence of optimal strategies in this setting has been shown in a previous
paper under certain conditions on the parameters of these power functions.
  In the present paper we prove the existence of optimal strategies under a
different set of conditions on the parameters, identical to the ones which were
shown to be necessary and sufficient in the Black-Scholes model.
  Although there exists no natural dual problem for optimisation under
behavioural criteria (due to the lack of concavity), we will rely on techniques
based on the usual duality between attainable contingent claims and equivalent
martingale measures.
"
1405.4716,2015-02-24,Combining Alpha Streams with Costs,"  We discuss investment allocation to multiple alpha streams traded on the same
execution platform with internal crossing of trades and point out differences
with allocating investment when alpha streams are traded on separate execution
platforms with no crossing. First, in the latter case allocation weights are
non-negative, while in the former case they can be negative. Second, the
effects of both linear and nonlinear (impact) costs are different in these two
cases due to turnover reduction when the trades are crossed. Third, the
turnover reduction depends on the universe of traded alpha streams, so if some
alpha streams have zero allocations, turnover reduction needs to be recomputed,
hence an iterative procedure. We discuss an algorithm for finding allocation
weights with crossing and linear costs. We also discuss a simple approximation
when nonlinear costs are added, making the allocation problem tractable while
still capturing nonlinear portfolio capacity bound effects. We also define
""regression with costs"" as a limit of optimization with costs, useful in
often-occurring cases with singular alpha covariance matrix.
"
1406.0044,2014-11-10,Can Turnover Go to Zero?,"  Internal crossing of trades between multiple alpha streams results in
portfolio turnover reduction. Turnover reduction can be modeled using the
correlation structure of the alpha streams. As more and more alphas are added,
generally turnover reduces. In this note we use a factor model approach to
address the question of whether the turnover goes to zero or a finite limit as
the number of alphas N goes to infinity. We argue that the limiting turnover
value is determined by the number of alpha clusters F, not the number of alphas
N. This limiting value behaves according to the ""power law"" ~ F^(-3/2). So, to
achieve zero limiting turnover, the number of alpha clusters must go to
infinity along with the number of alphas. We further argue on general grounds
that, if the number of underlying tradable instruments is finite, then the
turnover cannot go to zero, which implies that the number of alpha clusters
also appears to be finite.
"
1406.0437,2023-04-19,Estimation of the Global Minimum Variance Portfolio in High Dimensions,"  We estimate the global minimum variance (GMV) portfolio in the
high-dimensional case using results from random matrix theory. This approach
leads to a shrinkage-type estimator which is distribution-free and it is
optimal in the sense of minimizing the out-of-sample variance. Its asymptotic
properties are investigated assuming that the number of assets $p$ depends on
the sample size $n$ such that $\frac{p}{n}\rightarrow c\in (0,+\infty)$ as $n$
tends to infinity. The results are obtained under weak assumptions imposed on
the distribution of the asset returns, namely it is only required the fourth
moments existence. Furthermore, we make no assumption on the upper bound of the
spectrum of the covariance matrix. As a result, the theoretical findings are
also valid if the dependencies between the asset returns are described by a
factor model which appears to be very popular in financial literature nowadays.
This is also well-documented in a numerical study where the small- and
large-sample behavior of the derived estimator are compared with existing
estimators of the GMV portfolio. The resulting estimator shows significant
improvements and it turns out to be robust to the deviations from normality.
"
1406.0824,2014-06-04,"Supervised classification-based stock prediction and portfolio
  optimization","  As the number of publicly traded companies as well as the amount of their
financial data grows rapidly, it is highly desired to have tracking, analysis,
and eventually stock selections automated. There have been few works focusing
on estimating the stock prices of individual companies. However, many of those
have worked with very small number of financial parameters. In this work, we
apply machine learning techniques to address automated stock picking, while
using a larger number of financial parameters for individual companies than the
previous studies. Our approaches are based on the supervision of prediction
parameters using company fundamentals, time-series properties, and correlation
information between different stocks. We examine a variety of supervised
learning techniques and found that using stock fundamentals is a useful
approach for the classification problem, when combined with the high
dimensional data handling capabilities of support vector machine. The portfolio
our system suggests by predicting the behavior of stocks results in a 3% larger
growth on average than the overall market within a 3-month time period, as the
out-of-sample test suggests.
"
1406.1249,2015-06-26,Notes on Alpha Stream Optimization,"  In these notes we discuss investment allocation to multiple alpha streams
traded on the same execution platform, including when trades are crossed
internally resulting in turnover reduction. We discuss approaches to alpha
weight optimization where one maximizes P&L subject to bounds on volatility (or
Sharpe ratio). The presence of negative alpha weights, which are allowed when
alpha streams are traded on the same execution platform, complicates the
optimization problem. By using factor model approach to alpha covariance
matrix, the original optimization problem can be viewed as a 1-dimensional root
searching problem plus an optimization problem that requires a finite number of
iterations. We discuss this approach without costs and with linear costs, and
also with nonlinear costs in a certain approximation, which makes the
allocation problem tractable without forgoing nonlinear portfolio capacity
bound effects.
"
1406.3112,2014-06-13,"Martingale approach to optimal portfolio-consumption problems in
  Markov-modulated pure-jump models","  We study optimal investment strategies that maximize expected utility from
consumption and terminal wealth in a pure-jump asset price model with
Markov-modulated (regime switching) jump-size distributions. We give sufficient
conditions for existence of optimal policies and find closed-form expressions
for the optimal value function for agents with logarithmic and fractional power
(CRRA) utility in the case of two-state Markov chains. The main tools are
convex duality techniques, stochastic calculus for pure-jump processes and
explicit formulae for the moments of telegraph processes with Markov-modulated
random jumps.
"
1406.3396,2014-12-02,Factor Models for Alpha Streams,"  We propose a framework for constructing factor models for alpha streams. Our
motivation is threefold. 1) When the number of alphas is large, the sample
covariance matrix is singular. 2) Its out-of-sample stability is challenging.
3) Optimization of investment allocation into alpha streams can be tractable
for a factor model alpha covariance matrix. We discuss various risk factors for
alphas such as: style risk factors; cluster risk factors based on alpha
taxonomy; principal components; and also using the underlying tradables
(stocks) as alpha risk factors, for which computing the factor loadings and
factor covariance matrices does not involve any correlations with alphas, and
their number is much larger than that of the relevant principal components. We
draw insight from stock factor models, but also point out substantial
differences.
"
1406.4322,2014-06-18,"Upside and Downside Risk Exposures of Currency Carry Trades via Tail
  Dependence","  Currency carry trade is the investment strategy that involves selling low
interest rate currencies in order to purchase higher interest rate currencies,
thus profiting from the interest rate differentials. This is a well known
financial puzzle to explain, since assuming foreign exchange risk is
uninhibited and the markets have rational risk-neutral investors, then one
would not expect profits from such strategies. That is, according to uncovered
interest rate parity (UIP), changes in the related exchange rates should offset
the potential to profit from such interest rate differentials. However, it has
been shown empirically, that investors can earn profits on average by borrowing
in a country with a lower interest rate, exchanging for foreign currency, and
investing in a foreign country with a higher interest rate, whilst allowing for
any losses from exchanging back to their domestic currency at maturity. This
paper explores the financial risk that trading strategies seeking to exploit a
violation of the UIP condition are exposed to with respect to multivariate tail
dependence present in both the funding and investment currency baskets. It will
outline in what contexts these portfolio risk exposures will benefit
accumulated portfolio returns and under what conditions such tail exposures
will reduce portfolio returns.
"
1406.4783,2014-06-19,"Advisors and indicators based on the SSA models and non-linear
  generalizations","  This paper considers method of creation of an advisor and indicator based on
the spectral stochastic analysis model, both with linear and non-linear
approximation. The problem of entrance to one or another trade position is
solved on the basis of combined analysis of dynamics of quotations of all
currency pairs, what allows to actively hedge open positions.
"
1406.5312,2014-06-23,"Asymptotic Exponential Arbitrage and Utility-based Asymptotic Arbitrage
  in Markovian Models of Financial Markets","  Consider a discrete-time infinite horizon financial market model in which the
logarithm of the stock price is a time discretization of a stochastic
differential equation. Under conditions different from those given in a
previous paper of ours, we prove the existence of investment opportunities
producing an exponentially growing profit with probability tending to $1$
geometrically fast. This is achieved using ergodic results on Markov chains and
tools of large deviations theory.
  Furthermore, we discuss asymptotic arbitrage in the expected utility sense
and its relationship to the first part of the paper.
"
1406.5755,2014-09-22,A Bond Consistent Derivative Fair Value,"  In this paper we present a rigorously motivated pricing equation for
derivatives, including general cash collateralization schemes, which is
consistent with quoted market bond prices. Traditionally, there have been
differences in how instruments with similar cash flow structures have been
priced if their definition falls under that of a financial derivative versus if
they correspond to bonds, leading to possibilities such as funding through
derivatives transactions. Furthermore, the problem has not been solved with the
recent introduction of Funding Valuation Adjustments in derivatives pricing,
and in some cases has even been made worse.
  In contrast, our proposed equation is not only consistent with fixed income
assets and liabilities, but is also symmetric, implying a well-defined exit
price, independent of the entity performing the valuation. Also, we provide
some practical proxies, such as first-order approximations or basing
calculations of CVA and DVA on bond curves, rather than Credit Default Swaps.
"
1406.5852,2015-03-17,Moral Hazard in Dynamic Risk Management,"  We consider a contracting problem in which a principal hires an agent to
manage a risky project. When the agent chooses volatility components of the
output process and the principal observes the output continuously, the
principal can compute the quadratic variation of the output, but not the
individual components. This leads to moral hazard with respect to the risk
choices of the agent. We identify a family of admissible contracts for which
the optimal agent's action is explicitly characterized, and, using the recent
theory of singular changes of measures for It\^o processes, we study how
restrictive this family is. In particular, in the special case of the standard
Homlstr\""om-Milgrom model with fixed volatility, the family includes all
possible contracts. We solve the principal-agent problem in the case of CARA
preferences, and show that the optimal contract is linear in these factors: the
contractible sources of risk, including the output, the quadratic variation of
the output and the cross-variations between the output and the contractible
risk sources. Thus, like sample Sharpe ratios used in practice, path-dependent
contracts naturally arise when there is moral hazard with respect to risk
management. In a numerical example, we show that the loss of efficiency can be
significant if the principal does not use the quadratic variation component of
the optimal contract.
"
1406.6245,2022-02-24,Optimal investment with time-varying stochastic endowments,"  This paper considers a utility maximization and optimal asset allocation
problem in the presence of a stochastic endowment that cannot be fully hedged
through trading in the financial market. After studying continuity properties
of the value function for general utility functions, we rely on the dynamic
programming approach to solve the optimization problem for power utility
investors including the empirically relevant and mathematically challenging
case of relative risk aversion larger than one. For this, we argue that the
value function is the unique viscosity solution of the Hamilton-Jacobi-Bellman
(HJB) equation. The homogeneity of the value function is then used to reduce
the HJB equation by one dimension, which allows us to prove that the value
function is even a classical solution thereof. Using this, an optimal strategy
is derived and its asymptotic behavior in the large wealth regime is discussed.
"
1406.6902,2014-11-18,"Hedging of unit-linked life insurance contracts with unobservable
  mortality hazard rate via local risk-minimization","  In this paper we investigate the local risk-minimization approach for a
combined financial-insurance model where there are restrictions on the
information available to the insurance company. In particular we assume that,
at any time, the insurance company may observe the number of deaths from a
specific portfolio of insured individuals but not the mortality hazard rate. We
consider a financial market driven by a general semimartingale and we aim to
hedge unit-linked life insurance contracts via the local risk-minimization
approach under partial information. The F\""ollmer-Schweizer decomposition of
the insurance claim and explicit formulas for the optimal strategy for pure
endowment and term insurance contracts are provided in terms of the projection
of the survival process on the information flow. Moreover, in a Markovian
framework, we reduce to solve a filtering problem with point process
observations.
"
1406.6940,2014-06-27,Optimal Investment with Stopping in Finite Horizon,"  In this paper, we investigate dynamic optimization problems featuring both
stochastic control and optimal stopping in a finite time horizon. The paper
aims to develop new methodologies, which are significantly different from those
of mixed dynamic optimal control and stopping problems in the existing
literature, to study a manager's decision. We formulate our model to a free
boundary problem of a fully nonlinear equation. Furthermore, by means of a dual
transformation for the above problem, we convert the above problem to a new
free boundary problem of a linear equation. Finally, we apply the theoretical
results to challenging, yet practically relevant and important, risk-sensitive
problems in wealth management to obtain the properties of the optimal strategy
and the right time to achieve a certain level over a finite time investment
horizon.
"
1406.7040,2014-06-30,"Optimal Portfolio Problem Using Entropic Value at Risk: When the
  Underlying Distribution is Non-Elliptical","  This paper is devoted to study the optimal portfolio problem. Harry
Markowitz's Ph.D. thesis prepared the ground for the mathematical theory of
finance. In modern portfolio theory, we typically find asset returns that are
modeled by a random variable with an elliptical distribution and the notion of
portfolio risk is described by an appropriate risk measure. In this paper, we
propose new stochastic models for the asset returns that are based on Jumps-
Diffusion (J-D) distributions. This family of distributions are more compatible
with stylized features of asset returns. On the other hand, in the past
decades, we find attempts in the literature to use well-known risk measures,
such as Value at Risk and Expected Shortfall, in this context. Unfortunately,
one drawback with these previous approaches is that no explicit formulas are
available and numerical approximations are used to solve the optimization
problem. In this paper, we propose to use a new coherent risk measure,
so-called, Entropic Value at Risk(EVaR), in the optimization problem. For
certain models, including a jump-diffusion distribution, this risk measure
yields an explicit formula for the objective function so that the optimization
problem can be solved without resorting to numerical approximations.
"
1406.7604,2014-07-01,Optimal investment-reinsurance policy under a long-term perspective,"  In this paper, we assume an insure is allowed to purchase proportional
reinsurance and can invest his or her wealth into the financial market where a
savings account, stocks and bonds are available. Different from classical
optimal investment and reinsurance problem, this paper studies the insurer's
long-term investment decision. Under this setting, our model consider the
interest risk and the inflation risk. Specifically, we suppose the interest
rate follows a stochastic process, while price index is described by a
classical model. By solving Hamilton-Jacobi-Bellman equation, the closed-form
expression of the optimal policy is obtained. Further, we prove the
corresponding verification theorem without the usual Lipschitz condition. In
the end, numerical examples are made to illustrate the difference of the
optimal polices under Ho-lee model and Vasicek model.
"
1406.7723,2014-07-01,"Active extension portfolio optimization with non-convex risk measures
  using metaheuristics","  We consider the optimization of active extension portfolios. For this
purpose, the optimization problem is rewritten as a stochastic programming
model and solved using a clever multi-start local search heuristic, which turns
out to provide stable solutions. The heuristic solutions are compared to
optimization results of convex optimization solvers where applicable.
Furthermore, the approach is applied to solve problems with non-convex risk
measures, most notably to minimize Value-at-Risk. Numerical results using data
from both the Dow Jones Industrial Average as well as the DAX 30 are shown.
"
1407.1595,2015-07-28,"Non-linear filtering and optimal investment under partial information
  for stochastic volatility models","  This paper studies the question of filtering and maximizing terminal wealth
from expected utility in a partially information stochastic volatility models.
The special features is that the only information available to the investor is
the one generated by the asset prices, and the unobservable processes will be
modeled by a stochastic differential equations. Using the change of measure
techniques, the partial observation context can be transformed into a full
information context such that coefficients depend only on past history of
observed prices (filters processes). Adapting the stochastic non-linear
filtering, we show that under some assumptions on the model coefficients, the
estimation of the filters depend on a priorimodels for the trend and the
stochastic volatility. Moreover, these filters satisfy a stochastic partial
differential equations named ""Kushner-Stratonovich equations"". Using the
martingale duality approach in this partially observed incomplete model, we can
characterize the value function and the optimal portfolio. The main result here
is that the dual value function associated to the martingale approach can be
expressed, via the dynamic programmingapproach, in terms of the solution to a
semilinear partial differential equation. We illustrate our results with some
examples of stochastic volatility models popular in the financial literature.
"
1407.3154,2020-09-28,"Portfolio optimization in the case of an asset with a given liquidation
  time distribution","  Management of the portfolios containing low liquidity assets is a tedious
problem. The buyer proposes the price that can differ greatly from the paper
value estimated by the seller, the seller, on the other hand, can not liquidate
his portfolio instantly and waits for a more favorable offer. To minimize
losses in this case we need to develop new methods. One of the steps moving the
theory towards practical needs is to take into account the time lag of the
liquidation of an illiquid asset. This task became especially significant for
the practitioners in the time of the global financial crises. Working in the
Merton's optimal consumption framework with continuous time we consider an
optimization problem for a portfolio with an illiquid, a risky and a risk-free
asset. While a standard Black-Scholes market describes the liquid part of the
investment the illiquid asset is sold at a random moment with prescribed
liquidation time distribution. In the moment of liquidation it generates
additional liquid wealth dependent on illiquid assets paper value. The investor
has the logarithmic utility function as a limit case of a HARA-type utility.
Different distributions of the liquidation time of the illiquid asset are under
consideration - a classical exponential distribution and Weibull distribution
that is more practically relevant. Under certain conditions we show the
existence of the viscosity solution in both cases. Applying numerical methods
we compare classical Merton's strategies and the optimal consumption-allocation
strategies for portfolios with different liquidation-time distributions of an
illiquid asset.
"
1407.3372,2014-07-15,Arbitrage in markets with bid-ask spreads,"  In this paper a finite discrete time market with an arbitrary state space and
bid-ask spreads is considered. The notion of an equivalent bid-ask martingale
measure (EBAMM) is introduced and the fundamental theorem of asset pricing is
proved using (EBAMM) as an equivalent condition for no-arbitrage. The
Cox-Ross-Rubinstein model with bid-ask spreads is presented as an application
of our results.
"
1407.5278,2016-01-21,Risk-sensitive investment in a finite-factor model,"  A new jump diffusion regime-switching model is introduced, which allows for
linking jumps in asset prices with regime changes. We prove the existence and
uniqueness of the solution to the risk-sensitive asset management criterion
maximisation problem in this setting. We provide an ODE for the optimal value
function, which may be efficiently solved numerically. Relevant probability
measure changes are discussed in the appendix. The approach of Klebaner and
Lipster (2014) is used to prove the martingale property of the relevant density
processes.
"
1407.6649,2015-03-09,"On the role of F\""ollmer-Schweizer minimal martingale measure in Risk
  Sensitive control Asset Management","  Kuroda and Nagai \cite{KN} state that the factor process in the Risk
Sensitive control Asset Management (RSCAM) is stable under the
F\""ollmer-Schweizer minimal martingale measure . Fleming and Sheu \cite{FS} and
more recently F\""ollmer and Schweizer \cite{FoS} have observed that the role of
the minimal martingale measure in this portfolio optimization is yet to be
established. In this article we aim to address this question by explicitly
connecting the optimal wealth allocation to the minimal martingale measure. We
achieve this by using a ""trick"" of observing this problem in the context of
model uncertainty via a two person zero sum stochastic differential game
between the investor and an antagonistic market that provides a probability
measure. We obtain some startling insights. Firstly, if short-selling is not
permitted and if the factor process evolves under the minimal martingale
measure then the investor's optimal strategy can only be to invest in the
riskless asset (i.e. the no-regret strategy). Secondly, if the factor process
and the stock price process have independent noise, then even if the market
allows short selling, the optimal strategy for the investor must be the
no-regret strategy while the factor process will evolve under the minimal
martingale measure .
"
1407.7717,2014-07-30,Convex duality for stochastic singular control problems,"  We develop a general theory of convex duality for certain singular control
problems, taking the abstract results by Kramkov and Schachermayer (1999) for
optimal expected utility from nonnegative random variables to the level of
optimal expected utility from increasing, adapted controls. The main
contributions are the formulation of a suitable duality framework, the
identification of the problem's dual functional as well as the full duality for
the primal and dual value functions and their optimizers. The scope of our
results is illustrated by an irreversible investment problem and the
Hindy-Huang-Kreps utility maximization problem for incomplete financial
markets.
"
1407.8300,2014-11-26,Optimization of relative arbitrage,"  In stochastic portfolio theory, a relative arbitrage is an equity portfolio
which is guaranteed to outperform a benchmark portfolio over a finite horizon.
When the market is diverse and sufficiently volatile, and the benchmark is the
market or a buy-and-hold portfolio, functionally generated portfolios
introduced by Fernholz provide a systematic way of constructing relative
arbitrages. In this paper we show that if the market portfolio is replaced by
the equal or entropy weighted portfolio among many others, no relative
arbitrages can be constructed under the same conditions using functionally
generated portfolios. We also introduce and study a shaped-constrained
optimization problem for functionally generated portfolios in the spirit of
maximum likelihood estimation of a log-concave density.
"
1408.0916,2016-05-05,A system of quadratic BSDEs arising in a price impact model,"  We consider a financial model where the prices of risky assets are quoted by
a representative market maker who takes into account an exogenous demand. We
characterize these prices in terms of a system of BSDEs with quadratic growth.
We show that this system admits a unique solution for every bounded demand if
and only if the market maker's risk-aversion is sufficiently small. The
uniqueness is established in the natural class of solutions, without any
additional norm restrictions. To the best of our knowledge, this is the first
study that proves such (global) uniqueness result for a system of fully coupled
quadratic BSDEs.
"
1408.1159,2014-09-30,Determining Optimal Trading Rules without Backtesting,"  Calibrating a trading rule using a historical simulation (also called
backtest) contributes to backtest overfitting, which in turn leads to
underperformance. In this paper we propose a procedure for determining the
optimal trading rule (OTR) without running alternative model configurations
through a backtest engine. We present empirical evidence of the existence of
such optimal solutions for the case of prices following a discrete
Ornstein-Uhlenbeck process, and show how they can be computed numerically.
Although we do not derive a closed-form solution for the calculation of OTRs,
we conjecture its existence on the basis of the empirical evidence presented.
"
1408.1382,2016-07-26,"Optimal Consumption under Habit Formation In Markets with Transaction
  Costs and Random Endowments","  This paper studies the optimal consumption under the addictive habit
formation preference in markets with transaction costs and unbounded random
endowments. To model the proportional transaction costs, we adopt the Kabanov's
multi-asset framework with a cash account. At the terminal time T, the investor
can receive unbounded random endowments for which we propose a new definition
of acceptable portfolios based on the strictly consistent price system (SCPS).
We prove a type of super-hedging theorem using the acceptable portfolios which
enables us to obtain the consumption budget constraint condition under market
frictions. Applying the path dependence reduction and the embedding approach,
we obtain the existence and uniqueness of the optimal consumption using some
auxiliary processes and the duality analysis. As an application of the duality
theory, the market isomorphism with special discounting factors is also
discussed in the sense that the original optimal consumption with habit
formation is equivalent to the standard optimal consumption problem without the
habits impact, however, in a modified isomorphic market model.
"
1408.2217,2016-02-15,Mean-Reversion and Optimization,"  The purpose of these notes is to provide a systematic quantitative framework
- in what is intended to be a ""pedagogical"" fashion - for discussing
mean-reversion and optimization. We start with pair trading and add complexity
by following the sequence ""mean-reversion via demeaning -> regression ->
weighted regression -> (constrained) optimization -> factor models"". We discuss
in detail how to do mean-reversion based on this approach, including common
pitfalls encountered in practical applications, such as the difference between
maximizing the Sharpe ratio and minimizing an objective function when trading
costs are included. We also discuss explicit algorithms for optimization with
linear costs, constraints and bounds.
"
1408.2805,2014-08-13,"Accelerated Portfolio Optimization with Conditional Value-at-Risk
  Constraints using a Cutting-Plane Method","  Financial portfolios are often optimized for maximum profit while subject to
a constraint formulated in terms of the Conditional Value-at-Risk (CVaR). This
amounts to solving a linear problem. However, in its original formulation this
linear problem has a very large number of linear constraints, too many to be
enforced in practice. In the literature this is addressed by a reformulation of
the problem using so-called dummy variables. This reduces the large number of
constraints in the original linear problem at the cost of increasing the number
of variables. In the context of reinsurance portfolio optimization we observe
that the increase in variable count can lead to situations where solving the
reformulated problem takes a long time. Therefore we suggest a different
approach. We solve the original linear problem with cutting-plane method: The
proposed algorithm starts with the solution of a relaxed problem and then
iteratively adds cuts until the solution is approximated within a preset
threshold. This is a new approach. For a reinsurance case study we show that a
significant reduction of necessary computer resources can be achieved.
"
1408.3774,2015-06-08,"Risk Minimization for Game Options in Markets Imposing Minimal
  Transaction Costs","  We study partial hedging for game options in markets with transaction costs
bounded from below. More precisely, we assume that the investor's transaction
costs for each trade are the maximum between proportional transaction costs and
a fixed transaction costs. We prove that in the continuous time Black--Scholes
(BS) model, there exists a trading strategy which minimizes the shortfall risk.
Furthermore, we use binomial models in order to provide numerical schemes for
the calculation of the shortfall risk and the corresponding optimal portfolio
in the BS model.
"
1408.5989,2014-08-27,Duality Theory for Portfolio Optimisation under Transaction Costs,"  For portfolio optimisation under proportional transaction costs, we provide a
duality theory for general cadlag price processes. In this setting, we prove
the existence of a dual optimiser as well as a shadow price process in a
generalised sense. This shadow price is defined via a ""sandwiched"" process
consisting of a predictable and an optional strong supermartingale and pertains
to all strategies which remain solvent under transaction costs. We provide
examples showing that in the present general setting the shadow price process
has to be of this generalised form.
"
1408.6065,2015-05-06,Shadow prices for continuous processes,"  In a financial market with a continuous price process and proportional
transaction costs we investigate the problem of utility maximization of
terminal wealth. We give sufficient conditions for the existence of a shadow
price process, i.e.~a least favorable frictionless market leading to the same
optimal strategy and utility as in the original market under transaction costs.
The crucial ingredients are the continuity of the price process and the
hypothesis of ""no unbounded profit with bounded risk"". A counter-example
reveals that these hypotheses cannot be relaxed.
"
1408.6070,2015-08-04,"Time Consistent Behavior Portfolio Policy for Dynamic Mean-Variance
  Formulation","  When we implement a portfolio selection methodology under a mean-risk
formulation, it is essential to correctly model investors' risk aversion which
may be time-dependent, or even state-dependent during the investment procedure.
In this paper, we propose a behavior risk aversion model, which is a piecewise
linear function of the current wealth level with a reference point at a preset
investment target. Due to the time inconsistency of the resulting multi-period
mean-variance model with an adaptive risk aversion, we investigate in this
paper the time consistent behavior portfolio policy by solving a nested
mean-variance game formulation. We derive semi-analytical time consistent
behavior portfolio policy which takes a piecewise linear feedback form of the
current wealth level with respect to the discounted investment target.
"
1408.6455,2014-08-28,Long time asymptotics for optimal investment,"  This survey reviews portfolio selection problem for long-term horizon. We
consider two objectives: (i) maximize the probability for outperforming a
target growth rate of wealth process (ii) minimize the probability of falling
below a target growth rate. We study the asymptotic behavior of these criteria
formulated as large deviations control pro\-blems, that we solve by duality
method leading to ergodic risk-sensitive portfolio optimization problems.
Special emphasis is placed on linear factor models where explicit solutions are
obtained.
"
1409.0407,2016-11-04,"Optimal dividend problems for a jump-diffusion model with capital
  injections and proportional transaction costs","  In this paper, we study the optimal control problem for a company whose
surplus process evolves as an upward jump diffusion with random return on
investment. Three types of practical optimization problems faced by a company
that can control its liquid reserves by paying dividends and injecting capital.
In the first problem, we consider the classical dividend problem without
capital injections. The second problem aims at maximizing the expected
discounted dividend payments minus the expected discounted costs of capital
injections over strategies with positive surplus at all times. The third
problem has the same objective as the second one, but without the constraints
on capital injections. Under the assumption of proportional transaction costs,
we identify the value function and the optimal strategies for any distribution
of gains.
"
1409.0665,2015-06-12,"Optimal Dynamic Procurement Policies for a Storable Commodity with
  L\'evy Prices and Convex Holding Costs","  In this paper we study a continuous time stochastic inventory model for a
commodity traded in the spot market and whose supply purchase is affected by
price and demand uncertainty. A firm aims at meeting a random demand of the
commodity at a random time by maximizing total expected profits. We model the
firm's optimal procurement problem as a singular stochastic control problem in
which controls are nondecreasing processes and represent the cumulative
investment made by the firm in the spot market (a so-called stochastic
""monotone follower problem""). We assume a general exponential L\'evy process
for the commodity's spot price, rather than the commonly used geometric
Brownian motion, and general convex holding costs.
  We obtain necessary and sufficient first order conditions for optimality and
we provide the optimal procurement policy in terms of a ""base inventory""
process; that is, a minimal time-dependent desirable inventory level that the
firm's manager must reach at any time. In particular, in the case of linear
holding costs and exponentially distributed demand, we are also able to obtain
the explicit analytic form of the optimal policy and a probabilistic
representation of the optimal revenue. The paper is completed by some computer
drawings of the optimal inventory when spot prices are given by a geometric
Brownian motion and by an exponential jump-diffusion process. In the first case
we also make a numerical comparison between the value function and the revenue
associated to the classical static ""newsvendor"" strategy.
"
1409.2023,2014-09-09,Optimal investment with bounded above utilities in discrete time markets,"  We consider an arbitrage-free, discrete time and frictionless market. We
prove that an investor maximising the expected utility of her terminal wealth
can always find an optimal investment strategy provided that her
dissatisfaction of infinite losses is infinite and her utility function is
non-decreasing, continuous and bounded above. The same result is shown for
cumulative prospect theory preferences, under additional assumptions.
"
1409.2575,2015-05-21,Custom v. Standardized Risk Models,"  We discuss when and why custom multi-factor risk models are warranted and
give source code for computing some risk factors. Pension/mutual funds do not
require customization but standardization. However, using standardized risk
models in quant trading with much shorter holding horizons is suboptimal: 1)
longer horizon risk factors (value, growth, etc.) increase noise trades and
trading costs; 2) arbitrary risk factors can neutralize alpha; 3)
""standardized"" industries are artificial and insufficiently granular; 4)
normalization of style risk factors is lost for the trading universe; 5)
diversifying risk models lowers P&L correlations, reduces turnover and market
impact, and increases capacity. We discuss various aspects of custom risk model
building.
"
1409.3394,2014-09-12,Optimal consumption and sale strategies for a risk averse agent,"  In this article we consider a special case of an optimal consumption/optimal
portfolio problem first studied by Constantinides and Magill and by Davis and
Norman, in which an agent with constant relative risk aversion seeks to
maximise expected discounted utility of consumption over the infinite horizon,
in a model comprising a risk-free asset and a risky asset with proportional
transaction costs. The special case that we consider is that the cost of
purchases of the risky asset is infinite, or equivalently the risky asset can
only be sold and not bought.
  In this special setting new solution techniques are available, and we can
make considerable progress towards an analytical solution. This means we are
able to consider the comparative statics of the problem. There are some
surprising conclusions, such as consumption rates are not monotone increasing
in the return of the asset, nor are the certainty equivalent values of the
risky positions monotone in the risk aversion.
"
1409.3969,2014-09-16,Portfolio Selection with Mandatory Bequest,"  In this paper, optimal consumption and investment decisions are studied for
an investor who can invest in a fixed interest rate bank account and a stock
whose price is a log normal diffusion. We present the method of the HJB
equation in order to explicitly solve problems of this type with modifications
such as a fixed percentage transaction cost and a mandatory bequest function.
It is shown that the investor treats the mandatory bequest as an expense that
she factors into her personal wealth when making consumption and transaction
decisions. Furthermore, the investor keeps her portfolio proportions inside a
fixed boundary relating to Merton's optimal proportion and the transaction
costs.
"
1409.5936,2014-09-23,Bounds on Portfolio Quality,"  The signal-noise ratio of a portfolio of p assets, its expected return
divided by its risk, is couched as an estimation problem on the sphere. When
the portfolio is built using noisy data, the expected value of the signal-noise
ratio is bounded from above via a Cramer-Rao bound, for the case of Gaussian
returns. The bound holds for `biased' estimators, thus there appears to be no
bias-variance tradeoff for the problem of maximizing the signal-noise ratio. An
approximate distribution of the signal-noise ratio for the Markowitz portfolio
is given, and shown to be fairly accurate via Monte Carlo simulations, for
Gaussian returns as well as more exotic returns distributions. These findings
imply that if the maximal population signal-noise ratio grows slower than the
universe size to the 1/4 power, there may be no diversification benefit, rather
expected signal-noise ratio can decrease with additional assets. As a practical
matter, this may explain why the Markowitz portfolio is typically applied to
small asset universes. Finally, the theorem is expanded to cover more general
models of returns and trading schemes, including the conditional expectation
case where mean returns are linear in some observable features, subspace
constraints (i.e., dimensionality reduction), and hedging constraints.
"
1409.7269,2014-09-26,High-Resilience Limits of Block-Shaped Order Books,"  We show that wealth processes in the block-shaped order book model of
Obizhaeva/Wang converge to their counterparts in the reduced-form model
proposed by Almgren/Chriss, as the resilience of the order book tends to
infinity. As an application of this limit theorem, we explain how to reduce
portfolio choice in highly-resilient Obizhaeva/Wang models to the corresponding
problem in an Almgren/Chriss setup with small quadratic trading costs.
"
1409.7933,2014-09-30,Parametric Risk Parity,"  Any optimization algorithm based on the risk parity approach requires the
formulation of portfolio total risk in terms of marginal contributions. In this
paper we use the independence of the underlying factors in the market to derive
the centered moments required in the risk decomposition process when the
modified versions of Value at Risk and Expected Shortfall are considered.
  The choice of the Mixed Tempered Stable distribution seems adequate for
fitting skewed and heavy tailed distributions. The ensuing detailed description
of the optimization procedure is due to the existence of analytical higher
order moments. Better results are achieved in terms of out of sample
performance and greater diversification.
"
1410.0915,2015-06-25,Stability of Utility Maximization in Nonequivalent Markets,"  Stability of the utility maximization problem with random endowment and
indifference prices is studied for a sequence of financial markets in an
incomplete Brownian setting. Our novelty lies in the nonequivalence of markets,
in which the volatility of asset prices (as well as the drift) varies.
Degeneracies arise from the presence of nonequivalence. In the positive real
line utility framework, a counterexample is presented showing that the expected
utility maximization problem can be unstable. A positive stability result is
proven for utility functions on the entire real line.
"
1410.0946,2016-08-11,An expansion in the model space in the context of utility maximization,"  In the framework of an incomplete financial market where the stock price
dynamics are modeled by a continuous semimartingale (not necessarily Markovian)
an explicit second-order expansion formula for the power investor's value
function - seen as a function of the underlying market price of risk process -
is provided. This allows us to provide first-order approximations of the
optimal primal and dual controls. Two specific calibrated numerical examples
illustrating the accuracy of the method are also given.
"
1410.1136,2014-10-07,"Dynamic Investment Portfolio Optimization under Constraints in the
  Financial Market with Regime Switching using Model Predictive Control","  In this work, we consider the optimal portfolio selection problem under hard
constraints on trading volume amounts when the dynamics of the risky asset
returns are governed by a discrete-time approximation of the Markov-modulated
geometric Brownian motion. The states of Markov chain are interpreted as the
states of an economy. The problem is stated as a dynamic tracking problem of a
reference portfolio with desired return. We propose to use the model predictive
control (MPC) methodology in order to obtain feedback trading strategies. Our
approach is tested on a set of a real data from the radically different
financial markets: the Russian Stock Exchange MICEX, the New York Stock
Exchange and the Foreign Exchange Market (FOREX).
"
1410.3793,2015-12-08,Optimal dividend payment under time of ruin contraint: Exponential case,"  We consider the classical optimal dividends problem under the
Cram\'er-Lundberg model with exponential claim sizes subject to a constraint on
the time of ruin. We introduce the dual problem and show that the complementary
slackness conditions are satisfied, thus there is no duality gap. Therefore the
optimal value function can be obtained as the point-wise infimum of auxiliary
value functions indexed by Lagrange multipliers. We also present a series of
numerical examples.
"
1410.5328,2015-03-26,Portfolio Selection with Multiple Spectral Risk Constraints,"  We propose an iterative gradient-based algorithm to efficiently solve the
portfolio selection problem with multiple spectral risk constraints. Since the
conditional value at risk (CVaR) is a special case of the spectral risk
measure, our algorithm solves portfolio selection problems with multiple CVaR
constraints. In each step, the algorithm solves very simple separable convex
quadratic programs; hence, we show that the spectral risk constrained portfolio
selection problem can be solved using the technology developed for solving
mean-variance problems. The algorithm extends to the case where the objective
is a weighted sum of the mean return and either a weighted combination or the
maximum of a set of spectral risk measures. We report numerical results that
show that our proposed algorithm is very efficient; it is at least one order of
magnitude faster than the state-of-the-art general purpose solver for all
practical instances. One can leverage this efficiency to be robust against
model risk by including constraints with respect to several different risk
models.
"
1410.5513,2015-09-24,4-Factor Model for Overnight Returns,"  We propose a 4-factor model for overnight returns and give explicit
definitions of our 4 factors. Long horizon fundamental factors such as value
and growth lack predictive power for overnight (or similar short horizon)
returns and are not included. All 4 factors are constructed based on intraday
price and volume data and are analogous to size (price), volatility, momentum
and liquidity (volume). Historical regressions a la Fama and MacBeth (1973)
suggest that our 4 factors have sizable serial t-statistic and appear to be
relevant predictors for overnight returns. We check this by using our 4-factor
model in an explicit intraday mean-reversion alpha.
"
1410.5621,2014-10-22,"Risk diversification: a study of persistence with a filtered
  correlation-network approach","  The evolution with time of the correlation structure of equity returns is
studied by means of a filtered network approach investigating persistences and
recurrences and their implications for risk diversification strategies. We
build dynamically Planar Maximally Filtered Graphs from the correlation
structure over a rolling window and we study the persistence of the associated
Directed Bubble Hierarchical Tree (DBHT) clustering structure. We observe that
the DBHT clustering structure is quite stable during the early 2000' becoming
gradually less persistent before the unfolding of the 2007-2008 crisis. The
correlation structure eventually recovers persistence in the aftermath of the
crisis settling up a new phase, distinct from the pre-cysts structure, where
the market structure is less related to industrial sector activity. Notably, we
observe that - presently - the correlation structure is loosing again
persistence indicating the building-up of another, different, phase. Such
dynamical changes in persistence and their occurrence at the unfolding of
financial crises rises concerns about the effectiveness of correlation-based
portfolio management tools for risk diversification.
"
1410.5996,2015-06-30,"Log-Optimal Portfolio Selection Using the Blackwell Approachability
  Theorem","  We present a method for constructing the log-optimal portfolio using the
well-calibrated forecasts of market values. Dawid's notion of calibration and
the Blackwell approachability theorem are used for computing well-calibrated
forecasts. We select a portfolio using this ""artificial"" probability
distribution of market values. Our portfolio performs asymptotically at least
as well as any stationary portfolio that redistributes the investment at each
round using a continuous function of side information. Unlike in classical
mathematical finance theory, no stochastic assumptions are made about market
values.
"
1410.6144,2016-08-30,"Stability and analytic expansions of local solutions of systems of
  quadratic BSDEs with applications to a price impact model","  We obtain stability estimates and derive analytic expansions for local
solutions of multi-dimensional quadratic BSDEs. We apply these results to a
financial model where the prices of risky assets are quoted by a representative
dealer in such a way that it is optimal to meet an exogenous demand. We show
that the prices are stable under the demand process and derive their analytic
expansions for small risk aversion coefficients of the dealer.
"
1410.8042,2014-10-30,"Portfolio Optimization in the Financial Market with Correlated Returns
  under Constraints, Transaction Costs and Different Rates for Borrowing and
  Lending","  In this work, we consider the optimal portfolio selection problem under hard
constraints on trading amounts, transaction costs and different rates for
borrowing and lending when the risky asset returns are serially correlated. No
assumptions about the correlation structure between different time points or
about the distribution of the asset returns are needed. The problem is stated
as a dynamic tracking problem of a reference portfolio with desired return. Our
approach is tested on a set of a real data from Russian Stock Exchange MICEX.
"
1410.8409,2020-01-03,Optimal Allocation of Trend Following Strategies,"  We consider a portfolio allocation problem for trend following (TF)
strategies on multiple correlated assets. Under simplifying assumptions of a
Gaussian market and linear TF strategies, we derive analytical formulas for the
mean and variance of the portfolio return. We construct then the optimal
portfolio that maximizes risk-adjusted return by accounting for inter-asset
correlations. The dynamic allocation problem for $n$ assets is shown to be
equivalent to the classical static allocation problem for $n^2$ virtual assets
that include lead-lag corrections in positions of TF strategies. The respective
roles of asset auto-correlations and inter-asset correlations are investigated
in depth for the two-asset case and a sector model. In contrast to the
principle of diversification suggesting to treat uncorrelated assets, we show
that inter-asset correlations allow one to estimate apparent trends more
reliably and to adjust the TF positions more efficiently. If properly accounted
for, inter-asset correlations are not deteriorative but beneficial for
portfolio management that can open new profit opportunities for trend
followers.
"
1411.1103,2015-09-22,"Utility maximization in pure-jump models driven by marked point
  processes and nonlinear wealth dynamics","  We explore martingale and convex duality techniques to study optimal
investment strategies that maximize expected risk-averse utility from
consumption and terminal wealth. We consider a market model with jumps driven
by (multivariate) marked point processes and so-called non-linear wealth
dynamics which allows to take account of relaxed assumptions such as
differential borrowing and lending interest rates or short positions with cash
collateral and negative rebate rates. We give suffcient conditions for
existence of optimal policies for agents with logarithmic and CRRA power
utility. We find closed-form solutions for the optimal value function in the
case of pure-jump models with jump-size distributions modulated by a two-state
Markov chain.
"
1411.2395,2014-11-11,"Irreversible Investment under L\'evy Uncertainty: an Equation for the
  Optimal Boundary","  We derive a new equation for the optimal investment boundary of a general
irreversible investment problem under exponential L\'evy uncertainty. The
problem is set as an infinite time-horizon, two-dimensional degenerate singular
stochastic control problem. In line with the results recently obtained in a
diffusive setting, we show that the optimal boundary is intimately linked to
the unique optional solution of an appropriate Bank-El Karoui representation
problem. Such a relation and the Wiener Hopf factorization allow us to derive
an integral equation for the optimal investment boundary. In case the
underlying L\'evy process hits any real point with positive probability we show
that the integral equation for the investment boundary is uniquely satisfied by
the unique solution of another equation which is easier to handle. As a
remarkable by-product we prove the continuity of the optimal investment
boundary. The paper is concluded with explicit results for profit functions of
(i) Cobb-Douglas type and (ii) CES type. In the first case the function is
separable and in the second case non-separable.
"
1411.2525,2016-07-20,"Optimising Credit Portfolio Using a Quadratic Nonlinear Projection
  Method","  A novel optimisation framework through quadratic nonlinear projection is
introduced for credit portfolio when the portfolio risk is measured by
Conditional Value-at-Risk (CVaR). The whole optimisation procedure to search
toward the optimal portfolio state is conducted by a series of single-step
optimisations under the local constraints described in the multi-dimensional
constraint parameter space as functions of the total amount of portfolio
adjustment. Each single-step optimisation is approximated by the first-order
variation of the weight increments with respect to the total amount of
portfolio adjustment and is solved in the form of locally exact formula
formulated in the general Lagrange multiplier method. Our method can deal with
optimisation for general nonlinear objective functions, such as the
return-to-risk ratio maximisation or the diversification index, as well as the
risk minimisation or the return maximisation.
"
1411.2675,2016-11-30,"Process-Based Risk Measures and Risk-Averse Control of Discrete-Time
  Systems","  For controlled discrete-time stochastic processes we introduce a new class of
dynamic risk measures, which we call process-based. Their main features are
that they measure risk of processes that are functions of the history of a base
process. We introduce a new concept of conditional stochastic time consistency
and we derive the structure of process-based risk measures enjoying this
property. We show that they can be equivalently represented by a collection of
static law-invariant risk measures on the space of functions of the state of
the base process. We apply this result to controlled Markov processes and we
derive dynamic programming equations.
"
1411.3615,2014-11-14,Kelly criterion for variable pay-off,"  We determine Kelly criterion for a game with variable pay-off. The Kelly
fraction satisfies a fundamental integral equation and is smaller than the
classical Kelly fraction for the same game with the constant average pay-off.
"
1411.6657,2014-12-16,Risk minimization and portfolio diversification,"  We consider the problem of minimizing capital at risk in the Black-Scholes
setting. The portfolio problem is studied given the possibility that a
correlation constraint between the portfolio and a financial index is imposed.
The optimal portfolio is obtained in closed form. The effects of the
correlation constraint are explored; it turns out that this portfolio
constraint leads to a more diversified portfolio.
"
1411.7494,2015-04-14,An Evolutionary Optimization Approach to Risk Parity Portfolio Selection,"  In this paper we present an evolutionary optimization approach to solve the
risk parity portfolio selection problem. While there exist convex optimization
approaches to solve this problem when long-only portfolios are considered, the
optimization problem becomes non-trivial in the long-short case. To solve this
problem, we propose a genetic algorithm as well as a local search heuristic.
This algorithmic framework is able to compute solutions successfully. Numerical
results using real-world data substantiate the practicability of the approach
presented in this paper.
"
1411.7670,2015-11-05,"Liquidity Management with Decreasing-returns-to-scale and Secured Credit
  Line","  This paper examines the dividend and investment policies of a cash
constrained firm that has access to costly external funding. We depart from the
literature by allowing the firm to issue collateralized debt to increase its
investment in productive assets resulting in a performance sensitive interest
rate on debt. We formulate this problem as a bi-dimensional singular control
problem and use both a viscosity solution approch and a verification technique
to get qualitative properties of the value function. We further solve
quasi-explicitly the control problem in two special cases.
"
1412.2262,2016-02-29,Purchasing Term Life Insurance to Reach a Bequest Goal while Consuming,"  We determine the optimal strategies for purchasing term life insurance and
for investing in a risky financial market in order to maximize the probability
of reaching a bequest goal while consuming from an investment account. We
extend Bayraktar and Young (2015) by allowing the individual to purchase term
life insurance to reach her bequest goal. The premium rate for life insurance,
$h$, serves as a parameter to connect two seemingly unrelated problems. As the
premium rate approaches $0$, covering the bequest goal becomes costless, so the
individual simply wants to avoid ruin that might result from her consumption.
Thus, as $h$ approaches $0$, the problem in this paper becomes equivalent to
minimizing the probability of lifetime ruin, which is solved in Young (2004).
On the other hand, as the premium rate becomes arbitrarily large, the
individual will not buy life insurance to reach her bequest goal. Thus, as $h$
approaches infinity, the problem in this paper becomes equivalent to maximizing
the probability of reaching the bequest goal when life insurance is not
available in the market, which is solved in Bayraktar and Young (2015).
"
1412.4342,2017-11-07,Russian-Doll Risk Models,"  We give a simple explicit algorithm for building multi-factor risk models. It
dramatically reduces the number of or altogether eliminates the risk factors
for which the factor covariance matrix needs to be computed. This is achieved
via a nested ""Russian-doll"" embedding: the factor covariance matrix itself is
modeled via a factor model, whose factor covariance matrix in turn is modeled
via a factor model, and so on. We discuss in detail how to implement this
algorithm in the case of (binary) industry classification based risk factors
(e.g., ""sector -> industry -> sub-industry""), and also in the presence of
(non-binary) style factors. Our algorithm is particularly useful when long
historical lookbacks are unavailable or undesirable, e.g., in short-horizon
quant trading.
"
1412.4698,2016-06-15,Conditional Analysis and a Principal-Agent problem,"  We analyze conditional optimization problems arising in discrete time
Principal-Agent problems of delegated portfolio optimization with linear
contracts. Applying tools from Conditional Analysis we show that some results
known in the literature for very specific instances of the problem carry over
to translation invariant and time-consistent utility functions in very general
probabilistic settings. However, we find that optimal contracts must in general
make use of derivatives for compensation.
"
1412.5332,2014-12-23,"Efficient XVA Management: Pricing, Hedging, and Attribution using
  Trade-Level Regression and Global Conditioning","  Banks must manage their trading books, not just value them. Pricing includes
valuation adjustments collectively known as XVA (at least credit, funding,
capital and tax), so management must also include XVA. In trading book
management we focus on pricing, hedging, and allocation of prices or hedging
costs to desks on an individual trade basis. We show how to combine three
technical elements to radically simplify XVA management, both in terms of the
calculations, and the implementation of the calculations. The three technical
elements are: trade-level regression; analytic computation of sensitivities;
and global conditioning. All three are required to obtain the radical
efficiency gains and implementation simplification. Moreover, many of the
calculations are inherently parallel and suitable for GPU implementation. The
resulting methodology for XVA management is sufficiently general that we can
cover pricing, first- and second-order sensitivities, and exact trade-level
allocation of pricing and sensitivities within the same framework. Managing
incremental changes to portfolios exactly is also radically simplified.
"
1412.7269,2015-03-20,"Large-scale empirical study on pairs trading for all possible pairs of
  stocks listed on the first section of the Tokyo Stock Exchange","  We carry out a large-scale empirical data analysis to examine the efficiency
of the so-called pairs trading. On the basis of relevant three thresholds,
namely, starting, profit-taking, and stop-loss for the `first-passage process'
of the spread (gap) between two highly-correlated stocks, we construct an
effective strategy to make a trade via `active' stock-pairs automatically. The
algorithm is applied to $1,784$ stocks listed on the first section of the Tokyo
Stock Exchange leading up to totally $1,590,436$ pairs. We are numerically
confirmed that the asset management by means of the pairs trading works
effectively at least for the past three years (2010-2012) data sets in the
sense that the profit rate becomes positive (totally positive arbitrage) in
most cases of the possible combinations of thresholds corresponding to
`absorbing boundaries' in the literature of first-passage processes.
"
1501.00026,2015-01-05,Optimal Selling Time of a Stock under Capital Gains Taxes,"  We investigate the impact of capital gains taxes on optimal investment
decisions in a quite simple model. Namely, we consider a risk neutral investor
who owns one risky stock from which she assumes that it has a lower expected
return than the riskless bank account and determine the optimal stopping time
at which she sells the stock to invest the proceeds in the bank account up to
the maturity date. In the case of linear taxes and a positive riskless interest
rate, the problem is nontrivial because at the selling time the investor has to
realize book profits which triggers tax payments. We derive a boundary that is
continuous and increasing in time and decreasing in the volatility of the stock
such that the investor sells the stock at the first time its price is smaller
or equal to this boundary.
"
1501.01126,2015-01-07,A Composite Risk Measure Framework for Decision Making under Uncertainty,"  In this paper, we present a unified framework for decision making under
uncertainty. Our framework is based on the composite of two risk measures,
where the inner risk measure accounts for the risk of decision given the exact
distribution of uncertain model parameters, and the outer risk measure
quantifies the risk that occurs when estimating the parameters of distribution.
We show that the model is tractable under mild conditions. The framework is a
generalization of several existing models, including stochastic programming,
robust optimization, distributionally robust optimization, etc. Using this
framework, we study a few new models which imply probabilistic guarantees for
solutions and yield less conservative results comparing to traditional models.
Numerical experiments are performed on portfolio selection problems to
demonstrate the strength of our models.
"
1501.01504,2016-08-07,"Optimal investment under behavioural criteria in incomplete diffusion
  market models","  The most commonly accepted model for investors' preferences is expected
utility theory. More recently, other theories have emerged and pose new
challenges to mathematics. The present paper treats preferences of cumulative
prospect theory (CPT), where an ""S-shaped"" utility function is considered (i.e.
convex up to a certain point and concave from there on). Also, distorted
probability measures are applied for calculating the utility of a given
position with respect to a (possibly random) benchmark $G$. Such problems have
heretofore been solved essentially for complete continuous-time market models
only. In the present paper we make a step forward and consider incomplete
models of a diffusion type where the return of the investment in consideration
depends on some economic factors. Our main result asserts, under mild
assumptions, the existence of an optimal strategy when the driving noise of the
economic factors is independent of that of the investment and the rate of
return is non-negative. We are also able to accommodate models of a specific
type where the factor may have non-zero correlation with the investment.
"
1501.01573,2016-06-28,The Temporal Dimension of Risk,"  Multi-period measures of risk account for the path that the value of an
investment portfolio takes. In the context of probabilistic risk measures, the
focus has traditionally been on the magnitude of investment loss and not on the
dimension associated with the passage of time. In this paper, the concept of
temporal path-dependent risk measure is mathematically formalized to capture
the risk associated with the temporal dimension of a stochastic process. We
discuss the properties of temporal measures of risk and show that they can
never be coherent. We then study the temporal dimension of investment drawdown,
its duration, which measures the length of excursions below a running maximum.
Its properties in the context of risk measures are analyzed both theoretically
and empirically. In particular, we show that duration captures serial
correlation in the returns of two major asset classes. We conclude by
discussing the challenges of path-dependent temporal risk estimation in
practice.
"
1501.02382,2015-01-13,Robust Inference of Risks of Large Portfolios,"  We propose a bootstrap-based robust high-confidence level upper bound (Robust
H-CLUB) for assessing the risks of large portfolios. The proposed approach
exploits rank-based and quantile-based estimators, and can be viewed as a
robust extension of the H-CLUB method (Fan et al., 2015). Such an extension
allows us to handle possibly misspecified models and heavy-tailed data. Under
mixing conditions, we analyze the proposed approach and demonstrate its
advantage over the H-CLUB. We further provide thorough numerical results to
back up the developed theory. We also apply the proposed method to analyze a
stock market dataset.
"
1501.03768,2015-01-16,On the martingale-fair index of return for investment funds,"  A concept of martingale-fair index of return, consistent with Arbitrage Free
Pricing Theory, is introduced. An explicit formula for the average rate of
return of a group of investment/pension funds in a discrete time stochastic
model is derived and several properties of this index are shown. In particular,
it is proven to be martingale-fair, i.e. be a martingale provided the prices of
assets on the financial market form a vector martingale. The problem of merger
of the funds is treated in detail.
"
1501.04747,2015-11-13,"Consumption investment optimization with Epstein-Zin utility in
  incomplete markets","  In a market with stochastic investment opportunities, we study an optimal
consumption investment problem for an agent with recursive utility of
Epstein-Zin type. Focusing on the empirically relevant specification where both
risk aversion and elasticity of intertemporal substitution are in excess of
one, we characterize optimal consumption and investment strategies via backward
stochastic differential equations. The supperdifferential of indirect utility
is also obtained, meeting demands from applications in which Epstein-Zin
utilities were used to resolve several asset pricing puzzles. The empirically
relevant utility specification introduces difficulties to the optimization
problem due to the fact that the Epstein-Zin aggregator is neither Lipschitz
nor jointly concave in all its variables.
"
1501.05381,2015-11-05,Combining Alphas via Bounded Regression,"  We give an explicit algorithm and source code for combining alpha streams via
bounded regression. In practical applications typically there is insufficient
history to compute a sample covariance matrix (SCM) for a large number of
alphas. To compute alpha allocation weights, one then resorts to (weighted)
regression over SCM principal components. Regression often produces alpha
weights with insufficient diversification and/or skewed distribution against,
e.g., turnover. This can be rectified by imposing bounds on alpha weights
within the regression procedure. Bounded regression can also be applied to
stock and other asset portfolio construction. We discuss illustrative examples.
"
1501.07124,2015-01-29,Optimal strategies of investment in a linear stochastic model of market,"  We study the continuous time portfolio optimization model on the market where
the mean returns of individual securities or asset categories are linearly
dependent on underlying economic factors. We introduce the functional
$Q_\gamma$ featuring the expected earnings yield of portfolio minus a penalty
term proportional with a coefficient $\gamma$ to the variance when we keep the
value of the factor levels fixed. The coefficient $\gamma$ plays the role of a
risk-aversion parameter. We find the optimal trading positions that can be
obtained as the solution to a maximization problem for $Q_\gamma$ at any moment
of time. The single-factor case is analyzed in more details. We present a
simple asset allocation example featuring an interest rate which affects a
stock index and also serves as a second investment opportunity. We consider two
possibilities: the interest rate for the bank account is governed by
Vasicek-type and Cox-Ingersoll-Ross dynamics, respectively. Then we compare our
results with the theory of Bielecki and Pliska where the authors employ the
methods of the risk-sensitive control theory thereby using an infinite horizon
objective featuring the long run expected growth rate, the asymptotic variance,
and a risk-aversion parameter similar to $\gamma$.
"
1501.07480,2016-06-28,Portfolio Optimization under Shortfall Risk Constraint,"  This paper solves a utility maximization problem under utility-based
shortfall risk constraint, by proposing an approach using Lagrange multiplier
and convex duality. Under mild conditions on the asymptotic elasticity of the
utility function and the loss function, we find an optimal wealth process for
the constrained problem and characterize the bi-dual relation between the
respective value functions of the constrained problem and its dual. This
approach applies to both complete and incomplete markets. Moreover, the
extension to more complicated cases is illustrated by solving the problem with
a consumption process added. Finally, we give an example of utility and loss
functions in the Black-Scholes market where the solutions have explicit forms.
"
1502.00358,2015-03-31,"Optimal Derivative Liquidation Timing Under Path-Dependent Risk
  Penalties","  This paper studies the risk-adjusted optimal timing to liquidate an option at
the prevailing market price. In addition to maximizing the expected discounted
return from option sale, we incorporate a path-dependent risk penalty based on
shortfall or quadratic variation of the option price up to the liquidation
time. We establish the conditions under which it is optimal to immediately
liquidate or hold the option position through expiration. Furthermore, we study
the variational inequality associated with the optimal stopping problem, and
prove the existence and uniqueness of a strong solution. A series of analytical
and numerical results are provided to illustrate the non-trivial optimal
liquidation strategies under geometric Brownian motion (GBM) and exponential
Ornstein-Uhlenbeck models. We examine the combined effects of price dynamics
and risk penalty on the sell and delay regions for various options. In
addition, we obtain an explicit closed-form solution for the liquidation of a
stock with quadratic penalty under the GBM model.
"
1502.01658,2015-10-16,"Weighted Elastic Net Penalized Mean-Variance Portfolio Design and
  Computation","  It is well known that the out-of-sample performance of Markowitz's
mean-variance portfolio criterion can be negatively affected by estimation
errors in the mean and covariance. In this paper we address the problem by
regularizing the mean-variance objective function with a weighted elastic net
penalty. We show that the use of this penalty can be motivated by a robust
reformulation of the mean-variance criterion that directly accounts for
parameter uncertainty. With this interpretation of the weighted elastic net
penalty we derive data driven techniques for calibrating the weighting
parameters based on the level of uncertainty in the parameter estimates. We
test our proposed technique on US stock return data and our results show that
the calibrated weighted elastic net penalized portfolio outperforms both the
unpenalized portfolio and uniformly weighted elastic net penalized portfolio.
  This paper also introduces a novel Adaptive Support Split-Bregman approach
which leverages the sparse nature of $\ell_{1}$ penalized portfolios to
efficiently compute a solution of our proposed portfolio criterion. Numerical
results show that this modification to the Split-Bregman algorithm results in
significant improvements in computational speed compared with other techniques.
"
1502.02286,2015-02-10,Asymptotic Investment Behaviors under a Jump-Diffusion Risk Process,"  We study an optimal investment control problem for an insurance company. The
surplus process follows the Cramer-Lundberg process with perturbation of a
Brownian motion. The company can invest its surplus into a risk free asset and
a Black-Scholes risky asset. The optimization objective is to minimize the
probability of ruin. We show by new operators that the minimal ruin probability
function is a classical solution to the corresponding HJB equation. Asymptotic
behaviors of the optimal investment control policy and the minimal ruin
probability function are studied for low surplus levels with a general claim
size distribution. Some new asymptotic results for large surplus levels in the
case with exponential claim distributions are obtained. We consider two cases
of investment control - unconstrained investment and investment with a limited
amount.
"
1502.02352,2015-02-10,"Optimal portfolio with unobservable market parameters and certainty
  equivalence principle","  We consider a multi-stock continuous time incomplete market model with random
coefficients. We study the investment problem in the class of strategies which
do not use direct observations of the appreciation rates of the stocks, but
rather use historical stock prices and an a priory given distribution of the
appreciation rates. An explicit solution is found for case of power utilities
and for a case when the problem can be embedded to a Markovian setting. Some
new estimates and filters for the appreciation rates are given.
"
1502.02847,2015-02-11,The Robust Merton Problem of an Ambiguity Averse Investor,"  We derive a closed form portfolio optimization rule for an investor who is
diffident about mean return and volatility estimates, and has a CRRA utility.
The novelty is that confidence is here represented using ellipsoidal
uncertainty sets for the drift, given a volatility realization. This
specification affords a simple and concise analysis, as the optimal portfolio
allocation policy is shaped by a rescaled market Sharpe ratio, computed under
the worst case volatility. The result is based on a max-min
Hamilton-Jacobi-Bellman-Isaacs PDE, which extends the classical Merton problem
and reverts to it for an ambiguity-neutral investor.
"
1502.02968,2015-02-11,Learning and Portfolio Decisions for HARA Investors,"  We maximize the expected utility from terminal wealth for an HARA investor
when the market price of risk is an unobservable random variable. We compute
the optimal portfolio explicitly and explore the effects of learning by
comparing it with the corresponding myopic policy. In particular, we show that,
for a market price of risk constant in sign, the ratio between the portfolio
under partial observation and its myopic counterpart increases with respect to
risk tolerance. As a consequence, the absolute value of the partial observation
case is larger (smaller) than the myopic one if the investor is more (less)
risk tolerant than the logarithmic investor. Moreover, our explicit
computations enable to study in details the so called hedging demand induced by
learning about market price of risk.
"
1502.05920,2016-03-23,Robust Utility Maximization with L\'evy Processes,"  We study a robust portfolio optimization problem under model uncertainty for
an investor with logarithmic or power utility. The uncertainty is specified by
a set of possible L\'evy triplets; that is, possible instantaneous drift,
volatility and jump characteristics of the price process. We show that an
optimal investment strategy exists and compute it in semi-closed form.
Moreover, we provide a saddle point analysis describing a worst-case model.
"
1502.06217,2015-02-24,Contour map of estimation error for Expected Shortfall,"  The contour map of estimation error of Expected Shortfall (ES) is
constructed. It allows one to quantitatively determine the sample size (the
length of the time series) required by the optimization under ES of large
institutional portfolios for a given size of the portfolio, at a given
confidence level and a given estimation error.
"
1503.00961,2016-05-25,Optimally Investing to Reach a Bequest Goal,"  We determine the optimal strategy for investing in a Black-Scholes market in
order to maximize the probability that wealth at death meets a bequest goal
$b$, a type of goal-seeking problem, as pioneered by Dubins and Savage (1965,
1976). The individual consumes at a constant rate $c$, so the level of wealth
required for risklessly meeting consumption equals $c/r$, in which $r$ is the
rate of return of the riskless asset.
  Our problem is related to, but different from, the goal-reaching problems of
Browne (1997). First, Browne (1997, Section 3.1) maximizes the probability that
wealth reaches $b < c/r$ before it reaches $a < b$. Browne's game ends when
wealth reaches $b$. By contrast, for the problem we consider, the game
continues until the individual dies or until wealth reaches 0; reaching $b$ and
then falling below it before death does not count.
  Second, Browne (1997, Section 4.2) maximizes the expected discounted reward
of reaching $b > c/r$ before wealth reaches $c/r$. If one interprets his
discount rate as a hazard rate, then our two problems are {\it mathematically}
equivalent for the special case for which $b > c/r$, with ruin level $c/r$.
However, we obtain different results because we set the ruin level at 0,
thereby allowing the game to continue when wealth falls below $c/r$.
"
1503.01802,2015-03-09,Game-theoretic approach to risk-sensitive benchmarked asset management,"  In this article we consider a game theoretic approach to the Risk-Sensitive
Benchmarked Asset Management problem (RSBAM) of Davis and Lleo \cite{DL}. In
particular, we consider a stochastic differential game between two players,
namely, the investor who has a power utility while the second player represents
the market which tries to minimize the expected payoff of the investor. The
market does this by modulating a stochastic benchmark that the investor needs
to outperform. We obtain an explicit expression for the optimal pair of
strategies as for both the players.
"
1503.02237,2015-03-10,"Purchasing Term Life Insurance to Reach a Bequest Goal: Time-Dependent
  Case","  We consider the problem of how an individual can use term life insurance to
maximize the probability of reaching a given bequest goal, an important problem
in financial planning. We assume that the individual buys instantaneous term
life insurance with a premium payable continuously. By contrast with Bayraktar
et al. (2014), we allow the force of mortality to vary with time, which, as we
show, greatly complicates the problem.
"
1503.03986,2015-03-16,"Measuring switching processes in financial markets with the
  Mean-Variance spin glass approach","  In this article we use the Mean-Variance Model in order to measure the
current market state. In our study we take the approach of detecting the
overall alignment of portfolios in the spin picture. The projection to the
ground-states enables us to use physical observables in order to describe the
current state of the explored market. The defined magnetization of portfolios
shows cursor effects, which we use to detect turmoils.
"
1503.06205,2018-01-19,Canonical Sectors and Evolution of Firms in the US Stock Markets,"  A classification of companies into sectors of the economy is important for
macroeconomic analysis and for investments into the sector-specific financial
indices and exchange traded funds (ETFs). Major industrial classification
systems and financial indices have historically been based on expert opinion
and developed manually. Here we show how unsupervised machine learning can
provide a more objective and comprehensive broad-level sector decomposition of
stocks. An emergent low-dimensional structure in the space of historical stock
price returns automatically identifies ""canonical sectors"" in the market, and
assigns every stock a participation weight into these sectors. Furthermore, by
analyzing data from different periods, we show how these weights for listed
firms have evolved over time.
"
1503.08013,2016-01-20,A Robust Statistics Approach to Minimum Variance Portfolio Optimization,"  We study the design of portfolios under a minimum risk criterion. The
performance of the optimized portfolio relies on the accuracy of the estimated
covariance matrix of the portfolio asset returns. For large portfolios, the
number of available market returns is often of similar order to the number of
assets, so that the sample covariance matrix performs poorly as a covariance
estimator. Additionally, financial market data often contain outliers which, if
not correctly handled, may further corrupt the covariance estimation. We
address these shortcomings by studying the performance of a hybrid covariance
matrix estimator based on Tyler's robust M-estimator and on Ledoit-Wolf's
shrinkage estimator while assuming samples with heavy-tailed distribution.
Employing recent results from random matrix theory, we develop a consistent
estimator of (a scaled version of) the realized portfolio risk, which is
minimized by optimizing online the shrinkage intensity. Our portfolio
optimization method is shown via simulations to outperform existing methods
both for synthetic and real market data.
"
1504.01026,2016-05-10,Diversity-Weighted Portfolios with Negative Parameter,"  We analyze a negative-parameter variant of the diversity-weighted portfolio
studied by Fernholz, Karatzas, and Kardaras (Finance Stoch 9(1):1-27, 2005),
which invests in each company a fraction of wealth inversely proportional to
the company's market weight (the ratio of its capitalization to that of the
entire market). We show that this strategy outperforms the market with
probability one, under a non-degeneracy assumption on the volatility structure
and the assumption that the market weights admit a positive lower bound.
Several modifications of this portfolio, which outperform the market under
milder versions of this ""no-failure"" condition, are put forward, one of which
is rank-based. An empirical study suggests that such strategies as studied here
have indeed the potential to outperform the market and to be preferable
investment opportunities, even under realistic proportional transaction costs.
"
1504.01152,2015-05-27,"Time-Inconsistent Stochastic Linear--Quadratic Control: Characterization
  and Uniqueness of Equilibrium","  In this paper, we continue our study on a general time-inconsistent
stochastic linear--quadratic (LQ) control problem originally formulated in [6].
We derive a necessary and sufficient condition for equilibrium controls via a
flow of forward--backward stochastic differential equations. When the state is
one dimensional and the coefficients in the problem are all deterministic, we
prove that the explicit equilibrium control constructed in \cite{HJZ} is indeed
unique. Our proof is based on the derived equivalent condition for equilibria
as well as a stochastic version of the Lebesgue differentiation theorem.
Finally, we show that the equilibrium strategy is unique for a mean--variance
portfolio selection model in a complete financial market where the risk-free
rate is a deterministic function of time but all the other market parameters
are possibly stochastic processes.
"
1504.02972,2015-04-14,"Computing trading strategies based on financial sentiment data using
  evolutionary optimization","  In this paper we apply evolutionary optimization techniques to compute
optimal rule-based trading strategies based on financial sentiment data. The
sentiment data was extracted from the social media service StockTwits to
accommodate the level of bullishness or bearishness of the online trading
community towards certain stocks. Numerical results for all stocks from the Dow
Jones Industrial Average (DJIA) index are presented and a comparison to
classical risk-return portfolio selection is provided.
"
1504.02988,2015-04-14,Topics in Stochastic Portfolio Theory,"  This is an overview of the area of Stochastic Portfolio Theory, and can be
seen as an updated and extended version of the survey paper by Fernholz and
Karatzas (Handbook of Numerical Analysis Vol.15:89-167, 2009).
"
1504.03079,2015-04-14,"Explicit solution to dynamic portfolio choice problem : The
  continuous-time detour","  This paper solves the dynamic portfolio choice problem. Using an explicit
solution with a power utility, we construct a bridge between a continuous and
discrete VAR model to assess portfolio sensitivities. We find, from a well
analyzed example that the optimal allocation to stocks is particularly
sensitive to Sharpe ratio. Our quantitative analysis highlights that this
sensitivity increases when the risk aversion decreases and/or when the time
horizon increases. This finding explains the low accuracy of discrete numerical
methods especially along the tails of the unconditional distribution of the
state variable.
"
1504.03934,2015-04-21,Forecasting trends with asset prices,"  In this paper, we consider a stochastic asset price model where the trend is
an unobservable Ornstein Uhlenbeck process. We first review some classical
results from Kalman filtering. Expectedly, the choice of the parameters is
crucial to put it into practice. For this purpose, we obtain the likelihood in
closed form, and provide two on-line computations of this function. Then, we
investigate the asymptotic behaviour of statistical estimators. Finally, we
quantify the effect of a bad calibration with the continuous time mis-specified
Kalman filter. Numerical examples illustrate the difficulty of trend
forecasting in financial time series.
"
1504.06031,2015-07-08,"Optimal Portfolio Liquidation in Target Zone Models and Catalytic
  Superprocesses","  We study optimal buying and selling strategies in target zone models. In
these models the price is modeled by a diffusion process which is reflected at
one or more barriers. Such models arise for example when a currency exchange
rate is kept above a certain threshold due to central bank intervention. We
consider the optimal portfolio liquidation problem for an investor for whom
prices are optimal at the barrier and who creates temporary price impact. This
problem will be formulated as the minimization of a cost-risk functional over
strategies that only trade when the price process is located at the barrier. We
solve the corresponding singular stochastic control problem by means of a
scaling limit of critical branching particle systems, which is known as a
catalytic superprocess. In this setting the catalyst is a set of points which
is given by the barriers of the price process. For the cases in which the
unaffected price process is a reflected arithmetic or geometric Brownian motion
with drift, we moreover give a detailed financial justification of our cost
functional by means of an approximation with discrete-time models.
"
1504.06113,2017-01-16,"Transitions in the Stock Markets of the US, UK, and Germany","  In an analysis of the US, the UK, and the German stock market we find a
change in the behavior based on the stock's beta values. Before 2006 risky
trades were concentrated on stocks in the IT and technology sector. Afterwards
risky trading takes place for stocks from the financial sector. We show that an
agent-based model can reproduce these changes. We further show that the initial
impulse for the transition might stem from the increase of high frequency
trading at that time.
"
1505.02416,2016-08-30,"Portfolio optimisation beyond semimartingales: shadow prices and
  fractional Brownian motion","  While absence of arbitrage in frictionless financial markets requires price
processes to be semimartingales, non-semimartingales can be used to model
prices in an arbitrage-free way, if proportional transaction costs are taken
into account. In this paper, we show, for a class of price processes which are
not necessarily semimartingales, the existence of an optimal trading strategy
for utility maximisation under transaction costs by establishing the existence
of a so-called shadow price. This is a semimartingale price process, taking
values in the bid ask spread, such that frictionless trading for that price
process leads to the same optimal strategy and utility as the original problem
under transaction costs. Our results combine arguments from convex duality with
the stickiness condition introduced by P. Guasoni. They apply in particular to
exponential utility and geometric fractional Brownian motion. In this case, the
shadow price is an Ito process. As a consequence we obtain a rather surprising
result on the pathwise behaviour of fractional Brownian motion: the
trajectories may touch an Ito process in a one-sided manner without reflection.
"
1505.03980,2015-05-18,Optimal Dividend Strategies for Two Collaborating Insurance Companies,"  We consider a two-dimensional optimal dividend problem in the context of two
insurance companies with compound Poisson surplus processes, who collaborate by
paying each other's deficit when possible. We solve the stochastic control
problem of maximizing the weighted sum of expected discounted dividend payments
(among all admissible dividend strategies) until ruin of both companies, by
extending results of univariate optimal control theory. In the case that the
dividends paid by the two companies are equally weighted, the value function of
this problem compares favorably with the one of merging the two companies
completely. We identify this optimal value function as the smallest viscosity
supersolution of the respective Hamilton-Jacobi-Bellman equation and provide an
iterative approach to approximate it numerically. Curve strategies are
identified as the natural analogue of barrier strategies in this
two-dimensional context. A numerical example is given for which such a curve
strategy is indeed optimal among all admissible dividend strategies, and for
which this collaboration mechanism also outperforms the suitably weighted
optimal dividend strategies of the two stand-alone companies.
"
1505.04045,2015-05-18,"Portfolio optimization for heavy-tailed assets: Extreme Risk Index vs.
  Markowitz","  Using daily returns of the S&P 500 stocks from 2001 to 2011, we perform a
backtesting study of the portfolio optimization strategy based on the extreme
risk index (ERI). This method uses multivariate extreme value theory to
minimize the probability of large portfolio losses. With more than 400 stocks
to choose from, our study seems to be the first application of extreme value
techniques in portfolio management on a large scale. The primary aim of our
investigation is the potential of ERI in practice. The performance of this
strategy is benchmarked against the minimum variance portfolio and the equally
weighted portfolio. These fundamental strategies are important benchmarks for
large-scale applications. Our comparison includes annualized portfolio returns,
maximal drawdowns, transaction costs, portfolio concentration, and asset
diversity in the portfolio. In addition to that we study the impact of an
alternative tail index estimator. Our results show that the ERI strategy
significantly outperforms both the minimum-variance portfolio and the equally
weighted portfolio on assets with heavy tails.
"
1505.04921,2015-05-20,"Optimal control of predictive mean-field equations and applications to
  finance","  We study a coupled system of controlled stochastic differential equations
(SDEs) driven by a Brownian motion and a compensated Poisson random measure,
consisting of a forward SDE in the unknown process $X(t)$ and a
\emph{predictive mean-field} backward SDE (BSDE) in the unknowns $Y(t), Z(t),
K(t,\cdot)$. The driver of the BSDE at time $t$ may depend not just upon the
unknown processes $Y(t), Z(t), K(t,\cdot)$, but also on the predicted future
value $Y(t+\delta)$, defined by the conditional expectation $A(t):=
E[Y(t+\delta) | \mathcal{F}_t]$. \\ We give a sufficient and a necessary
maximum principle for the optimal control of such systems, and then we apply
these results to the following two problems:\\ (i) Optimal portfolio in a
financial market with an \emph{insider influenced asset price process.} \\ (ii)
  Optimal consumption rate from a cash flow modeled as a geometric It\^ o-L\'
evy SDE, with respect to \emph{predictive recursive utility}.
"
1505.05491,2022-01-04,Portfolio Optimization,"  In this paper Portfolio Optimization techniques were used to determine the
most favorable investment portfolio. In particular, stock indices of three
companies, namely Microsoft Corporation, Christian Dior Fashion House and
Shevron Corporation were evaluated. Using this data the amounts invested in
each asset when a portfolio is chosen on the efficient frontier were
calculated. In addition, the Portfolio with minimum variance, tangency
portfolio and optimal Markowitz portfolio are presented.
"
1506.00535,2015-11-18,New exact Taylor's expansions and simple solutions to PDEs,"  We provide new exact Taylor's series with fixed coefficients and without the
remainder. We demonstrate the usefulness of this contribution by using it to
obtain very simple solutions to (non-linear) PDEs. We also apply the method to
the portfolio model.
"
1506.02020,2015-06-08,Portfolio Allocation for Sellers in Online Advertising,"  In markets for online advertising, some advertisers pay only when users
respond to ads. So publishers estimate ad response rates and multiply by
advertiser bids to estimate expected revenue for showing ads. Since these
estimates may be inaccurate, the publisher risks not selecting the ad for each
ad call that would maximize revenue. The variance of revenue can be decomposed
into two components -- variance due to `uncertainty' because the true response
rate is unknown, and variance due to `randomness' because realized response
statistics fluctuate around the true response rate. Over a sequence of many ad
calls, the variance due to randomness nearly vanishes due to the law of large
numbers. However, the variance due to uncertainty doesn't diminish.
  We introduce a technique for ad selection that augments existing estimation
and explore-exploit methods. The technique uses methods from portfolio
optimization to produce a distribution over ads rather than selecting the
single ad that maximizes estimated expected revenue. Over a sequence of similar
ad calls, ads are selected according to the distribution. This approach
decreases the effects of uncertainty and increases revenue.
"
1506.02802,2019-01-29,The Limits of Leverage,"  When trading incurs proportional costs, leverage can scale an asset's return
only up to a maximum multiple, which is sensitive to its volatility and
liquidity. In a model with one safe and one risky asset, with constant
investment opportunities and proportional costs, we find strategies that
maximize long term returns given average volatility. As leverage increases,
rising rebalancing costs imply declining Sharpe ratios. Beyond a critical
level, even returns decline. Holding the Sharpe ratio constant, higher asset
volatility leads to superior returns through lower costs.
"
1506.05990,2015-06-22,Annuitization and asset allocation,"  This paper examines the optimal annuitization, investment and consumption
strategies of a utility-maximizing retiree facing a stochastic time of death
under a variety of institutional restrictions. We focus on the impact of aging
on the optimal purchase of life annuities which form the basis of most Defined
Benefit pension plans. Due to adverse selection, acquiring a lifetime payout
annuity is an irreversible transaction that creates an incentive to delay.
Under the institutional all-or-nothing arrangement where annuitization must
take place at one distinct point in time (i.e. retirement), we derive the
optimal age at which to annuitize and develop a metric to capture the loss from
annuitizing prematurely. In contrast, under an open-market structure where
individuals can annuitize any fraction of their wealth at anytime, we locate a
general optimal annuity purchasing policy. In this case, we find that an
individual will initially annuitize a lump sum and then buy annuities to keep
wealth to one side of a separating ray in wealth-annuity space. We believe our
paper is the first to integrate life annuity products into the portfolio choice
literature while taking into account realistic institutional restrictions which
are unique to the market for mortality-contingent claims.
"
1506.08360,2015-06-30,"Optimal financing and dividend distribution in a general diffusion model
  with regime switching","  We study the optimal financing and dividend distribution problem with
restricted dividend rates in a diffusion type surplus model where the drift and
volatility coefficients are general functions of the level of surplus and the
external environment regime. The environment regime is modeled by a Markov
process. Both capital injections and dividend payments incur expenses. The
objective is to maximize the expectation of the total discounted dividends
minus the total cost of capital injections. We prove that it is optimal to
inject capitals only when the surplus tends to fall below zero and to pay out
dividends at the maximal rate when the surplus is at or above the threshold
dependent on the environment regime.
"
1506.08690,2015-06-30,"Portfolio optimization using local linear regression ensembles in
  RapidMiner","  In this paper we implement a Local Linear Regression Ensemble Committee
(LOLREC) to predict 1-day-ahead returns of 453 assets form the S&P500. The
estimates and the historical returns of the committees are used to compute the
weights of the portfolio from the 453 stock. The proposed method outperforms
benchmark portfolio selection strategies that optimize the growth rate of the
capital. We investigate the effect of algorithm parameter m: the number of
selected stocks on achieved average annual yields. Results suggest the
algorithm's practical usefulness in everyday trading.
"
1507.00250,2015-07-02,Asset Allocation Strategies Based on Penalized Quantile Regression,"  It is well known that quantile regression model minimizes the portfolio
extreme risk, whenever the attention is placed on the estimation of the
response variable left quantiles. We show that, by considering the entire
conditional distribution of the dependent variable, it is possible to optimize
different risk and performance indicators. In particular, we introduce a
risk-adjusted profitability measure, useful in evaluating financial portfolios
under a pessimistic perspective, since the reward contribution is net of the
most favorable outcomes. Moreover, as we consider large portfolios, we also
cope with the dimensionality issue by introducing an l1-norm penalty on the
assets weights.
"
1507.02025,2016-10-07,Diversification Preferences in the Theory of Choice,"  Diversification represents the idea of choosing variety over uniformity.
Within the theory of choice, desirability of diversification is axiomatized as
preference for a convex combination of choices that are equivalently ranked.
This corresponds to the notion of risk aversion when one assumes the
von-Neumann-Morgenstern expected utility model, but the equivalence fails to
hold in other models. This paper studies axiomatizations of the concept of
diversification and their relationship to the related notions of risk aversion
and convex preferences within different choice theoretic models. Implications
of these notions on portfolio choice are discussed. We cover model-independent
diversification preferences, preferences within models of choice under risk,
including expected utility theory and the more general rank-dependent expected
utility theory, as well as models of choice under uncertainty axiomatized via
Choquet expected utility theory. Remarks on interpretations of diversification
preferences within models of behavioral choice are given in the conclusion.
"
1507.06850,2015-07-27,"Continuous-Time Mean-Variance Portfolio Selection with Constraints on
  Wealth and Portfolio","  We consider continuous-time mean-variance portfolio selection with bankruptcy
prohibition under convex cone portfolio constraints. This is a long-standing
and difficult problem not only because of its theoretical significance, but
also for its practical importance. First of all, we transform the above problem
into an equivalent mean-variance problem with bankruptcy prohibition without
portfolio constraints. The latter is then treated using martingale theory. Our
findings indicate that we can directly present the semi-analytical expressions
of the pre-committed efficient mean-variance policy without a viscosity
solution technique but within a general framework of the cone portfolio
constraints. The numerical simulation also sheds light on results established
in this paper.
"
1507.08713,2016-05-20,"Minimizing the Probability of Lifetime Drawdown under Constant
  Consumption","  We assume that an individual invests in a financial market with one riskless
and one risky asset, with the latter's price following geometric Brownian
motion as in the Black-Scholes model. Under a constant rate of consumption, we
find the optimal investment strategy for the individual who wishes to minimize
the probability that her wealth drops below some fixed proportion of her
maximum wealth to date, the so-called probability of {\it lifetime drawdown}.
If maximum wealth is less than a particular value, $m^*$, then the individual
optimally invests in such a way that maximum wealth never increases above its
current value. By contrast, if maximum wealth is greater than $m^*$ but less
than the safe level, then the individual optimally allows the maximum to
increase to the safe level.
"
1508.01914,2015-08-25,"Minimizing the Expected Lifetime Spent in Drawdown under Proportional
  Consumption","  We determine the optimal amount to invest in a Black-Scholes financial market
for an individual who consumes at a rate equal to a constant proportion of her
wealth and who wishes to minimize the expected time that her wealth spends in
drawdown during her lifetime. Drawdown occurs when wealth is less than some
fixed proportion of maximum wealth. We compare the optimal investment strategy
with those for three related goal-seeking problems and learn that the
individual is myopic in her investing behavior, as expected from other
goal-seeking research.
"
1508.04883,2016-01-26,Heterotic Risk Models,"  We give a complete algorithm and source code for constructing what we refer
to as heterotic risk models (for equities), which combine: i) granularity of an
industry classification; ii) diagonality of the principal component factor
covariance matrix for any sub-cluster of stocks; and iii) dramatic reduction of
the factor covariance matrix size in the Russian-doll risk model construction.
This appears to prove a powerful approach for constructing out-of-sample stable
short-lookback risk models. Thus, for intraday mean-reversion alphas based on
overnight returns, Sharpe ratio optimization using our heterotic risk models
sizably improves the performance characteristics compared to weighted
regressions based on principal components or industry classification. We also
give source code for: a) building statistical risk models; and ii) Sharpe ratio
optimization with homogeneous linear constraints and position bounds.
"
1508.05241,2015-11-10,Volatility Harvesting: Extracting Return from Randomness,"  Studying Binomial and Gaussian return dynamics in discrete time, we show how
excess volatility can be traded to create growth. We test our results on real
world data to confirm the observed model phenomena while also highlighting
implicit risks.
"
1508.05460,2015-08-25,Long run risk sensitive portfolio with general factors,"  In the paper portfolio optimization over long run risk sensitive criterion is
considered. It is assumed that economic factors which stimulate asset prices
are ergodic but non necessarily uniformly ergodic. Solution to suitable Bellman
equation using local span contraction with weighted norms is shown. The form of
optimal strategy is presented and examples of market models satisfying imposed
assumptions are shown.
"
1508.06182,2016-09-29,Solving the Optimal Trading Trajectory Problem Using a Quantum Annealer,"  We solve a multi-period portfolio optimization problem using D-Wave Systems'
quantum annealer. We derive a formulation of the problem, discuss several
possible integer encoding schemes, and present numerical examples that show
high success rates. The formulation incorporates transaction costs (including
permanent and temporary market impact), and, significantly, the solution does
not require the inversion of a covariance matrix. The discrete multi-period
portfolio optimization problem we solve is significantly harder than the
continuous variable problem. We present insight into how results may be
improved using suitable software enhancements, and why current quantum
annealing technology limits the size of problem that can be successfully solved
today. The formulation presented is specifically designed to be scalable, with
the expectation that as quantum annealing technology improves, larger problems
will be solvable using the same techniques.
"
1508.06376,2015-08-27,A white noise approach to insider trading,"  We present a new approach to the optimal portfolio problem for an insider
with logarithmic utility. Our method is based on white noise theory, stochastic
forward integrals, Hida-Malliavin calculus and the Donsker delta function.
"
1509.01672,2017-09-20,"Optimal investment with intermediate consumption under no unbounded
  profit with bounded risk","  We consider the problem of optimal investment with intermediate consumption
in a general semimartingale model of an incomplete market, with preferences
being represented by a utility stochastic field. We show that the key
conclusions of the utility maximization theory hold under the assumptions of no
unbounded profit with bounded risk (NUPBR) and of the finiteness of both primal
and dual value functions.
"
1509.01694,2018-05-02,Minimizing Lifetime Poverty with a Penalty for Bankruptcy,"  We provide investment advice for an individual who wishes to minimize her
lifetime poverty, with a penalty for bankruptcy or ruin. We measure poverty via
a non-negative, non-increasing function of (running) wealth. Thus, the lower
wealth falls and the longer wealth stays low, the greater the penalty. This
paper generalizes the problems of minimizing the probability of lifetime ruin
and minimizing expected lifetime occupation, with the poverty function serving
as a bridge between the two. To illustrate our model, we compute the optimal
investment strategies for a specific poverty function and two consumption
functions, and we prove some interesting properties of those investment
strategies.
"
1509.04135,2015-09-16,"Analytical solution to an investment problem under uncertainties with
  shocks","  We derive the optimal investment decision in a project where both demand and
investment costs are stochastic processes, eventually subject to shocks. We
extend the approach used in Dixit and Pindyck (1994), chapter 6.5, to deal with
two sources of uncertainty, but assuming that the underlying processes are no
longer geometric Brownian diffusions but rather jump diffusion processes. For
the class of isoelastic functions that we address in this paper, it is still
possible to derive a closed expression for the value of the firm. We prove
formally that the result we get is indeed the solution of the optimization
problem.
"
1509.05024,2015-09-17,"Modeling Concordances of Company's Investment Directions With Its Market
  Attraction","  This work models the interconnection of company's investment managers'
representations and the market attraction of its shares. The models that
reflect the connection of the company's market effectiveness indices and
parameters of its economic activity are created on the basis of the
Mean-Variance Analysis and Regression Analysis. On another side, expert
evaluation methods also clarified the same influence parameters, but it was
made according to the opinion of company managers. These two evaluation rows
are used when making managerial decisions.
"
1509.07953,2016-06-22,Optimal trading strategies - a time series approach,"  Motivated by recent advances in the spectral theory of auto-covariance
matrices, we are led to revisit a reformulation of Markowitz' mean-variance
portfolio optimization approach in the time domain. In its simplest incarnation
it applies to a single traded asset and allows to find an optimal trading
strategy which - for a given return - is minimally exposed to market price
fluctuations. The model is initially investigated for a range of synthetic
price processes, taken to be either second order stationary, or to exhibit
second order stationary increments. Attention is paid to consequences of
estimating auto-covariance matrices from small finite samples, and
auto-covariance matrix cleaning strategies to mitigate against these are
investigated. Finally we apply our framework to real world data.
"
1509.08110,2016-03-22,"Performance v. Turnover: A Story by 4,000 Alphas","  We analyze empirical data for 4,000 real-life trading portfolios (U.S.
equities) with holding periods of about 0.7-19 trading days. We find a simple
scaling C ~ 1/T, where C is cents-per-share, and T is the portfolio turnover.
Thus, the portfolio return R has no statistically significant dependence on the
turnover T. We also find a scaling R ~ V^X, where V is the portfolio
volatility, and the power X is around 0.8-0.85 for holding periods up to 10
days or so. To our knowledge, this is the only publicly available empirical
study on such a large number of real-life trading portfolios/alphas.
"
1510.01679,2015-10-08,Deconstructing the Low-Vol Anomaly,"  We study several aspects of the so-called low-vol and low-beta anomalies,
some already documented (such as the universality of the effect over different
geographical zones), others hitherto not clearly discussed in the literature.
Our most significant message is that the low-vol anomaly is the result of two
independent effects. One is the striking negative correlation between past
realized volatility and dividend yield. Second is the fact that ex-dividend
returns themselves are weakly dependent on the volatility level, leading to
better risk-adjusted returns for low-vol stocks. This effect is further
amplified by compounding. We find that the low-vol strategy is not associated
to short term reversals, nor does it qualify as a Risk-Premium strategy, since
its overall skewness is slightly positive. For practical purposes, the strong
dividend bias and the resulting correlation with other valuation metrics (such
as Earnings to Price or Book to Price) does make the low-vol strategies to some
extent redundant, at least for equities.
"
1510.02808,2016-12-13,Universal portfolios in stochastic portfolio theory,"  Consider a family of portfolio strategies with the aim of achieving the
asymptotic growth rate of the best one. The idea behind Cover's universal
portfolio is to build a wealth-weighted average which can be viewed as a
buy-and-hold portfolio of portfolios. When an optimal portfolio exists, the
wealth-weighted average converges to it by concentration of wealth. Working
under a discrete time and pathwise setup, we show under suitable conditions
that the distribution of wealth in the family satisfies a pathwise large
deviation principle as time tends to infinity. Our main result extends Cover's
portfolio to the nonparametric family of functionally generated portfolios in
stochastic portfolio theory and establishes its asymptotic universality.
"
1510.03550,2018-01-16,Why Indexing Works,"  We develop a simple stock selection model to explain why active equity
managers tend to underperform a benchmark index. We motivate our model with the
empirical observation that the best performing stocks in a broad market index
often perform much better than the other stocks in the index. Randomly
selecting a subset of securities from the index may dramatically increase the
chance of underperforming the index. The relative likelihood of
underperformance by investors choosing active management likely is much more
important than the loss to those same investors from the higher fees for active
management relative to passive index investing. Thus, active management may be
even more challenging than previously believed, and the stakes for finding the
best active managers may be larger than previously assumed.
"
1510.03596,2015-10-14,Performance analysis of the optimal strategy under partial information,"  The question addressed in this paper is the performance of the optimal
strategy, and the impact of partial information. The setting we consider is
that of a stochastic asset price model where the trend follows an unobservable
Ornstein-Uhlenbeck process. We focus on the optimal strategy with a logarithmic
utility function under full or partial information. For both cases, we provide
the asymptotic expectation and variance of the logarithmic return as functions
of the signal-to-noise ratio and of the trend mean reversion speed. Finally, we
compare the asymptotic Sharpe ratios of these strategies in order to quantify
the loss of performance due to partial information.
"
1510.04943,2015-10-19,"Portfolio Optimization under Expected Shortfall: Contour Maps of
  Estimation Error","  The contour maps of the error of historical resp. parametric estimates for
large random portfolios optimized under the risk measure Expected Shortfall
(ES) are constructed. Similar maps for the sensitivity of the portfolio weights
to small changes in the returns as well as the VaR of the ES-optimized
portfolio are also presented, along with results for the distribution of
portfolio weights over the random samples and for the out-of-sample and
in-the-sample estimates for ES. The contour maps allow one to quantitatively
determine the sample size (the length of the time series) required by the
optimization for a given number of different assets in the portfolio, at a
given confidence level and a given level of relative estimation error. The
necessary sample sizes invariably turn out to be unrealistically large for any
reasonable choice of the number of assets and the confidence level. These
results are obtained via analytical calculations based on methods borrowed from
the statistical physics of random systems, supported by numerical simulations.
"
1510.05097,2017-09-05,Optimal Rebalancing Frequencies for Multidimensional Portfolios,"  We study optimal investment with multiple assets in the presence of small
proportional transaction costs. Rather than computing an asymptotically optimal
no-trade region, we optimize over suitable trading frequencies. We derive
explicit formulas for these and the associated welfare losses due to small
transaction costs in a general, multidimensional diffusion setting, and compare
their performance to a number of alternatives using Monte Carlo simulations.
"
1510.05123,2016-08-31,Optimal growth trajectories with finite carrying capacity,"  We consider the problem of finding optimal strategies that maximize the
average growth-rate of multiplicative stochastic processes. For a geometric
Brownian motion the problem is solved through the so-called Kelly criterion,
according to which the optimal growth rate is achieved by investing a constant
given fraction of resources at any step of the dynamics. We generalize these
finding to the case of dynamical equations with finite carrying capacity, which
can find applications in biology, mathematical ecology, and finance. We
formulate the problem in terms of a stochastic process with multiplicative
noise and a non-linear drift term that is determined by the specific functional
form of carrying capacity. We solve the stochastic equation for two classes of
carrying capacity functions (power laws and logarithmic), and in both cases
compute optimal trajectories of the control parameter. We further test the
validity of our analytical results using numerical simulations.
"
1510.05790,2017-04-12,Risk management under Omega measure,"  We prove that the Omega measure, which considers all moments when assessing
portfolio performance, is equivalent to the widely used Sharpe ratio under
jointly elliptic distributions of returns. Portfolio optimization of the Sharpe
ratio is then explored, with an active-set algorithm presented for markets
prohibiting short sales. When asymmetric returns are considered we show that
the Omega measure and Sharpe ratio lead to different optimal portfolios.
"
1511.00468,2015-11-23,Real Options and Threshold Strategies,"  The paper considers an investment timing problem appearing in real options
theory. Present values from an investment project are modeled by general
diffusion process. We prove necessary and sufficient conditions under which an
optimal investment time is induced by threshold strategy. We study also the
conditions of optimality of threshold strategy (over all threshold strategies)
and discuss the connection between solutions to investment timing problem and
to free-boundary problem.
"
1511.01395,2015-11-05,On Origins of Alpha,"  We argue that an important contributing factor into market inefficiency is
the lack of a robust mechanism for the stock price to rise if a company has
good earnings, e.g., via buybacks/dividends. Instead, the stock price is prone
to volatility due to rather random perception/interpretation of earnings
announcements (among other data) by market participants. We present empirical
evidence indicating that dividend paying stocks on average are less volatile,
even factoring out market cap. We further ponder possible ways of increasing
market efficiency via 1) instituting such a mechanism, 2) a taxation scheme
that would depend on holding periods, and 3) a universal crossing
engine/exchange for mutual and pension funds (and similar long holding horizon
vehicles) with no dark pools, 100% transparency, and no advantage for timing
orders.
"
1511.04764,2016-08-02,Shrinkage = Factor Model,"  Shrunk sample covariance matrix is a factor model of a special form combining
some (typically, style) risk factor(s) and principal components with a
(block-)diagonal factor covariance matrix. As such, shrinkage, which
essentially inherits out-of-sample instabilities of the sample covariance
matrix, is not an alternative to multifactor risk models but one out of myriad
possible regularization schemes. We give an example of a scheme designed to be
less prone to said instabilities. We contextualize this within multifactor
models.
"
1511.04768,2016-11-15,"Optimal Investment with Transaction Costs under Cumulative Prospect
  Theory in Discrete Time","  We study optimal investment problems under the framework of cumulative
prospect theory (CPT). A CPT investor makes investment decisions in a
single-period financial market with transaction costs. The objective is to seek
the optimal investment strategy that maximizes the prospect value of the
investor's final wealth. We obtain the optimal investment strategy explicitly
in two examples. An economic analysis is conducted to investigate the impact of
the transaction costs and risk aversion on the optimal investment strategy.
"
1512.01905,2015-12-08,"A Comparision of Three Network Portfolio Selection Methods -- Evidence
  from the Dow Jones","  We compare three network portfolio selection methods; hierarchical clustering
trees, minimum spanning trees and neighbor-Nets, with random and industry group
selection methods on twelve years of data from the 30 Dow Jones Industrial
Average stocks from 2001 to 2013 for very small private investor sized
portfolios. We find that the three network methods perform on par with randomly
selected portfolios.
"
1512.03537,2015-12-14,"Identifying Highly Correlated Stocks Using the Last Few Principal
  Components","  We show that the last few components in principal component analysis of the
correlation matrix of a group of stocks may contain useful financial
information by identifying highly correlated pairs or larger groups of stocks.
The results of this type of analysis can easily be included in the information
an investor uses to manage their portfolio.
"
1512.04583,2017-05-24,"Constrained Quadratic Risk Minimization via Forward and Backward
  Stochastic Differential Equations","  In this paper we study a continuous-time stochastic linear quadratic control
problem arising from mathematical finance. We model the asset dynamics with
random market coefficients and portfolio strategies with convex constraints.
Following the convex duality approach, we show that the necessary and
sufficient optimality conditions for both the primal and dual problems can be
written in terms of processes satisfying a system of FBSDEs together with other
conditions. We characterise explicitly the optimal wealth and portfolio
processes as functions of adjoint processes from the dual FBSDEs in a dynamic
fashion and vice versa. We apply the results to solve quadratic risk
minimization problems with cone-constraints and derive the explicit
representations of solutions to the extended stochastic Riccati equations for
such problems.
"
1512.05015,2020-05-27,Optimal Control of Conditional Value-at-Risk in Continuous Time,"  We consider continuous-time stochastic optimal control problems featuring
Conditional Value-at-Risk (CVaR) in the objective. The major difficulty in
these problems arises from time-inconsistency, which prevents us from directly
using dynamic programming. To resolve this challenge, we convert to an
equivalent bilevel optimization problem in which the inner optimization problem
is standard stochastic control. Furthermore, we provide conditions under which
the outer objective function is convex and differentiable. We compute the outer
objective's value via a Hamilton-Jacobi-Bellman equation and its gradient via
the viscosity solution of a linear parabolic equation, which allows us to
perform gradient descent. The significance of this result is that we provide an
efficient dynamic programming-based algorithm for optimal control of CVaR
without lifting the state-space. To broaden the applicability of the proposed
algorithm, we propose convergent approximation schemes in cases where our key
assumptions do not hold and characterize relevant suboptimality bounds. In
addition, we extend our method to a more general class of risk metrics, which
includes mean-variance and median-deviation. We also demonstrate a concrete
application to portfolio optimization under CVaR constraints. Our results
contribute an efficient framework for solving time-inconsistent CVaR-based
sequential optimization.
"
1512.06247,2015-12-22,"Which measure for PFE? The Risk Appetite Measure, A","  Potential Future Exposure (PFE) is a standard risk metric for managing
business unit counterparty credit risk but there is debate on how it should be
calculated. The debate has been whether to use one of many historical
(""physical"") measures (one per calibration setup), or one of many risk-neutral
measures (one per numeraire). However, we argue that limits should be based on
the bank's own risk appetite provided that this is consistent with regulatory
backtesting and that whichever measure is used it should behave (in a sense
made precise) like a historical measure. Backtesting is only required by
regulators for banks with IMM approval but we expect that similar methods are
part of limit maintenance generally. We provide three methods for computing the
bank price of risk from readily available business unit data, i.e. business
unit budgets (rate of return) and limits (e.g. exposure percentiles). Hence we
define and propose a Risk Appetite Measure, A, for PFE and suggest that this is
uniquely consistent with the bank's Risk Appetite Framework as required by
sound governance.
"
1512.06486,2015-12-22,"How much diversification potential is there in a single market? Evidence
  from the Australian Stock Exchange","  We present four methods of assessing the diversification potential within a
stock market, two of these are based on principal component analysis. They were
applied to the Australian stock exchange for the years 2000 to 2014 and all
show a consistent picture. The potential for diversification declined almost
monotonically in the three years prior to the 2008 financial crisis. On one of
the measures the diversification potential declined even further in the 2011
European debt crisis and the American credit downgrade.
"
1512.08037,2015-12-29,Risk Aversion in the Small and in the Large under Rank-Dependent Utility,"  Under expected utility the local index of absolute risk aversion has played a
central role in many applications. Besides, its link with the ""global"" concepts
of the risk and probability premia has reinforced its attractiveness. This
paper shows that, with an appropriate approach, similar developments can be
achieved in the framework of Yaari's dual theory and, more generally, under
rank-dependent utility.
"
1512.08098,2016-01-05,On a Generalization of Markowitz Preference Relation,"  Given two families of continuous functions $u$ and $v$ on a topological space
$X$, we define a preorder $R=R(u,v)$ on $X$ by the condition that any member of
$u$ is an $R$-increasing and any member of $v$ is an $R$-decreasing function.
It turns out that if the topological space $X$ is quasi-compact and
sequentially compact, then any element of $X$ is $R$-dominated by an
$R$-maximal element of $X$. In particular, since the $(n-1)$-dimensional
simplex is a compact subset of the real $n$-dimensional vector space, then
considering its members as portfolios consisting of $n$ financial assets, we
obtain the classical 1952 result of Harry Markowitz that any portfolio is
dominated by an efficient portfolio. Moreover, several other examples of
possible application of this general setup are presented.
"
1601.00175,2016-07-15,"Minimax perfect stopping rules for selling an asset near its ultimate
  maximum","  We study the problem of selling an asset near its ultimate maximum in the
minimax setting. The regret-based notion of a perfect stopping time is
introduced. A perfect stopping time is uniquely characterized by its optimality
properties and has the following form: one should sell the asset if its price
deviates from the running maximum by a certain time-dependent quantity. The
related selling rule improves any earlier one and cannot be improved by further
delay. The results, which are applicable to a quite general price model, are
illustrated by several examples.
"
1601.00712,2016-01-25,"Multistage Portfolio Optimization: A Duality Result in Conic Market
  Models","  We prove a general duality result for multi-stage portfolio optimization
problems in markets with proportional transaction costs. The financial market
is described by Kabanov's model of foreign exchange markets over a finite
probability space and finite-horizon discrete time steps. This framework allows
us to compare vector-valued portfolios under a partial ordering, so that our
model does not require liquidation into some numeraire at terminal time.
  We embed the vector-valued portfolio problem into the set-optimization
framework, and generate a problem dual to portfolio optimization. Using recent
results in the development of set optimization, we then show that a strong
duality relationship holds between the problems.
"
1601.00991,2016-08-01,101 Formulaic Alphas,"  We present explicit formulas - that are also computer code - for 101
real-life quantitative trading alphas. Their average holding period
approximately ranges 0.6-6.4 days. The average pair-wise correlation of these
alphas is low, 15.9%. The returns are strongly correlated with volatility, but
have no significant dependence on turnover, directly confirming an earlier
result based on a more indirect empirical analysis. We further find empirically
that turnover has poor explanatory power for alpha correlations.
"
1601.03435,2022-12-08,Asymptotic Analysis for Optimal Dividends in a Dual Risk Model,"  The dual risk model is a popular model in finance and insurance, which is
often used to model the wealth process of a venture capital or high tech
company. Optimal dividends have been extensively studied in the literature for
a dual risk model. It is well known that the value function of this optimal
control problem does not yield closed-form solutions except in some special
cases. In this paper, we study the asymptotics of the optimal dividend problem
when the parameters of the model go to either zero or infinity. Our results
provide insights to the optimal strategies and the optimal values when the
parameters are extreme.
"
1601.03562,2016-01-15,Convex duality for stochastic differential utility,"  This paper introduces a dual problem to study a continuous-time consumption
and investment problem with incomplete markets and stochastic differential
utility. For Epstein-Zin utility, duality between the primal and dual problems
is established. Consequently the optimal strategy of the consumption and
investment problem is identified without assuming several technical conditions
on market model, utility specification, and agent's admissible strategy.
Meanwhile the minimizer of the dual problem is identified as the utility
gradient of the primal value and is economically interpreted as the ""least
favorable"" completion of the market.
"
1601.04478,2016-01-19,"The Excess Returns of ""Quality"" Stocks: A Behavioral Anomaly","  This note investigates the causes of the quality anomaly, which is one of the
strongest and most scalable anomalies in equity markets. We explore two
potential explanations. The ""risk view"", whereby investing in high quality
firms is somehow riskier, so that the higher returns of a quality portfolio are
a compensation for risk exposure. This view is consistent with the Efficient
Market Hypothesis. The other view is the ""behavioral view"", which states that
some investors persistently underestimate the true value of high quality firms.
We find no evidence in favor of the ""risk view"": The returns from investing in
quality firms are abnormally high on a risk-adjusted basis, and are not prone
to crashes. We provide novel evidence in favor of the ""behavioral view"": In
their forecasts of future prices, and while being overall overoptimistic,
analysts systematically underestimate the future return of high quality firms,
compared to low quality firms.
"
1601.05199,2016-01-21,Portfolio Optimisation Under Flexible Dynamic Dependence Modelling,"  Signals coming from multivariate higher order conditional moments as well as
the information contained in exogenous covariates, can be effectively exploited
by rational investors to allocate their wealth among different risky investment
opportunities. This paper proposes a new flexible dynamic copula model being
able to explain and forecast the time-varying shape of large dimensional asset
returns distributions. Moreover, we let the univariate marginal distributions
to be driven by an updating mechanism based on the scaled score of the
conditional distribution. This framework allows us to introduce time-variation
in up to the fourth moment of the conditional distribution. The time-varying
dependence pattern is subsequently modelled as function of a latent Markov
Switching process, allowing also for the inclusion of exogenous covariates in
the dynamic updating equation. We empirically assess that the proposed model
substantially improves the optimal portfolio allocation of rational investors
maximising their expected utility.
"
1601.07593,2016-01-29,Sufficiency on the Stock Market,"  It is well-known that there are a number of relations between theoretical
finance theory and information theory. Some of these relations are exact and
some are approximate. In this paper we will explore some of these relations and
determine under which conditions the relations are exact. It turns out that
portfolio theory always leads to Bregman divergences. The Bregman divergence is
only proportional to information divergence in situations that are essentially
equal to the type of gambling studied by Kelly. This can be related an abstract
sufficiency condition.
"
1601.07626,2016-01-29,Trading-profit attribution for the size factor,"  An algorithm was recently introduced by INTECH for the purposes of estimating
the trading-profit contribution of systematic rebalancing to the relative
return of rules-based investment strategies. We apply this methodology to
analyze the size factor through the use of equal-weighted portfolios. These
strategies combine a natural exposure to the size factor with a simple
understanding within the framework of Stochastic Portfolio Theory, furnishing a
natural test subject for the attribution algorithm.
"
1601.07628,2016-01-29,Portfolio Optimization in the Stochastic Portfolio Theory Framework,"  I discuss some theoretical results with a view to motivate some practical
choices in portfolio optimization. Even though the setting is not completely
general (for example, the covariance matrix is assumed to be non-singular), I
attempt to highlight the features that have practical relevance. The
mathematical setting is Stochastic Portfolio Theory, which is flexible enough
to describe most realistic assets, and it has been successfully employed for
managing equity portfolios since 1987.
"
1601.07961,2016-02-01,"Exact solutions for optimal execution of portfolios transactions and the
  Riccati equation","  We propose two methods to obtain exact solutions for the Almgren-Chriss model
about optimal execution of portfolio transactions. In the first method we
rewrite the Almgren-Chriss equation and find two exact solutions. In the second
method, employing a general reparametrized time, we show that the
Almgren-Chriss equation can be reduced to some known equations which can be
exactly solved in different cases.For this last case we obtain a quantity
conserved. In addition, we show that in both methods the Almgren-Chriss
equation is equivalent to a Riccati equation.
"
1601.08155,2021-11-04,"Expert Opinions and Logarithmic Utility Maximization for Multivariate
  Stock Returns with Gaussian Drift","  This paper investigates optimal trading strategies in a financial market with
multidimensional stock returns where the drift is an unobservable multivariate
Ornstein-Uhlenbeck process. Information about the drift is obtained by
observing stock returns and expert opinions. The latter provide unbiased
estimates on the current state of the drift at discrete points in time.
  The optimal trading strategy of investors maximizing expected logarithmic
utility of terminal wealth depends on the filter which is the conditional
expectation of the drift given the available information. We state filtering
equations to describe its dynamics for different information settings. Between
expert opinions this is the Kalman filter. The conditional covariance matrices
of the filter follow ordinary differential equations of Riccati type. We rely
on basic theory about matrix Riccati equations to investigate their properties.
Firstly, we consider the asymptotic behaviour of the covariance matrices for an
increasing number of expert opinions on a finite time horizon. Secondly, we
state conditions for the convergence of the covariance matrices on an infinite
time horizon with regularly arriving expert opinions.
  Finally, we derive the optimal trading strategy of an investor. The optimal
expected logarithmic utility of terminal wealth, the value function, is a
functional of the conditional covariance matrices. Hence, our analysis of the
covariance matrices allows us to deduce properties of the value function.
"
1602.00570,2017-08-04,"Portfolio optimization under dynamic risk constraints: continuous vs.
  discrete time trading","  We consider an investor facing a classical portfolio problem of optimal
investment in a log-Brownian stock and a fixed-interest bond, but constrained
to choose portfolio and consumption strategies that reduce a dynamic shortfall
risk measure. For continuous- and discrete-time financial markets we
investigate the loss in expected utility of intermediate consumption and
terminal wealth caused by imposing a dynamic risk constraint. We derive the
dynamic programming equations for the resulting stochastic optimal control
problems and solve them numerically. Our numerical results indicate that the
loss of portfolio performance is not too large while the risk is notably
reduced. We then investigate time discretization effects and find that the loss
of portfolio performance resulting from imposing a risk constraint is typically
bigger than the loss resulting from infrequent trading.
"
1602.00782,2017-08-08,Portfolio Selection: The Power of Equal Weight,"  We empirically show the superiority of the equally weighted S\&P 500
portfolio over Sharpe's market capitalization weighted S\&P 500 portfolio. We
proceed to consider the MaxMedian rule, a non-proprietary rule designed for the
investor who wishes to do his/her own investing on a laptop with the purchase
of only 20 stocks. Rather surprisingly, over the 1958-2016 horizon, the
cumulative returns of MaxMedian beat those of the equally weighted S\&P 500
portfolio by a factor of 1.15.
"
1602.01109,2017-02-24,"On the existence of shadow prices for optimal investment with random
  endowment","  In this paper, we consider a num\'eraire-based utility maximization problem
under constant proportional transaction costs and random endowment. Assuming
that the agent cannot short sell assets and is endowed with a strictly positive
contingent claim, a primal optimizer of this utility maximization problem
exists. Moreover, we observe that the original market with transaction costs
can be replaced by a frictionless shadow market that yields the same
optimality. On the other hand, we present an example to show that in some case
when these constraints are relaxed, the existence of shadow prices is still
warranted.
"
1602.02192,2017-05-04,On minimising a portfolio's shortfall probability,"  We obtain a lower asymptotic bound on the decay rate of the probability of a
portfolio's underperformance against a benchmark over a large time horizon. It
is assumed that the prices of the securities are governed by geometric Brownian
motions with the coefficients depending on an economic factor, possibly
nonlinearly. The economic factor is modelled with a general Ito equation. The
bound is shown to be tight. More specifically, epsilon-optimal portfolios are
obtained under additional conditions.
"
1602.02542,2023-01-12,"Dynamic Spatial Autoregressive Models with Autoregressive and
  Heteroskedastic Disturbances","  We propose a new class of models specifically tailored for spatio-temporal
data analysis. To this end, we generalize the spatial autoregressive model with
autoregressive and heteroskedastic disturbances, i.e. SARAR(1,1), by exploiting
the recent advancements in Score Driven (SD) models typically used in time
series econometrics. In particular, we allow for time-varying spatial
autoregressive coefficients as well as time-varying regressor coefficients and
cross-sectional standard deviations. We report an extensive Monte Carlo
simulation study in order to investigate the finite sample properties of the
Maximum Likelihood estimator for the new class of models as well as its
flexibility in explaining several dynamic spatial dependence processes. The new
proposed class of models are found to be economically preferred by rational
investors through an application in portfolio optimization.
"
1602.04656,2016-08-03,Dividend maximization in a hidden Markov switching model,"  In this paper we study the valuation problem of an insurance company by
maximizing the expected discounted future dividend payments in a model with
partial information that allows for a changing economic environment. The
surplus process is modeled as a Brownian motion with drift. This drift depends
on an underlying Markov chain the current state of which is assumed to be
unobservable. The different states of the Markov chain thereby represent
different phases of the economy. We apply results from filtering theory to
overcome uncertainty and then we give an analytic characterization of the
optimal value function. Finally, we present a numerical study covering various
scenarios to get a clear picture of how dividends should be paid out.
"
1602.04902,2016-09-12,Multifactor Risk Models and Heterotic CAPM,"  We give a complete algorithm and source code for constructing general
multifactor risk models (for equities) via any combination of style factors,
principal components (betas) and/or industry factors. For short horizons we
employ the Russian-doll risk model construction to obtain a nonsingular factor
covariance matrix. This generalizes the heterotic risk model construction to
include arbitrary non-industry risk factors as well as industry risk factors
with generic ""weights"". The aim of sharing our proprietary know-how with the
investment community is to encourage organic risk model building. The
presentation is intended to be essentially self-contained and pedagogical. So,
stop wasting money and complaining, start building risk models and enjoy!
"
1602.04975,2016-02-17,Dynamic portfolio selection without risk-free assets,"  We consider the mean--variance portfolio optimization problem under the game
theoretic framework and without risk-free assets. The problem is solved
semi-explicitly by applying the extended Hamilton--Jacobi--Bellman equation.
Although the coefficient of risk aversion in our model is a constant, the
optimal amounts of money invested in each stock still depend on the current
wealth in general. The optimal solution is obtained by solving a system of
ordinary differential equations whose existence and uniqueness are proved and a
numerical algorithm as well as its convergence speed are provided. Different
from portfolio selection with risk-free assets, our value function is quadratic
in the current wealth, and the equilibrium allocation is linearly sensitive to
the initial wealth. Numerical results show that this model performs better than
both the classical one and the variance model in a bull market.
"
1602.05858,2016-02-19,On the Profitability of Optimal Mean Reversion Trading Strategies,"  We study the profitability of optimal mean reversion trading strategies in
the US equity market. Different from regular pair trading practice, we apply
maximum likelihood method to construct the optimal static pairs trading
portfolio that best fits the Ornstein-Uhlenbeck process, and rigorously
estimate the parameters. Therefore, we ensure that our portfolios match the
mean-reverting process before trading. We then generate contrarian trading
signals using the model parameters. We also optimize the thresholds and the
length of in-sample period by multiple tests. In nine good pair examples, we
can see that our pairs exhibit high Sharpe ratio (above 1.9) over the in-sample
period and out-of-sample period. In particular, Crown Castle International
Corp. (CCI) and HCP, Inc. (HCP) achieve a Sharpe ratio of 2.326 during
in-sample period and a Sharpe ratio of 2.425 in out-of-sample test. Crown
Castle International Corp. (CCI) and Realty Income Corporation (O) achieve a
Sharpe ratio of 2.405 and 2.903 respectively during in-sample period and
out-of-sample period.
"
1602.08070,2017-03-14,Statistical Risk Models,"  We give complete algorithms and source code for constructing statistical risk
models, including methods for fixing the number of risk factors. One such
method is based on eRank (effective rank) and yields results similar to (and
further validates) the method set forth in an earlier paper by one of us. We
also give a complete algorithm and source code for computing eigenvectors and
eigenvalues of a sample covariance matrix which requires i) no costly
iterations and ii) the number of operations linear in the number of returns.
The presentation is intended to be pedagogical and oriented toward practical
applications.
"
1602.08297,2018-07-04,"Bias-variance trade-off in portfolio optimization under Expected
  Shortfall with $\ell_2$ regularization","  The optimization of a large random portfolio under the Expected Shortfall
risk measure with an $\ell_2$ regularizer is carried out by analytical
calculation. The regularizer reins in the large sample fluctuations and the
concomitant divergent estimation error, and eliminates the phase transition
where this error would otherwise blow up. In the data-dominated region, where
the number $N$ of different assets in the portfolio is much less than the
length $T$ of the available time series, the regularizer plays a negligible
role even if its strength $\eta$ is large, while in the opposite limit, where
the size of samples is comparable to, or even smaller than the number of
assets, the optimum is almost entirely determined by the regularizer. We
construct the contour map of estimation error on the $N/T$ vs. $\eta$ plane and
find that for a given value of the estimation error the gain in $N/T$ due to
the regularizer can reach a factor of about 4 for a sufficiently strong
regularizer.
"
1603.02354,2016-03-09,Stock Selection as a Problem in Phylogenetics -- Evidence from the ASX,"  We report the results of fifteen sets of portfolio selection simulations
using stocks in the ASX200 index for the period May 2000 to December 2013. We
investigated five portfolio selection methods, randomly and from within
industrial groups, and three based on neighbor-Net phylogenetic networks. We
report that using random, industrial groups, or neighbor-Net phylogenetic
networks alone rarely produced statistically significant reduction in risk,
though in four out of the five cases in which it did so, the portfolios
selected using the phylogenetic networks had the lowest risk. However, we
report that when using the neighbor-Net phylogenetic networks in combination
with industry group selection that substantial reductions in portfolio return
spread were achieved.
"
1603.02438,2017-05-23,A Mathematical Model of Foreign Capital Inflow,"  The paper models foreign capital inflow from the developed to the developing
countries in a stochastic dynamic programming (SDP) framework. Under some
regularity conditions, the existence of the solutions to the SDP problem is
proved and they are then obtained by numerical technique because of the
non-linearity of the related functions. A number of comparative dynamic
analyses explore the impact of parameters of the model on dynamic paths of
capital inflow, interest rate in the international loan market and the exchange
rate.
"
1603.03538,2016-11-08,"Asymptotic Optimal Strategy for Portfolio Optimization in a Slowly
  Varying Stochastic Environment","  In this paper, we study the portfolio optimization problem with general
utility functions and when the return and volatility of underlying asset are
slowly varying. An asymptotic optimal strategy is provided within a specific
class of admissible controls under this problem setup. Specifically, we first
establish a rigorous first order approximation of the value function associated
to a fixed zeroth order suboptimal trading strategy, which is given by the
heuristic argument in [J.-P. Fouque, R. Sircar and T. Zariphopoulou, {\it
Mathematical Finance}, 2016]. Then, we show that this zeroth order suboptimal
strategy is asymptotically optimal in a specific family of admissible trading
strategies. Finally, we show that our assumptions are satisfied by a particular
fully solvable model.
"
1603.05937,2016-12-19,How to Combine a Billion Alphas,"  We give an explicit algorithm and source code for computing optimal weights
for combining a large number N of alphas. This algorithm does not cost O(N^3)
or even O(N^2) operations but is much cheaper, in fact, the number of required
operations scales linearly with N. We discuss how in the absence of binary or
quasi-binary clustering of alphas, which is not observed in practice, the
optimization problem simplifies when N is large. Our algorithm does not require
computing principal components or inverting large matrices, nor does it require
iterations. The number of risk factors it employs, which typically is limited
by the number of historical observations, can be sizably enlarged via using
position data for the underlying tradables.
"
1603.06047,2016-04-04,"The Circle of Investment: Connecting the Dots of the Portfolio
  Management Cycle...","  We will look at the entire cycle of the investment process relating to all
aspects of, formulating an investment hypothesis, constructing a portfolio
based on that, executing the trades to implement it, on-going risk management,
periodically measuring the performance of the portfolio, and rebalancing the
portfolio either due to an increase in the risk parameters or due to a
deviation from the intended asset allocation. We provide several illustrative
analogies that are meant to intuitively explain the pleasures and the pitfalls
that can arise while managing a portfolio. If we consider the entire investment
management procedure as being akin to connecting the dots of a circle, then the
Circle of Investment can be represented as a dotted circle with many dots
falling approximately on the circumference and with no clue about the exact
location of the centre or the length of the radius. We represent the investment
process as a dotted circle since there is a lot of ambiguity in the various
steps involved. The circle also indicates the repetitive nature of many steps
that are continuously carried out while investing. This work introduces two new
points pertaining to this dotted circle and improves the ability, to understand
how far-off this dotted circle is, from a more well-defined circle and, to
create a well-formed circle. The two innovations we introduce are:
  1. The first, relating to the limitations that apply to any finding in the
social sciences, would be the additional point we introduce that lies near the
centre of the circle. We title this as, 'The Uncertainty Principle of the
Social Sciences'.
  2. The second, relating to establishing confidence levels in a systematic
manner for each view we associate with a security or group of securities as
required by the Black-Litterman framework, would be the new point we present
near the circumference of the circle.
"
1603.06050,2017-08-08,Tukey's transformational ladder for portfolio management,"  Over the past half-century, the empirical finance community has produced vast
literature on the advantages of the equally weighted S\&P 500 portfolio as well
as the often overlooked disadvantages of the market capitalization weighted
Standard and Poor's (S\&P 500) portfolio (see \cite{Bloom}, \cite{Uppal},
\cite{Jacobs}, \cite{Treynor}). However, portfolio allocation based on Tukey's
transformational ladde have, rather surprisingly, remained absent from the
literature. In this work, we consider the S\&P 500 portfolio over the 1958-2015
time horizon weighted by Tukey's transformational ladder (\cite{Tukey2}):
$1/x^2,\,\, 1/x,\,\, 1/\sqrt{x},\,\, \text{log}(x),\,\, \sqrt{x},\,\, x,\,\,
\text{and} \,\, x^2$, where $x$ is defined as the market capitalization
weighted S\&P 500 portfolio. Accounting for dividends and transaction fees, we
find that the 1/$x^2$ weighting strategy produces cumulative returns that
significantly dominates all other portfolios, achieving a compound annual
growth rate of 18\% over the 1958-2015 horizon. Our story is furthered by a
startling phenomenon: both the cumulative and annual returns of the $1/x^2$
weighting strategy are superior to those of the $1/x$ weighting strategy, which
are in turn superior to those of the 1/$\sqrt{x}$ weighted portfolio, and so
forth, ending with the $x^2$ transformation, whose cumulative returns are the
lowest of the seven transformations of Tukey's transformational ladder. The
order of cumulative returns precisely follows that of Tukey's transformational
ladder. To the best of our knowledge, we are the first to discover this
phenomenon.
"
1603.06183,2016-03-22,Risk-Constrained Kelly Gambling,"  We consider the classic Kelly gambling problem with general distribution of
outcomes, and an additional risk constraint that limits the probability of a
drawdown of wealth to a given undesirable level. We develop a bound on the
drawdown probability; using this bound instead of the original risk constraint
yields a convex optimization problem that guarantees the drawdown risk
constraint holds. Numerical experiments show that our bound on drawdown
probability is reasonably close to the actual drawdown risk, as computed by
Monte Carlo simulation. Our method is parametrized by a single parameter that
has a natural interpretation as a risk-aversion parameter, allowing us to
systematically trade off asymptotic growth rate and drawdown risk. Simulations
show that this method yields bets that out perform fractional-Kelly bets for
the same drawdown risk level or growth rate. Finally, we show that a natural
quadratic approximation of our convex problem is closely connected to the
classical mean-variance Markowitz portfolio selection problem.
"
1603.07019,2018-04-12,Optimal dividend payments for a two-dimensional insurance risk process,"  We consider a two-dimensional optimal dividend problem in the context of two
branches of an insurance company with compound Poisson surplus processes
dividing claims and premia in some specified proportions. We solve the
stochastic control problem of maximizing expected cumulative discounted
dividend payments (among all admissible dividend strategies) until ruin of at
least one company. We prove that the value function is the smallest viscosity
supersolution of the respective Hamilton-Jacobi-Bellman equation and we
describe the optimal strategy. We analize some numerical examples.
"
1603.08169,2016-03-29,Robust Optimization of Credit Portfolios,"  We introduce a dynamic credit portfolio framework where optimal investment
strategies are robust against misspecifications of the reference credit model.
The risk-averse investor models his fear of credit risk misspecification by
considering a set of plausible alternatives whose expected log likelihood
ratios are penalized. We provide an explicit characterization of the optimal
robust bond investment strategy, in terms of default state dependent value
functions associated with the max-min robust optimization criterion. The value
functions can be obtained as the solutions of a recursive system of HJB
equations. We show that each HJB equation is equivalent to a suitably truncated
equation admitting a unique bounded regular solution. The truncation technique
relies on estimates for the solution of the master HJB equation that we
establish.
"
1603.08245,2016-03-29,Trading Strategies Generated by Lyapunov Functions,"  Functional portfolio generation, initiated by E.R. Fernholz almost twenty
years ago, is a methodology for constructing trading strategies with controlled
behavior. It is based on very weak and descriptive assumptions on the
covariation structure of the underlying market model, and needs no estimation
of model parameters. In this paper, the corresponding generating functions $G$
are interpreted as Lyapunov functions for the vector process $\mu(\cdot)$ of
market weights; that is, via the property that $G(\mu(\cdot))$ is a
supermartingale under an appropriate change of measure. This point of view
unifies, generalizes, and simplifies several existing results, and allows the
formulation of conditions under which it is possible to outperform the market
portfolio over appropriate time-horizons. From a probabilistic point of view,
the present paper yields results concerning the interplay of stochastic
discount factors and concave transformations of semimartingales on compact
domains.
"
1603.09149,2019-10-21,"Risk Sensitive Portfolio Optimization in a Jump Diffusion Model with
  Regimes","  This article studies a portfolio optimization problem, where the market
consisting of several stocks is modeled by a multi-dimensional jump-diffusion
process with age-dependent semi-Markov modulated coefficients. We study risk
sensitive portfolio optimization on the finite time horizon. We study the
problem by using a probabilistic approach to establish the existence and
uniqueness of the classical solution to the corresponding
Hamilton-Jacobi-Bellman (HJB) equation. We also implement a numerical scheme to
investigate the behavior of solutions for different values of the initial
portfolio wealth, the maturity, and the risk of aversion parameter.
"
1603.09519,2016-04-01,Deterministic Income with Deterministic and Stochastic Interest Rates,"  We consider an individual or household endowed with an initial capital and an
income, modeled as a deterministic process with a continuous drift rate. At
first, we model the discounting rate as the price of a zero-coupon bond at zero
under the assumption of a short rate evolving as an Ornstein-Uhlenbeck process.
Then, a geometric Brownian motion as the preference function and an
Ornstein-Uhlenbeck process as the short rate are taken into consideration. It
is assumed that the primal interest of the economic agent is to maximise the
cumulated value of (expected) discounted consumption from a given time up to a
finite deterministic time horizon $T\in\R_+$ or, in a stochastic setting,
infinite time horizon. We find an explicit expression for the value function
and for the optimal strategy in the first two cases. In the third case, we have
to apply the viscosity ansatz.
"
1604.06892,2016-04-26,"On the Optimal Dividend Problem for Insurance Risk Models with
  Surplus-Dependent Premiums","  This paper concerns an optimal dividend distribution problem for an insurance
company with surplus-dependent premium. In the absence of dividend payments,
such a risk process is a particular case of so-called piecewise deterministic
Markov processes. The control mechanism chooses the size of dividend payments.
The objective consists in maximazing the sum of the expected cumulative
discounted dividend payments received until the time of ruin and a penalty
payment at the time of ruin, which is an increasing function of the size of the
shortfall at ruin. A complete solution is presented to the corresponding
stochastic control problem. We identify the associated Hamilton-Jacobi-Bellman
equation and find necessary and sufficient conditions for optimality of a
single dividend-band strategy, in terms of particular Gerber-Shiu functions. A
number of concrete examples are analyzed.
"
1604.08037,2016-04-28,On Dynamic Deviation Measures and Continuous-Time Portfolio Optimisation,"  In this paper we propose the notion of dynamic deviation measure, as a
dynamic time-consistent extension of the (static) notion of deviation measure.
To achieve time-consistency we require that a dynamic deviation measures
satisfies a generalised conditional variance formula. We show that, under a
domination condition, dynamic deviation measures are characterised as the
solutions to a certain class of backward SDEs. We establish for any dynamic
deviation measure an integral representation, and derive a dual
characterisation result in terms of additively $m$-stable dual sets. Using this
notion of dynamic deviation measure we formulate a dynamic mean-deviation
portfolio optimisation problem in a jump-diffusion setting and identify a
subgame-perfect Nash equilibrium strategy that is linear as function of wealth
by deriving and solving an associated extended HJB equation.
"
1605.00173,2016-05-03,Robustness of mathematical models and technical analysis strategies,"  The aim of this paper is to compare the performances of the optimal strategy
under parameters mis-specification and of a technical analysis trading
strategy. The setting we consider is that of a stochastic asset price model
where the trend follows an unobservable Ornstein-Uhlenbeck process. For both
strategies, we provide the asymptotic expectation of the logarithmic return as
a function of the model parameters. Finally, numerical examples find that an
investment strategy using the cross moving averages rule is more robust than
the optimal strategy under parameters mis-specification.
"
1605.02654,2016-07-06,Stochastic Portfolio Theory: A Machine Learning Perspective,"  In this paper we propose a novel application of Gaussian processes (GPs) to
financial asset allocation. Our approach is deeply rooted in Stochastic
Portfolio Theory (SPT), a stochastic analysis framework introduced by Robert
Fernholz that aims at flexibly analysing the performance of certain investment
strategies in stock markets relative to benchmark indices. In particular, SPT
has exhibited some investment strategies based on company sizes that, under
realistic assumptions, outperform benchmark indices with probability 1 over
certain time horizons. Galvanised by this result, we consider the inverse
problem that consists of learning (from historical data) an optimal investment
strategy based on any given set of trading characteristics, and using a
user-specified optimality criterion that may go beyond outperforming a
benchmark index. Although this inverse problem is of the utmost interest to
investment management practitioners, it can hardly be tackled using the SPT
framework. We show that our machine learning approach learns investment
strategies that considerably outperform existing SPT strategies in the US stock
market.
"
1605.04600,2018-10-08,Learning zero-cost portfolio selection with pattern matching,"  We consider and extend the adversarial agent-based learning approach of
Gy{\""o}rfi {\it et al} to the situation of zero-cost portfolio selection
implemented with a quadratic approximation derived from the mutual fund
separation theorems. The algorithm is applied to daily sampled sequential
Open-High-Low-Close data and sequential intraday 5-minute bar-data from the
Johannesburg Stock Exchange (JSE). Statistical tests of the algorithms are
considered. The algorithms are directly compared to standard NYSE test cases
from prior literature. The learning algorithm is used to select parameters for
agents (or experts) generated by pattern matching past dynamics using a simple
nearest-neighbour search algorithm. It is shown that there is a speed advantage
associated with using an analytic solution of the mutual fund separation
theorems. It is argued that the expected loss in performance does not undermine
the potential application to intraday quantitative trading and that when
transactions costs and slippage are considered the strategies can still remain
profitable when unleveraged. The paper demonstrates that patterns in financial
time-series on the JSE can be systematically exploited in collective but that
this does not imply predictability of the individual asset time-series
themselves.
"
1605.06840,2016-05-24,"Asymptotic Eigenvalue Distribution of Wishart Matrices whose Components
  are not Independently and Identically Distributed","  In the present work, eigenvalue distributions defined by a random rectangular
matrix whose components are neither independently nor identically distributed
are analyzed using replica analysis and belief propagation. In particular, we
consider the case in which the components are independently but not identically
distributed; for example, only the components in each row or in each column may
be {identically distributed}. We also consider the more general case in which
the components are correlated with one another. We use the replica approach
while making only weak assumptions in order to determine the asymptotic
eigenvalue distribution and to derive an algorithm for doing so, based on
belief propagation. One of our findings supports the results obtained from
Feynman diagrams. We present the results of several numerical experiments that
validate our proposed methods.
"
1605.06843,2016-12-15,"Portfolio Optimization Problem with Non-identical Variances of Asset
  Returns using Statistical Mechanical Informatics","  The portfolio optimization problem in which the variances of the return rates
of assets are not identical is analyzed in this paper using the methodology of
statistical mechanical informatics, specifically, replica analysis. We define
two characteristic quantities of an optimal portfolio, namely, minimal
investment risk and concentrated investment level, in order to solve the
portfolio optimization problem and analytically determine their asymptotical
behaviors using replica analysis. Moreover, numerical experiments were
performed, and a comparison between the results of our simulation and those
obtained via replica analysis validated our proposed method.
"
1605.06845,2017-02-21,"Minimal Investment Risk of Portfolio Optimization Problem with Budget
  and Investment Concentration Constraints","  In the present paper, the minimal investment risk for a portfolio
optimization problem with imposed budget and investment concentration
constraints is considered using replica analysis. Since the minimal investment
risk is influenced by the investment concentration constraint (as well as the
budget constraint), it is intuitive that the minimal investment risk for the
problem with an investment concentration constraint be larger than that without
the constraint (that is, with only the budget constraint). Moreover, a
numerical experiment shows the effectiveness of our proposed analysis.
"
1605.06849,2017-05-08,"A note on optimal expected utility of dividend payments with
  proportional reinsurance","  In this paper, we consider the problem of maximizing the expected discounted
utility of dividend payments for an insurance company that controls risk
exposure by purchasing proportional reinsurance. We assume the preference of
the insurer is of CRRA form. By solving the corresponding
Hamilton-Jacobi-Bellman equation, we identify the value function and the
corresponding optimal strategy. We also analyze the asymptotic behavior of the
value function for large initial reserves. Finally, we provide some numerical
examples to illustrate the results and analyze the sensitivity of the
parameters.
"
1605.07230,2018-01-16,Deep Portfolio Theory,"  We construct a deep portfolio theory. By building on Markowitz's classic
risk-return trade-off, we develop a self-contained four-step routine of encode,
calibrate, validate and verify to formulate an automated and general portfolio
selection process. At the heart of our algorithm are deep hierarchical
compositions of portfolios constructed in the encoding step. The calibration
step then provides multivariate payouts in the form of deep hierarchical
portfolios that are designed to target a variety of objective functions. The
validate step trades-off the amount of regularization used in the encode and
calibrate steps. The verification step uses a cross validation approach to
trace out an ex post deep portfolio efficient frontier. We demonstrate all four
steps of our portfolio theory numerically.
"
1605.08908,2016-05-31,"What does past correlation structure tell us about the future? An answer
  from network filtering","  We discovered that past changes in the market correlation structure are
significantly related with future changes in the market volatility. By using
correlation-based information filtering networks we device a new tool for
forecasting the market volatility changes. In particular, we introduce a new
measure, the ""correlation structure persistence"", that quantifies the rate of
change of the market dependence structure. This measure shows a deep interplay
with changes in volatility and we demonstrate it can anticipate market risk
variations. Notably, our method overcomes the curse of dimensionality that
limits the applicability of traditional econometric tools to portfolios made of
a large number of assets. We report on forecasting performances and statistical
significance of this tool for two different equity datasets. We also identify
an optimal region of parameters in terms of True Positive and False Positive
trade-off, through a ROC curve analysis. We find that our forecasting method is
robust and it outperforms predictors based on past volatility only. Moreover
the temporal analysis indicates that our method is able to adapt to abrupt
changes in the market, such as financial crises, more rapidly than methods
based on past volatility.
"
1605.09181,2016-11-23,"The use of the multi-cumulant tensor analysis for the algorithmic
  optimisation of investment portfolios","  The cumulant analysis plays an important role in non Gaussian distributed
data analysis. The shares' prices returns are good example of such data. The
purpose of this research is to develop the cumulant based algorithm and use it
to determine eigenvectors that represent investment portfolios with low
variability. Such algorithm is based on the Alternating Least Square method and
involves the simultaneous minimisation 2'nd -- 6'th cumulants of the
multidimensional random variable (percentage shares' returns of many
companies). Then the algorithm was tested during the recent crash on the Warsaw
Stock Exchange. To determine incoming crash and provide enter and exit signal
for the investment strategy the Hurst exponent was calculated using the local
DFA. It was shown that introduced algorithm is on average better that benchmark
and other portfolio determination methods, but only within examination window
determined by low values of the Hurst exponent. Remark that the algorithm of is
based on cumulant tensors up to the 6'th order calculated for a
multidimensional random variable, what is the novel idea. It can be expected
that the algorithm would be useful in the financial data analysis on the world
wide scale as well as in the analysis of other types of non Gaussian
distributed data.
"
1606.03325,2018-05-25,Model-free portfolio theory and its functional master formula,"  We use pathwise It\^o calculus to prove two strictly pathwise versions of the
master formula in Fernholz' stochastic portfolio theory. Our first version is
set within the framework of F\""ollmer's pathwise It\^o calculus and works for
portfolios generated from functions that may depend on the current states of
the market portfolio and an additional path of finite variation. The second
version is formulated within the functional pathwise It\^o calculus of Dupire
(2009) and Cont \& Fourni\'e (2010) and allows for portfolio-generating
functionals that may depend additionally on the entire path of the market
portfolio. Our results are illustrated by several examples and shown to work on
empirical market data.
"
1606.05488,2016-06-20,"Explicit solutions for continuous time mean-variance portfolio selection
  with nonlinear wealth equations","  This paper concerns the continuous time mean-variance portfolio selection
problem with a special nonlinear wealth equation. This nonlinear wealth
equation has a nonsmooth coefficient and the dual method developed in [6] does
not work. We invoke the HJB equation of this problem and give an explicit
viscosity solution of the HJB equation. Furthermore, via this explicit
viscosity solution, we obtain explicitly the efficient portfolio strategy and
efficient frontier for this problem. Finally, we show that our nonlinear wealth
equation can cover three important cases.
"
1606.06578,2016-09-20,"Multi-Period Portfolio Optimization: Translation of Autocorrelation Risk
  to Excess Variance","  Growth-optimal portfolios are guaranteed to accumulate higher wealth than any
other investment strategy in the long run. However, they tend to be risky in
the short term. For serially uncorrelated markets, similar portfolios with more
robust guarantees have been recently proposed. This paper extends these robust
portfolios by accommodating non-zero autocorrelations that may reflect
investors' beliefs about market movements. Moreover, we prove that the risk
incurred by such autocorrelations can be absorbed by modifying the covariance
matrix of asset returns.
"
1606.07277,2016-06-24,Validation of the Replica Trick for Simple Models,"  We discuss replica analytic continuation using several simple models in order
to prove mathematically the validity of replica analysis, which is used in a
wide range of fields related to large scale complex systems. While replica
analysis consists of two analytical techniques, the replica trick (or replica
analytic continuation) and the thermodynamical limit (and/or order parameter
expansion), we focus our study on replica analytic continuation, which is the
mathematical basis of the replica trick. We apply replica analysis to solve a
variety of analytical models, and examine the properties of replica analytic
continuation. Based on the positive results for these models we propose that
replica analytic continuation is a robust procedure in replica analysis.
"
1606.07311,2017-04-13,"Skorohod's representation theorem and optimal strategies for markets
  with frictions","  We prove the existence of optimal strategies for agents with cumulative
prospect theory preferences who trade in a continuous-time illiquid market,
transcending known results which pertained only to risk-averse utility
maximizers. The arguments exploit an extension of Skorohod's representation
theorem for tight sequences of probability measures. This method is applicable
in a number of similar optimization problems.
"
1606.08679,2017-01-04,Replica approach to mean-variance portfolio optimization,"  We consider the problem of mean-variance portfolio optimization for a generic
covariance matrix subject to the budget constraint and the constraint for the
expected return, with the application of the replica method borrowed from the
statistical physics of disordered systems. We find that the replica symmetry of
the solution does not need to be assumed, but emerges as the unique solution of
the optimization problem. We also check the stability of this solution and find
that the eigenvalues of the Hessian are positive for $r=N/T<1$, where $N$ is
the dimension of the portfolio and $T$ the length of the time series used to
estimate the covariance matrix. At the critical point $r=1$ a phase transition
is taking place. The out of sample estimation error blows up at this point as
$1/(1-r)$, independently of the covariance matrix or the expected return,
displaying the universality not only of the critical index, but also the
critical point. As a conspicuous illustration of the dangers of in-sample
estimates, the optimal in-sample variance is found to vanish at the critical
point inversely proportional to the divergent estimation error.
"
1607.02289,2017-04-18,"An ergodic BSDE approach to forward entropic risk measures:
  representation and large-maturity behavior","  Using elements from the theory of ergodic backward stochastic differential
equations (BSDE), we study the behavior of forward entropic risk measures. We
provide their general representation results (via both BSDE and convex duality)
and examine their behavior for risk positions of long maturities. We show that
forward entropic risk measures converge to some constant exponentially fast. We
also compare them with their classical counterparts and derive a parity result.
"
1607.04153,2017-12-29,"On the Optimal Management of Public Debt: a Singular Stochastic Control
  Problem","  Consider the problem of a government that wants to reduce the debt-to-GDP
(gross domestic product) ratio of a country. The government aims at choosing a
debt reduction policy which minimises the total expected cost of having debt,
plus the total expected cost of interventions on the debt ratio. We model this
problem as a singular stochastic control problem over an infinite time-horizon.
In a general not necessarily Markovian framework, we first show by
probabilistic arguments that the optimal debt reduction policy can be expressed
in terms of the optimal stopping rule of an auxiliary optimal stopping problem.
We then exploit such link to characterise the optimal control in a
two-dimensional Markovian setting in which the state variables are the level of
the debt-to-GDP ratio and the current inflation rate of the country. The latter
follows uncontrolled Ornstein-Uhlenbeck dynamics and affects the growth rate of
the debt ratio. We show that it is optimal for the government to adopt a policy
that keeps the debt-to-GDP ratio under an inflation-dependent ceiling. This
curve is given in terms of the solution of a nonlinear integral equation
arising in the study of a fully two-dimensional optimal stopping problem.
"
1607.04883,2019-01-01,Statistical Industry Classification,"  We give complete algorithms and source code for constructing (multilevel)
statistical industry classifications, including methods for fixing the number
of clusters at each level (and the number of levels). Under the hood there are
clustering algorithms (e.g., k-means). However, what should we cluster?
Correlations? Returns? The answer turns out to be neither and our backtests
suggest that these details make a sizable difference. We also give an algorithm
and source code for building ""hybrid"" industry classifications by improving
off-the-shelf ""fundamental"" industry classifications by applying our
statistical industry classification methods to them. The presentation is
intended to be pedagogical and geared toward practical applications in
quantitative trading.
"
1607.08287,2017-06-12,The effect of heterogeneity on flocking behavior and systemic risk,"  The goal of this paper is to study organized flocking behavior and systemic
risk in heterogeneous mean-field interacting diffusions. We illustrate in a
number of case studies the effect of heterogeneity in the behavior of systemic
risk in the system, i.e., the risk that several agents default simultaneously
as a result of interconnections. We also investigate the effect of
heterogeneity on the ""flocking behavior"" of different agents, i.e., when agents
with different dynamics end up following very similar paths and follow closely
the mean behavior of the system. Using Laplace asymptotics, we derive an
asymptotic formula for the tail of the loss distribution as the number of
agents grows to infinity. This characterizes the tail of the loss distribution
and the effect of the heterogeneity of the network on the tail loss
probability.
"
1608.04522,2016-08-17,"Maximizing and Minimizing Investment Concentration with Constraints of
  Budget and Investment Risk","  In this paper, as a first step in examining the properties of a feasible
portfolio subset that is characterized by budget and risk constraints, we
assess the maximum and minimum of the investment concentration using replica
analysis. To do this, we apply an analytical approach of statistical mechanics.
We note that the optimization problem considered in this paper is the dual
problem of the portfolio optimization problem discussed in the literature, and
we verify that these optimal solutions are also dual. We also present numerical
experiments, in which we use the method of steepest descent that is based on
Lagrange's method of undetermined multipliers, and we compare the numerical
results to those obtained by replica analysis in order to assess the
effectiveness of our proposed approach.
"
1608.05024,2016-08-19,"Risk reduction and Diversification within Markowitz's Mean-Variance
  Model: Theoretical Revisit","  The conventional wisdom of mean-variance (MV) portfolio theory asserts that
the nature of the relationship between risk and diversification is a decreasing
asymptotic function, with the asymptote approximating the level of portfolio
systematic risk or undiversifiable risk. This literature assumes that investors
hold an equally-weighted or a MV portfolio and quantify portfolio
diversification using portfolio size. However, the equally-weighted portfolio
and portfolio size are MV optimal if and only if asset returns distribution is
exchangeable or investors have no useful information about asset expected
return and risk. Moreover, the whole of literature, absolutely all of it,
focuses only on risky assets, ignoring the role of the risk free asset in the
efficient diversification. Therefore, it becomes interesting and important to
answer this question: how valid is this conventional wisdom when investors have
full information about asset expected return and risk and asset returns
distribution is not exchangeable in both the case where the risk free rate is
available or not? Unfortunately, this question have never been addressed in the
current literature. This paper fills the gap.
"
1608.06121,2016-08-23,Volatility and Arbitrage,"  The capitalization-weighted total relative variation $\sum_{i=1}^d
\int_0^\cdot \mu_i (t) \mathrm{d} \langle \log \mu_i \rangle (t)$ in an equity
market consisting of a fixed number $d$ of assets with capitalization weights
$\mu_i (\cdot)$ is an observable and nondecreasing function of time. If this
observable of the market is not just nondecreasing, but actually grows at a
rate which is bounded away from zero, then strong arbitrage can be constructed
relative to the market over sufficiently long time horizons. It has been an
open issue for more than ten years, whether such strong outperformance of the
market is possible also over arbitrary time horizons under the stated
condition. We show that this is not possible in general, thus settling this
long-open question. We also show that, under appropriate additional conditions,
outperformance over any time horizon indeed becomes possible, and exhibit
investment strategies that effect it.
"
1608.08268,2016-08-31,On the Market-Neutrality of Optimal Pairs-Trading Strategies,"  We consider the problem of optimal investment in a market with two
cointegrated stocks and an agent with CRRA utility. We extend the findings of
Liu and Timmermann [The Review of Financial Studies, 26(4):1048-1086, 2013] by
paying special attention to when/if the associated stochastic control problem
is well-posed and providing a verification result. Our new findings lead to a
sharp well-posedness condition which is, surprisingly, also the necessary and
sufficient condition for the optimal investment to be market-neutral (i.e.
having offsetting long/short positions in the stocks). Hence, we provide a
theoretical justification for market-neutral pairs-trading which, despite
having a strong practical relevance, has been lacking a theoretical ground.
"
1608.08468,2019-08-07,Sparse Bayesian time-varying covariance estimation in many dimensions,"  We address the curse of dimensionality in dynamic covariance estimation by
modeling the underlying co-volatility dynamics of a time series vector through
latent time-varying stochastic factors. The use of a global-local shrinkage
prior for the elements of the factor loadings matrix pulls loadings on
superfluous factors towards zero. To demonstrate the merits of the proposed
framework, the model is applied to simulated data as well as to daily
log-returns of 300 S&P 500 members. Our approach yields precise correlation
estimates, strong implied minimum variance portfolio performance and superior
forecasting accuracy in terms of log predictive scores when compared to typical
benchmarks.
"
1608.08490,2019-03-26,Multi-period investment strategies under Cumulative Prospect Theory,"  In this article, inspired by Shi, et al. we investigate the optimal portfolio
selection with one risk-free asset and one risky asset in a multiple period
setting under cumulative prospect theory (CPT). Compared with their study, our
novelty is that we consider a stochastic benchmark, and portfolio constraints.
We test the sensitivity of the optimal CPT-investment strategies to different
model parameters by performing a numerical analysis.
"
1608.08582,2017-01-04,"Discrete hierarchy of sizes and performances in the exchange-traded fund
  universe","  Using detailed statistical analyses of the size distribution of a universe of
equity exchange-traded funds (ETFs), we discover a discrete hierarchy of sizes,
which imprints a log-periodic structure on the probability distribution of ETF
sizes that dominates the details of the asymptotic tail. This allows us to
propose a classification of the studied universe of ETFs into seven size layers
approximately organized according to a multiplicative ratio of 3.5 in their
total market capitalization. Introducing a similarity metric generalising the
Herfindhal index, we find that the largest ETFs exhibit a significantly
stronger intra-layer and inter-layer similarity compared with the smaller ETFs.
Comparing the performance across the seven discerned ETF size layers, we find
an inverse size effect, namely large ETFs perform significantly better than the
small ones both in 2014 and 2015.
"
1609.00869,2016-09-06,"Determining Optimal Stop-Loss Thresholds via Bayesian Analysis of
  Drawdown Distributions","  Stop-loss rules are often studied in the financial literature, but the
stop-loss levels are seldom constructed systematically. In many papers, and
indeed in practice as well, the level of the stops is too often set
arbitrarily. Guided by the overarching goal in finance to maximize expected
returns given available information, we propose a natural method by which to
systematically select the stop-loss threshold by analyzing the distribution of
maximum drawdowns. We present results for an hourly trading strategy with two
variations on the construction.
"
1609.01274,2022-03-29,"Options as Silver Bullets: Valuation of Term Loans, Inventory
  Management, Emissions Trading and Insurance Risk Mitigation using Option
  Theory","  Models to price long term loans in the securities lending business are
developed. These longer horizon deals can be viewed as contracts with
optionality embedded in them. This insight leads to the usage of established
methods from derivatives theory to price such contracts. Numerical simulations
are used to demonstrate the practical applicability of these models. The
techniques advanced here can lead to greater synergies between the management
of derivative and delta-one trading desks, perhaps even being able to combine
certain aspects of the day to day operations of these seemingly disparate
entities. These models are part of one of the least explored, yet profit laden,
areas of modern investment management.
  A heuristic is developed to mitigate any loss of information, which might set
in when parameters are estimated first and then the valuations are performed,
by directly calculating valuations using the historical time series. This
approach to valuations can lead to reduced models errors, robust estimation
systems, greater financial stability and economic strength. An illustration is
provided regarding how the methodologies developed here could be useful for
inventory management, emissions trading and insurance risk mitigation. All
these techniques could have applications for dealing with other financial
instruments, non-financial commodities and many forms of uncertainty.
"
1609.01655,2017-11-27,The dividend problem with a finite horizon,"  We characterise the value function of the optimal dividend problem with a
finite time horizon as the unique classical solution of a suitable
Hamilton-Jacobi-Bellman equation. The optimal dividend strategy is realised by
a Skorokhod reflection of the fund's value at a time-dependent optimal
boundary. Our results are obtained by establishing for the first time a new
connection between singular control problems with an absorbing boundary and
optimal stopping problems on a diffusion reflected at $0$ and created at a rate
proportional to its local time.
"
1609.04065,2016-09-15,"Closed-form solutions for worst-case law invariant risk measures with
  application to robust portfolio optimization","  Worst-case risk measures refer to the calculation of the largest value for
risk measures when only partial information of the underlying distribution is
available. For the popular risk measures such as Value-at-Risk (VaR) and
Conditional Value-at-Risk (CVaR), it is now known that their worst-case
counterparts can be evaluated in closed form when only the first two moments
are known for the underlying distribution. These results are remarkable since
they not only simplify the use of worst-case risk measures but also provide
great insight into the connection between the worst-case risk measures and
existing risk measures. We show in this paper that somewhat surprisingly
similar closed-form solutions also exist for the general class of law invariant
coherent risk measures, which consists of spectral risk measures as special
cases that are arguably the most important extensions of CVaR. We shed light on
the one-to-one correspondence between a worst-case law invariant risk measure
and a worst-case CVaR (and a worst-case VaR), which enables one to carry over
the development of worst-case VaR in the context of portfolio optimization to
the worst-case law invariant risk measures immediately.
"
1609.05475,2016-12-20,Replica Analysis for the Duality of the Portfolio Optimization Problem,"  In the present paper, the primal-dual problem consisting of the investment
risk minimization problem and the expected return maximization problem in the
mean-variance model is discussed using replica analysis. As a natural extension
of the investment risk minimization problem under only a budget constraint that
we analyzed in a previous study, we herein consider a primal-dual problem in
which the investment risk minimization problem with budget and expected return
constraints is regarded as the primal problem, and the expected return
maximization problem with budget and investment risk constraints is regarded as
the dual problem. With respect to these optimal problems, we analyze a quenched
disordered system involving both of these optimization problems using the
approach developed in statistical mechanical informatics, and confirm that both
optimal portfolios can possess the primal-dual structure. Finally, the results
of numerical simulations are shown to validate the effectiveness of the
proposed method.
"
1609.07051,2021-12-03,Multivariate Garch with dynamic beta,"  We investigate a solution for the problems related to the application of
multivariate GARCH models to markets with a large number of stocks by
restricting the form of the conditional covariance matrix. The model is a
factor model and uses only six free GARCH parameters. One factor can be
interpreted as the market component, the remaining factors are equal. This
allow the analytical calculation of the inverse covariance matrix. The
time-dependence of the factors enables the determination of dynamical beta
coefficients. We compare the results from our model with the results of other
GARCH models for the daily returns from the S\&P500 market and find that they
are competitive. As applications we use the daily values of beta coefficients
to confirm a transition of the market in 2006. Furthermore we discuss the
relationship of our model with the leverage effect.
"
1610.00256,2016-10-04,XVA at the Exercise Boundary,"  XVA is a material component of a trade valuation and hence it must impact the
decision to exercise options within a given netting set. This is true for both
unsecured trades and secured / cleared trades where KVA and MVA play a material
role even if CVA and FVA do not. However, this effect has frequently been
ignored in XVA models and indeed in exercise decisions made by option owners.
This paper describes how XVA impacts the exercise decision and how this can be
readily evaluated using regression techniques (Longstaff and Schwartz 2001).
The paper then assesses the materiality of the impact of XVA at the exercise
boundary on swaption examples.
"
1610.00395,2016-10-04,Optimal Portfolios of Illiquid Assets,"  This paper investigates the investment behaviour of a large unregulated
financial institution (FI) with CARA risk preferences. It shows how the FI
optimizes its trading to account for market illiquidity using an extension of
the Almgren-Chriss market impact model of multiple risky assets. This expected
utility optimization problem over the set of adapted strategies turns out to
have the same solutions as a mean-variance optimization over deterministic
trading strategies. That means the optimal adapted trading strategy is both
deterministic and time-consistent. It is also found to have an explicit closed
form that clearly displays interesting properties. For example, the classic
constant Merton portfolio strategy, a particular solution of the frictionless
limit of the problem, behaves like an attractor in the space of more general
solutions. The main effect of temporary market impact is to slow down the speed
of convergence to this constant Merton portfolio. The effect of permanent
market impact is to incentivize the FI to buy additional risky assets near the
end of the period. This property, that we name the Ponzi property, is related
to the creation and bursting of bubbles in the market. The proposed model can
be used as a stylized dynamic model of a typical FI in the study of the asset
fire sale channel relevant to understanding systemic risk and financial
stability.
"
1610.00937,2020-05-28,Sharpe portfolio using a cross-efficiency evaluation,"  The Sharpe ratio is a way to compare the excess returns (over the risk free
asset) of portfolios for each unit of volatility that is generated by a
portfolio. In this paper we introduce a robust Sharpe ratio portfolio under the
assumption that the risk free asset is unknown. We propose a robust portfolio
that maximizes the Sharpe ratio when the risk free asset is unknown, but is
within a given interval. To compute the best Sharpe ratio portfolio all the
Sharpe ratios for any risk free asset are considered and compared by using the
so-called cross-efficiency evaluation. An explicit expression of the
Cross-Eficiency Sharpe ratio portfolio is presented when short selling is
allowed.
"
1610.00999,2019-02-12,"Exponential utility maximization under model uncertainty for unbounded
  endowments","  We consider the robust exponential utility maximization problem in discrete
time: An investor maximizes the worst case expected exponential utility with
respect to a family of nondominated probabilistic models of her endowment by
dynamically investing in a financial market, and statically in available
options. We show that, for any measurable random endowment (regardless of
whether the problem is finite or not) an optimal strategy exists, a dual
representation in terms of (calibrated) martingale measures holds true, and
that the problem satisfies the dynamic programming principle (in case of no
options). Further it is shown that the value of the utility maximization
problem converges to the robust superhedging price as the risk aversion
parameter gets large, and examples of nondominated probabilistic models are
discussed.
"
1610.01937,2016-10-07,"Trading against disorderly liquidation of a large position under
  asymmetric information and market impact","  We consider trading against a hedge fund or large trader that must liquidate
a large position in a risky asset if the market price of the asset crosses a
certain threshold. Liquidation occurs in a disorderly manner and negatively
impacts the market price of the asset. We consider the perspective of small
investors whose trades do not induce market impact and who possess different
levels of information about the liquidation trigger mechanism and the market
impact. We classify these market participants into three types: fully informed,
partially informed and uninformed investors. We consider the portfolio
optimization problems and compare the optimal trading and wealth processes for
the three classes of investors theoretically and by numerical illustrations.
"
1610.03958,2016-10-14,"Optimal Consumption and Investment with Fixed and Proportional
  Transaction Costs","  The classical optimal investment and consumption problem with infinite
horizon is studied in the presence of transaction costs. Both proportional and
fixed costs as well as general utility functions are considered. Weak dynamic
programming is proved in the general setting and a comparison result for
possibly discontinuous viscosity solutions of the dynamic programming equation
is provided. Detailed numerical experiments illustrate several properties of
the optimal investment strategies.
"
1610.06805,2017-03-14,"Robust Markowitz mean-variance portfolio selection under ambiguous
  covariance matrix *","  This paper studies a robust continuous-time Markowitz portfolio selection
pro\-blem where the model uncertainty carries on the covariance matrix of
multiple risky assets. This problem is formulated into a min-max mean-variance
problem over a set of non-dominated probability measures that is solved by a
McKean-Vlasov dynamic programming approach, which allows us to characterize the
solution in terms of a Bellman-Isaacs equation in the Wasserstein space of
probability measures. We provide explicit solutions for the optimal robust
portfolio strategies and illustrate our results in the case of uncertain
volatilities and ambiguous correlation between two risky assets. We then derive
the robust efficient frontier in closed-form, and obtain a lower bound for the
Sharpe ratio of any robust efficient portfolio strategy. Finally, we compare
the performance of Sharpe ratios for a robust investor and for an investor with
a misspecified model. MSC Classification: 91G10, 91G80, 60H30
"
1610.07694,2019-06-05,"Dynamic portfolio optimization with liquidity cost and market impact: a
  simulation-and-regression approach","  We present a simulation-and-regression method for solving dynamic portfolio
allocation problems in the presence of general transaction costs, liquidity
costs and market impacts. This method extends the classical least squares Monte
Carlo algorithm to incorporate switching costs, corresponding to transaction
costs and transient liquidity costs, as well as multiple endogenous state
variables, namely the portfolio value and the asset prices subject to permanent
market impacts. To do so, we improve the accuracy of the control randomization
approach in the case of discrete controls, and propose a global iteration
procedure to further improve the allocation estimates. We validate our
numerical method by solving a realistic cash-and-stock portfolio with a
power-law liquidity model. We quantify the certainty equivalent losses
associated with ignoring liquidity effects, and illustrate how our dynamic
allocation protects the investor's capital under illiquid market conditions.
Lastly, we analyze, under different liquidity conditions, the sensitivities of
certainty equivalent returns and optimal allocations with respect to trading
volume, stock price volatility, initial investment amount, risk-aversion level
and investment horizon.
"
1610.08558,2016-10-28,"Portfolio Benchmarking under Drawdown Constraint and Stochastic Sharpe
  Ratio","  We consider an investor who seeks to maximize her expected utility derived
from her terminal wealth relative to the maximum performance achieved over a
fixed time horizon, and under a portfolio drawdown constraint, in a market with
local stochastic volatility (LSV). In the absence of closed-form formulas for
the value function and optimal portfolio strategy, we obtain approximations for
these quantities through the use of a coefficient expansion technique and
nonlinear transformations. We utilize regularity properties of the risk
tolerance function to numerically compute the estimates for our approximations.
In order to achieve similar value functions, we illustrate that, compared to a
constant volatility model, the investor must deploy a quite different portfolio
strategy which depends on the current level of volatility in the stochastic
volatility model.
"
1610.08818,2016-10-28,Agnostic Risk Parity: Taming Known and Unknown-Unknowns,"  Markowitz' celebrated optimal portfolio theory generally fails to deliver
out-of-sample diversification. In this note, we propose a new portfolio
construction strategy based on symmetry arguments only, leading to ""Eigenrisk
Parity"" portfolios that achieve equal realized risk on all the principal
components of the covariance matrix. This holds true for any other definition
of uncorrelated factors. We then specialize our general formula to the most
agnostic case where the indicators of future returns are assumed to be
uncorrelated and of equal variance. This ""Agnostic Risk Parity"" (AGP) portfolio
minimizes unknown-unknown risks generated by over-optimistic hedging of the
different bets. AGP is shown to fare quite well when applied to standard
technical strategies such as trend following.
"
1610.10029,2016-11-01,Meta-CTA Trading Strategies based on the Kelly Criterion,"  The influence of Commodity Trading Advisors (CTA) on the price process is
explored with the help of a simple model. CTA managers are taken to be Kelly
optimisers, which invest a fixed proportion of their assets in the risky asset
and the remainder in a riskless asset. This requires regular adjustment of the
portfolio weights as prices evolve. The CTA trading activity impacts the price
change in the form of a power law. These two rules governing investment ratios
and price impact are combined and lead through updating at fixed time intervals
to a deterministic price dynamic. For different choices of the model parameters
one gets qualitatively different dynamics. The result can be expressed as a
phase diagram. Meta-CTA strategies can be devised to exploit the predictability
inherent in the model dynamics by avoiding critical areas of the phase diagram
or by taking a contrarian position at an opportune time.
"
1611.00389,2021-06-18,Option pricing in exponential L\'evy models with transaction costs,"  We present an approach for pricing European call options in presence of
proportional transaction costs, when the stock price follows a general
exponential L\'{e}vy process. The model is a generalization of the celebrated
work of Davis, Panas and Zariphopoulou (1993), where the value of the option is
defined as the utility indifference price. This approach requires the solution
of two stochastic singular control problems in finite horizon, satisfying the
same Hamilton-Jacobi-Bellman equation, with different terminal conditions. We
introduce a general formulation for these portfolio selection problems, and
then we focus on the special case in which the probability of default is
ignored. We solve numerically the optimization problems using the Markov chain
approximation method and show results for diffusion, Merton and Variance Gamma
processes. Option prices are computed for both the writer and the buyer.
"
1611.00997,2016-11-07,LQG for portfolio optimization,"  We introduce a generic solver for dynamic portfolio allocation problems when
the market exhibits return predictability, price impact and partial
observability. We assume that the price modeling can be encoded into a linear
state-space and we demonstrate how the problem then falls into the LQG
framework. We derive the optimal control policy and introduce analytical tools
that preserve the intelligibility of the solution. Furthermore, we link the
existence and uniqueness of the optimal controller to a dynamical non-arbitrage
criterion. Finally, we illustrate our method using a synthetic portfolio
allocation problem.
"
1611.01280,2017-07-07,Optimal portfolio selection under vanishing fixed transaction costs,"  In this paper, asymptotic results in a long-term growth rate portfolio
optimization model under both fixed and proportional transaction costs are
obtained. More precisely, the convergence of the model when the fixed costs
tend to zero is investigated. A suitable limit model with purely proportional
costs is introduced and an optimal strategy is shown to consist of keeping the
risky fraction process in a unique interval $[A,B]\subseteq\,]0,1[$ with
minimal effort. Furthermore, the convergence of optimal boundaries, asymptotic
growth rates, and optimal risky fraction processes is rigorously proved. The
results are based on an in-depth analysis of the convergence of the solutions
to the corresponding HJB-equations.
"
1611.01285,2016-11-10,Naive Diversification Preferences and their Representation,"  A widely applied diversification paradigm is the naive diversification choice
heuristic. It stipulates that an economic agent allocates equal decision
weights to given choice alternatives independent of their individual
characteristics. This article provides mathematically and economically sound
choice theoretic foundations for the naive approach to diversification. We
axiomatize naive diversification by defining it as a preference for equality
over inequality and derive its relationship to the classical diversification
paradigm. In particular, we show that (i) the notion of permutation invariance
lies at the core of naive diversification and that an economic agent is a naive
diversifier if and only if his preferences are convex and permutation
invariant; (ii) Schur-concave utility functions capture the idea of being
inequality averse on top of being risk averse; and (iii) the transformations,
which rebalance unequal decision weights to equality, are characterized in
terms of their implied turnover.
"
1611.01463,2017-05-17,"International Portfolio Optimisation with Integrated Currency Overlay
  Costs and Constraints","  Portfolio optimisation typically aims to provide an optimal allocation that
minimises risk, at a given return target, by diversifying over different
investments. However, the potential scope of such risk diversification can be
limited if investments are concentrated in only one country, or more
specifically one currency. Multi-currency portfolio is an alternative to
achieve higher returns and more diversified portfolios but it requires a
careful management of the entailed risks from changes in exchange rates.
  The deviation between asset and currency exposures in a portfolio is defined
as the ""currency overlay"". This paper addresses risk mitigation by allowing
currency overlay and asset allocation be optimised together. We propose a model
of the international portfolio optimisation problem in which the currency
overlay is constructed by holding foreign exchange rate forward contracts.
Crucially, the cost of carry, transaction costs, and margin requirement of
forward contracts are also taken into account in portfolio return calculation.
This novel extension of previous overlay models improves the accuracy of risk
and return calculation of portfolios; furthermore, our experimental results
show that inclusion of such costs significantly changes the optimal decisions.
Effects of constraints imposed to reduce transaction costs associated are
examined and the empirical results show that risk-return compensation of
portfolios varies significantly with different return targets.
"
1611.01524,2023-04-19,"`To Have What They are Having': Portfolio Choice for Mimicking
  Mean-Variance Savers","  We consider a group of mean-variance investors with mimicking desire such
that each investor is willing to penalize deviations of his portfolio
composition from compositions of other group members. Penalizing norm
constraints are already applied for statistical improvement of Markowitz
portfolio procedure in order to cope with estimation risk. We relate these
penalties to individuals' wish of social learning and introduce a mutual fund
(investment club) aggregating group member preferences unknown for individual
savers. We derive the explicit analytical solution for the fund's optimal
portfolio weights and show advantages to invest in such a fund for individuals
willing to mimic.
"
1611.01958,2023-04-19,Optimal shrinkage-based portfolio selection in high dimensions,"  In this paper we estimate the mean-variance portfolio in the high-dimensional
case using the recent results from the theory of random matrices. We construct
a linear shrinkage estimator which is distribution-free and is optimal in the
sense of maximizing with probability $1$ the asymptotic out-of-sample expected
utility, i.e., mean-variance objective function for different values of risk
aversion coefficient which in particular leads to the maximization of the
out-of-sample expected utility and to the minimization of the out-of-sample
variance.
  One of the main features of our estimator is the inclusion of the estimation
risk related to the sample mean vector into the high-dimensional portfolio
optimization. The asymptotic properties of the new estimator are investigated
when the number of assets $p$ and the sample size $n$ tend simultaneously to
infinity such that $p/n \rightarrow c\in (0,+\infty)$. The results are obtained
under weak assumptions imposed on the distribution of the asset returns, namely
the existence of the $4+\varepsilon$ moments is only required.
  Thereafter we perform numerical and empirical studies where the small- and
large-sample behavior of the derived estimator is investigated. The suggested
estimator shows significant improvements over the existent approaches including
the nonlinear shrinkage estimator and the three-fund portfolio rule, especially
when the portfolio dimension is larger than the sample size. Moreover, it is
robust to deviations from normality.
"
1611.04494,2019-03-20,Predictable Forward Performance Processes: The Binomial Case,"  We introduce a new class of forward performance processes that are endogenous
and predictable with regards to an underlying market information set and,
furthermore, are updated at discrete times. We analyze in detail a binomial
model whose parameters are random and updated dynamically as the market
evolves. We show that the key step in the construction of the associated
predictable forward performance process is to solve a single-period inverse
investment problem, namely, to determine, period-by-period and conditionally on
the current market information, the end-time utility function from a given
initial-time value function. We reduce this inverse problem to solving a
functional equation and establish conditions for the existence and uniqueness
of its solutions in the class of inverse marginal functions.
"
1611.04877,2016-11-16,"The Asset Liability Management problem of a nuclear operator : a
  numerical stochastic optimization approach","  We numerically study an Asset Liability Management problem linked to the
decommissioning of French nuclear power plants. We link the risk aversion of
practitioners to an optimization problem. Using different price models we show
that the optimal solution is linked to a de-risking management strategy similar
to a concave strategy and we propose an effective heuristic to simulate the
underlying optimal strategy. Besides we show that the strategy is stable with
respect to the main parameters involved in the liability problem.
"
1611.07741,2019-09-11,The Markowitz Category,"  We give an algebraic definition of a Markowitz market and classify markets up
to isomorphism. Given this classification, the theory of portfolio optimization
in Markowitz markets without short selling constraints becomes trivial.
Conversely, this classification shows that, up to isomorphism, there is little
that can be said about a Markowitz market that is not already detected by the
theory of portfolio optimization. In particular, if one seeks to develop a
simplified low-dimensional model of a large financial market using
mean--variance analysis alone, the resulting model can be at most
two-dimensional.
"
1611.07843,2019-03-21,"Portfolio choice, portfolio liquidation, and portfolio transition under
  drift uncertainty","  This paper presents several models addressing optimal portfolio choice,
optimal portfolio liquidation, and optimal portfolio transition issues, in
which the expected returns of risky assets are unknown. Our approach is based
on a coupling between Bayesian learning and dynamic programming techniques that
leads to partial differential equations. It enables to recover the well-known
results of Karatzas and Zhao in a framework \`a la Merton, but also to deal
with cases where martingale methods are no longer available. In particular, we
address optimal portfolio choice, portfolio liquidation, and portfolio
transition problems in a framework \`a la Almgren-Chriss, and we build
therefore a model in which the agent takes into account in his decision process
both the liquidity of assets and the uncertainty with respect to their expected
return.
"
1611.08393,2016-11-28,Mean-Reverting Portfolio Design via Majorization-Minimization Method,"  This paper considers the mean-reverting portfolio design problem arising from
statistical arbitrage in the financial markets. The problem is formulated by
optimizing a criterion characterizing the mean-reversion strength of the
portfolio and taking into consideration the variance of the portfolio and an
investment budget constraint at the same time. An efficient algorithm based on
the majorization-minimization (MM) method is proposed to solve the problem.
Numerical results show that our proposed mean-reverting portfolio design method
can significantly outperform every underlying single spread and the benchmark
method in the literature.
"
1611.09300,2018-02-22,Asymptotic approximation of optimal portfolio for small time horizons,"  We consider the problem of portfolio optimization in a simple incomplete
market and under a general utility function. By working with the associated
Hamilton-Jacobi-Bellman partial differential equation (HJB PDE), we obtain a
closed-form formula for a trading strategy which approximates the optimal
trading strategy when the time horizon is small. This strategy is generated by
a first order approximation to the value function. The approximate value
function is obtained by constructing classical sub- and super-solutions to the
HJB PDE using a formal expansion in powers of horizon time. Martingale
inequalities are used to sandwich the true value function between the
constructed sub- and super-solutions. A rigorous proof of the accuracy of the
approximation formulas is given. We end with a heuristic scheme for extending
our small-time approximating formulas to approximating formulas in a finite
time horizon.
"
1612.01302,2017-05-25,A Primer on Portfolio Choice with Small Transaction Costs,"  This survey is an introduction to asymptotic methods for portfolio-choice
problems with small transaction costs. We outline how to derive the
corresponding dynamic programming equations and simplify them in the small-cost
limit. This allows to obtain explicit solutions in a wide range of settings,
which we illustrate for a model with mean-reverting expected returns and
proportional transaction costs. For even more complex models, we present a
policy iteration scheme that allows to compute the solution numerically.
"
1612.03698,2016-12-20,Fractal Optimization of Market Neutral Portfolio,"  A fractal approach to the long-short portfolio optimization is proposed. The
algorithmic system based on the composition of market-neutral spreads into a
single entity was considered. The core of the optimization scheme is a fractal
walk model of returns, optimizing a risk aversion according to the investment
horizon. The covariance matrix of spread returns has been used for the
optimization and modified according to the Hurst stability analysis.
Out-of-sample performance data has been represented for the space of exchange
traded funds in five period time period of observation. The considered
portfolio system has turned out to be statistically more stable than a passive
investment into benchmark with higher risk adjusted cumulative return over the
observed period.
"
1612.04370,2016-12-19,"S&P500 Forecasting and Trading using Convolution Analysis of Major Asset
  Classes","  By monitoring the time evolution of the most liquid Futures contracts traded
globally as acquired using the Bloomberg API from 03 January 2000 until 15
December 2014 we were able to forecast the S&P 500 index beating the Buy and
Hold trading strategy. Our approach is based on convolution computations of 42
of the most liquid Futures contracts of four basic financial asset classes,
namely, equities, bonds, commodities and foreign exchange. These key assets
were selected on the basis of the global GDP ranking across countries worldwide
according to the lists published by the International Monetary Fund (IMF,
Report for Selected Country Groups and Subjects, 2015). The main hypothesis is
that the shifts between the asset classes are smooth and are shaped by slow
dynamics as trading decisions are shaped by several constraints associated with
the portfolios allocation, as well as rules restrictions imposed by state
financial authorities. This hypothesis is grounded on recent research based on
the added value generated by diversification targets of market participants
specialized on active asset management, who try to efficiently and smoothly
navigate the market's volatility.
"
1612.06133,2016-12-20,Optimal Investment under Information Driven Contagious Distress,"  We introduce a dynamic optimization framework to analyze optimal portfolio
allocations within an information driven contagious distress model. The
investor allocates his wealth across several stocks whose growth rates and
distress intensities are driven by a hidden Markov chain, and also influenced
by the distress state of the economy. We show that the optimal investment
strategies depend on the gradient of value functions, recursively linked to
each other via the distress states. We establish uniform bounds for the
solutions to a sequence of approximation problems, show their convergence to
the unique Sobolev solution of the recursive system of Hamilton-Jacobi-Bellman
partial differential equations (HJB PDEs), and prove a verification theorem. We
provide a numerical study to illustrate the sensitivity of the strategies to
contagious distress, stock volatilities and risk aversion.
"
1612.07067,2018-01-17,Analytic solution to variance optimization with no short-selling,"  A large portfolio of independent returns is optimized under the variance risk
measure with a ban on short positions. The no-short selling constraint acts as
an asymmetric $\ell_1$ regularizer, setting some of the portfolio weights to
zero and keeping the out of sample estimator for the variance bounded, avoiding
the divergence present in the non-regularized case. However, the
susceptibility, i.e. the sensitivity of the optimal portfolio weights to
changes in the returns, diverges at a critical value $r=2$. This means that a
ban on short positions does not prevent the phase transition in the
optimization problem, it merely shifts the critical point from its
non-regularized value of $r=1$ to $2$. At $r=2$ the out of sample estimator for
the portfolio variance stays finite and the estimated in-sample variance
vanishes. We have performed numerical simulations to support the analytic
results and found perfect agreement for $N/T<2$. Numerical experiments on
finite size samples of symmetrically distributed returns show that above this
critical point the probability of finding solutions with zero in-sample
variance increases rapidly with increasing $N$, becoming one in the large $N$
limit. However, these are not legitimate solutions of the optimization problem,
as they are infinitely sensitive to any change in the input parameters, in
particular they will wildly fluctuate from sample to sample. We also calculate
the distribution of the optimal weights over the random samples and show that
the regularizer preferentially removes the assets with large variances, in
accord with one's natural expectation.
"
1612.07194,2016-12-22,Leverage and Uncertainty,"  Risk and uncertainty will always be a matter of experience, luck, skills, and
modelling. Leverage is another concept, which is critical for the investor
decisions and results. Adaptive skills and quantitative probabilistic methods
need to be used in successful management of risk, uncertainty and leverage. The
author explores how uncertainty beyond risk determines consistent leverage in a
simple model of the world with fat tails due to significant, not fully
quantifiable and not too rare events. Among particular technical results, for
the single asset fractional Kelly criterion is derived in the presence of the
fat tails associated with subjective uncertainty. For the multi-asset
portfolio, Kelly criterion provides an insightful perspective on Risk Parity
strategies, which can be extended for the assets with fat tails.
"
1612.09553,2019-02-28,Investor Experiences and Financial Market Dynamics,"  How do macro-financial shocks affect investor behavior and market dynamics?
Recent evidence on experience effects suggests a long-lasting influence of
personally experienced outcomes on investor beliefs and investment, but also
significant differences across older and younger generations. We formalize
experience-based learning in an OLG model, where different cross-cohort
experiences generate persistent heterogeneity in beliefs, portfolio choices,
and trade. The model allows us to characterize a novel link between investor
demographics and the dependence of prices on past dividends, while also
generating known features of asset prices, such as excess volatility and return
predictability. The model produces new implications for the cross-section of
asset holdings, trade volume, and investors' heterogenous responses to recent
financial crises, which we show to be in line with the data.
"
1701.02958,2017-01-12,Robust Portfolio Optimisation with Specified Competitors,"  We extend Relative Robust Portfolio Optimisation models to allow portfolios
to optimise their distance to a set of benchmarks. Portfolio managers are also
given the option of computing regret in a way which is more in line with market
practices than other approaches suggested in the literature. In addition, they
are given the choice of simply adding an extra constraint to their optimisation
problem instead of outright changing the objective function, as is commonly
suggested in the literature. We illustrate the benefits of this approach by
applying it to equity portfolios in a variety of regions.
"
1701.05016,2018-05-09,Mean-Reverting Portfolio Design with Budget Constraint,"  This paper considers the mean-reverting portfolio design problem arising from
statistical arbitrage in the financial markets. We first propose a general
problem formulation aimed at finding a portfolio of underlying component assets
by optimizing a mean-reversion criterion characterizing the mean-reversion
strength, taking into consideration the variance of the portfolio and an
investment budget constraint. Then several specific problems are considered
based on the general formulation, and efficient algorithms are proposed.
Numerical results on both synthetic and market data show that our proposed
mean-reverting portfolio design methods can generate consistent profits and
outperform the traditional design methods and the benchmark methods in the
literature.
"
1702.00982,2018-03-23,On utility maximization without passing by the dual problem,"  We treat utility maximization from terminal wealth for an agent with utility
function $U:\mathbb{R}\to\mathbb{R}$ who dynamically invests in a
continuous-time financial market and receives a possibly unbounded random
endowment. We prove the existence of an optimal investment without introducing
the associated dual problem. We rely on a recent result of Orlicz space theory,
due to Delbaen and Owari which leads to a simple and transparent proof.
  Our results apply to non-smooth utilities and even strict concavity can be
relaxed. We can handle certain random endowments with non-hedgeable risks,
complementing earlier papers. Constraints on the terminal wealth can also be
incorporated.
  As examples, we treat frictionless markets with finitely many assets and
large financial markets.
"
1702.01354,2017-02-07,"Market Depth and Risk Return Analysis of Dhaka Stock Exchange: An
  Empirical Test of Market Efficiency","  It is customary that when security prices fully reflect all available
information, the markets for those securities are said to be efficient. And if
markets are inefficient, investors can use available information ignored by the
market to earn abnormally high returns on their investments. In this context
this paper tries to find evidence supporting the reality of weak-form
efficiency of the Dhaka Stock Exchange (DSE) by examining the issues of market
risk-return relationship and market depth or liquidity for DSE. The study uses
a data set of daily market index and returns for the period of 1994 to 2005 and
weekly market capital turnover in proportion of total market capital for the
period of 1994 to 2005. The paper also looks about the market risk (systemic
risk) and return where it is found that market rate of return of DSE is very
low or sometimes negative. Eventually Capital Asset Pricing Model (CAPM), which
envisages the relationship between risk and the expected rate of return on a
risky security, is found unrelated in DSE market. As proper risk-return
relationships of the market is seems to be deficient in DSE and the market is
not liquid, interest of the available investors are bring into being very
insignificant. All these issues are very noteworthy to the security analysts,
investors and security exchange regulatory bodies in their policy making
decisions to progress the market condition.
"
1703.00476,2017-03-03,"Existence and Uniqueness for the Multivariate Discrete Terminal Wealth
  Relative","  In this paper the multivariate fractional trading ansatz of money management
from Ralph Vince (Portfolio Management Formulas: Mathematical Trading Methods
for the Futures, Options, and Stock Markets, John Wiley & Sons, Inc., 1990) is
discussed. In particular, we prove existence and uniqueness of an optimal f of
the respective optimization problem under reasonable assumptions on the trade
return matrix. This result generalizes a similar result for the univariate
fractional trading ansatz. Furthermore, our result guarantees that the
multivariate optimal f solutions can always be found numerically by steepest
ascent methods.
"
1703.02777,2017-03-09,Pythagorean theorem of Sharpe ratio,"  In the present paper, using a replica analysis, we examine the portfolio
optimization problem handled in previous work and discuss the minimization of
investment risk under constraints of budget and expected return for the case
that the distribution of the hyperparameters of the mean and variance of the
return rate of each asset are not limited to a specific probability family.
Findings derived using our proposed method are compared with those in previous
work to verify the effectiveness of our proposed method. Further, we derive a
Pythagorean theorem of the Sharpe ratio and macroscopic relations of
opportunity loss. Using numerical experiments, the effectiveness of our
proposed method is demonstrated for a specific situation.
"
1703.04423,2017-08-02,Extremal Behavior of Long-Term Investors with Power Utility,"  We consider a Bayesian financial market with one bond and one stock where the
aim is to maximize the expected power utility from terminal wealth. The
solution of this problem is known, however there are some conjectures in the
literature about the long-term behavior of the optimal strategy. In this paper
we prove now that for positive coefficient in the power utility the long-term
investor is very optimistic and behaves as if the best drift has been realized.
In case the coefficient in the power utility is negative the long-term investor
is very pessimistic and behaves as if the worst drift has been realized.
"
1703.07339,2025-03-24,"Stochastic control on the half-line and applications to the optimal
  dividend/consumption problem","  We consider a stochastic control problem with the assumption that the system
is controlled until the state process breaks the fixed barrier. Assuming some
general conditions, it is proved that the resulting Hamilton Jacobi Bellman
equations has smooth solution. The aforementioned result is used to solve the
optimal dividend and consumption problem. In the proof we use a fixed point
type argument, with an operator which is based on the stochastic representation
for a linear equation.
"
1703.09667,2017-04-18,Biased Risk Parity with Fractal Model of Risk,"  For the past two decades investors have observed long memory and highly
correlated behavior of asset classes that does not fit into the framework of
Modern Portfolio Theory. Custom correlation and standard deviation estimators
consider normal distribution of returns and market efficiency hypothesis. It
forced investors to search more universal instruments of tail risk protection.
One of the possible solutions is a naive risk parity strategy, which avoids
estimation of expected returns and correlations. The authors develop the idea
further and propose a fractal distribution of returns as a core. This class of
distributions is more general as it does not imply strict limitations on risk
evolution. The proposed model allows for modifying a rule for volatility
estimation, thus, enhancing its explanatory power. It turns out that the latter
improves the performance metrics of an investment portfolio over the ten year
period. The fractal model of volatility plays a significant protective role
during the periods of market abnormal drawdowns. Consequently, it may be useful
for a wide range of asset managers which incorporate innovative risk models
into globally allocated portfolios.
"
1704.00416,2019-07-11,"Skewed target range strategy for multiperiod portfolio optimization
  using a two-stage least squares Monte Carlo method","  In this paper, we propose a novel investment strategy for portfolio
optimization problems. The proposed strategy maximizes the expected portfolio
value bounded within a targeted range, composed of a conservative lower target
representing a need for capital protection and a desired upper target
representing an investment goal. This strategy favorably shapes the entire
probability distribution of returns, as it simultaneously seeks a desired
expected return, cuts off downside risk and implicitly caps volatility and
higher moments. To illustrate the effectiveness of this investment strategy, we
study a multiperiod portfolio optimization problem with transaction costs and
develop a two-stage regression approach that improves the classical least
squares Monte Carlo (LSMC) algorithm when dealing with difficult payoffs, such
as highly concave, abruptly changing or discontinuous functions. Our numerical
results show substantial improvements over the classical LSMC algorithm for
both the constant relative risk-aversion (CRRA) utility approach and the
proposed skewed target range strategy (STRS). Our numerical results illustrate
the ability of the STRS to contain the portfolio value within the targeted
range. When compared with the CRRA utility approach, the STRS achieves a
similar mean-variance efficient frontier while delivering a better downside
risk-return trade-off.
"
1704.01366,2017-05-19,Replica Analysis for Portfolio Optimization with Single-Factor Model,"  In this paper, we use replica analysis to investigate the influence of
correlation among the return rates of assets on the solution of the portfolio
optimization problem. We consider the behavior of the optimal solution for the
case where the return rate is described with a single-factor model and compare
the findings obtained from our proposed methods with correlated return rates
with those obtained with independent return rates. We then analytically assess
the increase in the investment risk when correlation is included. Furthermore,
we also compare our approach with analytical procedures for minimizing the
investment risk from operations research.
"
1704.02505,2017-04-11,"Good Deal Hedging and Valuation under Combined Uncertainty about Drift
  and Volatility","  We study robust notions of good-deal hedging and valuation under combined
uncertainty about the drifts and volatilities of asset prices. Good-deal bounds
are determined by a subset of risk-neutral pricing measures such that not only
opportunities for arbitrage are excluded but also deals that are too good, by
restricting instantaneous Sharpe ratios. A non-dominated multiple priors
approach to model uncertainty (ambiguity) leads to worst-case good-deal bounds.
Corresponding hedging strategies arise as minimizers of a suitable coherent
risk measure. Good-deal bounds and hedges for measurable claims are
characterized by solutions to second-order backward stochastic differential
equations whose generators are non-convex in the volatility. These hedging
strategies are robust with respect to uncertainty in the sense that their
tracking errors satisfy a supermartingale property under all a-priori valuation
measures, uniformly over all priors.
"
1704.06697,2018-10-24,Pairs Trading under Drift Uncertainty and Risk Penalization,"  In this work, we study a dynamic portfolio optimization problem related to
pairs trading, which is an investment strategy that matches a long position in
one security with a short position in another security with similar
characteristics. The relationship between pairs, called a spread, is modeled by
a Gaussian mean-reverting process whose drift rate is modulated by an
unobservable continuous-time, finite-state Markov chain. Using the classical
stochastic filtering theory, we reduce this problem with partial information to
the one with full information and solve it for the logarithmic utility
function, where the terminal wealth is penalized by the riskiness of the
portfolio according to the realized volatility of the wealth process. We
characterize optimal dollar-neutral strategies as well as optimal value
functions under full and partial information and show that the certainty
equivalence principle holds for the optimal portfolio strategy. Finally, we
provide a numerical analysis for a toy example with a two-state Markov chain.
"
1704.08234,2017-04-27,"Optimal excess-of-loss reinsurance and investment problem for an insurer
  with default risk under a stochastic volatility model","  In this paper, we study an optimal excess-of-loss reinsurance and investment
problem for an insurer in defaultable market. The insurer can buy reinsurance
and invest in the following securities: a bank account, a risky asset with
stochastic volatility and a defaultable corporate bond. We discuss the optimal
investment strategy into two subproblems: a pre-default case and a post-default
case. We show the existence of a classical solution to a pre-default case via
super-sub solution techniques and give an explicit characterization of the
optimal reinsurance and investment policies that maximize the expected CARA
utility of the terminal wealth. We prove a verification theorem establishing
the uniqueness of the solution. Numerical results are presented in the case of
the Scott model and we discuss economic insights obtained from these results.
"
1705.00109,2017-05-02,Multi-Period Trading via Convex Optimization,"  We consider a basic model of multi-period trading, which can be used to
evaluate the performance of a trading strategy. We describe a framework for
single-period optimization, where the trades in each period are found by
solving a convex optimization problem that trades off expected return, risk,
transaction cost and holding cost such as the borrowing cost for shorting
assets. We then describe a multi-period version of the trading method, where
optimization is used to plan a sequence of trades, with only the first one
executed, using estimates of future quantities that are unknown when the trades
are chosen. The single-period method traces back to Markowitz; the multi-period
methods trace back to model predictive control. Our contribution is to describe
the single-period and multi-period methods in one simple framework, giving a
clear description of the development and the approximations made. In this paper
we do not address a critical component in a trading algorithm, the predictions
or forecasts of future quantities. The methods we describe in this paper can be
thought of as good ways to exploit predictions, no matter how they are made. We
have also developed a companion open-source software library that implements
many of the ideas and methods described in the paper.
"
1705.00543,2017-05-02,Are target date funds dinosaurs? Failure to adapt can lead to extinction,"  Investors in Target Date Funds are automatically switched from high risk to
low risk assets as their retirements approach. Such funds have become very
popular, but our analysis brings into question the rationale for them. Based on
both a model with parameters fitted to historical returns and on bootstrap
resampling, we find that adaptive investment strategies significantly
outperform typical Target Date Fund strategies. This suggests that the vast
majority of Target Date Funds are serving investors poorly.
"
1705.00672,2020-04-15,Portfolio Choice with Small Temporary and Transient Price Impact,"  We study portfolio selection in a model with both temporary and transient
price impact introduced by Garleanu and Pedersen (2016). In the large-liquidity
limit where both frictions are small, we derive explicit formulas for the
asymptotically optimal trading rate and the corresponding minimal leading-order
performance loss. We find that the losses are governed by the volatility of the
frictionless target strategy, like in models with only temporary price impact.
In contrast, the corresponding optimal portfolio not only tracks the
frictionless optimizer, but also exploits the displacement of the market price
from its unaffected level.
"
1705.01407,2024-05-29,Sparse Portfolio selection via Bayesian Multiple testing,"  We presented Bayesian portfolio selection strategy, via the $k$ factor asset
pricing model. If the market is information efficient, the proposed strategy
will mimic the market; otherwise, the strategy will outperform the market. The
strategy depends on the selection of a portfolio via Bayesian multiple testing
methodologies. We present the ""discrete-mixture prior"" model and the
""hierarchical Bayes model with horseshoe prior."" We define the Oracle set and
prove that asymptotically the Bayes rule attains the risk of Bayes Oracle up to
$O(1)$. Our proposed Bayes Oracle test guarantees statistical power by
providing the upper bound of the type-II error. Simulation study indicates that
the proposed Bayes oracle test is suitable for the efficient market with few
stocks inefficiently priced. However, as the model becomes dense, i.e., the
market is highly inefficient, one should not use the Bayes oracle test. The
statistical power of the Bayes Oracle portfolio is uniformly better for the
$k$-factor model ($k>1$) than the one factor CAPM. We present the empirical
study, where we considered the 500 constituent stocks of S\&P 500 from the New
York Stock Exchange (NYSE), and S\&P 500 index as the benchmark for thirteen
years from the year 2006 to 2018. We showed the out-sample risk and return
performance of the four different portfolio selection strategies and compared
with the S\&P 500 index as the benchmark market index. Empirical results
indicate that it is possible to propose a strategy which can outperform the
market.
"
1705.03929,2017-05-12,Investing for the Long Run,"  This paper studies long term investing by an investor that maximizes either
expected utility from terminal wealth or from consumption. We introduce the
concepts of a generalized stochastic discount factor (SDF) and of the minimum
price to attain target payouts. The paper finds that the dynamics of the SDF
needs to be captured and not the entire market dynamics, which simplifies
significantly practical implementations of optimal portfolio strategies. We pay
particular attention to the case where the SDF is equal to the inverse of the
growth-optimal portfolio in the given market. Then, optimal wealth evolution is
closely linked to the growth optimal portfolio. In particular, our concepts
allow us to reconcile utility optimization with the practitioner approach of
growth investing. We illustrate empirically that our new framework leads to
improved lifetime consumption-portfolio choice and asset allocation strategies.
"
1705.05666,2018-07-03,Minimum R\'enyi Entropy Portfolios,"  Accounting for the non-normality of asset returns remains challenging in
robust portfolio optimization. In this article, we tackle this problem by
assessing the risk of the portfolio through the ""amount of randomness"" conveyed
by its returns. We achieve this by using an objective function that relies on
the exponential of R\'enyi entropy, an information-theoretic criterion that
precisely quantifies the uncertainty embedded in a distribution, accounting for
higher-order moments. Compared to Shannon entropy, R\'enyi entropy features a
parameter that can be tuned to play around the notion of uncertainty. A
Gram-Charlier expansion shows that it controls the relative contributions of
the central (variance) and tail (kurtosis) parts of the distribution in the
measure. We further rely on a non-parametric estimator of the exponential
R\'enyi entropy that extends a robust sample-spacings estimator initially
designed for Shannon entropy. A portfolio selection application illustrates
that minimizing R\'enyi entropy yields portfolios that outperform
state-of-the-art minimum variance portfolios in terms of risk-return-turnover
trade-off.
"
1705.06533,2023-04-19,"Bayesian Inference of the Multi-Period Optimal Portfolio for an
  Exponential Utility","  We consider the estimation of the multi-period optimal portfolio obtained by
maximizing an exponential utility. Employing Jeffreys' non-informative prior
and the conjugate informative prior, we derive stochastic representations for
the optimal portfolio weights at each time point of portfolio reallocation.
This provides a direct access not only to the posterior distribution of the
portfolio weights but also to their point estimates together with uncertainties
and their asymptotic distributions. Furthermore, we present the posterior
predictive distribution for the investor's wealth at each time point of the
investment period in terms of a stochastic representation for the future wealth
realization. This in turn makes it possible to use quantile-based risk measures
or to calculate the probability of default. We apply the suggested Bayesian
approach to assess the uncertainty in the multi-period optimal portfolio by
considering assets from the FTSE 100 in the weeks after the British referendum
to leave the European Union. The behaviour of the novel portfolio estimation
method in a precarious market situation is illustrated by calculating the
predictive wealth, the risk associated with the holding portfolio, and the
default probability in each period.
"
1705.07472,2017-05-23,On the Black's equation for the risk tolerance function,"  We analyze a nonlinear equation proposed by F. Black (1968) for the optimal
portfolio function in a log-normal model. We cast it in terms of the risk
tolerance function and provide, for general utility functions, existence,
uniqueness and regularity results, and we also examine various monotonicity,
concavity/convexity and S-shape properties. Stronger results are derived for
utilities whose inverse marginal belongs to a class of completely monotonic
functions.
"
1705.08022,2017-05-24,"Using Macroeconomic Forecasts to Improve Mean Reverting Trading
  Strategies","  A large class of trading strategies focus on opportunities offered by the
yield curve. In particular, a set of yield curve trading strategies are based
on the view that the yield curve mean-reverts. Based on these strategies'
positive performance, a multiple pairs trading strategy on major currency pairs
was implemented. To improve the algorithm's performance, machine learning
forecasts of a series of pertinent macroeconomic variables were factored in, by
optimizing the weights of the trading signals. This resulted in a clear
improvement in the APR over the evaluation period, demonstrating that
macroeconomic indicators, not only technical indicators, should be considered
in trading strategies.
"
1705.08291,2017-05-24,"Sensitivity analysis of the utility maximization problem with respect to
  model perturbations","  We study the sensitivity of the expected utility maximization problem in a
continuous semi-martingale market with respect to small changes in the market
price of risk. Assuming that the preferences of a rational economic agent are
modeled with a general utility function, we obtain a second-order expansion of
the value function, a first-order approximation of the terminal wealth, and
construct trading strategies that match the indirect utility function up to the
second order. If a risk-tolerance wealth process exists, using it as a
num\'eraire and under an appropriate change of measure, we reduce the
approximation problem to a Kunita-Watanabe decomposition.
"
1705.10454,2017-05-31,Dynamic Index Tracking and Risk Exposure Control Using Derivatives,"  We develop a methodology for index tracking and risk exposure control using
financial derivatives. Under a continuous-time diffusion framework for price
evolution, we present a pathwise approach to construct dynamic portfolios of
derivatives in order to gain exposure to an index and/or market factors that
may be not directly tradable. Among our results, we establish a general
tracking condition that relates the portfolio drift to the desired exposure
coefficients under any given model. We also derive a slippage process that
reveals how the portfolio return deviates from the targeted return. In our
multi-factor setting, the portfolio's realized slippage depends not only on the
realized variance of the index, but also the realized covariance among the
index and factors. We implement our trading strategies under a number of
models, and compare the tracking strategies and performances when using
different derivatives, such as futures and options.
"
1706.01562,2017-06-07,Pricing Asian options for NIG and VG Levy markets,"  In this work, we study the value of an Asian option in the case of
exponential Levy markets. More specifically, we are interested in the NIG
(normal inverse Gaussian) the VG (variance gamma) models. The exponential Levy
models produce incomplete markets. There are therefore an infinite number of
equivalent martingale measures. We are interested in two methods of
constructing of the risk-neutral measures. The first is based on the Esscher
transform, and the other consists of bringing a risk-neutral correction on the
dynamics of the trajectories. It turns out, according to the numerical results
obtained, that the two methods generally produce the same prices.
"
1706.03139,2018-02-12,"Optimal Portfolio under Fast Mean-reverting Fractional Stochastic
  Environment","  Empirical studies indicate the existence of long range dependence in the
volatility of the underlying asset. This feature can be captured by modeling
its return and volatility using functions of a stationary fractional
Ornstein--Uhlenbeck (fOU) process with Hurst index $H \in (\frac{1}{2}, 1)$. In
this paper, we analyze the nonlinear optimal portfolio allocation problem under
this model and in the regime where the fOU process is fast mean-reverting. We
first consider the case of power utility, and rigorously give first order
approximations of the value and the optimal strategy by a martingale distortion
transformation. We also establish the asymptotic optimality in all admissible
controls of a zeroth order trading strategy. Then, we extend the discussions to
general utility functions using the epsilon-martingale decomposition technique,
and we obtain similar asymptotic optimality results within a specific family of
admissible strategies.
"
1706.06832,2017-06-22,Market Efficiency and Growth Optimal Portfolio,"  The paper predicts an Efficient Market Property for the equity market, where
stocks, when denominated in units of the growth optimal portfolio (GP), have
zero instantaneous expected returns. Well-diversified equity portfolios are
shown to approximate the GP, which explains the well-observed good performance
of equally weighted portfolios. The proposed hierarchically weighted index
(HWI) is shown to be an even better proxy of the GP. It sets weights equal
within industrial and geographical groupings of stocks. When using the HWI as
proxy of the GP the Efficient Market Property cannot be easily rejected and
appears to be very robust.
"
1706.07021,2017-06-22,"Stop-loss and Leverage in optimal Statistical Arbitrage with an
  application to Energy market","  In this paper we develop a statistical arbitrage trading strategy with two
key elements in hi-frequency trading: stop-loss and leverage. We consider, as
in Bertram (2009), a mean-reverting process for the security price with
proportional transaction costs; we show how to introduce stop-loss and leverage
in an optimal trading strategy.
  We focus on repeated strategies using a self-financing portfolio. For every
given stop-loss level we derive analytically the optimal investment strategy
consisting of optimal leverage and market entry/exit levels.
  First we show that the optimal strategy a' la Bertram depends on the
probabilities to reach entry/exit levels, on expected First-Passage-Times and
on expected First-Exit-Times from an interval. Then, when the underlying
log-price follows an Ornstein-Uhlenbeck process, we deduce analytical
expressions for expected First-Exit-Times and we derive the long-run return of
the strategy as an elementary function of the stop-loss.
  Following industry practice of pairs trading we consider an example of pair
in the energy futures' market, reporting in detail the analysis for a spread on
Heating-Oil and Gas-Oil futures in one year sample of half-an-hour market
prices.
"
1706.10059,2017-07-18,"A Deep Reinforcement Learning Framework for the Financial Portfolio
  Management Problem","  Financial portfolio management is the process of constant redistribution of a
fund into different financial products. This paper presents a
financial-model-free Reinforcement Learning framework to provide a deep machine
learning solution to the portfolio management problem. The framework consists
of the Ensemble of Identical Independent Evaluators (EIIE) topology, a
Portfolio-Vector Memory (PVM), an Online Stochastic Batch Learning (OSBL)
scheme, and a fully exploiting and explicit reward function. This framework is
realized in three instants in this work with a Convolutional Neural Network
(CNN), a basic Recurrent Neural Network (RNN), and a Long Short-Term Memory
(LSTM). They are, along with a number of recently reviewed or published
portfolio-selection strategies, examined in three back-test experiments with a
trading period of 30 minutes in a cryptocurrency market. Cryptocurrencies are
electronic and decentralized alternatives to government-issued money, with
Bitcoin as the best-known example of a cryptocurrency. All three instances of
the framework monopolize the top three positions in all experiments,
outdistancing other compared trading algorithms. Although with a high
commission rate of 0.25% in the backtests, the framework is able to achieve at
least 4-fold returns in 50 days.
"
1706.10180,2017-07-25,Regret-based Selection for Sparse Dynamic Portfolios,"  This paper considers portfolio construction in a dynamic setting. We specify
a loss function comprised of utility and complexity components with an unknown
tradeoff parameter. We develop a novel regret-based criterion for selecting the
tradeoff parameter to construct optimal sparse portfolios over time.
"
1707.00203,2017-07-04,"Foreign exchange market modelling and an on-line portfolio selection
  algorithm","  In this paper, we introduce a matrix-valued time series model for foreign
exchange market. We then formulate trading matrices, foreign exchange options
and return options (matrices), as well as on-line portfolio strategies.
Moreover, we attempt to predict returns of portfolios by developing a cross
rate method. This leads us to construct an on-line portfolio selection
algorithm for this model. At the end, we prove the profitability and the
universality of our algorithm.
"
1707.01457,2017-07-24,You are in a drawdown. When should you start worrying?,"  Trading strategies that were profitable in the past often degrade with time.
Since unlucky streaks can also hit ""healthy"" strategies, how can one detect
that something truly worrying is happening? It is intuitive that a drawdown
that lasts too long or one that is too deep should lead to a downward revision
of the assumed Sharpe ratio of the strategy. In this note, we give a
quantitative answer to this question based on the exact probability
distributions for the length and depth of the last drawdown for upward drifting
Brownian motions. We also point out that both managers and investors tend to
underestimate the length and depth of drawdowns consistent with the Sharpe
ratio of the underlying strategy.
"
1707.02087,2017-07-10,"Model for Constructing an Options Portfolio with a Certain Payoff
  Function","  The portfolio optimization problem is a basic problem of financial analysis.
In the study, an optimization model for constructing an options portfolio with
a certain payoff function has been proposed. The model is formulated as an
integer linear programming problem and includes an objective payoff function
and a system of constraints. In order to demonstrate the performance of the
proposed model, we have constructed the portfolio on the European call and put
options of Taiwan Futures Exchange. The optimum solution was obtained using the
MATLAB software. Our approach is quite general and has the potential to design
options portfolios on financial markets.
"
1707.03588,2018-09-11,On Markowitz Geometry,"  By Markowitz geometry we mean the intersection theory of ellipsoids and
affine subspaces in a real finite-dimensional linear space. In the paper we
give a meticulous and self-contained treatment of this arch-classical subject,
which lays a solid mathematical groundwork of Markowitz mean-variance theory of
efficient portfolios in economics.
"
1707.07284,2018-05-25,"Optimal Trade Execution Under Endogenous Pressure to Liquidate: Theory
  and Numerical Solutions","  We study optimal liquidation of a trading position (so-called block order or
meta-order) in a market with a linear temporary price impact (Kyle, 1985). We
endogenize the pressure to liquidate by introducing a downward drift in the
unaffected asset price while simultaneously ruling out short sales. In this
setting the liquidation time horizon becomes a stopping time determined
endogenously, as part of the optimal strategy. We find that the optimal
liquidation strategy is consistent with the square-root law which states that
the average price impact per share is proportional to the square root of the
size of the meta-order (Bershova and Rakhlin, 2013; Farmer et al., 2013; Donier
et al., 2015; T\'oth et al., 2016).
  Mathematically, the Hamilton-Jacobi-Bellman equation of our optimization
leads to a severely singular and numerically unstable ordinary differential
equation initial value problem. We provide careful analysis of related singular
mixed boundary value problems and devise a numerically stable computation
strategy by re-introducing time dimension into an otherwise time-homogeneous
task.
"
1707.07977,2017-07-26,Ether: Bitcoin's competitor or ally?,"  Although Bitcoin has long been dominant in the crypto scene, it is certainly
not alone. Ether is another cryptocurrency related project that has attracted
an intensive attention because of its additional features. This study seeks to
test whether these cryptocurrencies differ in terms of their volatile and
speculative behaviors, hedge, safe haven and risk diversification properties.
Using different econometric techniques, we show that a) Bitcoin and Ether are
volatile and relatively more responsive to bad news, but the volatility of
Ether is more persistent than that of Bitcoin; b) for both cryptocurrencies,
the exuberance and the collapse of bubbles were identified, but Bitcoin appears
more speculative than Ether; c) there is negative and significant correlation
between Bitcoin/Ether and other assets (S\&P500 stocks, US bonds, oil), which
would indicate that digital currencies can hedge against the price movements of
these assets; d) there is negative tail independence between Bitcoin/Ether and
other financial assets, implying that these cryptocurrencies exhibit the
function of a weak safe haven; and e) The inclusion of Bitcoin/ Ether in a
portfolio improve its efficiency in terms of higher reward-to-risk ratios. But
investors who hold diversified portfolios made of stocks or bonds and Ether may
face losses over bearish regime. In such situation, stock and bond investors
may take a short position on Bitcoin.
"
1707.08464,2018-04-06,Equilibrium Returns with Transaction Costs,"  We study how trading costs are reflected in equilibrium returns. To this end,
we develop a tractable continuous-time risk-sharing model, where heterogeneous
mean-variance investors trade subject to a quadratic transaction cost. The
corresponding equilibrium is characterized as the unique solution of a system
of coupled but linear forward-backward stochastic differential equations.
Explicit solutions are obtained in a number of concrete settings. The
sluggishness of the frictional portfolios makes the corresponding equilibrium
returns mean-reverting. Compared to the frictionless case, expected returns are
higher if the more risk-averse agents are net sellers or if the asset supply
expands over time.
"
1708.00644,2017-08-24,"The ""Size Premium"" in Equity Markets: Where is the Risk?","  We find that when measured in terms of dollar-turnover, and once
$\beta$-neutralised and Low-Vol neutralised, the Size Effect is alive and well.
With a long term t-stat of $5.1$, the ""Cold-Minus-Hot"" (CMH) anomaly is
certainly not less significant than other well-known factors such as Value or
Quality. As compared to market-cap based SMB, CMH portfolios are much less
anti-correlated to the Low-Vol anomaly. In contrast with standard risk premia,
size-based portfolios are found to be virtually unskewed. In fact, the extreme
risk of these portfolios is dominated by the large cap leg; small caps actually
have a positive (rather than negative) skewness. The only argument that favours
a risk premium interpretation at the individual stock level is that the extreme
drawdowns are more frequent for small cap/turnover stocks, even after
accounting for volatility. This idiosyncratic risk is however clearly
diversifiable.
"
1708.02424,2020-03-19,Cardinality constrained portfolio selection via factor models,"  In this paper we propose and discuss different 0-1 linear models in order to
solve the cardinality constrained portfolio problem by using factor models.
Factor models are used to build portfolios to track indexes, together with
other objectives, also need a smaller number of parameters to estimate than the
classical Markowitz model. The addition of the cardinality constraints limits
the number of securities in the portfolio. Restricting the number of securities
in the portfolio allows us to obtain a concentrated portfolio, reduce the risk
and limit transaction costs. To solve this problem, a pure 0-1 model is
presented in this work, the 0-1 model is constructed by means of a piecewise
linear approximation. We also present a new quadratic combinatorial problem,
called a minimum edge-weighted clique problem, to obtain an equality weighted
cardinality constrained portfolio. A piecewise linear approximation for this
problem is presented in the context of a multi factor model. For a single
factor model, we present a fast heuristic, based on some theoretical results to
obtain an equality weighted cardinality constraint portfolio. The consideration
of a piecewise linear approximation allow us to reduce significantly the
computation time required for the equivalent quadratic problem. Computational
results from the 0-1 models are compared to those using a state-of-the-art
Quadratic MIP solver.
"
1708.02984,2018-02-12,Decoding Stock Market with Quant Alphas,"  We give an explicit algorithm and source code for extracting expected returns
for stocks from expected returns for alphas. Our algorithm altogether bypasses
combining alphas with weights into ""alpha combos"". Simply put, we have
developed a new method for trading alphas which does not involve combining
them. This yields substantial cost savings as alpha combos cost hedge funds
around 3% of the P&L, while alphas themselves cost around 10%. Also, the extra
layer of alpha combos, which our new method avoids, adds noise and
suboptimality. We also arrive at our algorithm independently by explicitly
constructing alpha risk models based on position data.
"
1708.05713,2020-04-17,Portfolio Optimization with Entropic Value-at-Risk,"  The entropic value-at-risk (EVaR) is a new coherent risk measure, which is an
upper bound for both the value-at-risk (VaR) and conditional value-at-risk
(CVaR). As important properties, the EVaR is strongly monotone over its domain
and strictly monotone over a broad sub-domain including all continuous
distributions, while well-known monotone risk measures, such as VaR and CVaR
lack these properties. A key feature for a risk measure, besides its financial
properties, is its applicability in large-scale sample-based portfolio
optimization. If the negative return of an investment portfolio is a
differentiable convex function, the portfolio optimization with the EVaR
results in a differentiable convex program whose number of variables and
constraints is independent of the sample size, which is not the case for the
VaR and CVaR. This enables us to design an efficient algorithm using
differentiable convex optimization. Our extensive numerical study shows the
high efficiency of the algorithm in large scales, compared to the existing
convex optimization software packages. The computational efficiency of the EVaR
portfolio optimization approach is also compared with that of CVaR-based
portfolio optimization. This comparison shows that the EVaR approach generally
performs similarly, and it outperforms as the sample size increases. Moreover,
the comparison of the portfolios obtained for a real case by the EVaR and CVaR
approaches shows that the EVaR approach can find portfolios with better
expectations and VaR values at high confidence levels.
"
1708.07567,2017-08-28,Active Preference Learning for Personalized Portfolio Construction,"  In financial asset management, choosing a portfolio requires balancing
returns, risk, exposure, liquidity, volatility and other factors. These
concerns are difficult to compare explicitly, with many asset managers using an
intuitive or implicit sense of their interaction. We propose a mechanism for
learning someone's sense of distinctness between portfolios with the goal of
being able to identify portfolios which are predicted to perform well but are
distinct from the perspective of the user. This identification occurs, e.g., in
the context of Bayesian optimization of a backtested performance metric.
Numerical experiments are presented which show the impact of personal beliefs
in informing the development of a diverse and high-performing portfolio.
"
1708.07637,2017-08-28,Trends and Risk Premia: Update and Additional Plots,"  Recently, our group has published two papers that have received some
attention in the finance community. One is about the profitability of trend
following strategies over 200 years, the second is about the correlation
between the profitability of ""Risk Premia"" and their skewness. In this short
note, we present two additional plots that fully corroborate our findings on
new data.
"
1709.03226,2017-09-12,"Predictive Modeling: An Optimized and Dynamic Solution Framework for
  Systematic Value Investing","  This paper defines systematic value investing as an empirical optimization
problem. Predictive modeling is introduced as a systematic value investing
methodology with dynamic and optimization features. A predictive modeling
process is demonstrated using financial metrics from Gray & Carlisle and
Buffett & Clark. A 31-year portfolio backtest (1985 - 2016) compares
performance between predictive models and Gray & Carlisle's Quantitative Value
strategy. A 26-year portfolio backtest (1990 - 2016) uses an expanded set of
predictor variables to show financial performance improvements. This paper
includes secondary novel contributions. Quantitative definitions are provided
for Buffett & Clark's value investing metrics. The ""Sak ratio"" is proposed as
an extension to the Benjamini-Hochberg procedure for the inferential
identification of false positive observations.
"
1709.04387,2017-09-14,"Welfare effects of information and rationality in portfolio decisions
  under parameter uncertainty","  We analyze and quantify, in a financial market with parameter uncertainty and
for a Constant Relative Risk Aversion investor, the utility effects of two
different boundedly rational (i.e., sub-optimal) investment strategies (namely,
myopic and unconditional strategies) and compare them between each other and
with the utility effect of full information. We show that effects are mainly
caused by full information and predictability, being the effect of learning
marginal. We also investigate the saver's decision of whether to manage her/his
portfolio personally (DIY investor) or hire, against the payment of a
management fee, a professional investor and find that delegation is mainly
motivated by the belief that professional advisors are, depending on investment
horizon and risk aversion, either better informed (""insiders"") or more capable
of gathering and processing information rather than their ability of learning
from financial data. In particular, for very short investment horizons,
delegation is primarily, if not exclusively, motivated by the beliefs that
professional investors are better informed.
"
1709.04415,2017-09-14,"Risk-Aware Multi-Armed Bandit Problem with Application to Portfolio
  Selection","  Sequential portfolio selection has attracted increasing interests in the
machine learning and quantitative finance communities in recent years. As a
mathematical framework for reinforcement learning policies, the stochastic
multi-armed bandit problem addresses the primary difficulty in sequential
decision making under uncertainty, namely the exploration versus exploitation
dilemma, and therefore provides a natural connection to portfolio selection. In
this paper, we incorporate risk-awareness into the classic multi-armed bandit
setting and introduce an algorithm to construct portfolio. Through filtering
assets based on the topological structure of financial market and combining the
optimal multi-armed bandit policy with the minimization of a coherent risk
measure, we achieve a balance between risk and return.
"
1709.04620,2018-01-17,Random matrix approach for primal-dual portfolio optimization problems,"  In this paper, we revisit the portfolio optimization problems of the
minimization/maximization of investment risk under constraints of budget and
investment concentration (primal problem) and the maximization/minimization of
investment concentration under constraints of budget and investment risk (dual
problem) for the case that the variances of the return rates of the assets are
identical. We analyze both optimization problems by using the Lagrange
multiplier method and the random matrix approach. Thereafter, we compare the
results obtained from our proposed approach with the results obtained in
previous work. Moreover, we use numerical experiments to validate the results
obtained from the replica approach and the random matrix approach as methods
for analyzing both the primal and dual portfolio optimization problems.
"
1709.05529,2017-09-19,"Explicit Solution for Constrained Stochastic Linear-Quadratic Control
  with Multiplicative Noise","  We study in this paper a class of constrained linear-quadratic (LQ) optimal
control problem formulations for the scalar-state stochastic system with
multiplicative noise, which has various applications, especially in the
financial risk management. The linear constraint on both the control and state
variables considered in our model destroys the elegant structure of the
conventional LQ formulation and has blocked the derivation of an explicit
control policy so far in the literature. We successfully derive in this paper
the analytical control policy for such a class of problems by utilizing the
state separation property induced from its structure. We reveal that the
optimal control policy is a piece-wise affine function of the state and can be
computed off-line efficiently by solving two coupled Riccati equations. Under
some mild conditions, we also obtain the stationary control policy for infinite
time horizon. We demonstrate the implementation of our method via some
illustrative examples and show how to calibrate our model to solve dynamic
constrained portfolio optimization problems.
"
1709.06296,2020-03-26,"Large-Scale Portfolio Allocation Under Transaction Costs and Model
  Uncertainty","  We theoretically and empirically study portfolio optimization under
transaction costs and establish a link between turnover penalization and
covariance shrinkage with the penalization governed by transaction costs. We
show how the ex ante incorporation of transaction costs shifts optimal
portfolios towards regularized versions of efficient allocations. The
regulatory effect of transaction costs is studied in an econometric setting
incorporating parameter uncertainty and optimally combining predictive
distributions resulting from high-frequency and low-frequency data. In an
extensive empirical study, we illustrate that turnover penalization is more
effective than commonly employed shrinkage methods and is crucial in order to
construct empirically well-performing portfolios.
"
1709.06641,2018-02-27,Dead Alphas as Risk Factors,"  We give an explicit algorithm and source code for extracting equity risk
factors from dead (a.k.a. ""flatlined"" or ""hockey-stick"") alphas and using them
to improve performance characteristics of good (tradable) alphas. In a
nutshell, we use dead alphas to extract directions in the space of stock
returns along which there is no money to be made (and/or those bets are too
volatile). In practice the number of dead alphas can be large compared with the
number of underlying stocks and care is required in identifying the aforesaid
directions.
"
1709.07527,2018-08-03,"A posteriori multi-stage optimal trading under transaction costs and a
  diversification constraint","  This paper presents a simple method for a posteriori (historical)
multi-variate multi-stage optimal trading under transaction costs and a
diversification constraint. Starting from a given amount of money in some
currency, we analyze the stage-wise optimal allocation over a time horizon with
potential investments in multiple currencies and various assets. Three variants
are discussed, including unconstrained trading frequency, a fixed number of
total admissable trades, and the waiting of a specific time-period after every
executed trade until the next trade. The developed methods are based on
efficient graph generation and consequent graph search, and are evaluated
quantitatively on real-world data. The fundamental motivation of this work is
preparatory labeling of financial time-series data for supervised machine
learning.
"
1709.08755,2018-07-16,Analytic approach to variance optimization under an $\ell_1$ constraint,"  The optimization of the variance supplemented by a budget constraint and an
asymmetric $\ell_1$ regularizer is carried out analytically by the replica
method borrowed from the theory of disordered systems. The asymmetric
regularizer allows us to penalize short and long positions differently, so the
present treatment includes the no-short-constrained portfolio optimization
problem as a special case. Results are presented for the out-of-sample and the
in-sample estimator of the regularized variance, the relative estimation error,
the density of the assets eliminated from the portfolio by the regularizer, and
the distribution of the optimal portfolio weights. We have studied the
dependence of these quantities on the ratio $r$ of the portfolio's dimension
$N$ to the sample size $T$, and on the strength of the regularizer. We have
checked the analytic results by numerical simulations, and found general
agreement. Regularization extends the interval where the optimization can be
carried out, and suppresses the large sample fluctuations, but the performance
of $\ell_1$ regularization is rather disappointing: if the sample size is large
relative to the dimension, i.e. $r$ is small, the regularizer does not play any
role, while for $r$'s where the regularizer starts to be felt the estimation
error is already so large as to make the whole optimization exercise pointless.
We find that the $\ell_1$ regularization can eliminate at most half the assets
from the portfolio, corresponding to this there is a critical ratio $r=2$
beyond which the $\ell_1$ regularized variance cannot be optimized: the
regularized variance becomes constant over the simplex. These facts do not seem
to have been noticed in the literature.
"
1709.09822,2018-08-03,"Threshold-Based Portfolio: The Role of the Threshold and Its
  Applications","  This paper aims at developing a new method by which to build a data-driven
portfolio featuring a target risk-return. We first present a comparative study
of recurrent neural network models (RNNs), including a simple RNN, long
short-term memory (LSTM), and gated recurrent unit (GRU) for selecting the best
predictor to use in portfolio construction. The models are applied to the
investment universe consisted of ten stocks in the S&P500. The experimental
results shows that LSTM outperforms the others in terms of hit ratio of
one-month-ahead forecasts. We then build predictive threshold-based portfolios
(TBPs) that are subsets of the universe satisfying given threshold criteria for
the predicted returns. The TBPs are rebalanced monthly to restore equal weights
to each security within the TBPs. We find that the risk and return profile of
the realized TBP represents a monotonically increasing frontier on the
risk-return plane, where the equally weighted portfolio (EWP) of all ten stocks
plays a role in their lower bound. This shows the availability of TBPs in
targeting specific risk-return levels, and an EWP based on all the assets plays
a role in the reference portfolio of TBPs. In the process, thresholds play
dominant roles in characterizing risk, return, and the prediction accuracy of
the subset. The TBP is more data-driven in designing portfolio target risk and
return than existing ones, in the sense that it requires no prior knowledge of
finance such as financial assumptions, financial mathematics, or expert
insights. In a practical application, we present the TBP management procedure
for a time horizon extending over multiple time periods; we also discuss their
application to mean-variance portfolios to reduce estimation risk.
"
1710.00431,2018-02-20,Kelly's Criterion in Portfolio Optimization: A Decoupled Problem,"  Kelly's Criterion is well known among gamblers and investors as a method for
maximizing the returns one would expect to observe over long periods of betting
or investing. These ideas are conspicuously absent from portfolio optimization
problems in the financial and automation literature. This paper will show how
Kelly's Criterion can be incorporated into standard portfolio optimization
models. The model developed here combines risk and return into a single
objective function by incorporating a risk parameter. This model is then solved
for a portfolio of 10 stocks from a major stock exchange using a differential
evolution algorithm. Monte Carlo calculations are used to verify the accuracy
of the results obtained from differential evolution. The results show that
evolutionary algorithms can be successfully applied to solve a portfolio
optimization problem where returns are calculated by applying Kelly's Criterion
to each of the assets in the portfolio.
"
1710.01503,2017-10-20,On Drawdown-Modulated Feedback Control in Stock Trading,"  Control of drawdown, that is, the control of the drops in wealth over time
from peaks to subsequent lows, is of great concern from a risk management
perspective. With this motivation in mind, the focal point of this paper is to
address the drawdown issue in a stock trading context. Although our analysis
can be carried out without reference to control theory, to make the work
accessible to this community, we use the language of feedback systems. The
takeoff point for the results to follow, which we call the Drawdown Modulation
Lemma, characterizes any investment which guarantees that the percentage
drawdown is no greater than a prespecified level with probability one. With the
aid of this lemma, we introduce a new scheme which we call the
drawdown-modulated feedback control. To illustrate the power of the theory, we
consider a drawdown-constrained version of the well-known Kelly Optimization
Problem which involves maximizing the expected logarithmic growth of the
trader's account value. As the drawdown parameter dmax in our new formulation
tends to one, we recover existing results as a special case. This new theory
leads to an optimal investment strategy whose application is illustrated via an
example with historical stock-price data.
"
1710.01786,2017-10-06,Kelly Betting Can Be Too Conservative,"  Kelly betting is a prescription for optimal resource allocation among a set
of gambles which are typically repeated in an independent and identically
distributed manner. In this setting, there is a large body of literature which
includes arguments that the theory often leads to bets which are ""too
aggressive"" with respect to various risk metrics. To remedy this problem, many
papers include prescriptions for scaling down the bet size. Such schemes are
referred to as Fractional Kelly Betting. In this paper, we take the opposite
tack. That is, we show that in many cases, the theoretical Kelly-based results
may lead to bets which are ""too conservative"" rather than too aggressive. To
make this argument, we consider a random vector X with its assumed probability
distribution and draw m samples to obtain an empirically-derived counterpart
Xhat. Subsequently, we derive and compare the resulting Kelly bets for both X
and Xhat with consideration of sample size m as part of the analysis. This
leads to identification of many cases which have the following salient feature:
The resulting bet size using the true theoretical distribution for X is much
smaller than that for Xhat. If instead the bet is based on empirical data,
""golden"" opportunities are identified which are essentially rejected when the
purely theoretical model is used. To formalize these ideas, we provide a result
which we call the Restricted Betting Theorem. An extreme case of the theorem is
obtained when X has unbounded support. In this situation, using X, the Kelly
theory can lead to no betting at all.
"
1710.01787,2017-10-06,On Kelly Betting: Some Limitations,"  The focal point of this paper is the so-called Kelly Criterion, a
prescription for optimal resource allocation among a set of gambles which are
repeated over time. The criterion calls for maximization of the expected value
of the logarithmic growth of wealth. While significant literature exists
providing the rationale for such an optimization, this paper concentrates on
the limitations of the Kelly-based theory. To this end, we fill a void in
published results by providing specific examples quantifying what difficulties
are encountered when Taylor-style approximations are used and when wealth
drawdowns are considered. For the case of drawdown, we describe some research
directions which we feel are promising for improvement of the theory.
"
1710.02435,2021-07-30,Sparse Portfolio Selection via the sorted $\ell_{1}$-Norm,"  We introduce a financial portfolio optimization framework that allows us to
automatically select the relevant assets and estimate their weights by relying
on a sorted $\ell_1$-Norm penalization, henceforth SLOPE. Our approach is able
to group constituents with similar correlation properties, and with the same
underlying risk factor exposures. We show that by varying the intensity of the
penalty, SLOPE can span the entire set of optimal portfolios on the
risk-diversification frontier, from minimum variance to the equally weighted.
To solve the optimization problem, we develop a new efficient algorithm, based
on the Alternating Direction Method of Multipliers. Our empirical analysis
shows that SLOPE yields optimal portfolios with good out-of-sample risk and
return performance properties, by reducing the overall turnover through more
stable asset weight estimates. Moreover, using the automatic grouping property
of SLOPE, new portfolio strategies, such as SLOPE-MV, can be developed to
exploit the data-driven detected similarities across assets.
"
1710.03267,2017-10-11,"A Strategic Investment Framework for Biotechnology Markets via Dynamic
  Asset Allocation and Class Diversification","  In this paper, we propose an innovative investment framework incorporating
asset allocation and class diversification oriented specifically for the
biotechnology industry. With growing interests and capitalization in multiple
biotech markets, investors require a more dynamic method of managing their
assets within individual portfolios for optimal return efficiency. By selecting
a single firm representative of identified industry trends, analyzing financial
metrics relevant to the suggested approaches, and assessing financial health,
we developed an adaptable investment methodology. We also performed analyses of
industrial viability and investigated the implications of the selected
strategies, with which we were able to optimize our framework for versatile
application within specialized biotech markets.
"
1710.04579,2018-05-16,"A General Framework for Portfolio Theory. Part I: theory and various
  models","  Utility and risk are two often competing measurements on the investment
success. We show that efficient trade-off between these two measurements for
investment portfolios happens, in general, on a convex curve in the two
dimensional space of utility and risk. This is a rather general pattern. The
modern portfolio theory of Markowitz [H. Markowitz, Portfolio Selection, 1959]
and its natural generalization, the capital market pricing model, [W. F.
Sharpe, Mutual fund performance , 1966] are special cases of our general
framework when the risk measure is taken to be the standard deviation and the
utility function is the identity mapping. Using our general framework, we also
recover the results in [R. T. Rockafellar, S. Uryasev and M. Zabarankin, Master
funds in portfolio analysis with general deviation measures, 2006] that extends
the capital market pricing model to allow for the use of more general deviation
measures. This generalized capital asset pricing model also applies to e.g.
when an approximation of the maximum drawdown is considered as a risk measure.
Furthermore, the consideration of a general utility function allows to go
beyond the ""additive"" performance measure to a ""multiplicative"" one of
cumulative returns by using the log utility. As a result, the growth optimal
portfolio theory [J. Lintner, The valuation of risk assets and the selection of
risky investments in stock portfolios and capital budgets, 1965] and the
leverage space portfolio theory [R. Vince, The Leverage Space Trading Model,
2009] can also be understood under our general framework. Thus, this general
framework allows a unification of several important existing portfolio theories
and goes much beyond.
"
1710.04818,2017-10-16,"A General Framework for Portfolio Theory. Part II: drawdown risk
  measures","  The aim of this paper is to provide several examples of convex risk measures
necessary for the application of the general framework for portfolio theory of
Maier-Paape and Zhu, presented in Part I of this series (arXiv:1710.04579
[q-fin.PM]). As alternative to classical portfolio risk measures such as the
standard deviation we in particular construct risk measures related to the
current drawdown of the portfolio equity. Combined with the results of Part I
(arXiv:1710.04579 [q-fin.PM]), this allows us to calculate efficient portfolios
based on a drawdown risk measure constraint.
"
1710.06350,2017-10-18,Navigating dark liquidity (How Fisher catches Poisson in the Dark),"  In order to reduce signalling, traders may resort to limiting access to dark
venues and imposing limits on minimum fill sizes they are willing to trade.
However, doing this also restricts the liquidity available to the trader since
an ever increasing quantity of orders are traded by algos in clips. An
alternative is to attempt to monitor signalling in real time and dynamically
make adjustments to the dark liquidity accessed.
  In practice, price slippage against the order is commonly taken as an
indication of signalling. However, estimating slippage is difficult and
requires a large number of fills to reliably detect it. Ultimately, even if
detected, it fails to capture an important element of causality between dark
fills and lit prints - a signature of information leakage. In the extreme, this
can lead to scaling back trading at a time when slippage is caused by a
competing trader consuming liquidity, and the appropriate action would be to
scale trading up -- not down -- in order to capture good prices.
  In this paper we describe a methodology aimed to address this dichotomy of
trading objectives, allowing to maximally capture available liquidity while at
the same time protecting the trader from excessive signalling. The method is
designed to profile dark liquidity in a dynamic fashion, on a per fill basis,
in contrast to historical venue analyses based on estimated slippage. This
allows for a dynamic and real-time control of the desired liquidity exposure.
"
1711.01017,2017-11-06,"A Numerical Scheme for A Singular control problem:
  Investment-Consumption Under Proportional Transaction Costs","  This paper concerns the numerical solution of a fully nonlinear parabolic
double obstacle problem arising from a finite portfolio selection with
proportional transaction costs. We consider the optimal allocation of wealth
among multiple stocks and a bank account in order to maximize the finite
horizon discounted utility of consumption. The problem is mainly governed by a
time-dependent Hamilton-Jacobi-Bellman equation with gradient constraints. We
propose a numerical method which is composed of Monte Carlo simulation to take
advantage of the high-dimensional properties and finite difference method to
approximate the gradients of the value function. Numerical results illustrate
behaviors of the optimal trading strategies and also satisfy all qualitative
properties proved in Dai et al. (2009) and Chen and Dai (2013).
"
1711.01760,2017-11-07,"Optimal investment-consumption and life insurance selection problem
  under inflation. A BSDE approach","  We discuss an optimal investment, consumption and insurance problem of a wage
earner under inflation. Assume a wage earner investing in a real money account
and three asset prices, namely: a real zero coupon bond, the inflation-linked
real money account and a risky share described by jump-diffusion processes.
Using the theory of quadratic-exponential backward stochastic differential
equation (BSDE) with jumps approach, we derive the optimal strategy for the two
typical utilities (exponential and power) and the value function is
characterized as a solution of BSDE with jumps. Finally, we derive the explicit
solutions for the optimal investment in both cases of exponential and power
utility functions for a diffusion case.
"
1711.02939,2018-12-06,"Constrained portfolio-consumption strategies with uncertain parameters
  and borrowing costs","  This paper studies the properties of the optimal portfolio-consumption
strategies in a {finite horizon} robust utility maximization framework with
different borrowing and lending rates. In particular, we allow for constraints
on both investment and consumption strategies, and model uncertainty on both
drift and volatility. With the help of explicit solutions, we quantify the
impacts of uncertain market parameters, portfolio-consumption constraints and
borrowing costs on the optimal strategies and their time monotone properties.
"
1711.03291,2019-02-21,Portfolio Optimization and Model Predictive Control: A Kinetic Approach,"  In this paper, we introduce a large system of interacting financial agents in
which each agent is faced with the decision of how to allocate his capital
between a risky stock or a risk-less bond. The investment decision of
investors, derived through an optimization, drives the stock price. The model
has been inspired by the econophysical Levy-Levy-Solomon model (Economics
Letters, 45). The goal of this work is to gain insights into the stock price
and wealth distribution. We especially want to discover the causes for the
appearance of power-laws in financial data. We follow a kinetic approach
similar to (D. Maldarella, L. Pareschi, Physica A, 391) and derive the mean
field limit of our microscopic agent dynamics. The novelty in our approach is
that the financial agents apply model predictive control (MPC) to approximate
and solve the optimization of their utility function. Interestingly, the MPC
approach gives a mathematical connection between the two opponent economic
concepts of modeling financial agents to be rational or boundedly rational.
Furthermore, this is to our knowledge the first kinetic portfolio model which
considers a wealth and stock price distribution simultaneously. Due to our
kinetic approach, we can study the wealth and price distribution on a
mesoscopic level. The wealth distribution is characterized by a lognormal law.
For the stock price distribution, we can either observe a lognormal behavior in
the case of long-term investors or a power-law in the case of high-frequency
trader. Furthermore, the stock return data exhibits a fat-tail, which is a well
known characteristic of real financial data.
"
1711.04717,2017-11-21,Black was right: Price is within a factor 2 of Value,"  We provide further evidence that markets trend on the medium term (months)
and mean-revert on the long term (several years). Our results bolster Black's
intuition that prices tend to be off roughly by a factor of 2, and take years
to equilibrate. The story behind these results fits well with the existence of
two types of behaviour in financial markets: ""chartists"", who act as trend
followers, and ""fundamentalists"", who set in when the price is clearly out of
line. Mean-reversion is a self-correcting mechanism, tempering (albeit only
weakly) the exuberance of financial markets.
"
1711.06565,2020-05-20,Calibration of Distributionally Robust Empirical Optimization Models,"  We study the out-of-sample properties of robust empirical optimization
problems with smooth $\phi$-divergence penalties and smooth concave objective
functions, and develop a theory for data-driven calibration of the non-negative
""robustness parameter"" $\delta$ that controls the size of the deviations from
the nominal model. Building on the intuition that robust optimization reduces
the sensitivity of the expected reward to errors in the model by controlling
the spread of the reward distribution, we show that the first-order benefit of
``little bit of robustness"" (i.e., $\delta$ small, positive) is a significant
reduction in the variance of the out-of-sample reward while the corresponding
impact on the mean is almost an order of magnitude smaller. One implication is
that substantial variance (sensitivity) reduction is possible at little cost if
the robustness parameter is properly calibrated. To this end, we introduce the
notion of a robust mean-variance frontier to select the robustness parameter
and show that it can be approximated using resampling methods like the
bootstrap. Our examples show that robust solutions resulting from ""open loop""
calibration methods (e.g., selecting a $90\%$ confidence level regardless of
the data and objective function) can be very conservative out-of-sample, while
those corresponding to the robustness parameter that optimizes an estimate of
the out-of-sample expected reward (e.g., via the bootstrap) with no regard for
the variance are often insufficiently robust.
"
1711.10640,2018-04-12,Notes on Fano Ratio and Portfolio Optimization,"  We discuss - in what is intended to be a pedagogical fashion - generalized
""mean-to-risk"" ratios for portfolio optimization. The Sharpe ratio is only one
example of such generalized ""mean-to-risk"" ratios. Another example is what we
term the Fano ratio (which, unlike the Sharpe ratio, is independent of the time
horizon). Thus, for long-only portfolios optimizing the Fano ratio generally
results in a more diversified and less skewed portfolio (compared with
optimizing the Sharpe ratio). We give an explicit algorithm for such
optimization. We also discuss (Fano-ratio-inspired) long-short strategies that
outperform those based on optimizing the Sharpe ratio in our backtests.
"
1712.00463,2017-12-05,"Retirement Wealth under Fixed Limits: The Optimal Strategy for
  Exponential Utility","  For an exponential utility maximizing investment strategy in a Black-Scholes
Setting, fixed upper and lower constraints are introduced on the terminal
wealth. This is equivalent to combining the optimal strategy with options. The
resulting distribution is investigated in terms of change of quantiles. The
theory is illustrated with quantitative examples, including an assessment of
the effects of restricting the strategy to positive investments.
"
1712.00585,2017-12-05,Dynamic optimization of a portfolio,"  In this paper, we consider the problem of optimization of a portfolio
consisting of securities. An investor with an initial capital, is interested in
constructing a portfolio of securities. If the prices of securities change, the
investor shall decide on reallocation of the portfolio. At each moment of time,
the prices of securities change and the investor is interested in constructing
a dynamic portfolio of securities. The investor wishes to maximize the value of
his portfolio at the end of time $T$. We use a novel theoretical approach based
on dynamic programming to solve the age old problem of dynamic programming. We
consider two cases i.e. Deterministic and Stochastic to approach the problem
and show how the portfolio is maximized using dynamic programming.
"
1712.05031,2018-07-20,The Mathematics of Market Timing,"  Market timing is an investment technique that tries to continuously switch
investment into assets forecast to have better returns. What is the likelihood
of having a successful market timing strategy? With an emphasis on modeling
simplicity, I calculate the feasible set of market timing portfolios using
index mutual fund data for perfectly timed (by hindsight) all or nothing
quarterly switching between two asset classes, US stocks and bonds over the
time period 1993--2017. The historical optimal timing path of switches is shown
to be indistinguishable from a random sequence. The key result is that the
probability distribution function of market timing returns is asymetric, that
the highest probability outcome for market timing is a below median return. Put
another way, simple math says market timing is more likely to lose than to
win---even before accounting for costs. The median of the market timing return
probability distribution can be directly calculated as a weighted average of
the returns of the model assets with the weights given by the fraction of time
each asset has a higher return than the other. For the time period of the data
the median return was close to, but not identical with, the return of a static
60:40 stock:bond portfolio. These results are illustrated through Monte Carlo
sampling of timing paths within the feasible set and by the observed return
paths of several market timing mutual funds.
"
1712.05676,2018-10-25,"Risk Sensitive Portfolio Optimization with Default Contagion and
  Regime-Switching","  We study an open problem of risk-sensitive portfolio allocation in a
regime-switching credit market with default contagion. The state space of the
Markovian regime-switching process is assumed to be a countably infinite set.
To characterize the value function, we investigate the corresponding recursive
infinite-dimensional nonlinear dynamical programming equations (DPEs) based on
default states. We propose to work in the following procedure: Applying the
theory of monotone dynamical system, we first establish the existence and
uniqueness of classical solutions to the recursive DPEs by a truncation
argument in the finite state space. The associated optimal feedback strategy is
characterized by developing a rigorous verification theorem. Building upon
results in the first stage, we construct a sequence of approximating risk
sensitive control problems with finite states and prove that the resulting
smooth value functions will converge to the classical solution of the original
system of DPEs. The construction and approximation of the optimal feedback
strategy for the original problem are also thoroughly discussed.
"
1712.07699,2019-02-12,Robust expected utility maximization with medial limits,"  In this paper we study a robust expected utility maximization problem with
random endowment in discrete time. We give conditions under which an optimal
strategy exists and derive a dual representation for the optimal utility. Our
approach is based on a general representation result for monotone convex
functionals, a functional version of Choquet's capacitability theorem and
medial limits. The novelty is that it works under nondominated model
uncertainty without any assumptions of time-consistency. As applications, we
discuss robust utility maximization problems with moment constraints,
Wasserstein constraints and Wasserstein penalties.
"
1712.09108,2018-02-28,Non-stochastic portfolio theory,"  This paper studies a non-stochastic version of Fernholz's stochastic
portfolio theory for a simple model of stock markets with continuous price
paths. It establishes non-stochastic versions of the most basic results of
stochastic portfolio theory and discusses connections with Stroock-Varadhan
martingales.
"
1801.00980,2020-06-23,Simple Explicit Formula for Near-Optimal Stochastic Lifestyling,"  In life-cycle economics the Samuelson paradigm (Samuelson, 1969) states that
the optimal investment is in constant proportions out of lifetime wealth
composed of current savings and the present value of future income. It is well
known that in the presence of credit constraints this paradigm no longer
applies. Instead, optimal lifecycle investment gives rise to so-called
stochastic lifestyling (Cairns et al., 2006), whereby for low levels of
accumulated capital it is optimal to invest fully in stocks and then gradually
switch to safer assets as the level of savings increases. In stochastic
lifestyling not only does the ratio between risky and safe assets change but
also the mix of risky assets varies over time. While the existing literature
relies on complex numerical algorithms to quantify optimal lifestyling the
present paper provides a simple formula that captures the main essence of the
lifestyling effect with remarkable accuracy.
"
1801.04080,2018-07-31,"Optimal contracts under competition when uncertainty from adverse
  selection and moral hazard are present","  In a continuous-time setting where a risk-averse agent controls the drift of
an output process driven by a Brownian motion, optimal contracts are linear in
the terminal output; this result is well-known in a setting with moral hazard
and -under stronger assumptions - adverse selection. We show that this result
continues to hold when in addition reservation utilities are type-dependent.
This type of problem occurs in the study of optimal compensation problems
involving competing principals.
"
1801.06425,2018-01-22,Ergodic robust maximization of asymptotic growth,"  We consider the problem of robustly maximizing the growth rate of investor
wealth in the presence of model uncertainty. Possible models are all those
under which the assets' region $E$ and instantaneous covariation $c$ are known,
and where additionally the assets are stable in that their occupancy time
measures converge to a law with density $p$. This latter assumption is
motivated by the observed stability of ranked relative market capitalizations
for equity markets. We seek to identify the robust optimal growth rate, as well
as a trading strategy which achieves this rate in all models. Under minimal
assumptions upon $(E,c,p)$, we identify the robust growth rate with the
Donsker-Varadhan rate function from occupancy time Large Deviations theory. We
also prove existence of, and explicitly identify, the optimal trading strategy.
We then apply our results in the case of drift uncertainty for ranked relative
market capitalizations. Assuming regularity under symmetrization for the
covariance and limiting density of the ranked capitalizations, we explicitly
identify the robust optimal trading strategy in this setting.
"
1801.06737,2018-08-23,At What Frequency Should the Kelly Bettor Bet?,"  We study the problem of optimizing the betting frequency in a dynamic game
setting using Kelly's celebrated expected logarithmic growth criterion as the
performance metric. The game is defined by a sequence of bets with independent
and identically distributed returns X(k). The bettor selects the fraction of
wealth K wagered at k = 0 and waits n steps before updating the bet size.
Between updates, the proceeds from the previous bets remain at risk in the
spirit of ""buy and hold."" Within this context, the main questions we consider
are as follows: How does the optimal performance, we call it gn*, change with
n? Does the high-frequency case, n = 1, always lead to the best performance?
What are the effects of accrued interest and transaction costs? First, we
provide rather complete answers to these questions for the important special
case when X(k) in {-1,1} is a Bernoulli random variable with probability p that
X(k) = 1. This serves as an entry point for future research using a binomial
lattice model for stock trading. The latter sections focus on more general
probability distributions for X(k) and two conjectures. The first conjecture is
simple to state: Absent transaction costs, gn* is non-increasing in n. The
second conjecture involves the technical condition which we call the sufficient
attractiveness inequality. We first prove that satisfaction of this inequality
is sufficient to guarantee that the low-frequency bettor using large n can
match the performance of the high-frequency bettor using n = 1. Subsequently,
we conjecture, and provide supporting evidence that this condition is also
necessary.
"
1802.03322,2018-05-23,Replica Approach for Minimal Investment Risk with Cost,"  In the present work, the optimal portfolio minimizing the investment risk
with cost is discussed analytically, where this objective function is
constructed in terms of two negative aspects of investment, the risk and cost.
We note the mathematical similarity between the Hamiltonian in the
mean-variance model and the Hamiltonians in the Hopfield model and the
Sherrington{Kirkpatrick model and show that we can analyze this portfolio
optimization problem by using replica analysis, and derive the minimal
investment risk with cost and the investment concentration of the optimal
portfolio. Furthermore, we validate our proposed method through numerical
simulations.
"
1802.03376,2020-02-12,Visualizing Treasury Issuance Strategy,"  We introduce simple cost and risk proxy metrics that can be attached to
Treasury issuance strategy to complement analysis of the resulting portfolio
weighted-average maturity (WAM). These metrics are based on mapping issuance
fractions to their long-term, asymptotic portfolio implications for cost and
risk under mechanical debt-rolling dynamics. The resulting mapping enables one
to visualize tradeoffs involved in contemplated issuance reallocation, and
identify an efficient frontier and optimal tenor. Historical Treasury issuance
strategy is analyzed empirically using these cost and risk metrics to
illustrate how changes in issuance needs and strategy have translated into
structural shifts in the cost and risk stance of Treasury issuance.
"
1802.03708,2022-11-18,A Time-Varying Network for Cryptocurrencies,"  Cryptocurrencies return cross-predictability and technological similarity
yield information on risk propagation and market segmentation. To investigate
these effects, we build a time-varying network for cryptocurrencies, based on
the evolution of return cross-predictability and technological similarities. We
develop a dynamic covariate-assisted spectral clustering method to consistently
estimate the latent community structure of cryptocurrencies network that
accounts for both sets of information. We demonstrate that investors can
achieve better risk diversification by investing in cryptocurrencies from
different communities. A cross-sectional portfolio that implements an
inter-crypto momentum trading strategy earns a 1.08% daily return. By
dissecting the portfolio returns on behavioral factors, we confirm that our
results are not driven by behavioral mechanisms.
"
1802.04413,2018-02-14,"What is the Sharpe Ratio, and how can everyone get it wrong?","  The Sharpe ratio is the most widely used risk metric in the quantitative
finance community - amazingly, essentially everyone gets it wrong. In this
note, we will make a quixotic effort to rectify the situation.
"
1802.05264,2018-04-03,Stock Market Visualization,"  We provide complete source code for a front-end GUI and its back-end
counterpart for a stock market visualization tool. It is built based on the
""functional visualization"" concept we discuss, whereby functionality is not
sacrificed for fancy graphics. The GUI, among other things, displays a
color-coded signal (computed by the back-end code) based on how ""out-of-whack""
each stock is trading compared with its peers (""mean-reversion""), and the most
sizable changes in the signal (""momentum""). The GUI also allows to efficiently
filter/tier stocks by various parameters (e.g., sector, exchange, signal,
liquidity, market cap) and functionally display them. The tool can be run as a
web-based or local application.
"
1802.06120,2021-03-23,Simple Bounds for Utility Maximization with Small Transaction Costs,"  Using elementary arguments, we show how to derive $\mathbf{L}_p$-error bounds
for the approximation of frictionless wealth process in markets with
proportional transaction costs. For utilities with bounded risk aversion, these
estimates yield lower bounds for the frictional value function, which pave the
way for its asymptotic analysis using stability results for viscosity
solutions. Using tools from Malliavin calculus, we also derive simple
sufficient conditions for the regularity of frictionless optimal trading
strategies, the second main ingredient for the asymptotic analysis of small
transaction costs.
"
1802.06386,2019-06-18,"How local in time is the no-arbitrage property under capital gains taxes
  ?","  In frictionless financial markets, no-arbitrage is a local property in time.
This means that a discrete time model is arbitrage-free if and only if there
does not exist a one-period-arbitrage. With capital gains taxes, this
equivalence fails. For a model with a linear tax and one non-shortable risky
stock, we introduce the concept of robust local no-arbitrage (RLNA) as the
weakest local condition which guarantees dynamic no-arbitrage. Under a sharp
dichotomy condition, we prove (RLNA). Since no-one-period-arbitrage is
necessary for no-arbitrage, the latter is sandwiched between two local
conditions, which allows us to estimate its non-locality.
  Furthermore, we construct a stock price process such that two long positions
in the same stock hedge each other. This puzzling phenomenon that cannot occur
in arbitrage-free frictionless markets (or markets with proportional
transaction costs) is used to show that no-arbitrage alone does not imply the
existence of an equivalent separating measure if the probability space is
infinite.
  Finally, we show that the model with a linear tax on capital gains can be
written as a model with proportional transaction costs by introducing several
fictitious securities.
"
1802.09165,2018-02-27,"Optimal contract for a fund manager, with capital injections and
  endogenous trading constraints","  In this paper, we construct a solution to the optimal contract problem for
delegated portfolio management of the fist-best (risk-sharing) type. The
novelty of our result is (i) in the robustness of the optimal contract with
respect to perturbations of the wealth process (interpreted as capital
injections), and (ii) in the more general form of principals objective
function, which is allowed to depend directly on the agents strategy, as
opposed to being a function of the generated wealth only. In particular, the
latter feature allows us to incorporate endogenous trading constraints in the
contract. We reduce the optimal contract problem to the following inverse
problem: for a given portfolio (defined in a feedback form, as a random field),
construct a stochastic utility whose optimal portfolio coincides with the given
one. We characterize the solution to this problem through a Stochastic Partial
Differential Equation (SPDE), prove its well-posedness, and compute the
solution explicitly in the Black-Scholes model.
"
1803.00611,2020-08-18,"Optimal investment-consumption problem: post-retirement with minimum
  guarantee","  We study the optimal investment-consumption problem for a member of defined
contribution plan during the decumulation phase. For a fixed annuitization
time, to achieve higher final annuity, we consider a variable consumption rate.
Moreover, to have a minimum guarantee for the final annuity, a safety level for
the wealth process is considered. To solve the stochastic optimal control
problem via dynamic programming, we obtain a Hamilton-Jacobi-Bellman (HJB)
equation on a bounded domain. The existence and uniqueness of classical
solutions are proved through the dual transformation. We apply the finite
difference method to find numerical approximations of the solution of the HJB
equation. Finally, the simulation results for the optimal
investment-consumption strategies, optimal wealth process and the final annuity
for different admissible ranges of consumption are given. Furthermore, by
taking into account the market present value of the cash flows before and after
the annuitization, we compare the outcomes of different scenarios.
"
1803.01381,2018-04-24,Generalized Information Ratio,"  Alpha-based performance evaluation may fail to capture correlated residuals
due to model errors. This paper proposes using the Generalized Information
Ratio (GIR) to measure performance under misspecified benchmarks. Motivated by
the theoretical link between abnormal returns and residual covariance matrix,
GIR is derived as alphas scaled by the inverse square root of residual
covariance matrix. GIR nests alphas and Information Ratio as special cases,
depending on the amount of information used in the residual covariance matrix.
We show that GIR is robust to various degrees of model misspecification and
produces stable out-of-sample returns. Incorporating residual correlations
leads to substantial gains that alleviate model error concerns of active
management.
"
1803.01389,2018-03-06,"Comparing Asset Pricing Models: Distance-based Metrics and Bayesian
  Interpretations","  In light of the power problems of statistical tests and undisciplined use of
alpha-based statistics to compare models, this paper proposes a unified set of
distance-based performance metrics, derived as the square root of the sum of
squared alphas and squared standard errors. The Bayesian investor views model
performance as the shortest distance between his dogmatic belief (model-implied
distribution) and complete skepticism (data-based distribution) in the model,
and favors models that produce low dispersion of alphas with high explanatory
power. In this view, the momentum factor is a crucial addition to the
five-factor model of Fama and French (2015), alleviating his prior concern of
model mispricing by -8% to 8% per annum. The distance metrics complement the
frequentist p-values with a diagnostic tool to guard against bad models.
"
1803.02974,2018-03-09,Optimal Portfolio Design for Statistical Arbitrage in Finance,"  In this paper, the optimal mean-reverting portfolio (MRP) design problem is
considered, which plays an important role for the statistical arbitrage (a.k.a.
pairs trading) strategy in financial markets. The target of the optimal MRP
design is to construct a portfolio from the underlying assets that can exhibit
a satisfactory mean reversion property and a desirable variance property. A
general problem formulation is proposed by considering these two targets and an
investment leverage constraint. To solve this problem, a successive convex
approximation method is used. The performance of the proposed model and
algorithms are verified by numerical simulations.
"
1803.03573,2023-04-19,"Bayesian mean-variance analysis: Optimal portfolio selection under
  parameter uncertainty","  The paper solves the problem of optimal portfolio choice when the parameters
of the asset returns distribution, like the mean vector and the covariance
matrix are unknown and have to be estimated by using historical data of the
asset returns. The new approach employs the Bayesian posterior predictive
distribution which is the distribution of the future realization of the asset
returns given the observable sample. The parameters of the posterior predictive
distributions are functions of the observed data values and, consequently, the
solution of the optimization problem is expressed in terms of data only and
does not depend on unknown quantities. In contrast, the optimization problem of
the traditional approach is based on unknown quantities which are estimated in
the second step leading to a suboptimal solution. We also derive a very useful
stochastic representation of the posterior predictive distribution whose
application leads not only to the solution of the considered optimization
problem, but provides the posterior predictive distribution of the optimal
portfolio return used to construct a prediction interval. A Bayesian efficient
frontier, a set of optimal portfolios obtained by employing the posterior
predictive distribution, is constructed as well. Theoretically and using real
data we show that the Bayesian efficient frontier outperforms the sample
efficient frontier, a common estimator of the set of optimal portfolios known
to be overoptimistic.
"
1803.05819,2018-07-31,"Outperformance and Tracking: Dynamic Asset Allocation for Active and
  Passive Portfolio Management","  Portfolio management problems are often divided into two types: active and
passive, where the objective is to outperform and track a preselected
benchmark, respectively. Here, we formulate and solve a dynamic asset
allocation problem that combines these two objectives in a unified framework.
We look to maximize the expected growth rate differential between the wealth of
the investor's portfolio and that of a performance benchmark while penalizing
risk-weighted deviations from a given tracking portfolio. Using stochastic
control techniques, we provide explicit closed-form expressions for the optimal
allocation and we show how the optimal strategy can be related to the growth
optimal portfolio. The admissible benchmarks encompass the class of
functionally generated portfolios (FGPs), which include the market portfolio,
as the only requirement is that they depend only on the prevailing asset
values. Finally, some numerical experiments are presented to illustrate the
risk-reward profile of the optimal allocation.
"
1803.06460,2018-03-20,Mean Reverting Portfolios via Penalized OU-Likelihood Estimation,"  We study an optimization-based approach to con- struct a mean-reverting
portfolio of assets. Our objectives are threefold: (1) design a portfolio that
is well-represented by an Ornstein-Uhlenbeck process with parameters estimated
by maximum likelihood, (2) select portfolios with desirable characteristics of
high mean reversion and low variance, and (3) select a parsimonious portfolio,
i.e. find a small subset of a larger universe of assets that can be used for
long and short positions. We present the full problem formulation, a
specialized algorithm that exploits partial minimization, and numerical
examples using both simulated and empirical price data.
"
1803.07720,2019-01-31,"Asymptotic Optimal Portfolio in Fast Mean-reverting Stochastic
  Environments","  This paper studies the portfolio optimization problem when the investor's
utility is general and the return and volatility of the risky asset are fast
mean-reverting, which are important to capture the fast-time scale in the
modeling of stock price volatility. Motivated by the heuristic derivation in
[J.-P. Fouque, R. Sircar and T. Zariphopoulou, \emph{Mathematical Finance},
2016], we propose a zeroth order strategy, and show its asymptotic optimality
within a specific (smaller) family of admissible strategies under proper
assumptions. This optimality result is achieved by establishing a first order
approximation of the problem value associated to this proposed strategy using
singular perturbation method, and estimating the risk-tolerance functions. The
results are natural extensions of our previous work on portfolio optimization
in a slowly varying stochastic environment [J.-P. Fouque and R. Hu, \emph{SIAM
Journal on Control and Optimization}, 2017], and together they form a whole
picture of analyzing portfolio optimization in both fast and slow environments.
"
1803.11467,2018-09-12,"Local Control Regression: Improving the Least Squares Monte Carlo Method
  for Portfolio Optimization","  The least squares Monte Carlo algorithm has become popular for solving
portfolio optimization problems. A simple approach is to approximate the value
functions on a discrete grid of portfolio weights, then use control regression
to generalize the discrete estimates. However, the classical global control
regression can be expensive and inaccurate. To overcome this difficulty, we
introduce a local control regression technique, combined with adaptive grids.
We show that choosing a coarse grid for local regression can produce
sufficiently accurate results.
"
1804.01764,2018-07-31,"Reducing Estimation Risk in Mean-Variance Portfolios with Machine
  Learning","  In portfolio analysis, the traditional approach of replacing population
moments with sample counterparts may lead to suboptimal portfolio choices. I
show that optimal portfolio weights can be estimated using a machine learning
(ML) framework, where the outcome to be predicted is a constant and the vector
of explanatory variables is the asset returns. It follows that ML specifically
targets estimation risk when estimating portfolio weights, and that
""off-the-shelf"" ML algorithms can be used to estimate the optimal portfolio in
the presence of parameter uncertainty. The framework nests the traditional
approach and recently proposed shrinkage approaches as special cases. By
relying on results from the ML literature, I derive new insights for existing
approaches and propose new estimation methods. Based on simulation studies and
several datasets, I find that ML significantly reduces estimation risk compared
to both the traditional approach and the equal weight strategy.
"
1804.05103,2018-04-17,"The Determinants of Home Bias in Stock Portfolio: An Emerging and
  Developed Markets Study","  The objective of this paper is to measure the degree of home bias (HB) within
holdings portfolio and to identify their determining factors. By following
literature and an international capital asset pricing model, we have chosen
quite a number of susceptible factors that impact HB. This model is, hence,
estimated for 20 countries, with cross-section econometrics, between 2008 and
2013. Our results show that all countries have recorded a high level of HB in
their holdings portfolio. After that, we test if the HB of the emerging markets
and that of the developed markets react differently to the determining factors.
The volatility of the exchange rate is statistically significant with emerging
markets, while it is hardly remarkable for the developed countries.
Co-variance, size, distance, language, legal framework and foreign organization
stocks prevents American investors to invest abroad.
"
1804.05454,2018-04-17,"A refinement of Bennett's inequality with applications to portfolio
  optimization","  A refinement of Bennett's inequality is introduced which is strictly tighter
than the classical bound. The new bound establishes the convergence of the
average of independent random variables to its expected value. It also
carefully exploits information about the potentially heterogeneous mean,
variance, and ceiling of each random variable. The bound is strictly sharper in
the homogeneous setting and very often significantly sharper in the
heterogeneous setting. The improved convergence rates are obtained by
leveraging Lambert's W function. We apply the new bound in a portfolio
optimization setting to allocate a budget across investments with heterogeneous
returns.
"
1804.08442,2018-04-24,"Explicit solutions to utility maximization problems in a
  regime-switching market model via Laplace transforms","  We study the problem of utility maximization from terminal wealth in which an
agent optimally builds her portfolio by investing in a bond and a risky asset.
The asset price dynamics follow a diffusion process with regime-switching
coefficients modeled by a continuous-time finite-state Markov chain. We
consider an investor with a Constant Relative Risk Aversion (CRRA) utility
function. We deduce the associated Hamilton-Jacobi-Bellman equation to
construct the solution and the optimal trading strategy and verify optimality
by showing that the value function is the unique constrained viscosity solution
of the HJB equation. By means of a Laplace transform method, we show how to
explicitly compute the value function and illustrate the method with the two-
and three-states cases. This method is interesting in its own right and can be
adapted in other applications involving hybrid systems and using other types of
transforms with basic properties similar to the Laplace transform.
"
1805.00205,2018-05-02,Robust Log-Optimal Strategy with Reinforcement Learning,"  We proposed a new Portfolio Management method termed as Robust Log-Optimal
Strategy (RLOS), which ameliorates the General Log-Optimal Strategy (GLOS) by
approximating the traditional objective function with quadratic Taylor
expansion. It avoids GLOS's complex CDF estimation process,hence resists the
""Butterfly Effect"" caused by estimation error. Besides,RLOS retains GLOS's
profitability and the optimization problem involved in RLOS is computationally
far more practical compared to GLOS. Further, we combine RLOS with
Reinforcement Learning (RL) and propose the so-called Robust Log-Optimal
Strategy with Reinforcement Learning (RLOSRL), where the RL agent receives the
analyzed results from RLOS and observes the trading environment to make
comprehensive investment decisions. The RLOSRL's performance is compared to
some traditional strategies on several back tests, where we randomly choose a
selection of constituent stocks of the CSI300 index as assets under management
and the test results validate its profitability and stability.
"
1805.05584,2018-05-28,"Forward-looking portfolio selection with multivariate non-Gaussian
  models and the Esscher transform","  In this study we suggest a portfolio selection framework based on
option-implied information and multivariate non-Gaussian models. The proposed
models incorporate skewness, kurtosis and more complex dependence structures
among stocks log-returns than the simple correlation matrix. The two models
considered are a multivariate extension of the normal tempered stable (NTS)
model and the generalized hyperbolic (GH) model, respectively, and the
connection between the historical measure P and the risk-neutral measure Q is
given by the Esscher transform. We consider an estimation method that
simultaneously calibrate the time series of univariate log-returns and the
univariate observed volatility smile. To calibrate the models, there is no need
of liquid multivariate derivative quotes. The method is applied to fit a
50-dimensional series of stock returns, to evaluate widely known portfolio risk
measures and to perform a portfolio selection analysis.
"
1805.06126,2018-05-18,"Market Self-Learning of Signals, Impact and Optimal Trading: Invisible
  Hand Inference with Free Energy","  We present a simple model of a non-equilibrium self-organizing market where
asset prices are partially driven by investment decisions of a bounded-rational
agent. The agent acts in a stochastic market environment driven by various
exogenous ""alpha"" signals, agent's own actions (via market impact), and noise.
Unlike traditional agent-based models, our agent aggregates all traders in the
market, rather than being a representative agent. Therefore, it can be
identified with a bounded-rational component of the market itself, providing a
particular implementation of an Invisible Hand market mechanism. In such
setting, market dynamics are modeled as a fictitious self-play of such
bounded-rational market-agent in its adversarial stochastic environment. As
rewards obtained by such self-playing market agent are not observed from market
data, we formulate and solve a simple model of such market dynamics based on a
neuroscience-inspired Bounded Rational Information Theoretic Inverse
Reinforcement Learning (BRIT-IRL). This results in effective asset price
dynamics with a non-linear mean reversion - which in our model is generated
dynamically, rather than being postulated. We argue that our model can be used
in a similar way to the Black-Litterman model. In particular, it represents, in
a simple modeling framework, market views of common predictive signals, market
impacts and implied optimal dynamic portfolio allocations, and can be used to
assess values of private signals. Moreover, it allows one to quantify a
""market-implied"" optimal investment strategy, along with a measure of market
rationality. Our approach is numerically light, and can be implemented using
standard off-the-shelf software such as TensorFlow.
"
1805.06345,2022-06-07,"Which portfolio is better? A discussion of several possible comparison
  criteria","  During the last few years, there has been an interest in comparing simple or
heuristic procedures for portfolio selection, such as the naive, equal weights,
portfolio choice, against more ""sophisticated"" portfolio choices, and in
explaining why, in some cases, the heuristic choice seems to outperform the
sophisticated choice. We believe that some of these results may be due to the
comparison criterion used. It is the purpose of this note to analyze some ways
of comparing the performance of portfolios. We begin by analyzing each
criterion proposed on the market line, in which there is only one random
return. Several possible comparisons between optimal portfolios and the naive
portfolio are possible and easy to establish. Afterwards, we study the case in
which there is no risk free asset. In this way, we believe some basic
theoretical questions regarding why some portfolios may seem to outperform
others can be clarified.
"
1805.07194,2018-05-21,"Distributionally Robust Inverse Covariance Estimation: The Wasserstein
  Shrinkage Estimator","  We introduce a distributionally robust maximum likelihood estimation model
with a Wasserstein ambiguity set to infer the inverse covariance matrix of a
$p$-dimensional Gaussian random vector from $n$ independent samples. The
proposed model minimizes the worst case (maximum) of Stein's loss across all
normal reference distributions within a prescribed Wasserstein distance from
the normal distribution characterized by the sample mean and the sample
covariance matrix. We prove that this estimation problem is equivalent to a
semidefinite program that is tractable in theory but beyond the reach of
general purpose solvers for practically relevant problem dimensions $p$. In the
absence of any prior structural information, the estimation problem has an
analytical solution that is naturally interpreted as a nonlinear shrinkage
estimator. Besides being invertible and well-conditioned even for $p>n$, the
new shrinkage estimator is rotation-equivariant and preserves the order of the
eigenvalues of the sample covariance matrix. These desirable properties are not
imposed ad hoc but emerge naturally from the underlying distributionally robust
optimization model. Finally, we develop a sequential quadratic approximation
algorithm for efficiently solving the general estimation problem subject to
conditional independence constraints typically encountered in Gaussian
graphical models.
"
1805.09068,2020-11-17,"Optimal investment for participating insurance contracts under
  VaR-Regulation","  This paper studies a Value-at-Risk (VaR)-regulated optimal portfolio problem
of the equity holders of a participating life insurance contract. In a setting
with unhedgeable mortality risk and complete financial market, the optimal
solution is given explicitly for contracts with mortality risk using a
martingale approach for constrained non-concave optimization problems. We show
that regulatory VaR constraints for participating insurance contracts lead to
more prudent investment than in the case of no regulation. This result is
contrary to the situation where the insurer maximizes the utility of the total
wealth of the company (without distinguishing between contributions of equity
holders and policyholders), in which case a VaR constraint may induce the
insurer to take excessive risks leading to higher losses than in the case of no
regulation. Compared to the unregulated problem, the VaR-constrained strategy
leads to a higher expected utility for the policyholders, highlighting the
potential usefulness of a VaR-regulation in the context of insurance. The
prudent investment behavior is more significant if a VaR-type regulation is
replaced by a portfolio insurance (PI)-type regulation. Furthermore, a stricter
regulation (a smaller allowed default probability in the VaR problem or a
higher minimum guarantee level in the PI problem) enhances the benefit of the
policyholder but deteriorates that of the insurer. For both types of
regulation, the gains in terms of expected utility are greater for higher
participation rates, while being smaller for higher bonus rates. We also extend
our analysis to frameworks where dividend and premature death benefit payments
are made at an intermediate time date.
"
1805.09996,2018-05-28,"Are multi-factor Gaussian term structure models still useful? An
  empirical analysis on Italian BTPs","  In this paper, we empirically study models for pricing Italian sovereign
bonds under a reduced form framework, by assuming different dynamics for the
short-rate process. We analyze classical Cox-Ingersoll-Ross and Vasicek
multi-factor models, with a focus on optimization algorithms applied in the
calibration exercise. The Kalman filter algorithm together with a maximum
likelihood estimation method are considered to fit the Italian term-structure
over a 12-year horizon, including the global financial crisis and the euro area
sovereign debt crisis. Analytic formulas for the gradient vector and the
Hessian matrix of the likelihood function are provided.
"
1805.11036,2019-02-21,"A Macroscopic Portfolio Model: From Rational Agents to Bounded
  Rationality","  We introduce a microscopic model of interacting financial agents, where each
agent is characterized by two portfolios; money invested in bonds and money
invested in stocks. Furthermore, each agent is faced with an optimization
problem in order to determine the optimal asset allocation. The stock price
evolution is driven by the aggregated investment decision of all agents. In
fact, we are faced with a differential game since all agents aim to invest
optimal. Mathematically such a problem is ill posed and we introduce the
concept of Nash equilibrium solutions to ensure the existence of a solution.
Especially, we denote an agent who solves this Nash equilibrium exactly a
rational agent. As next step we use model predictive control to approximate the
control problem. This enables us to derive a precise mathematical
characterization of the degree of rationality of a financial agent. This is a
novel concept in portfolio optimization and can be regarded as a general
approach. In a second step we consider the case of a fully myopic agent, where
we can solve the optimal investment decision of investors analytically. We
select the running cost to be the expected missed revenue of an agent and we
assume quadratic transaction costs. More precisely the expected revenues are
determined by a combination of a fundamentalist or chartist strategy. Then we
derive the mean field limit of the microscopic model in order to obtain a
macroscopic portfolio model. The novelty in comparison to existent
macroeconomic models in literature is that our model is derived from
microeconomic dynamics. The resulting portfolio model is a three dimensional
ODE system which enables us to derive analytical results. Simulations reveal,
that our model is able to replicate the most prominent features of financial
markets, namely booms and crashes.
"
1805.12066,2018-05-31,"The effect of prudence on the optimal allocation in possibilistic and
  mixed models","  In this paper two portfolio choice models are studied: a purely possibilistic
model, in which the return of a risky asset is a fuzzy number, and a mixed
model in which a probabilistic background risk is added. For the two models an
approximate formula of the optimal allocation is computed, with respect to the
possibilistic moments associated with fuzzy numbers and the indicators of the
investor risk preferences (risk aversion, prudence).
"
1806.01743,2018-08-09,A Machine Learning Framework for Stock Selection,"  This paper demonstrates how to apply machine learning algorithms to
distinguish good stocks from the bad stocks. To this end, we construct 244
technical and fundamental features to characterize each stock, and label stocks
according to their ranking with respect to the return-to-volatility ratio.
Algorithms ranging from traditional statistical learning methods to recently
popular deep learning method, e.g. Logistic Regression (LR), Random Forest
(RF), Deep Neural Network (DNN), and the Stacking, are trained to solve the
classification task. Genetic Algorithm (GA) is also used to implement feature
selection. The effectiveness of the stock selection strategy is validated in
Chinese stock market in both statistical and practical aspects, showing that:
1) Stacking outperforms other models reaching an AUC score of 0.972; 2) Genetic
Algorithm picks a subset of 114 features and the prediction performances of all
models remain almost unchanged after the selection procedure, which suggests
some features are indeed redundant; 3) LR and DNN are radical models; RF is
risk-neutral model; Stacking is somewhere between DNN and RF. 4) The portfolios
constructed by our models outperform market average in back tests.
"
1806.03294,2019-04-19,Applications of Gaussian Process Latent Variable Models in Finance,"  Estimating covariances between financial assets plays an important role in
risk management. In practice, when the sample size is small compared to the
number of variables, the empirical estimate is known to be very unstable. Here,
we propose a novel covariance estimator based on the Gaussian Process Latent
Variable Model (GP-LVM). Our estimator can be considered as a non-linear
extension of standard factor models with readily interpretable parameters
reminiscent of market betas. Furthermore, our Bayesian treatment naturally
shrinks the sample covariance matrix towards a more structured matrix given by
the prior and thereby systematically reduces estimation errors. Finally, we
discuss some financial applications of the GP-LVM.
"
1806.03496,2018-06-12,Optimal portfolio selection in an It\^o-Markov additive market,"  We study a portfolio selection problem in a continuous-time It\^o-Markov
additive market with prices of financial assets described by Markov additive
processes which combine L\'evy processes and regime switching models. Thus the
model takes into account two sources of risk: the jump diffusion risk and the
regime switching risk. For this reason the market is incomplete. We complete
the market by enlarging it with the use of a set of Markovian jump securities,
Markovian power-jump securities and impulse regime switching securities.
Moreover, we give conditions under which the market is
asymptotic-arbitrage-free. We solve the portfolio selection problem in the
It\^o-Markov additive market for the power utility and the logarithmic utility.
"
1806.03624,2018-06-12,"Optimal Control of Constrained Stochastic Linear-Quadratic Model with
  Applications","  This paper studies a class of continuous-time scalar-state stochastic
Linear-Quadratic (LQ) optimal control problem with the linear control
constraints. Applying the state separation theorem induced from its special
structure, we develop the explicit solution for this class of problem. The
revealed optimal control policy is a piece-wise affine function of system
state. This control policy can be computed efficiently by solving two Riccati
equations off-line. Under some mild conditions, the stationary optimal control
policy can be also derived for this class of problem with infinite horizon.
This result can be used to solve the constrained dynamic mean-variance
portfolio selection problem. Examples shed light on the solution procedure of
implementing our method.
"
1806.05160,2018-09-20,Weak Correlations of Stocks Future Returns,"  We analyze correlations among stock returns via a series of widely adopted
parameters which we refer to as explanatory variables. We subsequently exploit
the results to propose a long only quantitative adaptive technique to construct
a profitable portfolio of assets which exhibits minor drawdowns and higher
recoveries than both an equally weighted and an efficient frontier portfolio.
"
1806.05293,2018-08-21,Generalized framework for applying the Kelly criterion to stock markets,"  We develop a general framework for applying the Kelly criterion to stock
markets. By supplying an arbitrary probability distribution modeling the future
price movement of a set of stocks, the Kelly fraction for investing each stock
can be calculated by inverting a matrix involving only first and second
moments. The framework works for one or a portfolio of stocks and the Kelly
fractions can be efficiently calculated. For a simple model of geometric
Brownian motion of a single stock we show that our calculated Kelly fraction
agrees with existing results. We demonstrate that the Kelly fractions can be
calculated easily for other types of probabilities such as the Gaussian
distribution and correlated multivariate assets.
"
1806.07623,2018-06-21,"Measuring the response of gold prices to uncertainty: An analysis beyond
  the mean","  This paper provides an innovative perspective on the role of gold as a hedge
and safe haven. We use a quantile-on-quantile regression approach to capture
the dependence structure between gold returns and changes in uncertainty under
different gold market conditions, while considering the nuances of uncertainty
levels. To capture the core uncertainty effects on gold returns, a dynamic
factor model is used. This technique allows summarizing the impact of six
different indexes (namely economic, macroeconomic, microeconomic, monetary
policy, financial and political uncertainties) within one aggregate measure of
uncertainty. In doing so, we show that the gold's role as a hedge and safe
haven cannot be assumed to hold at all times. This ability seems to be
sensitive to the gold's various market states (bearish, normal or bullish) and
to whether the uncertainty is low, middle or high. Interestingly, we find a
positive and strong relationship between gold returns and the uncertainty
composite indicator when the uncertainty attains its highest level and under
normal gold market scenario. This suggests that holding a diversified portfolio
composed of gold could help protecting against exposure to uncertain risks.
"
1806.08005,2023-04-19,"Mean-Variance Efficiency of Optimal Power and Logarithmic Utility
  Portfolios","  We derive new results related to the portfolio choice problem for power and
logarithmic utilities. Assuming that the portfolio returns follow an
approximate log-normal distribution, the closed-form expressions of the optimal
portfolio weights are obtained for both utility functions. Moreover, we prove
that both optimal portfolios belong to the set of mean-variance feasible
portfolios and establish necessary and sufficient conditions such that they are
mean-variance efficient. Furthermore, an application to the stock market is
presented and the behavior of the optimal portfolio is discussed for different
values of the relative risk aversion coefficient. It turns out that the
assumption of log-normality does not seem to be a strong restriction.
"
1806.09906,2023-02-03,"Fund Characteristics and Performances of Socially Responsible Mutual
  Funds: Do ESG Ratings Play a Role?","  This paper examines the risk-adjusted performance and differential fund flows
for socially responsible mutual funds (SRMF). The results show that SRMF rated
high on ESG, perform better than lower rated ESG funds during the period of
economic crisis. The findings also show that low ESG rated SRMF had higher
differential cash-flows than high rated ESG funds except for the period of
economic down turn. The findings are of interest to financial advisors,
investors, mutual fund managers, and researchers on how SRMF performance
responds to periods of economic downturn and expansion
"
1807.00568,2021-11-04,"Diffusion Approximations for Expert Opinions in a Financial Market with
  Gaussian Drift","  This paper investigates a financial market where returns depend on an
unobservable Gaussian drift process. While the observation of returns yields
information about the underlying drift, we also incorporate discrete-time
expert opinions as an external source of information.
  For estimating the hidden drift it is crucial to consider the conditional
distribution of the drift given the available observations, the so-called
filter. For an investor observing both the return process and the discrete-time
expert opinions, we investigate in detail the asymptotic behavior of the filter
as the frequency of the arrival of expert opinions tends to infinity. In our
setting, a higher frequency of expert opinions comes at the cost of accuracy,
meaning that as the frequency of expert opinions increases, the variance of
expert opinions becomes larger. We consider a model where information dates are
deterministic and equidistant and another model where the information dates
arrive randomly as the jump times of a Poisson process. In both cases we derive
limit theorems stating that the information obtained from observing the
discrete-time expert opinions is asymptotically the same as that from observing
a certain diffusion process which can be interpreted as a continuous-time
expert.
  We use our limit theorems to derive so-called diffusion approximations of the
filter for high-frequency discrete-time expert opinions. These diffusion
approximations are extremely helpful for deriving simplified approximate
solutions of utility maximization problems.
"
1807.01979,2018-07-06,"Optimal Portfolio in Intraday Electricity Markets Modelled by
  L\'evy-Ornstein-Uhlenbeck Processes","  We study an optimal portfolio problem designed for an agent operating in
intraday electricity markets. The investor is allowed to trade in a single
risky asset modelling the continuously traded power and aims to maximize the
expected terminal utility of his wealth. We assume a mean-reverting additive
process to drive the power prices. In the case of logarithmic utility, we
reduce the fully non-linear Hamilton-Jacobi-Bellman equation to a linear
parabolic integro-differential equation, for which we explicitly exhibit a
classical solution in two cases of modelling interest. The optimal strategy is
given implicitly as the solution of an integral equation, which is possible to
solve numerically as well as to describe analytically. An analysis of two
different approximations for the optimal policy is provided. Finally, we
perform a numerical test by adapting the parameters of a popular electricity
spot price model.
"
1807.05265,2019-01-28,"Rebalancing Frequency Considerations for Kelly-Optimal Stock Portfolios
  in a Control-Theoretic Framework","  In this paper, motivated by the celebrated work of Kelly, we consider the
problem of portfolio weight selection to maximize expected logarithmic growth.
Going beyond existing literature, our focal point here is the rebalancing
frequency which we include as an additional parameter in our analysis. The
problem is first set in a control-theoretic framework, and then, the main
question we address is as follows: In the absence of transaction costs, does
high-frequency trading always lead to the best performance? Related to this is
our prior work on betting, also in the Kelly context, which examines the impact
of making a wager and letting it ride. Our results on betting frequency can be
interpreted in the context of weight selection for a two-asset portfolio
consisting of one risky asset and one riskless asset. With regard to the
question above, our prior results indicate that it is often the case that there
are no performance benefits associated with high-frequency trading. In the
present paper, we generalize the analysis to portfolios with multiple risky
assets. We show that if there is an asset satisfying a new condition which we
call dominance, then an optimal portfolio consists of this asset alone; i.e.,
the trader has ""all eggs in one basket"" and performance becomes a constant
function of rebalancing frequency. Said another way, the problem of rebalancing
is rendered moot. The paper also includes simulations which address practical
considerations associated with real stock prices and the dominant asset
condition.
"
1807.05773,2018-07-18,Portfolio Optimization with Nondominated Priors and Unbounded Parameters,"  We consider classical Merton problem of terminal wealth maximization in
finite horizon. We assume that the drift of the stock is following
Ornstein-Uhlenbeck process and the volatility of it is following GARCH(1)
process. In particular, both mean and volatility are unbounded. We assume that
there is Knightian uncertainty on the parameters of both mean and volatility.
We take that the investor has logarithmic utility function, and solve the
corresponding utility maximization problem explicitly. To the best of our
knowledge, this is the first work on utility maximization with unbounded mean
and volatility in Knightian uncertainty under nondominated priors.
"
1807.06449,2018-07-18,"Log-optimal portfolio without NFLVR: existence, complete
  characterization, and duality","  This paper addresses the log-optimal portfolio for a general semimartingale
model. The most advanced literature on the topic elaborates existence and
characterization of this portfolio under no-free-lunch-with-vanishing-risk
assumption (NFLVR). There are many financial models violating NFLVR, while
admitting the log-optimal portfolio on the one hand. On the other hand, for
financial markets under progressively enlargement of filtration, NFLVR remains
completely an open issue, and hence the literature can be applied to these
models. Herein, we provide a complete characterization of log-optimal portfolio
and its associated optimal deflator, necessary and sufficient conditions for
their existence, and we elaborate their duality as well without NFLVR.
"
1807.08278,2021-03-03,Liquidity in Competitive Dealer Markets,"  We study a continuous-time version of the intermediation model of Grossman
and Miller (1988). To wit, we solve for the competitive equilibrium prices at
which liquidity takers' demands are absorbed by dealers with quadratic
inventory costs, who can in turn gradually transfer these positions to an
exogenous open market with finite liquidity. This endogenously leads to
transient price impact in the dealer market. Smooth, diffusive, and discrete
trades all incur finite but nontrivial liquidity costs, and can arise naturally
from the liquidity takers' optimization.
"
1807.09864,2019-01-23,Incremental Sharpe and other performance ratios,"  We present a new methodology of computing incremental contribution for
performance ratios for portfolio like Sharpe, Treynor, Calmar or Sterling
ratios. Using Euler's homogeneous function theorem, we are able to decompose
these performance ratios as a linear combination of individual modified
performance ratios. This allows understanding the drivers of these performance
ratios as well as deriving a condition for a new asset to provide incremental
performance for the portfolio. We provide various numerical examples of this
performance ratio decomposition.
"
1807.09919,2018-08-02,"Betas, Benchmarks and Beating the Market","  We give an explicit formulaic algorithm and source code for building
long-only benchmark portfolios and then using these benchmarks in long-only
market outperformance strategies. The benchmarks (or the corresponding betas)
do not involve any principal components, nor do they require iterations.
Instead, we use a multifactor risk model (which utilizes multilevel industry
classification or clustering) specifically tailored to long-only benchmark
portfolios to compute their weights, which are explicitly positive in our
construction.
"
1807.09967,2018-07-27,"A Collaborative Approach to Angel and Venture Capital Investment
  Recommendations","  Matrix factorization was used to generate investment recommendations for
investors. An iterative conjugate gradient method was used to optimize the
regularized squared-error loss function. The number of latent factors, number
of iterations, and regularization values were explored. Overfitting can be
addressed by either early stopping or regularization parameter tuning. The
model achieved the highest average prediction accuracy of 13.3%. With a similar
model, the same dataset was used to generate investor recommendations for
companies undergoing fundraising, which achieved highest prediction accuracy of
11.1%.
"
1807.11381,2019-12-10,"A factor-model approach for correlation scenarios and correlation
  stress-testing","  In 2012, JPMorgan accumulated a USD~6.2 billion loss on a credit derivatives
portfolio, the so-called `London Whale', partly as a consequence of
de-correlations of non-perfectly correlated positions that were supposed to
hedge each other. Motivated by this case, we devise a factor model for
correlations that allows for scenario-based stress testing of correlations. We
derive a number of analytical results related to a portfolio of homogeneous
assets. Using the concept of Mahalanobis distance, we show how to identify
adverse scenarios of correlation risk. In addition, we demonstrate how
correlation and volatility stress tests can be combined. As an example, we
apply the factor-model approach to the ""London Whale"" portfolio and determine
the value-at-risk impact from correlation changes. Since our findings are
particularly relevant for large portfolios, where even small correlation
changes can have a large impact, a further application would be to stress test
portfolios of central counterparties, which are of systemically relevant size.
"
1808.00515,2018-08-03,"Optimal Trading with General Signals and Liquidation in Target Zone
  Models","  We study optimal trading in an Almgren-Chriss model with running and terminal
inventory costs and general predictive signals about price changes. As a
special case, this allows to treat optimal liquidation in ""target zone models"":
asset prices with a reflecting boundary enforced by regulatory interventions.
In this case, the optimal liquidation rate is the ""theta"" of a lookback option,
leading to explicit formulas for Bachelier or Black-Scholes dynamics.
"
1808.00982,2018-08-06,"Adaptive l1-regularization for short-selling control in portfolio
  selection","  We consider the l1-regularized Markowitz model, where a l1-penalty term is
added to the objective function of the classical mean-variance one to stabilize
the solution process, promoting sparsity in the solution. The l1-penalty term
can also be interpreted in terms of short sales, on which several financial
markets have posed restrictions. The choice of the regularization parameter
plays a key role to obtain optimal portfolios that meet the financial
requirements. We propose an updating rule for the regularization parameter in
Bregman iteration to control both the sparsity and the number of short
positions. We show that the modified scheme preserves the properties of the
original one. Numerical tests are reported, which show the effectiveness of the
approach.
"
1808.01560,2018-10-02,"Stock Price Correlation Coefficient Prediction with ARIMA-LSTM Hybrid
  Model","  Predicting the price correlation of two assets for future time periods is
important in portfolio optimization. We apply LSTM recurrent neural networks
(RNN) in predicting the stock price correlation coefficient of two individual
stocks. RNNs are competent in understanding temporal dependencies. The use of
LSTM cells further enhances its long term predictive properties. To encompass
both linearity and nonlinearity in the model, we adopt the ARIMA model as well.
The ARIMA model filters linear tendencies in the data and passes on the
residual value to the LSTM model. The ARIMA LSTM hybrid model is tested against
other traditional predictive financial models such as the full historical
model, constant correlation model, single index model and the multi group
model. In our empirical study, the predictive ability of the ARIMA-LSTM model
turned out superior to all other financial models by a significant scale. Our
work implies that it is worth considering the ARIMA LSTM model to forecast
correlation coefficient for portfolio optimization.
"
1808.02505,2018-08-13,Combining Independent Smart Beta Strategies for Portfolio Optimization,"  Smart beta, also known as strategic beta or factor investing, is the idea of
selecting an investment portfolio in a simple rule-based manner that
systematically captures market inefficiencies, thereby enhancing risk-adjusted
returns above capitalization-weighted benchmarks. We explore the idea of
applying a smart strategy in reverse, yielding a ""bad beta"" portfolio which can
be shorted, thus allowing long and short positions on independent smart beta
strategies to generate beta neutral returns. In this article we detail the
construction of a monthly reweighted portfolio involving two independent smart
beta strategies; the first component is a long-short beta-neutral strategy
derived from running an adaptive boosting classifier on a suite of momentum
indicators. The second component is a minimized volatility portfolio which
exploits the observation that low-volatility stocks tend to yield higher
risk-adjusted returns than high-volatility stocks. Working off a market
benchmark Sharpe Ratio of 0.42, we find that the market neutral component
achieves a ratio of 0.61, the low volatility approach achieves a ratio of 0.90,
while the combined leveraged strategy achieves a ratio of 0.96. In six months
of live trading, the combined strategy achieved a Sharpe Ratio of 1.35. These
results reinforce the effectiveness of smart beta strategies, and demonstrate
that combining multiple strategies simultaneously can yield better performance
than that achieved by any single component in isolation.
"
1808.03186,2019-05-29,"The financial value of knowing the distribution of stock prices in
  discrete market models","  An explicit formula is derived for the value of weak information in a
discrete time model that works for a wide range of utility functions including
the logarithmic and power utility. We assume a complete market with a finite
number of assets and a finite number of possible outcomes. Explicit
calculations are performed for a binomial model with two assets. The case of
trinomial models is also discussed.
"
1808.04265,2018-08-14,"Turnpike Property and Convergence Rate for an Investment and Consumption
  Model","  We discuss the turnpike property for optimal investment and consumption
problems. We find there exists a threshold value that determines the turnpike
property for investment policy. The threshold value only depends on the Sharpe
ratio, the riskless interest rate and the discount rate. We show that if
utilities behave asymptotically like power utilities and satisfy some simple
relations with the threshold value, then the turnpike property for investment
holds. There is in general no turnpike property for consumption policy. We also
provide the rate of convergence and illustrate the main results with examples
of power and non-HARA utilities and numerical tests.
"
1808.04604,2019-03-25,"Risk-based optimal portfolio of an insurer with regime switching and
  noisy memory","  In this paper, we consider a risk-based optimal investment problem of an
insurer in a regime-switching jump diffusion model with noisy memory. Using the
model uncertainty modeling, we formulate the investment problem as a zero-sum,
stochastic differential delay game between the insurer and the market, with a
convex risk measure of the terminal surplus and the Brownian delay surplus over
a period $[T-\varrho,T]$. Then, by the BSDE approach, the game problem is
solved. Finally, we derive analytical solutions of the game problem, for a
particular case of a quadratic penalty function and a numerical example is
considered.
"
1808.04608,2018-08-15,"On the optimal investment-consumption and life insurance selection
  problem with an external stochastic factor","  In this paper, we study a stochastic optimal control problem with stochastic
volatility. We prove the sufficient and necessary maximum principle for the
proposed problem. Then we apply the results to solve an investment, consumption
and life insurance problem with stochastic volatility, that is, we consider a
wage earner investing in one risk-free asset and one risky asset described by a
jump-diffusion process and has to decide concerning consumption and life
insurance purchase. We assume that the life insurance for the wage earner is
bought from a market composed of $M>1$ life insurance companies offering
pairwise distinct life insurance contracts. The goal is to maximize the
expected utilities derived from the consumption, the legacy in the case of a
premature death and the investor's terminal wealth.
"
1808.04611,2018-08-15,"A note on representation of BSDE-based dynamic risk measures and dynamic
  capital allocations","  In this paper, we provide a representation theorem for dynamic capital
allocation under It{\^o}-L{\'e}vy model. We consider the representation of
dynamic risk measures defined under Backward Stochastic Differential Equations
(BSDE) with generators that grow quadratic-exponentially in the control
variables. Dynamic capital allocation is derived from the differentiability of
BSDEs with jumps. The results are illustrated by deriving a capital allocation
representation for dynamic entropic risk measure and static coherent risk
measure.
"
1808.04613,2018-08-15,"Optimal investment-consumption and life insurance with capital
  constraints","  The aim of this paper is to solve an optimal investment, consumption and life
insurance problem when the investor is restricted to capital guarantee. We
consider an incomplete market described by a jump-diffusion model with
stochastic volatility. Using the martingale approach, we prove the existence of
the optimal strategy and the optimal martingale measure and we obtain the
explicit solutions for the power utility functions.
"
1808.05169,2019-06-06,"Inventory Management for High-Frequency Trading with Imperfect
  Competition","  We study Nash equilibria for inventory-averse high-frequency traders (HFTs),
who trade to exploit information about future price changes. For discrete
trading rounds, the HFTs' optimal trading strategies and their equilibrium
price impact are described by a system of nonlinear equations; explicit
solutions obtain around the continuous-time limit. Unlike in the risk-neutral
case, the optimal inventories become mean-reverting and vanish as the number of
trading rounds becomes large. In contrast, the HFTs' risk-adjusted profits and
the equilibrium price impact converge to their risk-neutral counterparts.
Compared to a social-planner solution for cooperative HFTs, Nash competition
leads to excess trading, so that marginal transaction taxes in fact decrease
market liquidity.
"
1808.06337,2018-08-23,"Optimal asset allocation for a DC plan with partial information under
  inflation and mortality risks","  We study an asset allocation stochastic problem with restriction for a
defined-contribution pension plan during the accumulation phase. We consider a
financial market with stochastic interest rate, composed of a risk-free asset,
a real zero coupon bond price, the inflation-linked bond and the risky asset. A
plan member aims to maximize the expected power utility derived from the
terminal wealth. In order to protect the rights of a member who dies before
retirement, we introduce a clause which allows to withdraw his premiums and the
difference is distributed among the survival members. Besides the mortality
risk, the fund manager takes into account the salary and the inflation risks.
We then obtain closed form solutions for the asset allocation problem using a
sufficient maximum principle approach for the problem with partial information.
Finally, we give a numerical example.
"
1808.09940,2018-11-20,Adversarial Deep Reinforcement Learning in Portfolio Management,"  In this paper, we implement three state-of-art continuous reinforcement
learning algorithms, Deep Deterministic Policy Gradient (DDPG), Proximal Policy
Optimization (PPO) and Policy Gradient (PG)in portfolio management. All of them
are widely-used in game playing and robot control. What's more, PPO has
appealing theoretical propeties which is hopefully potential in portfolio
management. We present the performances of them under different settings,
including different learning rates, objective functions, feature combinations,
in order to provide insights for parameters tuning, features selection and data
preparation. We also conduct intensive experiments in China Stock market and
show that PG is more desirable in financial market than DDPG and PPO, although
both of them are more advanced. What's more, we propose a so called Adversarial
Training method and show that it can greatly improve the training efficiency
and significantly promote average daily return and sharpe ratio in back test.
Based on this new modification, our experiments results show that our agent
based on Policy Gradient can outperform UCRP.
"
1809.00990,2018-09-10,"Optimal Reinsurance for Gerber-Shiu Functions in the Cramer-Lundberg
  Model","  Complementing existing results on minimal ruin probabilities, we minimize
expected discounted penalty functions (or Gerber-Shiu functions) in a
Cramer-Lundberg model by choosing optimal reinsurance. Reinsurance strategies
are modelled as time dependant control functions, which leads to a setting from
the theory of optimal stochastic control and ultimately to the problem's
Hamilton-Jacobi-Bellman equation. We show existence and uniqueness of the
solution found by this method and provide numerical examples involving light
and heavy tailed claims and also give a remark on the asymptotics.
"
1809.01464,2021-12-02,"Portfolio diversification and model uncertainty: a robust dynamic
  mean-variance approach","  This paper focuses on a dynamic multi-asset mean-variance portfolio selection
problem under model uncertainty. We develop a continuous time framework for
taking into account ambiguity aversion about both expected return rates and
correlation matrix of the assets, and for studying the join effects on
portfolio diversification. The dynamic setting allows us to consider time
varying ambiguity sets, which include the cases where the drift and correlation
are estimated on a rolling window of historical data or when the investor takes
into account learning on the ambiguity. In this context, we prove a general
separation principle for the associated robust control problem, which allows us
to reduce the determination of the optimal dynamic strategy to the parametric
computation of the minimal risk premium function. Our results provide a
justification for under-diversification, as documented in empirical studies and
in the static models [16], [34]. Furthermore, we explicitly quantify the degree
of under-diversification in termsof correlation bounds and Sharpe ratios
proximities, and emphasize the different features induced by drift and
correlation ambiguity. In particular, we show that an investor with a poor
confidence in the expected return estimation does not hold any risky asset, and
on the other hand, trades only one risky asset when the level of ambiguity on
correlation matrix is large. We also provide a complete picture of the
diversification for the optimal robust portfolio in the three-asset case JEL
Classification: G11, C61 MSC Classification: 91G10, 91G80, 60H30
"
1809.01989,2020-02-04,Diversity and Sparsity: A New Perspective on Index Tracking,"  We address the problem of partial index tracking, replicating a benchmark
index using a small number of assets. Accurate tracking with a sparse portfolio
is extensively studied as a classic finance problem. However in practice, a
tracking portfolio must also be diverse in order to minimise risk -- a
requirement which has only been dealt with by ad-hoc methods before. We
introduce the first index tracking method that explicitly optimises both
diversity and sparsity in a single joint framework. Diversity is realised by a
regulariser based on pairwise similarity of assets, and we demonstrate that
learning similarity from data can outperform some existing heuristics. Finally,
we show that the way we model diversity leads to an easy solution for sparsity,
allowing both constraints to be optimised easily and efficiently. we run
out-of-sample backtesting for a long interval of 15 years (2003 -- 2018), and
the results demonstrate the superiority of the proposed algorithm.
"
1809.03641,2019-03-05,Model Risk Measurement under Wasserstein Distance,"  The paper proposes a new approach to model risk measurement based on the
Wasserstein distance between two probability measures. It formulates the
theoretical motivation resulting from the interpretation of fictitious
adversary of robust risk management. The proposed approach accounts for
equivalent and non-equivalent probability measures and incorporates the
economic reality of the fictitious adversary. It provides practically feasible
results that overcome the restriction of considering only models implying
probability measures equivalent to the reference model. The Wasserstein
approach suits for various types of model risk problems, ranging from the
single-asset hedging risk problem to the multi-asset allocation problem. The
robust capital market line, accounting for the correlation risk, is not
achievable with other non-parametric approaches.
"
1809.03769,2018-09-12,"Diversification, Volatility, and Surprising Alpha","  It has been widely observed that capitalization-weighted indexes can be
beaten by surprisingly simple, systematic investment strategies. Indeed, in the
U.S. stock market, equal-weighted portfolios, random-weighted portfolios, and
other naive, non- optimized portfolios tend to outperform a
capitalization-weighted index over the long term. This outperformance is
generally attributed to beneficial factor exposures. Here, we provide a deeper,
more general explanation of this phenomenon by decomposing portfolio
log-returns into an average growth and an excess growth component. Using a
rank-based empirical study we argue that the excess growth component plays the
major role in explaining the outperformance of naive portfolios. In particular,
individual stock growth rates are not as critical as is traditionally assumed.
"
1809.05961,2019-05-28,Optimal Dynamic Basis Trading,"  We study the problem of dynamically trading a futures contract and its
underlying asset under a stochastic basis model. The basis evolution is modeled
by a stopped scaled Brownian bridge to account for non-convergence of the basis
at maturity. The optimal trading strategies are determined from a utility
maximization problem under hyperbolic absolute risk aversion (HARA) risk
preferences. By analyzing the associated Hamilton-Jacobi-Bellman equation, we
derive the exact conditions under which the equation admits a solution and
solve the utility maximization explicitly. A series of numerical examples are
provided to illustrate the optimal strategies and examine the effects of model
parameters.
"
1809.07040,2019-12-18,"Analysis of the Risk-Sharing Principal-Agent problem through the
  Reverse-H{\""o}lder inequality","  In this paper we provide an alternative framework to tackle the first-best
Principal-Agent problem under CARA utilities. This framework leads to both a
proof of existence and uniqueness of the solution to the Risk-Sharing problem
under very general assumptions on the underlying contract space. Our analysis
relies on an optimal decomposition of the expected utility of the Principal in
terms of the reservation utility of the Agent and works both in a discrete time
and continuous time setting. As a by-product this approach provides a novel way
of characterizing the optimal contract in the CARA setting, which is as an
alternative to the widely used Lagrangian method, and some analysis of the
optimum.
"
1809.08139,2018-09-24,"Optimal investment and consumption for Ornstein-Uhlenbeck spread
  financial markets with logarithmic utility","  We consider a spread financial market defined by the multidimensional
Ornstein--Uhlenbeck (OU) process. We study the optimal consumption/investment
problem for logarithmic utility functions in the base of stochastic dynamical
programming method. We show a special Verification Theorem for this case. We
find the solution to the Hamilton--Jacobi--Bellman (HJB) equation in explicit
form and as a consequence we construct the optimal financial strategies.
Moreover, we study the constructed strategy by numerical simulations.
"
1809.10123,2023-03-06,Trading Strategies Generated Pathwise by Functions of Market Weights,"  Almost twenty years ago, E.R. Fernholz introduced portfolio generating
functions which can be used to construct a variety of portfolios, solely in the
terms of the individual companies' market weights. I. Karatzas and J. Ruf
recently developed another methodology for the functional construction of
portfolios, which leads to very simple conditions for strong relative arbitrage
with respect to the market. In this paper, both of these notions of functional
portfolio generation are generalized in a pathwise, probability-free setting;
portfolio generating functions are substituted by path-dependent functionals,
which involve the current market weights, as well as additional
bounded-variation functions of past and present market weights. This
generalization leads to a wider class of functionally-generated portfolios than
was heretofore possible, and yields improved conditions for outperforming the
market portfolio over suitable time-horizons.
"
1809.10566,2018-09-28,Some Nontrivial Properties of a Formula for Compound Interest,"  We analyze the classical model of compound interest with a constant
per-period payment and interest rate. We examine the outstanding balance
function as well as the periodic payment function and show that the outstanding
balance function is not generally concave in the interest rate, but instead may
be initially convex on its domain and then concave.
"
1809.10716,2019-05-17,Portfolio Optimization in Fractional and Rough Heston Models,"  We consider a fractional version of the Heston volatility model which is
inspired by [16]. Within this model we treat portfolio optimization problems
for power utility functions. Using a suitable representation of the fractional
part, followed by a reasonable approximation we show that it is possible to
cast the problem into the classical stochastic control framework. This approach
is generic for fractional processes. We derive explicit solutions and obtain as
a by-product the Laplace transform of the integrated volatility. In order to
get rid of some undesirable features we introduce a new model for the rough
path scenario which is based on the Marchaud fractional derivative. We provide
a numerical study to underline our results.
"
1810.02125,2018-10-05,A Machine Learning-based Recommendation System for Swaptions Strategies,"  Derivative traders are usually required to scan through hundreds, even
thousands of possible trades on a daily basis. Up to now, not a single solution
is available to aid in their job. Hence, this work aims to develop a trading
recommendation system, and apply this system to the so-called Mid-Curve
Calendar Spread (MCCS), an exotic swaption-based derivatives package. In
summary, our trading recommendation system follows this pipeline: (i) on a
certain trade date, we compute metrics and sensitivities related to an MCCS;
(ii) these metrics are feed in a model that can predict its expected return for
a given holding period; and after repeating (i) and (ii) for all trades we
(iii) rank the trades using some dominance criteria. To suggest that such
approach is feasible, we used a list of 35 different types of MCCS; a total of
11 predictive models; and 4 benchmark models. Our results suggest that in
general linear regression with lasso regularisation compared favourably to
other approaches from a predictive and interpretability perspective.
"
1810.02444,2022-10-24,Super-Replication of the Best Pairs Trade in Hindsight,"  This paper derives a robust on-line equity trading algorithm that achieves
the greatest possible percentage of the final wealth of the best pairs
rebalancing rule in hindsight. A pairs rebalancing rule chooses some pair of
stocks in the market and then perpetually executes rebalancing trades so as to
maintain a target fraction of wealth in each of the two. After each discrete
market fluctuation, a pairs rebalancing rule will sell a precise amount of the
outperforming stock and put the proceeds into the underperforming stock. Under
typical conditions, in hindsight one can find pairs rebalancing rules that
would have spectacularly beaten the market. Our trading strategy, which extends
Ordentlich and Cover's (1998) ""max-min universal portfolio,"" guarantees to
achieve an acceptable percentage of the hindsight-optimized wealth, a
percentage which tends to zero at a slow (polynomial) rate. This means that on
a long enough investment horizon, the trader can enforce a compound-annual
growth rate that is arbitrarily close to that of the best pairs rebalancing
rule in hindsight. The strategy will ""beat the market asymptotically"" if there
turns out to exist a pairs rebalancing rule that grows capital at a higher
asymptotic rate than the market index. The advantages of our algorithm over the
Ordentlich and Cover (1998) strategy are twofold. First, their strategy is
impossible to compute in practice. Second, in considering the more modest
benchmark (instead of the best all-stock rebalancing rule in hindsight), we
reduce the ""cost of universality"" and achieve a higher learning rate.
"
1810.02447,2022-10-24,Multilinear Superhedging of Lookback Options,"  In a pathbreaking paper, Cover and Ordentlich (1998) solved a max-min
portfolio game between a trader (who picks an entire trading algorithm,
$\theta(\cdot)$) and ""nature,"" who picks the matrix $X$ of gross-returns of all
stocks in all periods. Their (zero-sum) game has the payoff kernel
$W_\theta(X)/D(X)$, where $W_\theta(X)$ is the trader's final wealth and $D(X)$
is the final wealth that would have accrued to a $\$1$ deposit into the best
constant-rebalanced portfolio (or fixed-fraction betting scheme) determined in
hindsight. The resulting ""universal portfolio"" compounds its money at the same
asymptotic rate as the best rebalancing rule in hindsight, thereby beating the
market asymptotically under extremely general conditions. Smitten with this
(1998) result, the present paper solves the most general tractable version of
Cover and Ordentlich's (1998) max-min game. This obtains for performance
benchmarks (read: derivatives) that are separately convex and homogeneous in
each period's gross-return vector. For completely arbitrary (even
non-measurable) performance benchmarks, we show how the axiom of choice can be
used to ""find"" an exact maximin strategy for the trader.
"
1810.02485,2019-06-06,Exact Replication of the Best Rebalancing Rule in Hindsight,"  This paper prices and replicates the financial derivative whose payoff at $T$
is the wealth that would have accrued to a $\$1$ deposit into the best
continuously-rebalanced portfolio (or fixed-fraction betting scheme) determined
in hindsight. For the single-stock Black-Scholes market, Ordentlich and Cover
(1998) only priced this derivative at time-0, giving
$C_0=1+\sigma\sqrt{T/(2\pi)}$. Of course, the general time-$t$ price is not
equal to $1+\sigma\sqrt{(T-t)/(2\pi)}$. I complete the Ordentlich-Cover (1998)
analysis by deriving the price at any time $t$. By contrast, I also study the
more natural case of the best levered rebalancing rule in hindsight. This
yields $C(S,t)=\sqrt{T/t}\cdot\,\exp\{rt+\sigma^2b(S,t)^2\cdot t/2\}$, where
$b(S,t)$ is the best rebalancing rule in hindsight over the observed history
$[0,t]$. I show that the replicating strategy amounts to betting the fraction
$b(S,t)$ of wealth on the stock over the interval $[t,t+dt].$ This fact holds
for the general market with $n$ correlated stocks in geometric Brownian motion:
we get $C(S,t)=(T/t)^{n/2}\exp(rt+b'\Sigma b\cdot t/2)$, where $\Sigma$ is the
covariance of instantaneous returns per unit time. This result matches the
$\mathcal{O}(T^{n/2})$ ""cost of universality"" derived by Cover in his
""universal portfolio theory"" (1986, 1991, 1996, 1998), which super-replicates
the same derivative in discrete-time. The replicating strategy compounds its
money at the same asymptotic rate as the best levered rebalancing rule in
hindsight, thereby beating the market asymptotically. Naturally enough, we find
that the American-style version of Cover's Derivative is never exercised early
in equilibrium.
"
1810.04370,2019-02-20,Complex Valued Risk Diversification,"  Risk diversification is one of the dominant concerns for portfolio managers.
Various portfolio constructions have been proposed to minimize the risk of the
portfolio under some constrains including expected returns. We propose a
portfolio construction method that incorporates the complex valued principal
component analysis into the risk diversification portfolio construction. The
proposed method is verified to outperform the conventional risk parity and risk
diversification portfolio constructions.
"
1810.06366,2018-10-16,Replica Analysis for Maximization of Net Present Value,"  In this paper, we use replica analysis to determine the investment strategy
that can maximize the net present value for portfolios containing multiple
development projects. Replica analysis was developed in statistical mechanical
informatics and econophysics to evaluate disordered systems, and here we use it
to formulate the maximization of the net present value as an optimization
problem under budget and investment concentration constraints. Furthermore, we
confirm that a common approach from operations research underestimates the true
maximal net present value as the maximal expected net present value by
comparing our results with the maximal expected net present value as derived in
operations research. Moreover, it is shown that the conventional method for
estimating the net present value does not consider variance in the cash flow.
"
1810.08384,2018-10-22,Portfolio Construction Matters,"  The role of portfolio construction in the implementation of equity market
neutral factors is often underestimated. Taking the classical momentum strategy
as an example, we show that one can significantly improve the main strategy's
features by properly taking care of this key step. More precisely, an optimized
portfolio construction algorithm allows one to significantly improve the Sharpe
Ratio, reduce sector exposures and volatility fluctuations, and mitigate the
strategy's skewness and tail correlation with the market. These results are
supported by long-term, world-wide simulations and will be shown to be
universal. Our findings are quite general and hold true for a number of other
""equity factors"". Finally, we discuss the details of a more realistic set-up
where we also deal with transaction costs.
"
1810.08466,2021-08-13,"ALM for insurers with multiple underwriting lines and portfolio
  constraints: a Lagrangian duality approach","  We study a continuous-time asset-allocation problem for an insurance firm
that backs up liabilities from multiple non-life business lines with
underwriting profits and investment income. The insurance risks are captured
via a multidimensional jump-diffusion process with a multivariate compound
Poisson process with dependent components, which allows to model claims that
occur in different lines simultaneously. Using Lagrangian convex duality
techniques, we provide a general verification-type result for
investment-underwriting strategies that maximize expected utility from the
dividend payout rate and final wealth over a finite-time horizon. We also study
the precautionary effect on earnings retention of risk aversion, prudence,
portfolio constraints and multivariate insurance risk. We find an explicit
characterization of optimal strategies under CRRA preferences. Numerical
results for two-dimensional examples with policy limits illustrate the impact
of co-integration for ALM with multiple (dependent and independent) sources of
insurance risk.
"
1810.08584,2019-07-01,Reverse Quantum Annealing Approach to Portfolio Optimization Problems,"  We investigate a hybrid quantum-classical solution method to the
mean-variance portfolio optimization problems. Starting from real financial
data statistics and following the principles of the Modern Portfolio Theory, we
generate parametrized samples of portfolio optimization problems that can be
related to quadratic binary optimization forms programmable in the analog
D-Wave Quantum Annealer 2000Q. The instances are also solvable by an
industry-established Genetic Algorithm approach, which we use as a classical
benchmark. We investigate several options to run the quantum computation
optimally, ultimately discovering that the best results in terms of expected
time-to-solution as a function of number of variables for the hardest instances
set are obtained by seeding the quantum annealer with a solution candidate
found by a greedy local search and then performing a reverse annealing
protocol. The optimized reverse annealing protocol is found to be more than 100
times faster than the corresponding forward quantum annealing on average.
"
1810.09825,2019-01-15,Asset allocation: new evidence through network approaches,"  The main contribution of the paper is to employ the financial market network
as a useful tool to improve the portfolio selection process, where nodes
indicate securities and edges capture the dependence structure of the system.
Three different methods are proposed in order to extract the dependence
structure between assets in a network context. Starting from this modified
structure, we formulate and then we solve the asset allocation problem. We find
that the portfolios obtained through a network-based approach are composed
mainly of peripheral assets, which are poorly connected with the others. These
portfolios, in the majority of cases, are characterized by an higher trade-off
between performance and risk with respect to the traditional Global Minimum
Variance (GMV) portfolio. Additionally, this methodology benefits of a
graphical visualization of the selected portfolio directly over the graphic
layout of the network, which helps in improving our understanding of the
optimal strategy.
"
1810.10726,2018-10-26,How Not To Do Mean-Variance Analysis,"  We use the 2014 market history of two high-returning biotechnology
exchange-traded funds to illustrate how ex post mean-variance analysis should
not be done. Unfortunately, the way it should not be done is the way it
generally is done -- to our knowledge.
"
1810.10800,2018-10-26,Spanning Tests for Markowitz Stochastic Dominance,"  We derive properties of the cdf of random variables defined as saddle-type
points of real valued continuous stochastic processes. This facilitates the
derivation of the first-order asymptotic properties of tests for stochastic
spanning given some stochastic dominance relation. We define the concept of
Markowitz stochastic dominance spanning, and develop an analytical
representation of the spanning property. We construct a non-parametric test for
spanning based on subsampling, and derive its asymptotic exactness and
consistency. The spanning methodology determines whether introducing new
securities or relaxing investment constraints improves the investment
opportunity set of investors driven by Markowitz stochastic dominance. In an
application to standard data sets of historical stock market returns, we reject
market portfolio Markowitz efficiency as well as two-fund separation. Hence, we
find evidence that equity management through base assets can outperform the
market, for investors with Markowitz type preferences.
"
1810.10970,2018-10-26,"Defining and estimating stochastic rate change in a dynamic general
  insurance portfolio","  Rate change calculations in the literature involve deterministic methods that
measure the change in premium for a given policy. The definition of rate change
as a statistical parameter is proposed to address the stochastic nature of the
premium charged for a policy. It promotes the idea that rate change is a
property of an asymptotic population to be estimated, not just a property to
measure or monitor in the sample of observed policies that are written. Various
models and techniques are given for estimating this stochastic rate change and
quantifying the uncertainty in the estimates. The use of matched sampling is
emphasized for rate change estimation, as it adjusts for changes in policy
characteristics by directly searching for similar policies across policy years.
This avoids any of the assumptions and recipes that are required to re-rate
policies in years where they were not written, as is common with deterministic
methods. Such procedures can be subjective or implausible if the structure of
rating algorithms change or there are complex and heterogeneous exposure bases
and coverages. The methods discussed are applied to a motor premium database.
The application includes the use of a genetic algorithm with parallel
computations to automatically optimize the matched sampling.
"
1810.11299,2020-10-09,On the solution uniqueness in portfolio optimization and risk analysis,"  We consider the issue of solution uniqueness for portfolio optimization
problem and its inverse for asset returns with a finite number of possible
scenarios. The risk is assessed by deviation measures introduced by
[Rockafellar et al., Mathematical Programming, Ser. B, 108 (2006), pp. 515-540]
instead of variance as in the Markowitz optimization problem. We prove that in
general one can expect uniqueness neither in forward nor in inverse problems.
We discuss consequences of that non-uniqueness for several problems in risk
analysis and portfolio optimization, including capital allocation, risk
sharing, cooperative investment, and the Black-Litterman methodology. In all
cases, the issue with non-uniqueness is closely related to the fact that
subgradient of a convex function is non-unique at the points of
non-differentiability. We suggest methodology to resolve this issue by
identifying a unique ""special"" subgradient satisfying some natural axioms. This
""special"" subgradient happens to be the Stainer point of the subdifferential
set.
"
1810.11619,2018-10-30,"Expected Utility Maximization and Conditional Value-at-Risk
  Deviation-based Sharpe Ratio in Dynamic Stochastic Portfolio Optimization","  In this paper we investigate the expected terminal utility maximization
approach for a dynamic stochastic portfolio optimization problem. We solve it
numerically by solving an evolutionary Hamilton-Jacobi-Bellman equation which
is transformed by means of the Riccati transformation. We examine the
dependence of the results on the shape of a chosen utility function in regard
to the associated risk aversion level. We define the
  Conditional value-at-risk deviation ($CVaRD$) based Sharpe ratio for
measuring risk-adjusted performance of a dynamic portfolio. We compute optimal
strategies for a portfolio investment problem motivated by the German DAX 30
Index and we evaluate and analyze the dependence of the $CVaRD$-based Sharpe
ratio on the utility function and the associated risk aversion level.
"
1810.12840,2018-10-31,Asset Price Distributions and Efficient Markets,"  We explore a decomposition in which returns on a large class of portfolios
relative to the market depend on a smooth non-negative drift and changes in the
asset price distribution. This decomposition is obtained using general
continuous semimartingale price representations, and is thus consistent with
virtually any asset pricing model. Fluctuations in portfolio relative returns
depend on stochastic time-varying dispersion in asset prices. Thus, our
framework uncovers an asset pricing factor whose existence emerges from an
accounting identity universal across different economic and financial
environments, a fact that has deep implications for market efficiency. In
particular, in a closed, dividend-free market in which asset price dispersion
is relatively constant, a large class of portfolios must necessarily outperform
the market portfolio over time. We show that price dispersion in commodity
futures markets has increased only slightly, and confirm the existence of
substantial excess returns that co-vary with changes in price dispersion as
predicted by our theory.
"
1811.01624,2018-11-06,"Better to stay apart: asset commonality, bipartite network centrality,
  and investment strategies","  By exploiting a bipartite network representation of the relationships between
mutual funds and portfolio holdings, we propose an indicator that we derive
from the analysis of the network, labelled the Average Commonality Coefficient
(ACC), which measures how frequently the assets in the fund portfolio are
present in the portfolios of the other funds of the market. This indicator
reflects the investment behavior of funds' managers as a function of the
popularity of the assets they held. We show that $ACC$ provides useful
information to discriminate between funds investing in niche markets and those
investing in more popular assets. More importantly, we find that $ACC$ is able
to provide indication on the performance of the funds. In particular, we find
that funds investing in less popular assets generally outperform those
investing in more popular financial instruments, even when correcting for
standard factors. Moreover, funds with a low $ACC$ have been less affected by
the 2007-08 global financial crisis, likely because less exposed to fire sales
spillovers.
"
1811.02382,2018-11-07,"Diversifying portfolios of U.S. stocks with crude oil and natural gas: A
  regime-dependent optimization with several risk measures","  Energy markets are strategic to governments and economic development. Several
commodities compete as substitutable energy sources and energy diversifiers.
Such competition reduces the energy vulnerability of countries as well as
portfolios' risk exposure. Vulnerability results mainly from price trends and
fluctuations, following supply and demand shocks. Such energy price uncertainty
attracts many market participants in the energy commodity markets. First,
energy producers and consumers hedge adverse price changes with energy
derivatives. Second, financial market participants use commodities and
commodity derivatives to diversify their conventional portfolios. For that
reason, we consider the joint dependence between the United States (U.S.)
natural gas, crude oil and stock markets. We use Gatfaoui's (2015) time varying
multivariate copula analysis and related variance regimes. Such approach
handles structural changes in asset prices. In this light, we draw implications
for portfolio optimization, when investors diversify their stock portfolios
with natural gas and crude oil assets. We minimize the portfolio's variance,
semi-variance and tail risk, in the presence and the absence of constraints on
the portfolio's expected return and/or U.S. stock investment. The return
constraint reduces the performance of the optimal portfolio. Moreover, the
regime-specific portfolio optimization helps implement an enhanced active
management strategy over the whole sample period. Under a return constraint,
the semi-variance optimal portfolio offers the best risk-return tradeoff,
whereas the tail-risk optimal portfolio offers the best tradeoff in the absence
of a return constraint.
"
1811.06893,2018-11-19,Bayesian learning for the Markowitz portfolio selection problem,"  We study the Markowitz portfolio selection problem with unknown drift vector
in the multidimensional framework. The prior belief on the uncertain expected
rate of return is modeled by an arbitrary probability law, and a Bayesian
approach from filtering theory is used to learn the posterior distribution
about the drift given the observed market data of the assets. The Bayesian
Markowitz problem is then embedded into an auxiliary standard control problem
that we characterize by a dynamic programming method and prove the existence
and uniqueness of a smooth solution to the related semi-linear partial
differential equation (PDE). The optimal Markowitz portfolio strategy is
explicitly computed in the case of a Gaussian prior distribution. Finally, we
measure the quantitative impact of learning, updating the strategy from
observed data, compared to non-learning, using a constant drift in an uncertain
context, and analyze the sensitivity of the value of information w.r.t. various
relevant parameters of our model.
"
1811.07860,2019-04-23,Cryptoasset Factor Models,"  We propose factor models for the cross-section of daily cryptoasset returns
and provide source code for data downloads, computing risk factors and
backtesting them out-of-sample. In ""cryptoassets"" we include all
cryptocurrencies and a host of various other digital assets (coins and tokens)
for which exchange market data is available. Based on our empirical analysis,
we identify the leading factor that appears to strongly contribute into daily
cryptoasset returns. Our results suggest that cross-sectional statistical
arbitrage trading may be possible for cryptoassets subject to efficient
executions and shorting.
"
1811.08255,2018-11-21,An updated review of (sub-)optimal diversification models,"  In the past decade many researchers have proposed new optimal portfolio
selection strategies to show that sophisticated diversification can outperform
the na\""ive 1/N strategy in out-of-sample benchmarks. Providing an updated
review of these models since DeMiguel et al. (2009b), I test sixteen strategies
across six empirical datasets to see if indeed progress has been made. However,
I find that none of the recently suggested strategies consistently outperforms
the 1/N or minimum-variance approach in terms of Sharpe ratio,
certainty-equivalent return or turnover. This suggests that simple
diversification rules are not in fact inefficient, and gains promised by
optimal portfolio choice remain unattainable out-of-sample due to large
estimation errors in expected returns. Therefore, further research effort
should be devoted to both improving estimation of expected returns, and
possibly exploring diversification rules that do not require the estimation of
expected returns directly, but also use other available information about the
stock characteristics.
"
1811.08604,2018-11-22,"The value of forecasts: Quantifying the economic gains of accurate
  quarter-hourly electricity price forecasts","  We propose a multivariate elastic net regression forecast model for German
quarter-hourly electricity spot markets. While the literature is diverse on
day-ahead prediction approaches, both the intraday continuous and intraday
call-auction prices have not been studied intensively with a clear focus on
predictive power. Besides electricity price forecasting, we check for the
impact of early day-ahead (DA) EXAA prices on intraday forecasts. Another
novelty of this paper is the complementary discussion of economic benefits. A
precise estimation is worthless if it cannot be utilized. We elaborate possible
trading decisions based upon our forecasting scheme and analyze their monetary
effects. We find that even simple electricity trading strategies can lead to
substantial economic impact if combined with a decent forecasting technique.
"
1811.09309,2018-12-27,Bayesian Alternatives to the Black-Litterman Model,"  The Black-Litterman model combines investors' personal views with historical
data and gives optimal portfolio weights. In this paper we will introduce the
original Black-Litterman model (section 1), we will modify the model such that
it fits in a Bayesian framework by considering the investors' personal views to
be a direct prior on the means of the returns and by adding a typical Inverse
Wishart prior on the covariance matrix of the returns (section 2). Lastly, we
will use Leonard and Hsu's (1992) idea of adding a prior on the logarithm of
the covariance matrix (section 3). Sensitivity simulations for the level of
confidence that the investor has in their own personal views were performed and
performance of the models was assessed on a test data set consisting of returns
over the month of January 2018.
"
1812.00093,2019-06-25,Using Column Generation to Solve Extensions to the Markowitz Model,"  We introduce a solution scheme for portfolio optimization problems with
cardinality constraints. Typical portfolio optimization problems are extensions
of the classical Markowitz mean-variance portfolio optimization model. We solve
such type of problems using a method similar to column generation. In this
scheme, the original problem is restricted to a subset of the assets resulting
in a master convex quadratic problem. Then the dual information of the master
problem is used in a sub-problem to propose more assets to consider. We also
consider other extensions to the Markowitz model to diversify the portfolio
selection within the given intervals for active weights.
"
1812.02340,2019-01-28,Continual Learning Augmented Investment Decisions,"  Investment decisions can benefit from incorporating an accumulated knowledge
of the past to drive future decision making. We introduce Continual Learning
Augmentation (CLA) which is based on an explicit memory structure and a feed
forward neural network (FFNN) base model and used to drive long term financial
investment decisions. We demonstrate that our approach improves accuracy in
investment decision making while memory is addressed in an explainable way. Our
approach introduces novel remember cues, consisting of empirically learned
change points in the absolute error series of the FFNN. Memory recall is also
novel, with contextual similarity assessed over time by sampling distances
using dynamic time warping (DTW). We demonstrate the benefits of our approach
by using it in an expected return forecasting task to drive investment
decisions. In an investment simulation in a broad international equity universe
between 2003-2017, our approach significantly outperforms FFNN base models. We
also illustrate how CLA's memory addressing works in practice, using a worked
example to demonstrate the explainability of our approach.
"
1812.03453,2020-03-24,"Asymptotic Filter Behavior for High-Frequency Expert Opinions in a
  Market with Gaussian Drift","  This paper investigates a financial market where stock returns depend on a
hidden Gaussian mean reverting drift process. Information on the drift is
obtained from returns and expert opinions in the form of noisy signals about
the current state of the drift arriving at the jump times of a homogeneous
Poisson process. Drift estimates are based on Kalman filter techniques and
described by the conditional mean and covariance matrix of the drift given the
observations. We study the filter asymptotics for increasing arrival intensity
of expert opinions and prove that the conditional mean is a consistent drift
estimator, it converges in the mean-square sense to the hidden drift. Thus, in
the limit as the arrival intensity goes to infinity investors have full
information about the drift.
"
1812.04603,2022-10-24,Game-Theoretic Optimal Portfolios for Jump Diffusions,"  This paper studies a two-person trading game in continuous time that
generalizes Garivaltis (2018) to allow for stock prices that both jump and
diffuse. Analogous to Bell and Cover (1988) in discrete time, the players start
by choosing fair randomizations of the initial dollar, by exchanging it for a
random wealth whose mean is at most 1. Each player then deposits the resulting
capital into some continuously-rebalanced portfolio that must be adhered to
over $[0,t]$. We solve the corresponding `investment $\phi$-game,' namely the
zero-sum game with payoff kernel
$\mathbb{E}[\phi\{\textbf{W}_1V_t(b)/(\textbf{W}_2V_t(c))\}]$, where
$\textbf{W}_i$ is player $i$'s fair randomization, $V_t(b)$ is the final wealth
that accrues to a one dollar deposit into the rebalancing rule $b$, and
$\phi(\bullet)$ is any increasing function meant to measure relative
performance. We show that the unique saddle point is for both players to use
the (leveraged) Kelly rule for jump diffusions, which is ordinarily defined by
maximizing the asymptotic almost-sure continuously-compounded capital growth
rate. Thus, the Kelly rule for jump diffusions is the correct behavior for
practically anybody who wants to outperform other traders (on any time frame)
with respect to practically any measure of relative performance.
"
1812.07635,2018-12-20,Portfolio Rebalancing under Uncertainty Using Meta-heuristic Algorithm,"  In this paper, we solve portfolio rebalancing problem when security returns
are represented by uncertain variables considering transaction costs. The
performance of the proposed model is studied using constant-proportion
portfolio insurance (CPPI) as rebalancing strategy. Numerical results showed
that uncertain parameters and different belief degrees will produce different
efficient frontiers, and affect the performance of the proposed model.
Moreover, CPPI strategy performs as an insurance mechanism and limits downside
risk in bear markets while it allows potential benefit in bull markets.
Finally, using a globally optimization solver and genetic algorithm (GA) for
solving the model, we concluded that the problem size is an important factor in
solving portfolio rebalancing problem with uncertain parameters and to gain
better results, it is recommended to use a meta-heuristic algorithm rather than
a global solver.
"
1812.10183,2019-10-29,Portfolio Optimization for Cointelated Pairs: SDEs vs. Machine Learning,"  With the recent rise of Machine Learning as a candidate to partially replace
classic Financial Mathematics methodologies, we investigate the performances of
both in solving the problem of dynamic portfolio optimization in
continuous-time, finite-horizon setting for a portfolio of two assets that are
intertwined.
  In Financial Mathematics approach we model the asset prices not via the
common approaches used in pairs trading such as a high correlation or
cointegration, but with the cointelation model that aims to reconcile both
short-term risk and long-term equilibrium. We maximize the overall P&L with
Financial Mathematics approach that dynamically switches between a
mean-variance optimal strategy and a power utility maximizing strategy. We use
a stochastic control formulation of the problem of power utility maximization
and solve numerically the resulting HJB equation with the Deep Galerkin method.
  We turn to Machine Learning for the same P&L maximization problem and use
clustering analysis to devise bands, combined with in-band optimization.
Although this approach is model agnostic, results obtained with data simulated
from the same cointelation model as FM give an edge to ML.
"
1901.01751,2019-04-02,"Generative Adversarial Networks for Financial Trading Strategies
  Fine-Tuning and Combination","  Systematic trading strategies are algorithmic procedures that allocate assets
aiming to optimize a certain performance criterion. To obtain an edge in a
highly competitive environment, the analyst needs to proper fine-tune its
strategy, or discover how to combine weak signals in novel alpha creating
manners. Both aspects, namely fine-tuning and combination, have been
extensively researched using several methods, but emerging techniques such as
Generative Adversarial Networks can have an impact into such aspects.
Therefore, our work proposes the use of Conditional Generative Adversarial
Networks (cGANs) for trading strategies calibration and aggregation. To this
purpose, we provide a full methodology on: (i) the training and selection of a
cGAN for time series data; (ii) how each sample is used for strategies
calibration; and (iii) how all generated samples can be used for ensemble
modelling. To provide evidence that our approach is well grounded, we have
designed an experiment with multiple trading strategies, encompassing 579
assets. We compared cGAN with an ensemble scheme and model validation methods,
both suited for time series. Our results suggest that cGANs are a suitable
alternative for strategies calibration and combination, providing
outperformance when the traditional techniques fail to generate any alpha.
"
1901.03030,2020-10-27,"Mean-variance portfolio selection under partial information with drift
  uncertainty","  In this paper, we study the mean-variance portfolio selection problem under
partial information with drift uncertainty. First we show that the market model
is complete even in this case while the information is not complete and the
drift is uncertain. Then, the optimal strategy based on partial information is
derived, which reduces to solving a related backward stochastic differential
equation (BSDE). Finally, we propose an efficient numerical scheme to
approximate the optimal portfolio that is the solution of the BSDE mentioned
above. Malliavin calculus and the particle representation play important roles
in this scheme.
"
1901.06309,2019-01-21,On a dividend problem with random funding,"  We consider a modification of the dividend maximization problem from ruin
theory. Based on a classical risk process we maximize the difference of
expected cumulated discounted dividends and total expected discounted
additional funding (subject to some proportional transaction costs). For
modelling dividends we use the common approach whereas for the funding
opportunity we use the jump times of another independent Poisson process at
which we choose an appropriate funding height. In case of exponentially
distributed claims we are able to determine an explicit solution to the problem
and derive an optimal strategy whose nature heavily depends on the size of the
transaction costs.
"
1901.08986,2019-01-28,"How the investor's risk preferences influence the optimal allocation in
  a credibilistic portfolio problem","  A classical portfolio theory deals with finding the optimal proportion in
which an agent invests a wealth in a risk-free asset and a probabilistic risky
asset. Formulating and solving the problem depend on how the risk is
represented and how, combined with the utility function defines a notion of
expected utility. In this paper the risk is a fuzzy variable and the notion of
expected utility is defined in the setting of Liu's credibility theory. Thus
the portfolio choice problem is formulated as an optimization problem in which
the objective function is a credibilistic expected utility. Different
approximation calculation formulas for the optimal allocation of the
credibilistic risky asset are proved. These formulas contain two types of
parameters: various credibilistic moments associated with fuzzy variables
(expected value, variance, skewness and kurtosis) and the risk aversion,
prudence and temperance indicators of the utility function.
"
1901.10771,2019-06-26,"Minimal Investment Risk with Cost and Return Constraints: A Replica
  Analysis","  Previous studies into the budget constraint of portfolio optimization
problems based on statistical mechanical informatics have not considered that
the purchase cost per unit of each asset is distinct. Moreover, the fact that
the optimal investment allocation differs depending on the size of investable
funds has also been neglected. In this paper, we approach the problem of
investment risk minimization using replica analysis. This problem imposes cost
and return constraints. We also derive the macroscopic theory indicated by the
optimal solution and confirm the validity of our proposed method through
numerical experiments.
"
1901.10989,2020-10-01,Equilibrium Asset Pricing with Transaction Costs,"  We study risk-sharing economies where heterogenous agents trade subject to
quadratic transaction costs. The corresponding equilibrium asset prices and
trading strategies are characterised by a system of nonlinear, fully-coupled
forward-backward stochastic differential equations. We show that a unique
solution generally exists provided that the agents' preferences are
sufficiently similar. In a benchmark specification with linear state dynamics,
the illiquidity discounts and liquidity premia observed empirically correspond
to a positive relationship between transaction costs and volatility.
"
1902.05710,2019-02-18,"Constrained Risk Budgeting Portfolios: Theory, Algorithms, Applications
  & Puzzles","  This article develops the theory of risk budgeting portfolios, when we would
like to impose weight constraints. It appears that the mathematical problem is
more complex than the traditional risk budgeting problem. The formulation of
the optimization program is particularly critical in order to determine the
right risk budgeting portfolio. We also show that numerical solutions can be
found using methods that are used in large-scale machine learning problems.
Indeed, we develop an algorithm that mixes the method of cyclical coordinate
descent (CCD), alternating direction method of multipliers (ADMM), proximal
operators and Dykstra's algorithm. This theoretical body is then applied to
some investment problems. In particular, we show how to dynamically control the
turnover of a risk parity portfolio and how to build smart beta portfolios
based on the ERC approach by improving the liquidity of the portfolio or
reducing the small cap bias. Finally, we highlight the importance of the
homogeneity property of risk measures and discuss the related scaling puzzle.
"
1902.06053,2020-01-17,Non-Stationary Dividend-Price Ratios,"  Dividend yields have been widely used in previous research to relate stock
market valuations to cash flow fundamentals. However, this approach relies on
the assumption that dividend yields are stationary. Due to the failure to
reject the hypothesis of a unit root in the classical dividend-price ratio for
the US stock market, Polimenis and Neokosmidis (2016) proposed the use of a
modified dividend price ratio (mdp) as the deviation between d and p from their
long run equilibrium, and showed that mdp provides substantially improved
forecasting results over the classical dp ratio. Here, we extend that paper by
performing multivariate regressions based on the Campbell-Shiller
approximation, by utilizing a dynamic econometric procedure to estimate the
modified dp, and by testing the modified ratios against reinvested
dividend-yields. By comparing the performance of mdp and dp in the period after
1965, we are not only able to enhance the robustness of the findings, but also
to debunk a possible false explanation that the enhanced mdp performance in
predicting future returns comes from a capacity to predict the risk-free return
component. Depending on whether one uses the recursive or population
methodology to measure the performance of mdp, the Out-of-Sample performance
gain is between 30% to 50%.
"
1902.06294,2019-02-19,Optimal dividends and capital injection under dividend restrictions,"  We study a singular stochastic control problem faced by the owner of an
insurance company that dynamically pays dividends and raises capital in the
presence of the restriction that the surplus process must be above a given
dividend payout barrier in order for dividend payments to be allowed.
Bankruptcy occurs if the surplus process becomes negative and there are
proportional costs for capital injection. We show that one of the following
strategies is optimal: (i) Pay dividends and inject capital in order to reflect
the surplus process at an upper barrier and at 0, implying bankruptcy never
occurs. (ii) Pay dividends in order to reflect the surplus process at an upper
barrier and never inject capital --- corresponding to absorption at 0 ---
implying bankruptcy occurs the first time the surplus reaches zero. We show
that if the costs of capital injection are low, then a sufficiently high
dividend payout barrier will change the optimal strategy from type (i) (without
bankruptcy) to type (ii) (with bankruptcy). Moreover, if the costs are high,
then the optimal strategy is of type (ii) regardless of the dividend payout
barrier. The uncontrolled surplus process is a Wiener process with drift.
"
1902.06505,2019-02-19,Options on CPPI with guaranteed minimum equity exposure,"  In the present paper we provide a two-step principal protection strategy
obtained by combining a modification of the Constant Proportion Portfolio
Insurance (CPPI) algorithm and a classical Option Based Portfolio Insurance
(OBPI) mechanism. Such a novel approach consists in assuming that the
percentage of wealth invested in stocks cannot go under a fixed level, called
guaranteed minimum equity exposure, and using such an adjusted CPPI portfolio
as the underlying of an option. The first stage ensures to overcome the so
called cash-in risk, typically related to a standard CPPI technique, while the
second one guarantees the equity market participation. To show the
effectiveness of our proposal we provide a detailed computational analysis
within the Heston-Vasicek framework, numerically comparing the evaluation of
the price of European plain vanilla options when the underlying is either a
purely risky asset, a standard CPPI portfolio and a CPPI with guaranteed
minimum equity exposure.
"
1902.06623,2019-12-03,"Model risk in mean-variance portfolio selection: an analytic solution to
  the worst-case approach","  In this paper we consider the worst-case model risk approach described in
Glasserman and Xu (2014). Portfolio selection with model risk can be a
challenging operational research problem. In particular, it presents an
additional optimisation compared to the classical one. We find the analytical
solution for the optimal mean-variance portfolio selection in the worst-case
scenario approach. In the minimum-variance case, we prove that the analytical
solution is significantly different from the one found numerically by
Glasserman and Xu (2014) and that model risk reduces to an estimation risk. A
detailed numerical example is provided.
"
1902.06883,2019-09-04,"Multiscale Asymptotic Analysis for Portfolio Optimization under
  Stochastic Environment","  Empirical studies indicate the presence of multi-scales in the volatility of
underlying assets: a fast-scale on the order of days and a slow-scale on the
order of months. In our previous works, we have studied the portfolio
optimization problem in a Markovian setting under each single scale, the slow
one in [Fouque and Hu, SIAM J. Control Optim., 55 (2017), 1990-2023], and the
fast one in [Hu, Proceedings of IEEE CDC 2018, accepted]. This paper is
dedicated to the analysis when the two scales coexist in a Markovian setting.
We study the terminal wealth utility maximization problem when the volatility
is driven by both fast- and slow-scale factors. We first propose a zeroth-order
strategy, and rigorously establish the first order approximation of the
associated problem value. This is done by analyzing the corresponding linear
partial differential equation (PDE) via regular and singular perturbation
techniques, as in the single-scale cases. Then, we show the asymptotic
optimality of our proposed strategy within a specific family of admissible
controls. Interestingly, we highlight that a pure PDE approach does not work in
the multi-scale case and, instead, we use the so-called epsilon-martingale
decomposition. This completes the analysis of portfolio optimization in both
fast mean-reverting and slowly-varying Markovian stochastic environments.
"
1902.07449,2019-02-21,Robust Asset Allocation for Robo-Advisors,"  In the last few years, the financial advisory industry has been impacted by
the emergence of digitalization and robo-advisors. This phenomenon affects
major financial services, including wealth management, employee savings plans,
asset managers, etc. Since the robo-advisory model is in its early stages, we
estimate that robo-advisors will help to manage around $1 trillion of assets in
2020 (OECD, 2017). And this trend is not going to stop with future generations,
who will live in a technology-driven and social media-based world. In the
investment industry, robo-advisors face different challenges: client profiling,
customization, asset pooling, liability constraints, etc. In its primary sense,
robo-advisory is a term for defining automated portfolio management. This
includes automated trading and rebalancing, but also automated portfolio
allocation. And this last issue is certainly the most important challenge for
robo-advisory over the next five years. Today, in many robo-advisors, asset
allocation is rather human-based and very far from being computer-based. The
reason is that portfolio optimization is a very difficult task, and can lead to
optimized mathematical solutions that are not optimal from a financial point of
view (Michaud, 1989). The big challenge for robo-advisors is therefore to be
able to optimize and rebalance hundreds of optimal portfolios without human
intervention. In this paper, we show that the mean-variance optimization
approach is mainly driven by arbitrage factors that are related to the concept
of hedging portfolios. This is why regularization and sparsity are necessary to
define robust asset allocation. However, this mathematical framework is more
complex and requires understanding how norm penalties impacts portfolio
optimization. From a numerical point of view, it also requires the
implementation of non-traditional algorithms based on ADMM methods.
"
1902.10044,2019-11-25,Fair Estimation of Capital Risk Allocation,"  In this paper we develop a novel methodology for estimation of risk capital
allocation. The methodology is rooted in the theory of risk measures. We work
within a general, but tractable class of law-invariant coherent risk measures,
with a particular focus on expected shortfall. We introduce the concept of fair
capital allocations and provide explicit formulae for fair capital allocations
in case when the constituents of the risky portfolio are jointly normally
distributed. The main focus of the paper is on the problem of approximating
fair portfolio allocations in the case of not fully known law of the portfolio
constituents. We define and study the concepts of fair allocation estimators
and asymptotically fair allocation estimators. A substantial part of our study
is devoted to the problem of estimating fair risk allocations for expected
shortfall. We study this problem under normality as well as in a nonparametric
setup. We derive several estimators, and prove their fairness and/or asymptotic
fairness. Last, but not least, we propose two backtesting methodologies that
are oriented at assessing the performance of the allocation estimation
procedure. The paper closes with a substantial numerical study of the subject.
"
1902.10849,2019-03-01,"A novel dynamic asset allocation system using Feature Saliency Hidden
  Markov models for smart beta investing","  The financial crisis of 2008 generated interest in more transparent,
rules-based strategies for portfolio construction, with Smart beta strategies
emerging as a trend among institutional investors. While they perform well in
the long run, these strategies often suffer from severe short-term drawdown
(peak-to-trough decline) with fluctuating performance across cycles. To address
cyclicality and underperformance, we build a dynamic asset allocation system
using Hidden Markov Models (HMMs). We test our system across multiple
combinations of smart beta strategies and the resulting portfolios show an
improvement in risk-adjusted returns, especially on more return oriented
portfolios (up to 50$\%$ in excess of market annually). In addition, we propose
a novel smart beta allocation system based on the Feature Saliency HMM (FSHMM)
algorithm that performs feature selection simultaneously with the training of
the HMM, to improve regime identification. We evaluate our systematic trading
system with real life assets using MSCI indices; further, the results (up to
60$\%$ in excess of market annually) show model performance improvement with
respect to portfolios built using full feature HMMs.
"
1903.00590,2019-03-06,"Non-Parametric Robust Model Risk Measurement with Path-Dependent Loss
  Functions","  Understanding and measuring model risk is important to financial
practitioners. However, there lacks a non-parametric approach to model risk
quantification in a dynamic setting and with path-dependent losses. We propose
a complete theory generalizing the relative-entropic approach by Glasserman and
Xu to the dynamic case under any $f$-divergence. It provides an unified
treatment for measuring both the worst-case risk and the $f$-divergence budget
that originate from the model uncertainty of an underlying state process.
"
1903.00829,2022-10-24,Cover's Rebalancing Option With Discrete Hindsight Optimization,"  We study T. Cover's rebalancing option (Ordentlich and Cover 1998) under
discrete hindsight optimization in continuous time. The payoff in question is
equal to the final wealth that would have accrued to a $\$1$ deposit into the
best of some finite set of (perhaps levered) rebalancing rules determined in
hindsight. A rebalancing rule (or fixed-fraction betting scheme) amounts to
fixing an asset allocation (i.e. $200\%$ stocks and $-100\%$ bonds) and then
continuously executing rebalancing trades to counteract allocation drift.
Restricting the hindsight optimization to a small number of rebalancing rules
(i.e. 2) has some advantages over the pioneering approach taken by Cover $\&$
Company in their brilliant theory of universal portfolios (1986, 1991, 1996,
1998), where one's on-line trading performance is benchmarked relative to the
final wealth of the best unlevered rebalancing rule of any kind in hindsight.
Our approach lets practitioners express an a priori view that one of the
favored asset allocations (""bets"") $b\in\{b_1,...,b_n\}$ will turn out to have
performed spectacularly well in hindsight. In limiting our robustness to some
discrete set of asset allocations (rather than all possible asset allocations)
we reduce the price of the rebalancing option and guarantee to achieve a
correspondingly higher percentage of the hindsight-optimized wealth at the end
of the planning period. A practitioner who lives to delta-hedge this variant of
Cover's rebalancing option through several decades is guaranteed to see the day
that his realized compound-annual capital growth rate is very close to that of
the best $b_i$ in hindsight. Hence the point of the rock-bottom option price.
"
1903.04257,2021-07-05,Optimal Entry and Consumption under Habit Formation,"  This paper studies a composite problem involving the decision making of the
optimal entry time and dynamic consumption afterwards. In stage-1, the investor
has access to full market information subjecting to some information costs and
needs to choose an optimal stopping time to initiate stage-2; in stage-2, the
investor terminates the costly full information acquisition and starts dynamic
investment and consumption under partial observations of free public stock
prices. The habit formation preference is employed, in which the past
consumption affects the investor's current decisions. By using the stochastic
Perron's method, the value function of the composite problem is proved to be
the unique viscosity solution of some variational inequalities.
"
1903.04841,2019-03-13,Financial Applications of Gaussian Processes and Bayesian Optimization,"  In the last five years, the financial industry has been impacted by the
emergence of digitalization and machine learning. In this article, we explore
two methods that have undergone rapid development in recent years: Gaussian
processes and Bayesian optimization. Gaussian processes can be seen as a
generalization of Gaussian random vectors and are associated with the
development of kernel methods. Bayesian optimization is an approach for
performing derivative-free global optimization in a small dimension, and uses
Gaussian processes to locate the global maximum of a black-box function. The
first part of the article reviews these two tools and shows how they are
connected. In particular, we focus on the Gaussian process regression, which is
the core of Bayesian machine learning, and the issue of hyperparameter
selection. The second part is dedicated to two financial applications. We first
consider the modeling of the term structure of interest rates. More precisely,
we test the fitting method and compare the GP prediction and the random walk
model. The second application is the construction of trend-following
strategies, in particular the online estimation of trend and covariance
windows.
"
1903.05990,2019-11-25,Modern tontine with bequest: innovation in pooled annuity products,"  We introduce a new pension product that offers retirees the opportunity for a
lifelong income and a bequest for their estate. Based on a tontine mechanism,
the product divides pension savings between a tontine account and a bequest
account. The tontine account is given up to a tontine pool upon death while the
bequest account value is paid to the retiree's estate. The values of these two
accounts are continuously re-balanced to the same proportion, which is the key
feature of our new product. Our main research question about the new product is
what proportion of pension savings should a retiree allocate to the tontine
account. Under a power utility function, we show that more risk averse retirees
allocate a fairly stable proportion of their pension savings to the tontine
account, regardless of the strength of their bequest motive. The proportion
declines as the retiree becomes less risk averse for a while. However, for the
least risk averse retirees, a high proportion of their pension savings is
optimally allocated to the tontine account. This surprising result is explained
by the least risk averse retirees seeking the potentially high value of the
bequest account at very old ages.
"
1903.06033,2019-04-04,Altcoin-Bitcoin Arbitrage,"  We give an algorithm and source code for a cryptoasset statistical arbitrage
alpha based on a mean-reversion effect driven by the leading momentum factor in
cryptoasset returns discussed in https://ssrn.com/abstract=3245641. Using
empirical data, we identify the cross-section of cryptoassets for which this
altcoin-Bitcoin arbitrage alpha is significant and discuss it in the context of
liquidity considerations as well as its implications for cryptoasset trading.
"
1903.06230,2019-03-18,Dynamic Energy Management,"  We present a unified method, based on convex optimization, for managing the
power produced and consumed by a network of devices over time. We start with
the simple setting of optimizing power flows in a static network, and then
proceed to the case of optimizing dynamic power flows, i.e., power flows that
change with time over a horizon. We leverage this to develop a real-time
control strategy, model predictive control, which at each time step solves a
dynamic power flow optimization problem, using forecasts of future quantities
such as demands, capacities, or prices, to choose the current power flow
values. Finally, we consider a useful extension of model predictive control
that explicitly accounts for uncertainty in the forecasts. We mirror our
framework with an object-oriented software implementation, an open-source
Python library for planning and controlling power flows at any scale. We
demonstrate our method with various examples. Appendices give more detail about
the package, and describe some basic but very effective methods for
constructing forecasts from historical data.
"
1903.06334,2019-04-10,Machine Learning Risk Models,"  We give an explicit algorithm and source code for constructing risk models
based on machine learning techniques. The resultant covariance matrices are not
factor models. Based on empirical backtests, we compare the performance of
these machine learning risk models to other constructions, including
statistical risk models, risk models based on fundamental industry
classifications, and also those utilizing multilevel clustering based industry
classifications.
"
1903.06632,2019-03-18,"Designing an Optimal Portfolio for Iran's Stock Market with Genetic
  Algorithm using Neural Network Prediction of Risk and Return Stocks","  Optimal capital allocation between different assets is an important financial
problem, which is generally framed as the portfolio optimization problem.
General models include the single-period and multi-period cases. The
traditional Mean-Variance model introduced by Harry Markowitz has been the
basis of many models used to solve the portfolio optimization problem. The
overall goal is to achieve the highest return and lowest risk in portfolio
optimization problems. In this paper, we will present an optimal portfolio
based the Markowitz Mean-Variance-Skewness with weight constraints model for
short-term investment opportunities in Iran's stock market. We will use a
neural network based predictor to predict the stock returns and measure the
risk of stocks based on the prediction errors in the neural network. We will
perform a series of experiments on our portfolio optimization model with the
real data from Iran's stock market indices including Bank, Insurance,
Investment, Petroleum Products and Chemicals indices. Finally, 8 different
portfolios with low, medium and high risks for different type of investors
(risk-averse or risk taker) using genetic algorithm will be designed and
analyzed.
"
1903.06912,2020-06-23,Semimartingale theory of monotone mean--variance portfolio allocation,"  We study dynamic optimal portfolio allocation for monotone mean--variance
preferences in a general semimartingale model. Armed with new results in this
area we revisit the work of Cui, Li, Wang and Zhu (2012, MAFI) and fully
characterize the circumstances under which one can set aside a non-negative
cash flow while simultaneously improving the mean--variance efficiency of the
left-over wealth. The paper analyzes, for the first time, the monotone hull of
the Sharpe ratio and highlights its relevance to the problem at hand.
"
1903.06928,2019-03-19,Active and Passive Portfolio Management with Latent Factors,"  We address a portfolio selection problem that combines active
(outperformance) and passive (tracking) objectives using techniques from convex
analysis. We assume a general semimartingale market model where the assets'
growth rate processes are driven by a latent factor. Using techniques from
convex analysis we obtain a closed-form solution for the optimal portfolio and
provide a theorem establishing its uniqueness. The motivation for incorporating
latent factors is to achieve improved growth rate estimation, an otherwise
notoriously difficult task. To this end, we focus on a model where growth rates
are driven by an unobservable Markov chain. The solution in this case requires
a filtering step to obtain posterior probabilities for the state of the Markov
chain from asset price information, which are subsequently used to find the
optimal allocation. We show the optimal strategy is the posterior average of
the optimal strategies the investor would have held in each state assuming the
Markov chain remains in that state. Finally, we implement a number of
historical backtests to demonstrate the performance of the optimal portfolio.
"
1903.08156,2019-03-21,Behavioural investors in conic market models,"  We treat a fairly broad class of financial models which includes markets with
proportional transaction costs. We consider an investor with cumulative
prospect theory preferences and a non-negativity constraint on portfolio
wealth. The existence of an optimal strategy is shown in this context in a
class of generalized strategies.
"
1903.08957,2019-03-22,"Expected exponential utility maximization of insurers with a general
  diffusion factor model : The complete market case","  In this paper, we consider the problem of optimal investment by an insurer.
The insurer invests in a market consisting of a bank account and $m$ risky
assets. The mean returns and volatilities of the risky assets depend
nonlinearly on economic factors that are formulated as the solutions of general
stochastic differential equations. The wealth of the insurer is described by a
Cram\'er--Lundberg process, and the insurer preferences are exponential.
Adapting a dynamic programming approach, we derive Hamilton--Jacobi--Bellman
(HJB) equation. And, we prove the unique solvability of HJB equation. In
addition, the optimal strategy is also obtained using the coupled forward and
backward stochastic differential equations (FBSDEs). Finally, proving the
verification theorem, we construct the optimal strategy.
"
1903.10065,2019-03-26,"Dynamic intertemporal utility optimization by means of Riccati
  transformation of Hamilton-Jacobi Bellman equation","  In this paper we investigate a dynamic stochastic portfolio optimization
problem involving both the expected terminal utility and intertemporal utility
maximization. We solve the problem by means of a solution to a fully nonlinear
evolutionary Hamilton-Jacobi-Bellman (HJB) equation. We propose the so-called
Riccati method for transformation of the fully nonlinear HJB equation into a
quasi-linear parabolic equation with non-local terms involving the
intertemporal utility function. As a numerical method we propose a
semi-implicit scheme in time based on a finite volume approximation in the
spatial variable. By analyzing an explicit traveling wave solution we show that
the numerical method is of the second experimental order of convergence. As a
practical application we compute optimal strategies for a portfolio investment
problem motivated by market financial data of German DAX 30 Index and show the
effect of considering intertemporal utility on optimal portfolio selection.
"
1903.10454,2021-01-19,Portfolio optimization with two coherent risk measures,"  We provide analytical results for a static portfolio optimization problem
with two coherent risk measures. The use of two risk measures is motivated by
joint decision-making for portfolio selection where the risk perception of the
portfolio manager is of primary concern, hence, it appears in the objective
function, and the risk perception of an external authority needs to be taken
into account as well, which appears in the form of a risk constraint. The
problem covers the risk minimization problem with an expected return constraint
and the expected return maximization problem with a risk constraint, as special
cases. For the general case of an arbitrary joint distribution for the asset
returns, under certain conditions, we characterize the optimal portfolio as the
optimal Lagrange multiplier associated to an equality-constrained dual problem.
Then, we consider the special case of Gaussian returns for which it is possible
to identify all cases where an optimal solution exists and to give an explicit
formula for the optimal portfolio whenever it exists.
"
1904.01745,2019-04-04,"Forward Rank-Dependent Performance Criteria: Time-Consistent Investment
  Under Probability Distortion","  We introduce the concept of forward rank-dependent performance processes,
extending the original notion to forward criteria that incorporate probability
distortions. A fundamental challenge is how to reconcile the time-consistent
nature of forward performance criteria with the time-inconsistency stemming
from probability distortions. For this, we first propose two distinct
definitions, one based on the preservation of performance value and the other
on the time-consistency of policies and, in turn, establish their equivalence.
We then fully characterize the viable class of probability distortion
processes, providing a bifurcation-type result. Specifically, it is either the
case that the probability distortions are degenerate in the sense that the
investor would never invest in the risky assets, or the marginal probability
distortion equals to a normalized power of the quantile function of the pricing
kernel. We also characterize the optimal wealth process, whose structure
motivates the introduction of a new, distorted measure and a related market. We
then build a striking correspondence between the forward rank-dependent
criteria in the original market and forward criteria without probability
distortions in the auxiliary market. This connection also provides a direct
construction method for forward rank-dependent criteria. A byproduct of our
work are some new results on the so-called dynamic utilities and on
time-inconsistent problems in the classical (backward) setting.
"
1904.04973,2019-06-11,"Model-Free Reinforcement Learning for Financial Portfolios: A Brief
  Survey","  Financial portfolio management is one of the problems that are most
frequently encountered in the investment industry. Nevertheless, it is not
widely recognized that both Kelly Criterion and Risk Parity collapse into Mean
Variance under some conditions, which implies that a universal solution to the
portfolio optimization problem could potentially exist. In fact, the process of
sequential computation of optimal component weights that maximize the
portfolio's expected return subject to a certain risk budget can be
reformulated as a discrete-time Markov Decision Process (MDP) and hence as a
stochastic optimal control, where the system being controlled is a portfolio
consisting of multiple investment components, and the control is its component
weights. Consequently, the problem could be solved using model-free
Reinforcement Learning (RL) without knowing specific component dynamics. By
examining existing methods of both value-based and policy-based model-free RL
for the portfolio optimization problem, we identify some of the key unresolved
questions and difficulties facing today's portfolio managers of applying
model-free RL to their investment portfolios.
"
1904.06628,2019-09-04,Nash Bargaining Over Margin Loans to Kelly Gamblers,"  I derive practical formulas for optimal arrangements between sophisticated
stock market investors (namely, continuous-time Kelly gamblers or, more
generally, CRRA investors) and the brokers who lend them cash for leveraged
bets on a high Sharpe asset (i.e. the market portfolio). Rather than, say, the
broker posting a monopoly price for margin loans, the gambler agrees to use a
greater quantity of margin debt than he otherwise would in exchange for an
interest rate that is lower than the broker would otherwise post. The gambler
thereby attains a higher asymptotic capital growth rate and the broker enjoys a
greater rate of intermediation profit than would obtain under non-cooperation.
If the threat point represents a vicious breakdown of negotiations (resulting
in zero margin loans), then we get an elegant rule of thumb:
$r_L^*=(3/4)r+(1/4)(\nu-\sigma^2/2)$, where $r$ is the broker's cost of funds,
$\nu$ is the compound-annual growth rate of the market index, and $\sigma$ is
the annual volatility. We show that, regardless of the particular threat point,
the gambler will negotiate to size his bets as if he himself could borrow at
the broker's call rate.
"
1904.08925,2019-04-22,"The impact of proportional transaction costs on systematically generated
  portfolios","  The effect of proportional transaction costs on systematically generated
portfolios is studied empirically. The performance of several portfolios (the
index tracking portfolio, the equally-weighted portfolio, the entropy-weighted
portfolio, and the diversity-weighted portfolio) in the presence of dividends
and transaction costs is examined under different configurations involving the
trading frequency, constituent list size, and renewing frequency. Moreover, a
method to smooth transaction costs is proposed.
"
1904.10250,2020-01-08,Best Portfolio Management Strategies For Synthetic and Real Assets,"  Managing investment portfolios is an old and well know problem in multiple
fields including financial mathematics and financial engineering as well as
econometrics and econophysics. Multiple different concepts and theories were
used so far to describe methods of handling with financial assets, including
differential equations, stochastic calculus and advanced statistics. In this
paper, using a set of tools from the probability theory, various strategies of
building financial portfolios are analysed in different market conditions. A
special attention is given to several realisations of a so called balanced
portfolio, which is rooted in the natural ""buy-low-sell-high"" principle.
Results show that there is no universal strategy, because they perform
differently in different circumstances (e.g. for varying transaction costs).
Moreover, the planned time of investment may also have a significant impact on
the profitability of certain strategies. All methods have been tested with both
simulated trajectories and real data from the Polish stock market.
"
1904.11392,2019-05-07,"Continuous-Time Mean-Variance Portfolio Selection: A Reinforcement
  Learning Framework","  We approach the continuous-time mean-variance (MV) portfolio selection with
reinforcement learning (RL). The problem is to achieve the best tradeoff
between exploration and exploitation, and is formulated as an
entropy-regularized, relaxed stochastic control problem. We prove that the
optimal feedback policy for this problem must be Gaussian, with time-decaying
variance. We then establish connections between the entropy-regularized MV and
the classical MV, including the solvability equivalence and the convergence as
exploration weighting parameter decays to zero. Finally, we prove a policy
improvement theorem, based on which we devise an implementable RL algorithm. We
find that our algorithm outperforms both an adaptive control based method and a
deep neural networks based algorithm by a large margin in our simulations.
"
1904.12442,2020-01-30,Mean-variance portfolio selection under Volterra Heston model,"  Motivated by empirical evidence for rough volatility models, this paper
investigates continuous-time mean-variance (MV) portfolio selection under the
Volterra Heston model. Due to the non-Markovian and non-semimartingale nature
of the model, classic stochastic optimal control frameworks are not directly
applicable to the associated optimization problem. By constructing an auxiliary
stochastic process, we obtain the optimal investment strategy, which depends on
the solution to a Riccati-Volterra equation. The MV efficient frontier is shown
to maintain a quadratic curve. Numerical studies show that both roughness and
volatility of volatility materially affect the optimal strategy.
"
1905.04821,2020-04-14,Optimal multi-asset trading with linear costs: a mean-field approach,"  Optimal multi-asset trading with Markovian predictors is well understood in
the case of quadratic transaction costs, but remains intractable when these
costs are $L_1$. We present a mean-field approach that reduces the multi-asset
problem to a single-asset problem, with an effective predictor that includes a
risk averse component. We obtain a simple approximate solution in the case of
Ornstein-Uhlenbeck predictors and maximum position constraints. The optimal
strategy is of the ""bang-bang"" type similar to that obtained in [de Lataillade
et al., 2012]. When the risk aversion parameter is small, we find that the
trading threshold is an affine function of the instantaneous global position,
with a slope coefficient that we compute exactly. We relate the risk aversion
parameter to the desired target risk and provide numerical simulations that
support our analytical results.
"
1905.04842,2019-05-14,"A Stock Selection Method Based on Earning Yield Forecast Using Sequence
  Prediction Models","  Long-term investors, different from short-term traders, focus on examining
the underlying forces that affect the well-being of a company. They rely on
fundamental analysis which attempts to measure the intrinsic value an equity.
Quantitative investment researchers have identified some value factors to
determine the cost of investment for a stock and compare different stocks. This
paper proposes using sequence prediction models to forecast a value factor-the
earning yield (EBIT/EV) of a company for stock selection. Two advanced sequence
prediction models-Long Short-term Memory (LSTM) and Gated Recurrent Unit (GRU)
networks are studied. These two models can overcome the inherent problems of a
standard Recurrent Neural Network, i.e., vanishing and exploding gradients.
This paper firstly introduces the theories of the networks. And then elaborates
the workflow of stock pool creation, feature selection, data structuring, model
setup and model evaluation. The LSTM and GRU models demonstrate superior
performance of forecast accuracy over a traditional Feedforward Neural Network
model. The GRU model slightly outperformed the LSTM model.
"
1905.05023,2019-05-14,"Avoiding Backtesting Overfitting by Covariance-Penalties: an empirical
  investigation of the ordinary and total least squares cases","  Systematic trading strategies are rule-based procedures which choose
portfolios and allocate assets. In order to attain certain desired return
profiles, quantitative strategists must determine a large array of trading
parameters. Backtesting, the attempt to identify the appropriate parameters
using historical data available, has been highly criticized due to the
abundance of misleading results. Hence, there is an increasing interest in
devising procedures for the assessment and comparison of strategies, that is,
devising schemes for preventing what is known as backtesting overfitting. So
far, many financial researchers have proposed different ways to tackle this
problem that can be broadly categorised in three types: Data Snooping,
Overestimated Performance, and Cross-Validation Evaluation. In this paper, we
propose a new approach to dealing with financial overfitting, a
Covariance-Penalty Correction, in which a risk metric is lowered given the
number of parameters and data used to underpins a trading strategy. We outlined
the foundation and main results behind the Covariance-Penalty correction for
trading strategies. After that, we pursue an empirical investigation, comparing
its performance with some other approaches in the realm of Covariance-Penalties
across more than 1300 assets, using Ordinary and Total Least Squares. Our
results suggest that Covariance-Penalties are a suitable procedure to avoid
Backtesting Overfitting, and Total Least Squares provides superior performance
when compared to Ordinary Least Squares.
"
1905.05371,2019-11-20,Merton's portfolio problem under Volterra Heston model,"  This paper investigates Merton's portfolio problem in a rough stochastic
environment described by Volterra Heston model. The model has a non-Markovian
and non-semimartingale structure. By considering an auxiliary random process,
we solve the portfolio optimization problem with the martingale optimality
principle. Optimal strategies for power and exponential utilities are derived
in semi-closed form solutions depending on the respective Riccati-Volterra
equations. We numerically examine the relationship between investment demand
and volatility roughness.
"
1905.05841,2019-05-16,"Efficient computation of mean reverting portfolios using cyclical
  coordinate descent","  The econometric challenge of finding sparse mean reverting portfolios based
on a subset of a large number of assets is well known. Many current
state-of-the-art approaches fall into the field of co-integration theory, where
the problem is phrased in terms of an eigenvector problem with sparsity
constraint. Although a number of approximate solutions have been proposed to
solve this NP-hard problem, all are based on relatively simple models and are
limited in their scalability. In this paper we leverage information obtained
from a heterogeneous simultaneous graphical dynamic linear model (H-SGDLM) and
propose a novel formulation of the mean reversion problem, which is phrased in
terms of a quasi-convex minimisation with a normalisation constraint. This new
formulation allows us to employ a cyclical coordinate descent algorithm for
efficiently computing an exact sparse solution, even in a large universe of
assets, while the use of H-SGDLM data allows us to easily control the required
level of sparsity. We demonstrate the flexibility, speed and scalability of the
proposed approach on S\&P$500$, FX and ETF futures data.
"
1905.07886,2020-11-17,"Conformal Prediction Interval Estimations with an Application to
  Day-Ahead and Intraday Power Markets","  We discuss a concept denoted as Conformal Prediction (CP) in this paper.
While initially stemming from the world of machine learning, it was never
applied or analyzed in the context of short-term electricity price forecasting.
Therefore, we elaborate the aspects that render Conformal Prediction worthwhile
to know and explain why its simple yet very efficient idea has worked in other
fields of application and why its characteristics are promising for short-term
power applications as well. We compare its performance with different
state-of-the-art electricity price forecasting models such as quantile
regression averaging (QRA) in an empirical out-of-sample study for three
short-term electricity time series. We combine Conformal Prediction with
various underlying point forecast models to demonstrate its versatility and
behavior under changing conditions. Our findings suggest that Conformal
Prediction yields sharp and reliable prediction intervals in short-term power
markets. We further inspect the effect each of Conformal Prediction's model
components has and provide a path-based guideline on how to find the best CP
model for each market.
"
1905.08004,2021-07-28,"Risk-Sensitive Credit Portfolio Optimization under Partial Information
  and Contagion Risk","  This paper investigates the finite horizon risk-sensitive portfolio
optimization in a regime-switching credit market with physical and
information-induced default contagion. It is assumed that the underlying
regime-switching process has countable states and is unobservable. The
stochastic control problem is formulated under partial observations of asset
prices and sequential default events. By establishing a martingale
representation theorem based on incomplete and phasing out filtration, we
connect the control problem to a quadratic BSDE with jumps, in which the driver
term is non-standard and carries the conditional filter as an
infinite-dimensional parameter. By proposing some truncation techniques and
proving a uniform a priori estimates, we obtain the existence of a solution to
the BSDE using the convergence of solutions associated to some truncated BSDEs.
The verification theorem can be concluded with the aid of our BSDE results,
which in turn yields the uniqueness of the solution to the BSDE.
"
1906.00573,2019-12-10,Conditional inference on the asset with maximum Sharpe ratio,"  We apply the procedure of Lee et al. to the problem of performing inference
on the signal-noise ratio of the asset which displays maximum sample Sharpe
ratio over a set of possibly correlated assets. We find a multivariate analogue
of the commonly used approximate standard error of the Sharpe ratio to use in
this conditional estimation procedure. We also consider several alternative
procedures, including the simple Bonferroni correction for multiple hypothesis
testing, which we fix for the case of positive common correlation among assets,
the chi-bar square test against one-sided alternatives, Follman's test, and
Hansen's asymptotic adjustments.
  Testing indicates the conditional inference procedure achieves nominal type I
rate, and does not appear to suffer from non-normality of returns. The
conditional estimation test has low power under the alternative where there is
little spread in the signal-noise ratios of the assets, and high power under
the alternative where a single asset has high signal-noise ratio. Unlike the
alternative procedures, it appears to enjoy rejection probabilities montonic in
the signal-noise ratio of the selected asset.
"
1906.00920,2019-09-23,Optimising portfolio diversification and dimensionality,"  A new framework for portfolio diversification is introduced which goes beyond
the classical mean-variance approach and portfolio allocation strategies such
as risk parity. It is based on a novel concept called portfolio dimensionality
that connects diversification to the non-Gaussianity of portfolio returns and
can typically be defined in terms of the ratio of risk measures which are
homogenous functions of equal degree. The latter arises naturally due to our
requirement that diversification measures should be leverage invariant. We
introduce this new framework and argue the benefits relative to existing
measures of diversification in the literature, before addressing the question
of optimizing diversification or, equivalently, dimensionality. Maximising
portfolio dimensionality leads to highly non-trivial optimization problems with
objective functions which are typically non-convex and potentially have
multiple local optima. Two complementary global optimization algorithms are
thus presented. For problems of moderate size and more akin to asset allocation
problems, a deterministic Branch and Bound algorithm is developed, whereas for
problems of larger size a stochastic global optimization algorithm based on
Gradient Langevin Dynamics is given. We demonstrate analytically and through
numerical experiments that the framework reflects the desired properties often
discussed in the literature.
"
1906.00946,2022-10-24,The Laws of Motion of the Broker Call Rate in the United States,"  In this paper, which is the third installment of the author's trilogy on
margin loan pricing, we analyze $1,367$ monthly observations of the U.S. broker
call money rate, which is the interest rate at which stock brokers can borrow
to fund their margin loans to retail clients. We describe the basic features
and mean-reverting behavior of this series and juxtapose the
empirically-derived laws of motion with the author's prior theories of margin
loan pricing (Garivaltis 2019a-b). This allows us to derive stochastic
differential equations that govern the evolution of the margin loan interest
rate and the leverage ratios of sophisticated brokerage clients (namely,
continuous time Kelly gamblers). Finally, we apply Merton's (1974) arbitrage
theory of corporate liability pricing to study theoretical constraints on the
risk premia that could be generated in the market for call money. Apparently,
if there is no arbitrage in the U.S. financial markets, the implication is that
the total volume of call loans must constitute north of $70\%$ of the value of
all leveraged portfolios.
"
1906.01025,2022-10-24,Two Resolutions of the Margin Loan Pricing Puzzle,"  This paper supplies two possible resolutions of Fortune's (2000) margin-loan
pricing puzzle. Fortune (2000) noted that the margin loan interest rates
charged by stock brokers are very high in relation to the actual (low) credit
risk and the cost of funds. If we live in the Black-Scholes world, the brokers
are presumably making arbitrage profits by shorting dynamically precise amounts
of their clients' portfolios. First, we extend Fortune's (2000) application of
Merton's (1974) no-arbitrage approach to allow for brokers that can only revise
their hedges finitely many times during the term of the loan. We show that
extremely small differences in the revision frequency can easily explain the
observed variation in margin loan pricing. In fact, four additional revisions
per three-day period serve to explain all of the currently observed
heterogeneity. Second, we study monopolistic (or oligopolistic) margin loan
pricing by brokers whose clients are continuous-time Kelly gamblers. The broker
solves a general stochastic control problem that yields simple and pleasant
formulas for the optimal interest rate and the net interest margin. If the
author owned a brokerage, he would charge an interest rate of
$(r+\nu)/2-\sigma^2/4$, where $r$ is the cost of funds, $\nu$ is the
compound-annual growth rate of the S&P 500 index, and $\sigma$ is the
volatility.
"
1906.01427,2019-06-05,Optimal Dynamic Strategies on Gaussian Returns,"  Dynamic trading strategies, in the spirit of trend-following or
mean-reversion, represent an only partly understood but lucrative and pervasive
area of modern finance. Assuming Gaussian returns and Gaussian dynamic weights
or signals, (e.g., linear filters of past returns, such as simple moving
averages, exponential weighted moving averages, forecasts from ARIMA models),
we are able to derive closed-form expressions for the first four moments of the
strategy's returns, in terms of correlations between the random signals and
unknown future returns. By allowing for randomness in the asset-allocation and
modelling the interaction of strategy weights with returns, we demonstrate that
positive skewness and excess kurtosis are essential components of all positive
Sharpe dynamic strategies, which is generally observed empirically; demonstrate
that total least squares (TLS) or orthogonal least squares is more appropriate
than OLS for maximizing the Sharpe ratio, while canonical correlation analysis
(CCA) is similarly appropriate for the multi-asset case; derive standard errors
on Sharpe ratios which are tighter than the commonly used standard errors from
Lo; and derive standard errors on the skewness and kurtosis of strategies,
apparently new results. We demonstrate these results are applicable
asymptotically for a wide range of stationary time-series.
"
1906.01981,2020-09-22,Understanding Distributional Ambiguity via Non-robust Chance Constraint,"  This paper provides a non-robust interpretation of the distributionally
robust optimization (DRO) problem by relating the distributional uncertainties
to the chance probabilities. Our analysis allows a decision-maker to interpret
the size of the ambiguity set, which is often lack of business meaning, through
the chance parameters constraining the objective function. We first show that,
for general $\phi$-divergences, a DRO problem is asymptotically equivalent to a
class of mean-deviation problems. These mean-deviation problems are not subject
to uncertain distributions, and the ambiguity radius in the original DRO
problem now plays the role of controlling the risk preference of the
decision-maker. We then demonstrate that a DRO problem can be cast as a
chance-constrained optimization (CCO) problem when a boundedness constraint is
added to the decision variables. Without the boundedness constraint, the CCO
problem is shown to perform uniformly better than the DRO problem, irrespective
of the radius of the ambiguity set, the choice of the divergence measure, or
the tail heaviness of the center distribution. Thanks to our high-order
expansion result, a notable feature of our analysis is that it applies to
divergence measures that accommodate well heavy tail distributions such as the
student $t$-distribution and the lognormal distribution, besides the
widely-used Kullback-Leibler (KL) divergence, which requires the distribution
of the objective function to be exponentially bounded. Using the portfolio
selection problem as an example, our comprehensive testings on multivariate
heavy-tail datasets, both synthetic and real-world, shows that this
business-interpretation approach is indeed useful and insightful.
"
1906.02216,2022-10-24,Game-Theoretic Optimal Portfolios in Continuous Time,"  We consider a two-person trading game in continuous time whereby each player
chooses a constant rebalancing rule $b$ that he must adhere to over $[0,t]$. If
$V_t(b)$ denotes the final wealth of the rebalancing rule $b$, then Player 1
(the `numerator player') picks $b$ so as to maximize
$\mathbb{E}[V_t(b)/V_t(c)]$, while Player 2 (the `denominator player') picks
$c$ so as to minimize it. In the unique Nash equilibrium, both players use the
continuous-time Kelly rule $b^*=c^*=\Sigma^{-1}(\mu-r\textbf{1})$, where
$\Sigma$ is the covariance of instantaneous returns per unit time, $\mu$ is the
drift vector of the stock market, and $\textbf{1}$ is a vector of ones. Thus,
even over very short intervals of time $[0,t]$, the desire to perform well
relative to other traders leads one to adopt the Kelly rule, which is
ordinarily derived by maximizing the asymptotic exponential growth rate of
wealth. Hence, we find agreement with Bell and Cover's (1988) result in
discrete time.
"
1906.05187,2019-06-13,The Case for Long-Only Agnostic Allocation Portfolios,"  We advocate the use of Agnostic Allocation for the construction of long-only
portfolios of stocks. We show that Agnostic Allocation Portfolios (AAPs) are a
special member of a family of risk-based portfolios that are able to mitigate
certain extreme features (excess concentration, high turnover, strong exposure
to low-risk factors) of classical portfolio construction methods, while
achieving similar performance. AAPs thus represent a very attractive
alternative risk-based portfolio construction framework that can be implemented
in different situations, with or without an active trading signal.
"
1906.05545,2019-06-14,"Sparse Approximate Factor Estimation for High-Dimensional Covariance
  Matrices","  We propose a novel estimation approach for the covariance matrix based on the
$l_1$-regularized approximate factor model. Our sparse approximate factor (SAF)
covariance estimator allows for the existence of weak factors and hence relaxes
the pervasiveness assumption generally adopted for the standard approximate
factor model. We prove consistency of the covariance matrix estimator under the
Frobenius norm as well as the consistency of the factor loadings and the
factors.
  Our Monte Carlo simulations reveal that the SAF covariance estimator has
superior properties in finite samples for low and high dimensions and different
designs of the covariance matrix. Moreover, in an out-of-sample portfolio
forecasting application the estimator uniformly outperforms alternative
portfolio strategies based on alternative covariance estimation approaches and
modeling strategies including the $1/N$-strategy.
"
1906.05898,2024-03-25,"Stochastic PDEs for large portfolios with general mean-reverting
  volatility processes","  We consider a structural stochastic volatility model for the loss from a
large portfolio of credit risky assets. Both the asset value and the volatility
processes are correlated through systemic Brownian motions, with default
determined by the asset value reaching a lower boundary. We prove that if our
volatility models are picked from a class of mean-reverting diffusions, the
system converges as the portfolio becomes large and, when the vol-of-vol
function satisfies certain regularity and boundedness conditions, the limit of
the empirical measure process has a density given in terms of a solution to a
stochastic initial-boundary value problem on a half-space. The problem is
defined in a special weighted Sobolev space. Regularity results are established
for solutions to this problem, and then we show that there exists a unique
solution. In contrast to the CIR volatility setting covered by the existing
literature, our results hold even when the systemic Brownian motions are taken
to be correlated.
"
1906.08892,2019-06-24,"Macroscopic theorem of the portfolio optimization problem with a
  risk-free asset","  The investment risk minimization problem with budget and return constraints
has been the subject of research using replica analysis but there are
shortcomings in the extant literature. With respect to Tobin's separation
theorem and the capital asset pricing model, it is necessary to investigate the
implications of a risk-free asset and examine its influence on the optimal
portfolio. Accordingly, in this work, we explore the investment risk
minimization problem in the presence of a risk-free asset with budget and
return constraints. Moreover, we discuss opportunity loss, the Pythagorean
theorem of the Sharpe ratio, and Tobin's separation theorem.
"
1906.09694,2020-10-14,"Business Taxonomy Construction Using Concept-Level Hierarchical
  Clustering","  Business taxonomies are indispensable tools for investors to do equity
research and make professional decisions. However, to identify the structure of
industry sectors in an emerging market is challenging for two reasons. First,
existing taxonomies are designed for mature markets, which may not be the
appropriate classification for small companies with innovative business models.
Second, emerging markets are fast-developing, thus the static business
taxonomies cannot promptly reflect the new features. In this article, we
propose a new method to construct business taxonomies automatically from the
content of corporate annual reports. Extracted concepts are hierarchically
clustered using greedy affinity propagation. Our method requires less
supervision and is able to discover new terms. Experiments and evaluation on
the Chinese National Equities Exchange and Quotations (NEEQ) market show
several advantages of the business taxonomy we build. Our results provide an
effective tool for understanding and investing in the new growth companies.
"
1906.10084,2022-10-24,Long Run Feedback in the Broker Call Money Market,"  I unravel the basic long run dynamics of the broker call money market, which
is the pile of cash that funds margin loans to retail clients (read: continuous
time Kelly gamblers). Call money is assumed to supply itself perfectly
inelastically, and to continuously reinvest all principal and interest. I show
that the relative size of the money market (that is, relative to the Kelly
bankroll) is a martingale that nonetheless converges in probability to zero.
The margin loan interest rate is a submartingale that converges in mean square
to the choke price $r_\infty:=\nu-\sigma^2/2$, where $\nu$ is the asymptotic
compound growth rate of the stock market and $\sigma$ is its annual volatility.
In this environment, the gambler no longer beats the market asymptotically a.s.
by an exponential factor (as he would under perfectly elastic supply). Rather,
he beats the market asymptotically with very high probability (think 98%) by a
factor (say 1.87, or 87% more final wealth) whose mean cannot exceed what the
leverage ratio was at the start of the model (say, $2:1$). Although the ratio
of the gambler's wealth to that of an equivalent buy-and-hold investor is a
submartingale (always expected to increase), his realized compound growth rate
converges in mean square to $\nu$. This happens because the equilibrium
leverage ratio converges to $1:1$ in lockstep with the gradual rise of margin
loan interest rates.
"
1906.11186,2019-06-27,A Triptych Approach for Reverse Stress Testing of Complex Portfolios,"  The quest for diversification has led to an increasing number of complex
funds with a high number of strategies and non-linear payoffs. The new
generation of Alternative Risk Premia (ARP) funds are an example that has been
very popular in recent years. For complex funds like these, a Reverse Stress
Test (RST) is regarded by the industry and regulators as a better
forward-looking risk measure than a Value-at-Risk (VaR). We present an Extended
RST (ERST) triptych approach with three variables: level of plausibility, level
of loss and scenario. In our approach, any two of these variables can be
derived by providing the third as the input. We advocate and demonstrate that
ERST is a powerful tool for both simple linear and complex portfolios and for
both risk management as well as day-to-day portfolio management decisions. An
updated new version of the Levenberg - Marquardt optimization algorithm is
introduced to derive ERST in certain complex cases.
"
1906.11831,2019-07-01,"A portfolio choice problem in the framework of expected utility
  operators","  Possibilistic risk theory starts from the hypothesis that risk is modelled by
fuzzy numbers. In particular, in a possibilistic portfolio choice problem, the
return of a risky asset will be a fuzzy number. The expected utility operators
have been introduced in a previous paper to build an abstract theory of
possibilistic risk aversion. To each expected utility operator one can
associate a notion of possibilistic expected utility. Using this notion, we
will formulate in this very general context a possibilistic choice problem. The
main results of the paper are two approximate calculation formulas for
corresponding optimization problem. The first formula approximates the optimal
allocation with respect to risk aversion and investor's prudence, as well as
the first three possibilistic moments. Besides these parameters, in the second
formula the temperance index of the utility function and the fourth
possibilistic moment appear.
"
1906.12317,2019-10-29,"Near-Optimal Dynamic Asset Allocation in Financial Markets with Trading
  Constraints","  We develop a dual-control method for approximating investment strategies in
incomplete environments that emerge from the presence of trading constraints.
Convex duality enables the approximate technology to generate lower and upper
bounds on the optimal value function. The mechanism rests on closed-form
expressions pertaining to the portfolio composition, from which we are able to
derive the near-optimal asset allocation explicitly. In a real financial
market, we illustrate the accuracy of our approximate method on a dual CRRA
utility function that characterises the preferences of a finite-horizon
investor. Negligible duality gaps and insignificant annual welfare losses
substantiate accuracy of the technique.
"
1907.00293,2019-07-02,Tracking VIX with VIX Futures: Portfolio Construction and Performance,"  We study a series of static and dynamic portfolios of VIX futures and their
effectiveness to track the VIX index. We derive each portfolio using
optimization methods, and evaluate its tracking performance from both empirical
and theoretical perspectives. Among our results, we show that static portfolios
of different VIX futures fail to track VIX closely. VIX futures simply do not
react quickly enough to movements in the spot VIX. In a discrete-time model, we
design and implement a dynamic trading strategy that adjusts daily to optimally
track VIX. The model is calibrated to historical data and a simulation study is
performed to understand the properties exhibited by the strategy. In addition,
comparing to the volatility ETN, VXX, we find that our dynamic strategy has a
superior tracking performance.
"
1907.01274,2022-04-14,Smart network based portfolios,"  In this article we deal with the problem of portfolio allocation by enhancing
network theory tools. We use the dependence structure of the correlations
network in constructing some well-known risk-based models in which the
estimation of correlation matrix is a building block in the portfolio
optimization. We formulate and solve all these portfolio allocation problems
using both the standard approach and the network-based approach. Moreover, in
constructing the network-based portfolios we propose the use of two different
estimators for the covariance matrix: the sample estimator and the shrinkage
toward constant correlation one. All the strategies under analysis are
implemented on two high-dimensional portfolios having different
characteristics, covering the period from January $2001$ to December $2017$. We
find that the network-based portfolio consistently better performs and has
lower risk compared to the corresponding standard portfolio in an out-of-sample
perspective.
"
1907.02457,2019-07-05,"Learning Threshold-Type Investment Strategies with Stochastic Gradient
  Method","  In online portfolio optimization the investor makes decisions based on new,
continuously incoming information on financial assets (typically their prices).
In our study we consider a learning algorithm, namely the Kiefer--Wolfowitz
version of the Stochastic Gradient method, that converges to the log-optimal
solution in the threshold-type, buy-and-sell strategy class.
  The systematic study of this method is novel in the field of portfolio
optimization; we aim to establish the theory and practice of Stochastic
Gradient algorithm used on parametrized trading strategies.
  We demonstrate on a wide variety of stock price dynamics (e.g. with
stochastic volatility and long-memory) that there is an optimal threshold type
strategy which can be learned. Subsequently, we numerically show the
convergence of the algorithm. Furthermore, we deal with the typically
problematic question of how to choose the hyperparameters (the parameters of
the algorithm and not the dynamics of the prices) without knowing anything
about the price other than a small sample.
"
1907.03093,2019-07-09,Dynamic Mean-Variance Portfolio Optimisation,"  The portfolio optimisation problem, first raised by Harry Markowitz in 1952,
has been a fundamental and central topic to understanding the stock market and
making decisions. There has been plenty of works contributing to development of
the mean-variance optimisation (MVO) so far. In this paper, one kind of them,
namely, dynamic mean-variance optimisation (DMVO) is mainly discussed. One can
apply either precommitment or game-theoritical approach to address
time-inconsistency in DMVO. We use the second approach to seek for a
time-consistent strategy. After obtaining the optimal strategy, we extend the
result to a CEV-driven economy. In order to prove the usefulness of them,
strategies are fit into both real market data and simulated data. It turns out
that the strategy whose assumptions are close to market conditions generally
gives a better result. Lastly, a selected strategy is chosen to compare with
another strategy came up by deep learning technique.
"
1907.03370,2019-07-09,Artificial Intelligence Alter Egos: Who benefits from Robo-investing?,"  Artificial intelligence, or AI, enhancements are increasingly shaping our
daily lives. Financial decision-making is no exception to this. We introduce
the notion of AI Alter Egos, which are shadow robo-investors, and use a unique
data set covering brokerage accounts for a large cross-section of investors
over a sample from January 2003 to March 2012, which includes the 2008
financial crisis, to assess the benefits of robo-investing. We have detailed
investor characteristics and records of all trades. Our data set consists of
investors typically targeted for robo-advising. We explore robo-investing
strategies commonly used in the industry, including some involving advanced
machine learning methods. The man versus machine comparison allows us to shed
light on potential benefits the emerging robo-advising industry may provide to
certain segments of the population, such as low income and/or high risk averse
investors.
"
1907.03665,2019-12-02,"An intelligent financial portfolio trading strategy using deep
  Q-learning","  Portfolio traders strive to identify dynamic portfolio allocation schemes so
that their total budgets are efficiently allocated through the investment
horizon. This study proposes a novel portfolio trading strategy in which an
intelligent agent is trained to identify an optimal trading action by using
deep Q-learning. We formulate a Markov decision process model for the portfolio
trading process, and the model adopts a discrete combinatorial action space,
determining the trading direction at prespecified trading size for each asset,
to ensure practical applicability. Our novel portfolio trading strategy takes
advantage of three features to outperform in real-world trading. First, a
mapping function is devised to handle and transform an initially found but
infeasible action into a feasible action closest to the originally proposed
ideal action. Second, by overcoming the dimensionality problem, this study
establishes models of agent and Q-network for deriving a multi-asset trading
strategy in the predefined action space. Last, this study introduces a
technique that has the advantage of deriving a well-fitted multi-asset trading
strategy by designing an agent to simulate all feasible actions in each state.
To validate our approach, we conduct backtests for two representative
portfolios and demonstrate superior results over the benchmark strategies.
"
1907.05593,2020-10-06,From small markets to big markets,"  We study the most famous example of a large financial market: the Arbitrage
Pricing Model, where investors can trade in a one-period setting with countably
many assets admitting a factor structure. We consider the problem of maximising
expected utility in this setting. Besides establishing the existence of
optimizers under weaker assumptions than previous papers, we go on studying the
relationship between optimal investments in finite market segments and those in
the whole market. We show that certain natural (but nontrivial) continuity
rules hold: maximal satisfaction, reservation prices and (convex combinations
of) optimizers computed in small markets converge to their respective
counterparts in the big market.
"
1907.07101,2019-07-17,Location and portfolio selection problems: A unified framework,"  Given a set of assets and an investment capital, the classical portfolio
selection problem consists in determining the amount of capital to be invested
in each asset in order to build the most profitable portfolio. The portfolio
optimization problem is naturally modeled as a mean-risk bi-criteria
optimization problem where the mean rate of return of the portfolio must be
maximized whereas a given risk measure must be minimized. Several mathematical
programming models and techniques have been presented in the literature in
order to efficiently solve the portfolio problem. A relatively recent promising
line of research is to exploit clustering information of an assets network in
order to develop new portfolio optimization paradigms. In this paper we endow
the assets network with a metric based on correlation coefficients between
assets' returns, and show how classical location problems on networks can be
used for clustering assets. In particular, by adding a new criterion to the
portfolio selection problem based on an objective function of a classical
location problem, we are able to measure the effect of clustering on the
selected assets with respect to the non-selected ones. Most papers dealing with
clustering and portfolio selection models solve these problems in two distinct
steps: cluster first and then selection. The innovative contribution of this
paper is that we propose a Mixed-Integer Linear Programming formulation for
dealing with this problem in a unified phase. The effectiveness of our approach
is validated reporting some preliminary computational experiments on some real
financial dataset.
"
1907.09704,2022-10-24,A Note on Universal Bilinear Portfolios,"  This note provides a neat and enjoyable expansion and application of the
magnificent Ordentlich-Cover theory of ""universal portfolios."" I generalize
Cover's benchmark of the best constant-rebalanced portfolio (or 1-linear
trading strategy) in hindsight by considering the best bilinear trading
strategy determined in hindsight for the realized sequence of asset prices. A
bilinear trading strategy is a mini two-period active strategy whose final
capital growth factor is linear separately in each period's gross return vector
for the asset market. I apply Cover's ingenious (1991) performance-weighted
averaging technique to construct a universal bilinear portfolio that is
guaranteed (uniformly for all possible market behavior) to compound its money
at the same asymptotic rate as the best bilinear trading strategy in hindsight.
Thus, the universal bilinear portfolio asymptotically dominates the original
(1-linear) universal portfolio in the same technical sense that Cover's
universal portfolios asymptotically dominate all constant-rebalanced portfolios
and all buy-and-hold strategies. In fact, like so many Russian dolls, one can
get carried away and use these ideas to construct an endless hierarchy of ever
more dominant $H$-linear universal portfolios.
"
1907.11718,2019-08-05,"Large scale continuous-time mean-variance portfolio allocation via
  reinforcement learning","  We propose to solve large scale Markowitz mean-variance (MV) portfolio
allocation problem using reinforcement learning (RL). By adopting the recently
developed continuous-time exploratory control framework, we formulate the
exploratory MV problem in high dimensions. We further show the optimality of a
multivariate Gaussian feedback policy, with time-decaying variance, in trading
off exploration and exploitation. Based on a provable policy improvement
theorem, we devise a scalable and data-efficient RL algorithm and conduct large
scale empirical tests using data from the S&P 500 stocks. We found that our
method consistently achieves over 10% annualized returns and it outperforms
econometric methods and the deep RL method by large margins, for both long and
medium terms of investment with monthly and daily trading.
"
1908.00811,2019-08-05,"A full and synthetic model for Asset-Liability Management in life
  insurance, and analysis of the SCR with the standard formula","  The aim of this paper is to introduce a synthetic ALM model that catches the
main specificity of life insurance contracts. First, it keeps track of both
market and book values to apply the regulatory profit sharing rule. Second, it
introduces a determination of the crediting rate to policyholders that is close
to the practice and is a trade-off between the regulatory rate, a competitor
rate and the available profits. Third, it considers an investment in bonds that
enables to match a part of the cash outflow due to surrenders, while avoiding
to store the trading history. We use this model to evaluate the Solvency
Capital Requirement (SCR) with the standard formula, and show that the choice
of the interest rate model is important to get a meaningful model after the
regulatory shocks on the interest rate. We discuss the different values of the
SCR modules first in a framework with moderate interest rates using the shocks
of the present legislation, and then we consider a low interest framework with
the latest recommandation of the EIOPA on the shocks. In both cases, we
illustrate the importance of matching cash-flows and its impact on the SCR.
"
1908.02101,2019-12-05,Analysing Global Fixed Income Markets with Tensors,"  Global fixed income returns span across multiple maturities and economies,
that is, they naturally reside on multi-dimensional data structures referred to
as tensors. In contrast to standard ""flat-view"" multivariate models that are
agnostic to data structure and only describe linear pairwise relationships, we
introduce a tensor-valued approach to model the global risks shared by multiple
interest rate curves. In this way, the estimated risk factors can be
analytically decomposed into maturity-domain and country-domain constituents,
which allows the investor to devise rigorous and tractable global portfolio
management and hedging strategies tailored to each risk domain. An empirical
analysis confirms the existence of global risk factors shared by eight
developed economies, and demonstrates their ability to compactly describe the
global macroeconomic environment.
"
1908.02164,2022-02-09,Statistical Arbitrage for Multiple Co-Integrated Stocks,"  In this article, we analyse optimal statistical arbitrage strategies from
stochastic control and optimisation problems for multiple co-integrated stocks
with eigenportfolios being factors. Optimal portfolio weights are found by
solving a Hamilton-Jacobi-Bellman (HJB) partial differential equation, which we
solve for both an unconstrained portfolio and a portfolio constrained to be
market neutral. Our analyses demonstrate sufficient conditions on the model
parameters to ensure long-term stability of the HJB solutions and stable growth
rates for the optimal portfolios. To gauge how these optimal portfolios behave
in practice, we perform backtests on historical stock prices of the S&P 500
constituents from year 2000 through year 2021. These backtests suggest three
key conclusions: that the proposed co-integrated model with eigenportfolios
being factors can generate a large number of co-integrated stocks over a long
time horizon, that the optimal portfolios are sensitive to parameter
estimation, and that the statistical arbitrage strategies are more profitable
in periods when overall market volatilities are high.
"
1908.03905,2020-12-02,"Portfolio Optimization Managing Value at Risk under Heavy Tail Return,
  using Stochastic Maximum Principle","  We consider an investor, whose portfolio consists of a single risky asset and
a risk free asset, who wants to maximize his expected utility of the portfolio
subject to managing the Value at Risk (VaR) assuming a heavy tailed
distribution of the stock prices return. We use a stochastic maximum principle
to formulate the dynamic optimisation problem. The equations which we obtain
does not have any explicit analytical solution, so we look for accurate
approximations to estimate the value function and optimal strategy. As our
calibration strategy is non-parametric in nature, no prior knowledge on the
form of the distribution function is needed. We also provide detailed empirical
illustration using real life data. Our results show close concordance with
financial intuition.We expect that our results will add to the arsenal of the
high frequency traders.
"
1908.03907,2020-12-02,"Discrete time portfolio optimisation managing value at risk under heavy
  tail return distribution","  We consider an investor, whose portfolio consists of a single risky asset and
a risk free asset, who wants to maximize his expected utility of the portfolio
subject to the Value at Risk assuming a heavy tail distribution of the stock
prices return. We use Markov Decision Process and dynamic programming principle
to get the optimal strategies and the value function which maximize the
expected utility for parametric as well as non parametric distributions. Due to
lack of explicit solution in the non parametric case, we use numerical
integration for optimization
"
1908.04243,2023-04-19,"Sampling Distributions of Optimal Portfolio Weights and Characteristics
  in Low and Large Dimensions","  Optimal portfolio selection problems are determined by the (unknown)
parameters of the data generating process. If an investor wants to realise the
position suggested by the optimal portfolios, he/she needs to estimate the
unknown parameters and to account for the parameter uncertainty in the decision
process. Most often, the parameters of interest are the population mean vector
and the population covariance matrix of the asset return distribution. In this
paper, we characterise the exact sampling distribution of the estimated optimal
portfolio weights and their characteristics. This is done by deriving their
sampling distribution by its stochastic representation. This approach possesses
several advantages, {e.g.} (i) it determines the sampling distribution of the
estimated optimal portfolio weights by expressions, which could be used to draw
samples from this distribution efficiently; (ii) the application of the derived
stochastic representation provides an easy way to obtain the asymptotic
approximation of the sampling distribution. The later property is used to show
that the high-dimensional asymptotic distribution of optimal portfolio weights
is a multivariate normal and to determine its parameters. Moreover, a
consistent estimator of optimal portfolio weights and their characteristics is
derived under the high-dimensional settings. Via an extensive simulation study,
we investigate the finite-sample performance of the derived asymptotic
approximation and study its robustness to the violation of the model
assumptions used in the derivation of the theoretical results.
"
1908.04697,2019-08-14,"Critical Decisions for Asset Allocation via Penalized Quantile
  Regression","  We extend the analysis of investment strategies derived from penalized
quantile regression models, introducing alternative approaches to improve
state\textendash of\textendash art asset allocation rules. First, we use a
post\textendash penalization procedure to deal with overshrinking and
concentration issues. Second, we investigate whether and to what extent the
performance changes when moving from convex to nonconvex penalty functions.
Third, we compare different methods to select the optimal tuning parameter
which controls the intensity of the penalization. Empirical analyses on
real\textendash world data show that these alternative methods outperform the
simple LASSO. This evidence becomes stronger when focusing on the extreme risk,
which is strictly linked to the quantile regression method.
"
1908.04962,2019-08-15,"Can robust optimization offer improved portfolio performance?: An
  empirical study of Indian market","  The emergence of robust optimization has been driven primarily by the
necessity to address the demerits of the Markowitz model. There has been a
noteworthy debate regarding consideration of robust approaches as superior or
at par with the Markowitz model, in terms of portfolio performance. In order to
address this skepticism, we perform empirical analysis of three robust
optimization models, namely the ones based on box, ellipsoidal and separable
uncertainty sets. We conclude that robust approaches can be considered as a
viable alternative to the Markowitz model, not only in simulated data but also
in a real market setup, involving the Indian indices of S&P BSE 30 and S&P BSE
100. Finally, we offer qualitative and quantitative justification regarding the
practical usefulness of robust optimization approaches from the point of view
of number of stocks, sample size and types of data.
"
1908.05002,2019-08-15,Is being `Robust' beneficial?: A perspective from the Indian market,"  The problem of data uncertainty has motivated the incorporation of robust
optimization in various arenas, beyond the Markowitz portfolio optimization.
This work presents the extension of the robust optimization framework for the
minimization of downside risk measures, such as Value-at-Risk (VaR) and
Conditional Value-at-Risk (CVaR). We perform an empirical study of VaR and CVaR
frameworks, with respect to their robust counterparts, namely, Worst-Case VaR
and Worst-Case CVaR, using the market data as well as the simulated data. After
discussing the practical usefulness of the robust optimization approaches from
various standpoints, we infer various takeaways. The robust models in the case
of VaR and CVaR minimization exhibit superior performance with respect to their
base versions in the cases involving higher number of stocks and simulated
setup respectively.
"
1908.05105,2019-08-15,Performance of tail hedged portfolio with third moment variation swap,"  The third moment variation of a financial asset return process is defined by
the quadratic covariation between the return and square return processes. The
skew and fat tail risk of an underlying asset can be hedged using a third
moment variation swap under which a predetermined fixed leg and the floating
leg of the realized third moment variation are exchanged. The probability
density function of the hedged portfolio with the third moment variation swap
was examined using a partial differential equation approach. An alternating
direction implicit method was used for numerical analysis of the partial
differential equation. Under the stochastic volatility and jump diffusion
stochastic volatility models, the distributions of the hedged portfolio return
are symmetric and have more Gaussian-like thin-tails.
"
1908.05534,2019-08-16,"Mean-variance hedging of unit linked life insurance contracts in a
  jump-diffusion model","  We consider a time-consistent mean-variance portfolio selection problem of an
insurer and allow for the incorporation of basis (mortality) risk. The optimal
solution is identified with a Nash subgame perfect equilibrium. We characterize
an optimal strategy as solution of a system of partial integro-differential
equations (PIDEs), a so called extended Hamilton-Jacobi-Bellman (HJB) system.
We prove that the equilibrium is necessarily a solution of the extended HJB
system. Under certain conditions we obtain an explicit solution to the extended
HJB system and provide the optimal trading strategies in closed-form. A
simulation shows that the previously found strategies yield payoffs whose
expectations and variances are robust regarding the distribution of jump sizes
of the stock. The same phenomenon is observed when the variance is correctly
estimated, but erroneously ascribed to the diffusion components solely.
Further, we show that differences in the insurance horizon and the time to
maturity of a longevity asset do not add to the variance of the terminal
wealth.
"
1908.07659,2021-07-27,Myopic robust index tracking with Bregman divergence,"  Index tracking is a popular form of asset management. Typically, a quadratic
function is used to define the tracking error of a portfolio and the look back
approach is applied to solve the index tracking problem. We argue that a
forward looking approach is more suitable, whereby the tracking error is
expressed as expectation of a function of the difference between the returns of
the index and of the portfolio. We also assume that there is an uncertainty in
the distribution of the assets, hence a robust version of the optimization
problem needs to be adopted. We use Bregman divergence in describing the
deviation between the nominal and actual distribution of the components of the
index. In this scenario, we derive the optimal robust index tracking strategy
in a semi-analytical form as a solution of a system of nonlinear equations.
Several numerical results are presented that allow us to compare the
performance of this robust strategy with the optimal non-robust strategy. We
show that, especially during market downturns, the robust strategy can be very
advantageous.
"
1908.07813,2019-08-22,"Relationship between optimal portfolios which can maximize and minimize
  the expected return","  In recent years, the evaluation of the minimal investment risk of the
quenched disordered system of a portfolio optimization problem and the
investment concentration of the optimal portfolio has been actively
investigated using the analysis methods of statistical mechanical informatics.
However, the work to date has not sufficiently compared the optimal portfolios
of different portfolio optimization problems. Therefore, in this paper, we use
the Lagrange undetermined multiplier method and replica analysis to examine the
relationship between the optimal portfolios of the expected return maximization
problem and the expected return minimization problem with constraints of budget
and investment risk. In particular, we derive the mean square error and the
correlation coefficient of the optimal portfolios of these maximization and
minimization problems as functions of a variable (the degree of risk tolerance)
that can characterize the feasible subspace defined by the two constraints.
"
1908.08040,2019-08-23,Quantum Algorithms for Portfolio Optimization,"  We develop the first quantum algorithm for the constrained portfolio
optimization problem. The algorithm has running time $\widetilde{O} \left(
n\sqrt{r} \frac{\zeta \kappa}{\delta^2} \log \left(1/\epsilon\right) \right)$,
where $r$ is the number of positivity and budget constraints, $n$ is the number
of assets in the portfolio, $\epsilon$ the desired precision, and $\delta,
\kappa, \zeta$ are problem-dependent parameters related to the
well-conditioning of the intermediate solutions. If only a moderately accurate
solution is required, our quantum algorithm can achieve a polynomial speedup
over the best classical algorithms with complexity $\widetilde{O} \left(
\sqrt{r}n^\omega\log(1/\epsilon) \right)$, where $\omega$ is the matrix
multiplication exponent that has a theoretical value of around $2.373$, but is
closer to $3$ in practice. We also provide some experiments to bound the
problem-dependent factors arising in the running time of the quantum algorithm,
and these experiments suggest that for most instances the quantum algorithm can
potentially achieve an $O(n)$ speedup over its classical counterpart.
"
1908.08442,2020-06-30,"Quantitative portfolio selection: using density forecasting to find
  consistent portfolios","  In the knowledge that the ex-post performance of Markowitz efficient
portfolios is inferior to that implied ex-ante, we make two contributions to
the portfolio selection literature. Firstly, we propose a methodology to
identify the region of risk-expected return space where ex-post performance
matches ex-ante estimates. Secondly, we extend ex-post efficient set
mathematics to overcome the biases in the estimation of the ex-ante efficient
frontier. A density forecasting approach is used to measure the accuracy of
ex-ante estimates using the Berkowitz statistic, we develop this statistic to
increase its sensitivity to changes in the data generating process. The area of
risk-expected return space where the density forecasts are accurate, where
ex-post performance matches ex-ante estimates, is termed the consistency
region. Under the 'laboratory' conditions of a simulated multivariate normal
data set, we compute the consistency region and the estimated ex-post frontier.
Over different sample sizes used for estimation, the behaviour of the
consistency region is shown to be both intuitively reasonable and to enclose
the estimated ex-post frontier. Using actual data from the constituents of the
US Dow Jones 30 index, we show that the size of the consistency region is time
dependent and, in volatile conditions, may disappear. Using our development of
the Berkowitz statistic, we demonstrate the superior performance of an
investment strategy based on consistent rather than efficient portfolios.
"
1908.08684,2019-08-26,"A nonlinear optimisation model for constructing minimal drawdown
  portfolios","  In this paper we consider the problem of minimising drawdown in a portfolio
of financial assets. Here drawdown represents the relative opportunity cost of
the single best missed trading opportunity over a specified time period. We
formulate the problem (minimising average drawdown, maximum drawdown, or a
weighted combination of the two) as a nonlinear program and show how it can be
partially linearised by replacing one of the nonlinear constraints by
equivalent linear constraints.
  Computational results are presented (generated using the nonlinear solver
SCIP) for three test instances drawn from the EURO STOXX 50, the FTSE 100 and
the S&P 500 with daily price data over the period 2010-2016. We present results
for long-only drawdown portfolios as well as results for portfolios with both
long and short positions. These indicate that (on average) our minimal drawdown
portfolios dominate the market indices in terms of return, Sharpe ratio,
maximum drawdown and average drawdown over the (approximately 1800 trading day)
out-of-sample period.
"
1908.09976,2020-08-03,"Optimal life-cycle consumption and investment decisions under
  age-dependent risk preferences","  In this article we solve the problem of maximizing the expected utility of
future consumption and terminal wealth to determine the optimal pension or
life-cycle fund strategy for a cohort of pension fund investors. The setup is
strongly related to a DC pension plan where additionally (individual)
consumption is taken into account. The consumption rate is subject to a
time-varying minimum level and terminal wealth is subject to a terminal floor.
Moreover, the preference between consumption and terminal wealth as well as the
intertemporal coefficient of risk aversion are time-varying and therefore
depend on the age of the considered pension cohort. The optimal consumption and
investment policies are calculated in the case of a Black-Scholes financial
market framework and hyperbolic absolute risk aversion (HARA) utility
functions. We generalize Ye (2008) (2008 American Control Conference, 356-362)
by adding an age-dependent coefficient of risk aversion and extend Steffensen
(2011) (Journal of Economic Dynamics and Control, 35(5), 659-667), Hentschel
(2016) (Doctoral dissertation, Ulm University) and Aase (2017) (Stochastics,
89(1), 115-141) by considering consumption in combination with terminal wealth
and allowing for consumption and terminal wealth floors via an application of
HARA utility functions. A case study on fitting several models to realistic,
time-dependent life-cycle consumption and relative investment profiles shows
that only our extended model with time-varying preference parameters provides
sufficient flexibility for an adequate fit. This is of particular interest to
life-cycle products for (private) pension investments or pension insurance in
general.
"
1909.01121,2020-10-27,Lifetime Ruin under High-watermark Fees and Drift Uncertainty,"  This paper aims to make a new contribution to the study of lifetime ruin
problem by considering investment in two hedge funds with high-watermark fees
and drift uncertainty. Due to multi-dimensional performance fees that are
charged whenever each fund profit exceeds its historical maximum, the value
function is expected to be multi-dimensional. New mathematical challenges arise
as the standard dimension reduction cannot be applied, and the convexity of the
value function and Isaacs condition may not hold in our ruin probability
minimization problem with drift uncertainty. We propose to employ the
stochastic Perron's method to characterize the value function as the unique
viscosity solution to the associated Hamilton Jacobi Bellman (HJB) equation
without resorting to the proof of dynamic programming principle. The required
comparison principle is also established in our setting to close the loop of
stochastic Perron's method.
"
1909.01830,2021-11-04,"Robust Utility Maximizing Strategies under Model Uncertainty and their
  Convergence","  In this paper we investigate a utility maximization problem with drift
uncertainty in a multivariate continuous-time Black-Scholes type financial
market which may be incomplete. We impose a constraint on the admissible
strategies that prevents a pure bond investment and we include uncertainty by
means of ellipsoidal uncertainty sets for the drift. Our main results consist
firstly in finding an explicit representation of the optimal strategy and the
worst-case parameter, secondly in proving a minimax theorem that connects our
robust utility maximization problem with the corresponding dual problem.
Thirdly, we show that, as the degree of model uncertainty increases, the
optimal strategy converges to a generalized uniform diversification strategy.
"
1909.04327,2019-09-11,"Empirical investigation of state-of-the-art mean reversion strategies
  for equity markets","  Recent studies have shown that online portfolio selection strategies that
exploit the mean reversion property can achieve excess return from equity
markets. This paper empirically investigates the performance of
state-of-the-art mean reversion strategies on real market data. The aims of the
study are twofold. The first is to find out why the mean reversion strategies
perform extremely well on well-known benchmark datasets, and the second is to
test whether or not the mean reversion strategies work well on recent market
data. The mean reversion strategies used in this study are the passive
aggressive mean reversion (PAMR) strategy, the on-line moving average reversion
(OLMAR) strategy, and the transaction cost optimization (TCO) strategies. To
test the strategies, we use the historical prices of the stocks that constitute
S\&P 500 index over the period from 2000 to 2017 as well as well-known
benchmark datasets. Our findings are that the well-known benchmark datasets
favor mean reversion strategies, and mean reversion strategies may fail even in
favorable market conditions, especially when there exist explicit or implicit
transaction costs.
"
1909.06332,2023-07-20,"Comparative Companies' Stock Valuation through Financial Metrics and its
  Social Implications","  Out of the companies, Dolby is the company with the best overall financial
and operation health. According to the table that accounted its financial
statements for the past three years, Dolby has stable profit margins that
generates a revenue in the billions, the only company in ten figures. Corporate
competition to gain more patents as old ones expire may mean new jobs created,
increased funding for schools, investment in technology or engineering
education, and further need for purchase of marketing and salespeople.
"
1909.07837,2019-09-19,The value of knowing the market price of risk,"  This paper presents an optimal allocation problem in a financial market with
one risk-free and one risky asset, when the market is driven by a stochastic
market price of risk. We solve the problem in continuous time, for an investor
with a Constant Relative Risk Aversion (CRRA) utility, under two scenarios:
when the market price of risk is observable (the {\em full information case}),
and when it is not (the {\em partial information case}). The corresponding
market models are complete in the partial information case and incomplete in
the other case, hence the two scenarios exhibit rather different features. We
study how the access to more accurate information on the market price of risk
affects the optimal strategies and we determine the maximal price that the
investor would be willing to pay to get such information. In particular, we
examine two cases of additional information, when an exact observation of the
market price of risk is available either at time $0$ only (the {\em initial
information case}), or during the whole investment period (the {\em dynamic
information case}).
"
1909.09571,2019-09-23,Reinforcement Learning for Portfolio Management,"  In this thesis, we develop a comprehensive account of the expressive power,
modelling efficiency, and performance advantages of so-called trading agents
(i.e., Deep Soft Recurrent Q-Network (DSRQN) and Mixture of Score Machines
(MSM)), based on both traditional system identification (model-based approach)
as well as on context-independent agents (model-free approach). The analysis
provides conclusive support for the ability of model-free reinforcement
learning methods to act as universal trading agents, which are not only capable
of reducing the computational and memory complexity (owing to their linear
scaling with the size of the universe), but also serve as generalizing
strategies across assets and markets, regardless of the trading universe on
which they have been trained. The relatively low volume of daily returns in
financial market data is addressed via data augmentation (a generative
approach) and a choice of pre-training strategies, both of which are validated
against current state-of-the-art models. For rigour, a risk-sensitive framework
which includes transaction costs is considered, and its performance advantages
are demonstrated in a variety of scenarios, from synthetic time-series
(sinusoidal, sawtooth and chirp waves), simulated market series (surrogate data
based), through to real market data (S\&P 500 and EURO STOXX 50). The analysis
and simulations confirm the superiority of universal model-free reinforcement
learning agents over current portfolio management model in asset allocation
strategies, with the achieved performance advantage of as much as 9.2\% in
annualized cumulative returns and 13.4\% in annualized Sharpe Ratio.
"
1909.10233,2019-09-24,Machine Learning Optimization Algorithms & Portfolio Allocation,"  Portfolio optimization emerged with the seminal paper of Markowitz (1952).
The original mean-variance framework is appealing because it is very efficient
from a computational point of view. However, it also has one well-established
failing since it can lead to portfolios that are not optimal from a financial
point of view. Nevertheless, very few models have succeeded in providing a real
alternative solution to the Markowitz model. The main reason lies in the fact
that most academic portfolio optimization models are intractable in real life
although they present solid theoretical properties. By intractable we mean that
they can be implemented for an investment universe with a small number of
assets using a lot of computational resources and skills, but they are unable
to manage a universe with dozens or hundreds of assets. However, the emergence
and the rapid development of robo-advisors means that we need to rethink
portfolio optimization and go beyond the traditional mean-variance optimization
approach. Another industry has faced similar issues concerning large-scale
optimization problems. Machine learning has long been associated with linear
and logistic regression models. Again, the reason was the inability of
optimization algorithms to solve high-dimensional industrial problems.
Nevertheless, the end of the 1990s marked an important turning point with the
development and the rediscovery of several methods that have since produced
impressive results. The goal of this paper is to show how portfolio allocation
can benefit from the development of these large-scale optimization algorithms.
Not all of these algorithms are useful in our case, but four of them are
essential when solving complex portfolio optimization problems. These four
algorithms are the coordinate descent, the alternating direction method of
multipliers, the proximal gradient method and the Dykstra's algorithm.
"
1909.12730,2020-04-08,Collectivised Post-Retirement Investment,"  We quantify the benefit of collectivised investment funds, in which the
assets of members who die are shared among the survivors. For our model, with
realistic parameter choices, an annuity or individual fund requires
approximately 20\% more initial capital to provide as good an outcome as a
collectivised investment fund. We demonstrate the importance of the new concept
of pension adequacy in defining investor preferences and determining optimal
fund management. We show how to manage heterogeneous funds of investors with
diverse needs. Our framework can be applied to existing pension products, such
as Collective Defined Contribution schemes.
"
1909.12904,2020-09-16,"Quantum Annealing Algorithm for Expected Shortfall based Dynamic Asset
  Allocation","  The 2008 mortgage crisis is an example of an extreme event. Extreme value
theory tries to estimate such tail risks. Modern finance practitioners prefer
Expected Shortfall based risk metrics (which capture tail risk) over
traditional approaches like volatility or even Value-at-Risk. This paper
provides a quantum annealing algorithm in QUBO form for a dynamic asset
allocation problem using expected shortfall constraint. It was motivated by the
need to refine the current quantum algorithms for Markowitz type problems which
are academically interesting but not useful for practitioners. The algorithm is
dynamic and the risk target emerges naturally from the market volatility.
Moreover, it avoids complicated statistics like generalized pareto
distribution. It translates the problem into qubit form suitable for
implementation by a quantum annealer like D-Wave. Such QUBO algorithms are
expected to be solved faster using quantum annealing systems than any classical
algorithm using classical computer (but yet to be demonstrated at scale).
"
1910.01438,2019-10-08,Optimal Convergence Trading with Unobservable Pricing Errors,"  We study a dynamic portfolio optimization problem related to convergence
trading, which is an investment strategy that exploits temporary mispricing by
simultaneously buying relatively underpriced assets and selling short
relatively overpriced ones with the expectation that their prices converge in
the future. We build on the model of Liu and Timmermann (2013) and extend it by
incorporating unobservable Markov-modulated pricing errors into the price
dynamics of two co-integrated assets. We characterize the optimal portfolio
strategies in full and partial information settings both under the assumption
of unrestricted and beta-neutral strategies. By using the innovations approach,
we provide the filtering equation that is essential for solving the
optimization problem under partial information. Finally, in order to illustrate
the model capabilities, we provide an example with a two-state Markov chain.
"
1910.02310,2019-10-08,Hierarchical PCA and Applications to Portfolio Management,"  It is widely known that the common risk-factors derived from PCA beyond the
first eigenportfolio are generally difficult to interpret and thus to use in
practical portfolio management. We explore a alternative approach (HPCA) which
makes strong use of the partition of the market into sectors. We show that this
approach leads to no loss of information with respect to PCA in the case of
equities (constituents of the S&P 500) and also that the associated common
factors admit simple interpretations. The model can also be used in markets in
which the sectors have asynchronous price information, such as single-name
credit default swaps, generalizing the works of Cont and Kan (2011) and Ivanov
(2016).
"
1910.04943,2019-10-14,Optimal Trading of a Basket of Futures Contracts,"  We study the problem of dynamically trading multiple futures contracts with
different underlying assets. To capture the joint dynamics of stochastic bases
for all traded futures, we propose a new model involving a multi-dimensional
scaled Brownian bridge that is stopped before price convergence. This leads to
the analysis of the corresponding Hamilton-Jacobi-Bellman (HJB) equations,
whose solutions are derived in semi-explicit form. The resulting optimal
trading strategy is a long-short policy that accounts for whether the futures
are in contango or backwardation. Our model also allows us to quantify and
compare the values of trading in the futures markets when the underlying assets
are traded or not. Numerical examples are provided to illustrate the optimal
strategies and the effects of model parameters.
"
1910.05555,2019-10-15,"Systematic Asset Allocation using Flexible Views for South African
  Markets","  We implement a systematic asset allocation model using the Historical
Simulation with Flexible Probabilities (HS-FP) framework developed by Meucci.
The HS-FP framework is a flexible non-parametric estimation approach that
considers future asset class behavior to be conditional on time and market
environments, and derives a forward looking distribution that is consistent
with this view while remaining close as possible to the prior distribution. The
framework derives the forward looking distribution by applying unequal time and
state conditioned probabilities to historical observations of asset class
returns. This is achieved using relative entropy to find estimates with the
least distortion to the prior distribution. Here, we use the HS-FP framework on
South African financial market data for asset allocation purposes; by
estimating expected returns, correlations and volatilities that are better
represented through the measured market cycle. We demonstrated a range of state
variables that can be useful towards understanding market environments.
Concretely, we compare the out-of-sample performance for a specific
configuration of the HS-FP model relative to classic Mean Variance
Optimization(MVO) and Equally Weighted (EW) benchmark models. The framework
displays low probability of backtest overfitting and the out-of-sample net
returns and Sharpe ratio point estimates of the HS-FP model outperforms the
benchmark models. However, the results are inconsistent when training windows
are varied, the Sharpe ratio is seen to be inflated, and the method does not
demonstrate statistically significant out-performance on a gross and net basis.
"
1910.05561,2019-10-17,Portfolio Cuts: A Graph-Theoretic Framework to Diversification,"  Investment returns naturally reside on irregular domains, however, standard
multivariate portfolio optimization methods are agnostic to data structure. To
this end, we investigate ways for domain knowledge to be conveniently
incorporated into the analysis, by means of graphs. Next, to relax the
assumption of the completeness of graph topology and to equip the graph model
with practically relevant physical intuition, we introduce the portfolio cut
paradigm. Such a graph-theoretic portfolio partitioning technique is shown to
allow the investor to devise robust and tractable asset allocation schemes, by
virtue of a rigorous graph framework for considering smaller, computationally
feasible, and economically meaningful clusters of assets, based on graph cuts.
In turn, this makes it possible to fully utilize the asset returns covariance
matrix for constructing the portfolio, even without the requirement for its
inversion. The advantages of the proposed framework over traditional methods
are demonstrated through numerical simulations based on real-world price data.
"
1910.06432,2019-10-16,Optimal Dynamic Futures Portfolio in a Regime-Switching Market Framework,"  We study the problem of dynamically trading futures in a regime-switching
market. Modeling the underlying asset price as a Markov-modulated diffusion
process, we present a utility maximization approach to determine the optimal
futures trading strategy. This leads to the analysis of the associated system
of Hamilton-Jacobi-Bellman (HJB) equations, which are reduced to a system of
linear ODEs. We apply our stochastic framework to two models, namely, the
Regime-Switching Geometric Brownian Motion (RS-GBM) model and Regime-Switching
Exponential Ornstein-Uhlenbeck (RS-XOU) model. Numerical examples are provided
to illustrate the investor's optimal futures positions and portfolio value
across market regimes.
"
1910.06463,2023-03-15,"Singular Perturbation Expansion for Utility Maximization with
  Order-$\epsilon$ Quadratic Transaction Costs","  We present an expansion for portfolio optimization in the presence of small,
instantaneous, quadratic transaction costs. Specifically, the magnitude of
transaction costs has a coefficient that is of the order $\epsilon$ small,
which leads to the optimization problem having an asymptotically-singular
Hamilton-Jacobi-Bellman equation whose solution can be expanded in powers of
$\sqrt\epsilon$. In this paper we derive explicit formulae for the first two
terms of this expansion. Analysis and simulation are provided to show the
behavior of this approximating solution.
"
1910.06910,2021-06-08,Optimal ratcheting of dividends in insurance,"  We address a long-standing open problem in risk theory, namely the optimal
strategy to pay out dividends from an insurance surplus process, if the
dividend rate can never be decreased. The optimality criterion here is to
maximize the expected value of the aggregate discounted dividend payments up to
the time of ruin. In the framework of the classical Cram\'{e}r-Lundberg risk
model, we solve the corresponding two-dimensional optimal control problem and
show that the value function is the unique viscosity solution of the
corresponding Hamilton-Jacobi-Bellman equation. We also show that the value
function can be approximated arbitrarily closely by ratcheting strategies with
only a finite number of possible dividend rates and identify the free boundary
and the optimal strategies in several concrete examples. These implementations
illustrate that the restriction of ratcheting does not lead to a large
efficiency loss when compared to the classical un-constrained optimal dividend
strategy.
"
1910.07417,2020-05-11,"Portfolio optimization in the case of an exponential utility function
  and in the presence of an illiquid asset","  We study an optimization problem for a portfolio with a risk-free, a liquid,
and an illiquid risky asset. The illiquid risky asset is sold in an exogenous
random moment with a prescribed liquidation time distribution. The investor
prefers a negative or a positive exponential utility function. We prove that
both cases are connected by a one-to-one analytical substitution and are
identical from the economic, analytical, or Lie algebraic points of view.
  It is well known that the exponential utility function is connected with the
HARA utility function through a limiting procedure if the parameter of the HARA
utility function is going to infinity. We show that the optimization problem
with the exponential utility function is not connected to the HARA case by the
limiting procedure and we obtain essentially different results.
  For the main three dimensional PDE with the exponential utility function we
obtain the complete set of the nonequivalent Lie group invariant reductions to
two dimensional PDEs according to an optimal system of subalgebras of the
admitted Lie algebra. We prove that in just one case the invariant reduction is
consistent with the boundary condition. This reduction represents a significant
simplification of the original problem.
"
1910.07564,2019-10-18,Residual Switching Network for Portfolio Optimization,"  This paper studies deep learning methodologies for portfolio optimization in
the US equities market. We present a novel residual switching network that can
automatically sense changes in market regimes and switch between momentum and
reversal predictors accordingly. The residual switching network architecture
combines two separate residual networks (ResNets), namely a switching module
that learns stock market conditions, and the main module that learns momentum
and reversal predictors. We demonstrate that over-fitting noisy financial data
can be controlled with stacked residual blocks and further incorporating the
attention mechanism can enhance powerful predictive properties. Over the period
2008 to H12017, the residual switching network (Switching-ResNet) strategy
verified superior out-of-sample performance with an average annual Sharpe ratio
of 2.22, compared with an average annual Sharpe ratio of 0.81 for the ANN-based
strategy and 0.69 for the linear model.
"
1910.08531,2019-10-30,Healthy... Distress... Default,"  We discuss a simple, exactly solvable model of stochastic stock dynamics that
incorporates regime switching between healthy and distressed regimes. Using
this model, which is analytically tractable, we discuss a way of extracting
expected returns for stocks from realized CDS spreads, essentially, the CDS
market sentiment about future stock returns. This alpha/signal could be useful
in a cross-sectional (statistical arbitrage) context for equities trading.
"
1910.11840,2019-10-28,Sparsity and Stability for Minimum-Variance Portfolios,"  The popularity of modern portfolio theory has decreased among practitioners
because of its unfavorable out-of-sample performance. Estimation errors tend to
affect the optimal weight calculation noticeably, especially when a large
number of assets is considered. To overcome these issues, many methods have
been proposed in recent years, although most only address a small set of
practically relevant questions related to portfolio allocation. This study
therefore sheds light on different covariance estimation techniques, combines
them with sparse model approaches, and includes a turnover constraint that
induces stability. We use two datasets - comprising 319 and 100 companies of
the S&P 500, respectively - to create a realistic and reproducible data
foundation for our empirical study. To the best of our knowledge, this study is
the first to show that it is possible to maintain the low-risk profile of
efficient estimation methods while automatically selecting only a subset of
assets and further inducing low portfolio turnover. Moreover, we provide
evidence that using the LASSO as the sparsity-generating model is insufficient
to lower turnover when the involved tuning parameter can change over time.
"
1910.12516,2021-03-18,Robust Contracting in General Contract Spaces,"  We consider a general framework of optimal mechanism design under adverse
selection and ambiguity about the type distribution of agents. We prove the
existence of optimal mechanisms under minimal assumptions on the contract space
and prove that centralized contracting implemented via mechanisms is equivalent
to delegated contracting implemented via a contract menu under these
assumptions. Our abstract existence results are applied to a series of
applications that include models of optimal risk sharing and of optimal
portfolio delegation.
"
1910.13882,2019-10-31,Michael Milken: The Junk Dealer,"  We take a closer look at the life and legacy of Micheal Milken. We discuss
why Michael Milken, also know as the Junk Bond King, was not just any other
King or run-of-the-mill Junk Dealer, but ""The Junk Dealer"". We find parallels
between the three parts to any magic act and what Micheal Milken did, showing
that his accomplishments were nothing short of a miracle. His compensation at
that time captures to a certain extent the magnitude of the changes he brought
about, the eco-system he created for businesses to flourish, the impact he had
on the wider economy and also on the future growth and development of American
Industry. We emphasize two of his contributions to the financial industry that
have grown in importance over the years. One was the impetus given to the
Private Equity industry and the use of LBOs. The second was the realization
that thorough research was the key to success, financial and otherwise. Perhaps
an unintended consequence of the growth in junk bonds and tailored financing
was the growth of Silicon valley and technology powerhouses in the California
bay area. Investors witnessed that there was a possibility for significant
returns and that financial success could be had due to the risk mitigation that
Milken demonstrated by investing in portfolios of so called high risk and low
profile companies. We point out the current trend in many regions of the world,
which is the birth of financial and technology firms and we suggest that
finding innovative ways of financing could be the key to the sustained growth
of these eco-systems.
"
1910.13960,2021-01-08,"Cross-validated covariance estimators for high-dimensional
  minimum-variance portfolios","  The global minimum-variance portfolio is a typical choice for investors
because of its simplicity and broad applicability. Although it requires only
one input, namely the covariance matrix of asset returns, estimating the
optimal solution remains a challenge. In the presence of high-dimensionality in
the data, the sample covariance estimator becomes ill-conditioned and leads to
suboptimal portfolios out-of-sample. To address this issue, we review recently
proposed efficient estimation methods for the covariance matrix and extend the
literature by suggesting a multi-fold cross-validation technique for selecting
the necessary tuning parameters within each method. Conducting an extensive
empirical analysis with four datasets based on the S&P 500, we show that the
data-driven choice of specific tuning parameters with the proposed
cross-validation improves the out-of-sample performance of the global
minimum-variance portfolio. In addition, we identify estimators that are
strongly influenced by the choice of the tuning parameter and detect a clear
relationship between the selection criterion within the cross-validation and
the evaluated performance measure.
"
1911.01391,2020-11-25,"Personalized Robo-Advising: Enhancing Investment through Client
  Interaction","  Automated investment managers, or robo-advisors, have emerged as an
alternative to traditional financial advisors. The viability of robo-advisors
crucially depends on their ability to offer personalized financial advice. We
introduce a novel framework, in which a robo-advisor interacts with a client to
solve an adaptive mean-variance portfolio optimization problem. The risk-return
tradeoff adapts to the client's risk profile, which depends on idiosyncratic
characteristics, market returns, and economic conditions. We show that the
optimal investment strategy includes both myopic and intertemporal hedging
terms which are impacted by the dynamics of the client's risk profile. We
characterize the optimal portfolio personalization via a tradeoff faced by the
robo-advisor between receiving client information in a timely manner and
mitigating behavioral biases in the risk profile communicated by the client. We
argue that the optimal portfolio's Sharpe ratio and return distribution improve
if the robo-advisor counters the client's tendency to reduce market exposure
during economic contractions when the market risk-return tradeoff is more
favorable.
"
1911.02067,2020-04-16,"Robo-advising: Learning Investors' Risk Preferences via Portfolio
  Choices","  We introduce a reinforcement learning framework for retail robo-advising. The
robo-advisor does not know the investor's risk preference, but learns it over
time by observing her portfolio choices in different market environments. We
develop an exploration-exploitation algorithm which trades off costly
solicitations of portfolio choices by the investor with autonomous trading
decisions based on stale estimates of investor's risk aversion. We show that
the algorithm's value function converges to the optimal value function of an
omniscient robo-advisor over a number of periods that is polynomial in the
state and action space. By correcting for the investor's mistakes, the
robo-advisor may outperform a stand-alone investor, regardless of the
investor's opportunity cost for making portfolio decisions.
"
1911.02296,2019-11-26,"Collectivised Pension Investment with Exponential Kihlstrom--Mirman
  Preferences","  In a collectivised pension fund, investors agree that any money remaining in
the fund when they die can be shared among the survivors.
  We give a numerical algorithm to compute the optimal investment-consumption
strategy for an infinite collective of identical investors with exponential
Kihlstrom--Mirman preferences, investing in the Black--Scholes market in
continuous time but consuming in discrete time. Our algorithm can also be
applied to an individual investor.
  We derive an analytic formula for the optimal consumption in the special case
of an individual who chooses not to invest in the financial markets. We prove
that our problem formulation for a fund with an infinite number of members is a
good approximation to a fund with a large, but finite number of members.
"
1911.04090,2019-11-12,A post hoc test on the Sharpe ratio,"  We describe a post hoc test for the Sharpe ratio, analogous to Tukey's test
for pairwise equality of means. The test can be applied after rejection of the
hypothesis that all population Signal-Noise ratios are equal. The test is
applicable under a simple correlation structure among asset returns.
Simulations indicate the test maintains nominal type I rate under a wide range
of conditions and is moderately powerful under reasonable alternatives.
"
1911.04489,2019-12-11,Making Good on LSTMs' Unfulfilled Promise,"  LSTMs promise much to financial time-series analysis, temporal and
cross-sectional inference, but we find that they do not deliver in a real-world
financial management task. We examine an alternative called Continual Learning
(CL), a memory-augmented approach, which can provide transparent explanations,
i.e. which memory did what and when. This work has implications for many
financial applications including credit, time-varying fairness in decision
making and more. We make three important new observations. Firstly, as well as
being more explainable, time-series CL approaches outperform LSTMs as well as a
simple sliding window learner using feed-forward neural networks (FFNN).
Secondly, we show that CL based on a sliding window learner (FFNN) is more
effective than CL based on a sequential learner (LSTM). Thirdly, we examine how
real-world, time-series noise impacts several similarity approaches used in CL
memory addressing. We provide these insights using an approach called Continual
Learning Augmentation (CLA) tested on a complex real-world problem, emerging
market equities investment decision making. CLA provides a test-bed as it can
be based on different types of time-series learners, allowing testing of LSTM
and FFNN learners side by side. CLA is also used to test several distance
approaches used in a memory recall-gate: Euclidean distance (ED), dynamic time
warping (DTW), auto-encoders (AE) and a novel hybrid approach, warp-AE. We find
that ED under-performs DTW and AE but warp-AE shows the best overall
performance in a real-world financial task.
"
1911.05052,2019-11-15,"Index Tracking with Cardinality Constraints: A Stochastic Neural
  Networks Approach","  Partial (replication) index tracking is a popular passive investment
strategy. It aims to replicate the performance of a given index by constructing
a tracking portfolio which contains some constituents of the index. The
tracking error optimisation is quadratic and NP-hard when taking the L0
constraint into account so it is usually solved by heuristic methods such as
evolutionary algorithms. This paper introduces a simple, efficient and scalable
connectionist model as an alternative. We propose a novel reparametrisation
method and then solve the optimisation problem with stochastic neural networks.
The proposed approach is examined with S&P 500 index data for more than 10
years and compared with widely used index tracking approaches such as forward
and backward selection and the largest market capitalisation methods. The
empirical results show our model achieves excellent performance. Compared with
the benchmarked models, our model has the lowest tracking error, across a range
of portfolio sizes. Meanwhile it offers comparable performance to the others on
secondary criteria such as volatility, Sharpe ratio and maximum drawdown.
"
1911.05309,2019-11-15,Adaptive Portfolio by Solving Multi-armed Bandit via Thompson Sampling,"  As the cornerstone of modern portfolio theory, Markowitz's mean-variance
optimization is considered a major model adopted in portfolio management.
However, due to the difficulty of estimating its parameters, it cannot be
applied to all periods. In some cases, naive strategies such as
Equally-weighted and Value-weighted portfolios can even get better performance.
Under these circumstances, we can use multiple classic strategies as multiple
strategic arms in multi-armed bandit to naturally establish a connection with
the portfolio selection problem. This can also help to maximize the rewards in
the bandit algorithm by the trade-off between exploration and exploitation. In
this paper, we present a portfolio bandit strategy through Thompson sampling
which aims to make online portfolio choices by effectively exploiting the
performances among multiple arms. Also, by constructing multiple strategic
arms, we can obtain the optimal investment portfolio to adapt different
investment periods. Moreover, we devise a novel reward function based on users'
different investment risk preferences, which can be adaptive to various
investment styles. Our experimental results demonstrate that our proposed
portfolio strategy has marked superiority across representative real-world
market datasets in terms of extensive evaluation criteria.
"
1911.06552,2021-10-13,"An approximate solution for the power utility optimization under
  predictable returns","  This work derives an approximate analytical single period solution of the
portfolio choice problem for the power utility function. It is possible to do
so if we consider that the asset returns follow a multivariate normal
distribution. It is shown in the literature that the log-normal distribution
seems to be a good proxy of the normal distribution in case if the standard
deviation of the last one is way smaller than its mean. So we can use this
property because this happens to be true for gross portfolio returns. In
addition, we present a different solution method that relies on the machine
learning algorithm called Gradient Descent. It is a powerful tool to solve a
wide range of problems, and it was possible to implement this approach to
portfolio selection. Besides, the paper provides a simulation study, where we
compare the derived results with the well-known solution, which uses a Taylor
series expansion of the utility function.
"
1911.06893,2019-11-19,Imitation in the Imitation Game,"  We discuss the objectives of automation equipped with non-trivial decision
making, or creating artificial intelligence, in the financial markets and
provide a possible alternative. Intelligence might be an unintended consequence
of curiosity left to roam free, best exemplified by a frolicking infant. For
this unintentional yet welcome aftereffect to set in a foundational list of
guiding principles needs to be present. A consideration of these requirements
allows us to propose a test of intelligence for trading programs, on the lines
of the Turing Test, long the benchmark for intelligent machines. We discuss the
application of this methodology to the dilemma in finance, which is whether,
when and how much to Buy, Sell or Hold.
"
1911.07526,2024-05-29,Bayesian Filtering for Multi-period Mean-Variance Portfolio Selection,"  For a long investment time horizon, it is preferable to rebalance the
portfolio weights at intermediate times. This necessitates a multi-period
market model in which portfolio optimization is usually done through dynamic
programming. However, this assumes a known distribution for the parameters of
the financial time series. We consider the situation where this distribution is
unknown and needs to be estimated from the data that is arriving dynamically.
We applied Bayesian filtering through dynamic linear models to sequentially
update the parameters. We considered uncertain investment lifetime to make the
model more adaptive to the market conditions. These updated parameters are put
into the dynamic mean-variance problem to arrive at optimal efficient
portfolios. Extensive simulations are conducted to study the effect of varying
underlying parameters and investment horizon on the performance of the method.
An implementation of this model to the S&P500 illustrates that the Bayesian
updating is strongly favored by the data and that it is practically
implementable.
"
1911.10047,2019-11-25,"Collectivised Pension Investment with Homogeneous Epstein-Zin
  Preferences","  In a collectivised pension fund, investors agree that any money remaining in
the fund when they die can be shared among the survivors.
  We compute analytically the optimal investment-consumption strategy for a
fund of $n$ identical investors with homogeneous Epstein--Zin preferences,
investing in the Black--Scholes market in continuous time but consuming in
discrete time. Our result holds for arbitrary mortality distributions.
  We also compute the optimal strategy for an infinite fund of investors, and
prove the convergence of the optimal strategy as $n\to \infty$. The proof of
convergence shows that effective strategies for inhomogeneous funds can be
obtained using the optimal strategies found in this paper for homogeneous
funds, using the results of [2].
  We find that a constant consumption strategy is suboptimal even for infinite
collectives investing in markets where assets provide no return so long as
investors are ""satisfaction risk-averse."" This suggests that annuities and
defined benefit investments will always be suboptimal investments.
  We present numerical results examining the importance of the fund size, $n$,
and the market parameters.
"
1911.10254,2019-11-26,Omega and Sharpe ratio,"  Omega ratio, defined as the probability-weighted ratio of gains over losses
at a given level of expected return, has been advocated as a better performance
indicator compared to Sharpe and Sortino ratio as it depends on the full return
distribution and hence encapsulates all information about risk and return. We
compute Omega ratio for the normal distribution and show that under some
distribution symmetry assumptions, the Omega ratio is oversold as it does not
provide any additional information compared to Sharpe ratio. Indeed, for
returns that have elliptic distributions, we prove that the optimal portfolio
according to Omega ratio is the same as the optimal portfolio according to
Sharpe ratio. As elliptic distributions are a weak form of symmetric
distributions that generalized Gaussian distributions and encompass many fat
tail distributions, this reduces tremendously the potential interest for the
Omega ratio.
"
1911.11880,2023-10-30,"A General Framework on Enhancing Portfolio Management with Reinforcement
  Learning","  Portfolio management is the art and science in fiance that concerns
continuous reallocation of funds and assets across financial instruments to
meet the desired returns to risk profile. Deep reinforcement learning (RL) has
gained increasing interest in portfolio management, where RL agents are trained
base on financial data to optimize the asset reallocation process. Though there
are prior efforts in trying to combine RL and portfolio management, previous
works did not consider practical aspects such as transaction costs or short
selling restrictions, limiting their applicability. To address these
limitations, we propose a general RL framework for asset management that
enables continuous asset weights, short selling and making decisions with
relevant features. We compare the performance of three different RL algorithms:
Policy Gradient with Actor-Critic (PGAC), Proximal Policy Optimization (PPO),
and Evolution Strategies (ES) and demonstrate their advantages in a simulated
environment with transaction costs. Our work aims to provide more options for
utilizing RL frameworks in real-life asset management scenarios and can benefit
further research in financial applications.
"
1912.04221,2019-12-10,Leakage of rank-dependent functionally generated trading strategies,"  This paper investigates the so-called leakage effect of trading strategies
generated functionally from rank-dependent portfolio generating functions. This
effect measures the loss in wealth of trading strategies due to renewing the
portfolio constituent stocks. Theoretically, the leakage effect of a trading
strategy is expressed explicitly by a finite-variation term. The computation of
the leakage is different from what previous research has suggested. The method
to estimate leakage in discrete time is then introduced with some practical
considerations. An empirical example illustrates the leakage of the
corresponding trading strategies under different constituent list sizes.
"
1912.04492,2019-12-11,151 Estrategias de Trading (151 Trading Strategies),"  This book, which is in Spanish, provides detailed descriptions, including
over 550 mathematical formulas, for over 150 trading strategies across a host
of asset classes (and trading styles). This includes stocks, options, fixed
income, futures, ETFs, indexes, commodities, foreign exchange, convertibles,
structured assets, volatility (as an asset class), real estate, distressed
assets, cash, cryptocurrencies, miscellany (such as weather, energy,
inflation), global macro, infrastructure, and tax arbitrage. Some strategies
are based on machine learning algorithms (such as artificial neural networks,
Bayes, k-nearest neighbors). We also give: source code for illustrating
out-of-sample backtesting with explanatory notes; around 2,000 bibliographic
references; and over 900 glossary, acronym and math definitions. The
presentation is intended to be descriptive and pedagogical.
  -----
  Este libro proporciona descripciones detalladas, que incluyen m\'as de 550
f\'ormulas matem\'aticas, para m\'as de 150 estrategias de trading para una
gran cantidad de clases de activos y estilos de trading. Esto incluye acciones,
opciones, bonos (renta fija), futuros, ETFs, \'indices, commodities, divisas,
bonos convertibles, activos estructurados, volatilidad (como clase de activos),
bienes inmuebles, activos en distress, efectivo, criptomonedas, miscel\'aneos
(como clima, energ\'ia, inflaci\'on), macro global, infraestructura y arbitraje
impositivo. Algunas estrategias se basan en algoritmos de aprendizaje
autom\'atico (como redes neuronales artificiales, Bayes, k vecinos m\'as
cercanos). El libro tambi\'en incluye c\'odigo para backtesting fuera de la
muestra con notas explicativas; cerca de 2,000 referencias bibliogr\'aficas;
m\'as de 900 t\'erminos que comprenden el glosario, acr\'onimos y definiciones
matem\'aticas. La presentaci\'on pretende ser descriptiva y pedag\'ogica.
"
1912.06426,2019-12-16,"Portfolio liquidation under transient price impact -- theoretical
  solution and implementation with 100 NASDAQ stocks","  We derive an explicit solution for deterministic market impact parameters in
the Graewe and Horst (2017) portfolio liquidation model. The model allows to
combine various forms of market impact, namely instantaneous, permanent and
temporary. We show that the solutions to the two benchmark models of Almgren
and Chris (2001) and of Obizhaeva and Wang (2013) are obtained as special
cases. We relate the different forms of market impact to the microstructure of
limit order book markets and show how the impact parameters can be estimated
from public market data. We investigate the numerical performance of the
derived optimal trading strategy based on high frequency limit order books of
100 NASDAQ stocks that represent a range of market impact profiles. It shows
the strategy achieves significant cost savings compared to the benchmark models
of Almgren and Chris (2001) and of Obizhaeva and Wang (2013).
"
1912.09573,2019-12-23,Comparison of various risk measures for an optimal portfolio,"  In this paper, we search for optimal portfolio strategies in the presence of
various risk measure that are common in financial applications. Particularly,
we deal with the static optimization problem with respect to Value at Risk,
Expected Loss and Expected Utility Loss measures. To do so, under the Black-
Scholes model for the financial market, Martingale method is applied to give
closed-form solutions for the optimal terminal wealths; then via representation
problem the optimal portfolio strategies are achieved. We compare the
performances of these measures on the terminal wealths and optimal strategies
of such constrained investors. Finally, we present some numerical results to
compare them in several respects to give light to further studies.
"
1912.09964,2019-12-23,Grouping of Contracts in Insurance using Neural Networks,"  Despite the high importance of grouping in practice, there exists little
research on the respective topic. The present work presents a complete
framework for grouping and a novel method to optimize model points. Model
points are used to substitute clusters of contracts in an insurance portfolio
and thus yield a smaller, computationally less burdensome portfolio. This
grouped portfolio is controlled to have similar characteristics as the original
portfolio. We provide numerical results for term life insurance and defined
contribution plans, which indicate the superiority of our approach compared to
K-means clustering, a common baseline algorithm for grouping. Lastly, we show
that the presented concept can optimize a fixed number of model points for the
entire portfolio simultaneously. This eliminates the need for any
pre-clustering of the portfolio, e.g. by K-means clustering, and therefore
presents our method as an entirely new and independent methodology.
"
1912.10328,2019-12-24,"Portfolio optimization based on forecasting models using vine copulas:
  An empirical assessment for the financial crisis","  We employ and examine vine copulas in modeling symmetric and asymmetric
dependency structures and forecasting financial returns. We analyze the asset
allocations performed during the 2008-2009 financial crisis and test different
portfolio strategies such as maximum Sharpe ratio, minimum variance, and
minimum conditional Value-at-Risk. We then specify the regular, drawable, and
canonical vine copulas, such as the Student-t, Clayton, Frank, Joe, Gumbel, and
mixed copulas, and analyze both in-sample and out-of-sample portfolio
performances. Out-of-sample portfolio back-testing shows that vine copulas
reduce portfolio risk better than simple copulas. Our econometric analysis of
the outcomes of the various models shows that in terms of reducing conditional
Value-at-Risk, D-vines appear to be better than R- and C-vines. Overall, we
find that the Student-t drawable vine copula models perform best with regard to
risk reduction, both for the entire period 2005-2012 as well as during the
financial crisis.
"
1912.10709,2020-08-17,"Centralizing-Unitizing Standardized High-Dimensional Directional
  Statistics and Its Applications in Finance","  Cross-sectional ""Information Coefficient"" (IC) is a widely and deeply
accepted measure in portfolio management. The paper gives an insight into IC in
view of high-dimensional directional statistics: IC is a linear operator on the
components of a centralizing-unitizing standardized random vector of
next-period cross-sectional returns. Our primary research first clearly defines
IC with the high-dimensional directional statistics, discussing its first two
moments. We derive the closed-form expressions of the directional statistics'
covariance matrix and IC's variance in a homoscedastic condition. Also, we
solve the optimization of IC's maximum expectation and minimum variance.
Simulation intuitively characterizes the standardized directional statistics
and IC's p.d.f.. The empirical analysis of the Chinese stock market uncovers
interesting facts about the standardized vectors of cross-sectional returns and
helps obtain the time series of the measure in the real market. The paper
discovers a potential application of directional statistics in finance, proves
explicit results of the projected normal distribution, and reveals IC's nature.
"
1912.12521,2020-01-01,Portfolio Optimization under Correlation Constraint,"  We consider the problem of portfolio optimization with a correlation
constraint. The framework is the multiperiod stochastic financial market
setting with one tradable stock, stochastic income and a non-tradable index.
The correlation constraint is imposed on the portfolio and the non-tradable
index at some benchmark time horizon. The goal is to maximize portofolio's
expected exponential utility subject to the correlation constraint. Two types
of optimal portfolio strategies are considered: the subgame perfect and the
precommitment ones. We find analytical expressions for the constrained subgame
perfect (CSGP) and the constrained precommitment (CPC) portfolio strategies.
Both these portfolio strategies yield significantly lower risk when compared to
the unconstrained setting, at the cost of a small utility loss. The performance
of the CSGP and CPC portfolio strategies is similar.
"
1912.12611,2020-01-01,Credit Risk: Simple Closed Form Approximate Maximum Likelihood Estimator,"  We consider discrete default intensity based and logit type reduced form
models for conditional default probabilities for corporate loans where we
develop simple closed form approximations to the maximum likelihood estimator
(MLE) when the underlying covariates follow a stationary Gaussian process. In a
practically reasonable asymptotic regime where the default probabilities are
small, say 1-3% annually, the number of firms and the time period of data
available is reasonably large, we rigorously show that the proposed estimator
behaves similarly or slightly worse than the MLE when the underlying model is
correctly specified. For more realistic case of model misspecification, both
estimators are seen to be equally good, or equally bad. Further, beyond a
point, both are more-or-less insensitive to increase in data. These conclusions
are validated on empirical and simulated data. The proposed approximations
should also have applications outside finance, where logit-type models are used
and probabilities of interest are small.
"
2001.01612,2020-01-07,A Note on Portfolio Optimization with Quadratic Transaction Costs,"  In this short note, we consider mean-variance optimized portfolios with
transaction costs. We show that introducing quadratic transaction costs makes
the optimization problem more difficult than using linear transaction costs.
The reason lies in the specification of the budget constraint, which is no
longer linear. We provide numerical algorithms for solving this issue and
illustrate how transaction costs may considerably impact the expected returns
of optimized portfolios.
"
2001.01646,2020-01-07,The Optimal Dynamic Reinsurance Strategies in Multidimensional Portfolio,"  The present paper addresses the issue of choosing an optimal dynamic
reinsurance policy, which is state-dependent, for an insurance company that
operates under multiple insurance business lines. The optimal survival function
is characterized as the unique nondecreasing viscosity solution of the
associated Hamilton-Jacobi-Bellman equation (HJB) equation with limit one at
infinity. The finite difference method (FDM) has been utilized for the
numerical solution of the optimal survival function and optimal dynamic
reinsurance strategies and the proof for the convergence of the numerical
solution to the survival probability function is provided.
"
2001.01998,2021-04-28,"A note on the worst case approach for a market with a stochastic
  interest rate","  We solve robust optimization problem and show the example of the market model
for which the worst case measure is not a martingale measure. In our model the
instantaneous interest rate is determined by the Hull-White model and the
investor employs the HARA utility to measure his satisfaction.To protect
against the model uncertainty he uses the worst case measure approach. The
problem is formulated as a stochastic game between the investor and the market
from the other side. PDE methods are used to find the saddle point and the
precise verification argument is provided.
"
2001.02966,2020-04-20,Clustering Approaches for Global Minimum Variance Portfolio,"  The only input to attain the portfolio weights of global minimum variance
portfolio (GMVP) is the covariance matrix of returns of assets being considered
for investment. Since the population covariance matrix is not known, investors
use historical data to estimate it. Even though sample covariance matrix is an
unbiased estimator of the population covariance matrix, it includes a great
amount of estimation error especially when the number of observed data is not
much bigger than number of assets. As it is difficult to estimate the
covariance matrix with high dimensionality all at once, clustering stocks is
proposed to come up with covariance matrix in two steps: firstly, within a
cluster and secondly, between clusters. It decreases the estimation error by
reducing the number of features in the data matrix. The motivation of this
dissertation is that the estimation error can still remain high even after
clustering, if a large amount of stocks is clustered together in a single
group. This research proposes to utilize a bounded clustering method in order
to limit the maximum cluster size. The result of experiments shows that not
only the gap between in-sample volatility and out-of-sample volatility
decreases, but also the out-of-sample volatility gets reduced. It implies that
we need a bounded clustering algorithm so that maximum clustering size can be
precisely controlled to find the best portfolio performance.
"
2001.08240,2020-01-24,A growth adjusted price-earnings ratio,"  The purpose of this paper is to introduce a new growth adjusted
price-earnings measure (GA-P/E) and assess its efficacy as measure of value and
predictor of future stock returns. Taking inspiration from the interpretation
of the traditional price-earnings ratio as a period of time, the new measure
computes the requisite payback period whilst accounting for earnings growth.
Having derived the measure, we outline a number of its properties before
conducting an extensive empirical study utilising a sorted portfolio
methodology. We find that the returns of the low GA-P/E stocks exceed those of
the high GA-P/E stocks, both in an absolute sense and also on a risk-adjusted
basis. Furthermore, the returns from the low GA-P/E porfolio was found to
exceed those of the value portfolio arising from a P/E sort on the same pool of
stocks. Finally, the returns of our GA-P/E sorted porfolios were subjected to
analysis by conducting regressions against the standard Fama and French risk
factors.
"
2001.08911,2020-01-27,Refined model of the covariance/correlation matrix between securities,"  A new methodology has been introduced to clean the correlation matrix of
single stocks returns based on a constrained principal component analysis using
financial data. Portfolios were introduced, namely ""Fundamental Maximum
Variance Portfolios"", to capture in an optimal way the risks defined by
financial criteria (""Book"", ""Capitalization"", etc.). The constrained
eigenvectors of the correlation matrix, which are the linear combination of
these portfolios, are then analyzed. Thanks to this methodology, several
stylized patterns of the matrix were identified: i) the increase of the first
eigenvalue with a time scale from 1 minute to several months seems to follow
the same law for all the significant eigenvalues with 2 regimes; ii) a
universal law seems to govern the weights of all the ""Maximum variance""
portfolios, so according to that law, the optimal weights should be
proportional to the ranking based on the financial studied criteria; iii) the
volatility of the volatility of the ""Maximum Variance"" portfolios, which are
not orthogonal, could be enough to explain a large part of the diffusion of the
correlation matrix; iv) the leverage effect (increase of the first eigenvalue
with the decline of the stock market) occurs only for the first mode and cannot
be generalized for other factors of risk. The leverage effect on the beta,
which is the sensitivity of stocks with the market mode, makes variable the
weights of the first eigenvector.
"
2001.09404,2023-03-10,"Semi-metric portfolio optimization: a new algorithm reducing
  simultaneous asset shocks","  This paper proposes a new method for financial portfolio optimization based
on reducing simultaneous asset shocks across a collection of assets. This may
be understood as an alternative approach to risk reduction in a portfolio based
on a new mathematical quantity. First, we apply recently introduced
semi-metrics between finite sets to determine the distance between time series'
structural breaks. Then, we build on the classical portfolio optimization
theory of Markowitz and use this distance between asset structural breaks for
our penalty function, rather than portfolio variance. Our experiments are
promising: on synthetic data, we show that our proposed method does indeed
diversify among time series with highly similar structural breaks and enjoys
advantages over existing metrics between sets. On real data, experiments
illustrate that our proposed optimization method performs well relative to nine
other commonly used options, producing the second-highest returns, the lowest
volatility, and second-lowest drawdown. The main implication for this method in
portfolio management is reducing simultaneous asset shocks and potentially
sharp associated drawdowns during periods of highly similar structural breaks,
such as a market crisis. Our method adds to a considerable literature of
portfolio optimization techniques in econometrics and could complement these
via portfolio averaging.
"
2001.11301,2021-07-21,Robust Optimal Investment and Reinsurance Problems with Learning,"  In this paper we consider an optimal investment and reinsurance problem with
partially unknown model parameters which are allowed to be learned. The model
includes multiple business lines and dependence between them. The aim is to
maximize the expected exponential utility of terminal wealth which is shown to
imply a robust approach. We can solve this problem using a generalized HJB
equation where derivatives are replaced by generalized Clarke gradients. The
optimal investment strategy can be determined explicitly and the optimal
reinsurance strategy is given in terms of the solution of an equation. Since
this equation is hard to solve, we derive bounds for the optimal reinsurance
strategy via comparison arguments.
"
2002.00201,2020-02-04,"Optimal portfolio choice with path dependent labor income: the infinite
  horizon case","  We consider an infinite horizon portfolio problem with borrowing constraints,
in which an agent receives labor income which adjusts to financial market
shocks in a path dependent way. This path-dependency is the novelty of the
model, and leads to an infinite dimensional stochastic optimal control problem.
We solve the problem completely, and find explicitly the optimal controls in
feedback form. This is possible because we are able to find an explicit
solution to the associated infinite dimensional Hamilton-Jacobi-Bellman (HJB)
equation, even if state constraints are present. To the best of our knowledge,
this is the first infinite dimensional generalization of Merton's optimal
portfolio problem for which explicit solutions can be found. The explicit
solution allows us to study the properties of optimal strategies and discuss
their financial implications.
"
2002.01800,2022-02-04,"Sharpe Ratio Analysis in High Dimensions: Residual-Based Nodewise
  Regression in Factor Models","  We provide a new theory for nodewise regression when the residuals from a
fitted factor model are used. We apply our results to the analysis of the
consistency of Sharpe ratio estimators when there are many assets in a
portfolio. We allow for an increasing number of assets as well as time
observations of the portfolio. Since the nodewise regression is not feasible
due to the unknown nature of idiosyncratic errors, we provide a
feasible-residual-based nodewise regression to estimate the precision matrix of
errors which is consistent even when number of assets, p, exceeds the time span
of the portfolio, n. In another new development, we also show that the
precision matrix of returns can be estimated consistently, even with an
increasing number of factors and p>n. We show that: (1) with p>n, the Sharpe
ratio estimators are consistent in global minimum-variance and mean-variance
portfolios; and (2) with p>n, the maximum Sharpe ratio estimator is consistent
when the portfolio weights sum to one; and (3) with p<<n, the
maximum-out-of-sample Sharpe ratio estimator is consistent.
"
2002.02008,2020-09-29,"Detecting Changes in Asset Co-Movement Using the Autoencoder
  Reconstruction Ratio","  Detecting changes in asset co-movements is of much importance to financial
practitioners, with numerous risk management benefits arising from the timely
detection of breakdowns in historical correlations. In this article, we propose
a real-time indicator to detect temporary increases in asset co-movements, the
Autoencoder Reconstruction Ratio, which measures how well a basket of asset
returns can be modelled using a lower-dimensional set of latent variables. The
ARR uses a deep sparse denoising autoencoder to perform the dimensionality
reduction on the returns vector, which replaces the PCA approach of the
standard Absorption Ratio, and provides a better model for non-Gaussian
returns. Through a systemic risk application on forecasting on the CRSP US
Total Market Index, we show that lower ARR values coincide with higher
volatility and larger drawdowns, indicating that increased asset co-movement
does correspond with periods of market weakness. We also demonstrate that
short-term (i.e. 5-min and 1-hour) predictors for realised volatility and
market crashes can be improved by including additional ARR inputs.
"
2002.03286,2020-11-25,"Stability and asymptotic analysis of the F\""ollmer-Schweizer
  decomposition on a finite probability space","  First, we consider the problem of hedging in complete binomial models. Using
the discrete-time F\""ollmer-Schweizer decomposition, we demonstrate the
equivalence of the backward induction and sequential regression approaches.
Second, in incomplete trinomial models, we examine the extension of the
sequential regression approach for approximation of contingent claims. Then, on
a finite probability space, we investigate stability of the discrete-time
F\""ollmer-Schweizer decomposition with respect to perturbations of the stock
price dynamics and, finally, perform its asymptotic analysis under simultaneous
perturbations of the drift and volatility of the underlying discounted stock
price process, where we prove stability and obtain explicit formulas for the
leading order correction terms.
"
2002.04304,2020-02-12,Timing Excess Returns A cross-universe approach to alpha,"  We present a simple model that uses time series momentum in order to
construct strategies that systematically outperform their benchmark. The
simplicity of our model is elegant: We only require a benchmark time series and
several related investable indizes, not requiring regression or other models to
estimate our parameters. We find that our one size fits all approach delivers
significant outperformance in both equity and bond markets while meeting the
ex-ante risk requirements, nearly doubling yearly returns vs. the MSCI World
and Bloomberg Barclays Euro Aggregate Corporate Bond benchmarks in a long-only
backtest. We then combine both approaches into an absolute return strategy by
benchmarking vs. the Eonia Total Return Index and find significant
outperformance at a sharpe ratio of 1.8. Furthermore, we demonstrate that our
model delivers a benefit versus a static portfolio with fixed mean weights,
showing that timing of excess return momentum has a sizeable benefit vs. static
allocations. This also applies to the passively investable equity factors,
where we outperform a static factor exposure portfolio with statistical
significance. Also, we show that our model delivers an alpha after deducting
transaction costs.
"
2002.05780,2020-02-17,"Reinforcement-Learning based Portfolio Management with Augmented Asset
  Movement Prediction States","  Portfolio management (PM) is a fundamental financial planning task that aims
to achieve investment goals such as maximal profits or minimal risks. Its
decision process involves continuous derivation of valuable information from
various data sources and sequential decision optimization, which is a
prospective research direction for reinforcement learning (RL). In this paper,
we propose SARL, a novel State-Augmented RL framework for PM. Our framework
aims to address two unique challenges in financial PM: (1) data heterogeneity
-- the collected information for each asset is usually diverse, noisy and
imbalanced (e.g., news articles); and (2) environment uncertainty -- the
financial market is versatile and non-stationary. To incorporate heterogeneous
data and enhance robustness against environment uncertainty, our SARL augments
the asset information with their price movement prediction as additional
states, where the prediction can be solely based on financial data (e.g., asset
prices) or derived from alternative sources such as news. Experiments on two
real-world datasets, (i) Bitcoin market and (ii) HighTech stock market with
7-year Reuters news articles, validate the effectiveness of SARL over existing
PM approaches, both in terms of accumulated profits and risk-adjusted profits.
Moreover, extensive simulations are conducted to demonstrate the importance of
our proposed state augmentation, providing new insights and boosting
performance significantly over standard RL-based PM method and other baselines.
"
2002.06243,2020-07-21,"TPLVM: Portfolio Construction by Student's $t$-process Latent Variable
  Model","  Optimal asset allocation is a key topic in modern finance theory. To realize
the optimal asset allocation on investor's risk aversion, various portfolio
construction methods have been proposed. Recently, the applications of machine
learning are rapidly growing in the area of finance. In this article, we
propose the Student's $t$-process latent variable model (TPLVM) to describe
non-Gaussian fluctuations of financial timeseries by lower dimensional latent
variables. Subsequently, we apply the TPLVM to minimum-variance portfolio as an
alternative of existing nonlinear factor models. To test the performance of the
proposed portfolio, we construct minimum-variance portfolios of global stock
market indices based on the TPLVM or Gaussian process latent variable model. By
comparing these portfolios, we confirm the proposed portfolio outperforms that
of the existing Gaussian process latent variable model.
"
2002.06975,2020-07-21,"Cross-sectional Stock Price Prediction using Deep Learning for Actual
  Investment Management","  Stock price prediction has been an important research theme both academically
and practically. Various methods to predict stock prices have been studied
until now. The feature that explains the stock price by a cross-section
analysis is called a ""factor"" in the field of finance. Many empirical studies
in finance have identified which stocks having features in the cross-section
relatively increase and which decrease in terms of price. Recently, stock price
prediction methods using machine learning, especially deep learning, have been
proposed since the relationship between these factors and stock prices is
complex and non-linear. However, there are no practical examples for actual
investment management. In this paper, therefore, we present a cross-sectional
daily stock price prediction framework using deep learning for actual
investment management. For example, we build a portfolio with information
available at the time of market closing and invest at the time of market
opening the next day. We perform empirical analysis in the Japanese stock
market and confirm the profitability of our framework.
"
2002.07477,2020-04-07,ESG investments: Filtering versus machine learning approaches,"  We designed a machine learning algorithm that identifies patterns between ESG
profiles and financial performances for companies in a large investment
universe. The algorithm consists of regularly updated sets of rules that map
regions into the high-dimensional space of ESG features to excess return
predictions. The final aggregated predictions are transformed into scores which
allow us to design simple strategies that screen the investment universe for
stocks with positive scores. By linking the ESG features with financial
performances in a non-linear way, our strategy based upon our machine learning
algorithm turns out to be an efficient stock picking tool, which outperforms
classic strategies that screen stocks according to their ESG ratings, as the
popular best-in-class approach. Our paper brings new ideas in the growing field
of financial literature that investigates the links between ESG behavior and
the economy. We show indeed that there is clearly some form of alpha in the ESG
profile of a company, but that this alpha can be accessed only with powerful,
non-linear techniques such as machine learning.
"
2002.10990,2020-02-26,"G-Learner and GIRL: Goal Based Wealth Management with Reinforcement
  Learning","  We present a reinforcement learning approach to goal based wealth management
problems such as optimization of retirement plans or target dated funds. In
such problems, an investor seeks to achieve a financial goal by making periodic
investments in the portfolio while being employed, and periodically draws from
the account when in retirement, in addition to the ability to re-balance the
portfolio by selling and buying different assets (e.g. stocks). Instead of
relying on a utility of consumption, we present G-Learner: a reinforcement
learning algorithm that operates with explicitly defined one-step rewards, does
not assume a data generation process, and is suitable for noisy data. Our
approach is based on G-learning - a probabilistic extension of the Q-learning
method of reinforcement learning.
  In this paper, we demonstrate how G-learning, when applied to a quadratic
reward and Gaussian reference policy, gives an entropy-regulated Linear
Quadratic Regulator (LQR). This critical insight provides a novel and
computationally tractable tool for wealth management tasks which scales to high
dimensional portfolios. In addition to the solution of the direct problem of
G-learning, we also present a new algorithm, GIRL, that extends our goal-based
G-learning approach to the setting of Inverse Reinforcement Learning (IRL)
where rewards collected by the agent are not observed, and should instead be
inferred. We demonstrate that GIRL can successfully learn the reward parameters
of a G-Learner agent and thus imitate its behavior. Finally, we discuss
potential applications of the G-Learner and GIRL algorithms for wealth
management and robo-advising.
"
2003.00656,2021-11-05,Machine Learning Portfolio Allocation,"  We find economically and statistically significant gains when using machine
learning for portfolio allocation between the market index and risk-free asset.
Optimal portfolio rules for time-varying expected returns and volatility are
implemented with two Random Forest models. One model is employed in forecasting
the sign probabilities of the excess return with payout yields. The second is
used to construct an optimized volatility estimate. Reward-risk timing with
machine learning provides substantial improvements over the buy-and-hold in
utility, risk-adjusted returns, and maximum drawdowns. This paper presents a
new theoretical basis and unifying framework for machine learning applied to
both return- and volatility-timing.
"
2003.00884,2020-03-03,"Cleaner Production in Optimized Multivariate Networks: Operations
  Management through a Roll of Dice","  The importance of supply chain management in analyzing and later catalyzing
economic expectations while simultaneously prioritizing cleaner production
aspects is a vital component of modern finance. Such predictions, though, are
often known to be less than accurate due to the ubiquitous uncertainty plaguing
most business decisions. Starting from a multi-dimensional cost function
defining the sustainability of the supply chain (SC) kernel, this article
outlines a 4-component SC module - environmental, demand, economic, and social
uncertainties - each ranked according to its individual weight. Our
mathematical model then assesses the viability of a sustainable business by
first ranking the potentially stochastic variables in order of their subjective
importance, and then optimizing the cost kernel, defined from a utility
function. The model will then identify conditions (as equations) validating the
sustainability of a business venture. The ranking is initially obtained from an
Analytical Hierarchical Process; the resultant weighted cost function is then
optimized to analyze the impact of market uncertainty based on our supply chain
model. Model predictions are then ratified against SME data to emphasize the
importance of cleaner production in business strategies.
"
2003.01809,2020-03-05,"Numerical Solution of Dynamic Portfolio Optimization with Transaction
  Costs","  We apply numerical dynamic programming techniques to solve discrete-time
multi-asset dynamic portfolio optimization problems with proportional
transaction costs and shorting/borrowing constraints. Examples include problems
with multiple assets, and many trading periods in a finite horizon problem. We
also solve dynamic stochastic problems, with a portfolio including one
risk-free asset, an option, and its underlying risky asset, under the existence
of transaction costs and constraints. These examples show that it is now
tractable to solve such problems.
"
2003.02515,2021-01-25,Time-varying neural network for stock return prediction,"  We consider the problem of neural network training in a time-varying context.
Machine learning algorithms have excelled in problems that do not change over
time. However, problems encountered in financial markets are often
time-varying. We propose the online early stopping algorithm and show that a
neural network trained using this algorithm can track a function changing with
unknown dynamics. We compare the proposed algorithm to current approaches on
predicting monthly U.S. stock returns and show its superiority. We also show
that prominent factors (such as the size and momentum effects) and industry
indicators, exhibit time varying stock return predictiveness. We find that
during market distress, industry indicators experience an increase in
importance at the expense of firm level features. This indicates that
industries play a role in explaining stock returns during periods of heightened
risk.
"
2003.06365,2020-03-16,Application of Deep Q-Network in Portfolio Management,"  Machine Learning algorithms and Neural Networks are widely applied to many
different areas such as stock market prediction, face recognition and
population analysis. This paper will introduce a strategy based on the classic
Deep Reinforcement Learning algorithm, Deep Q-Network, for portfolio management
in stock market. It is a type of deep neural network which is optimized by Q
Learning. To make the DQN adapt to financial market, we first discretize the
action space which is defined as the weight of portfolio in different assets so
that portfolio management becomes a problem that Deep Q-Network can solve.
Next, we combine the Convolutional Neural Network and dueling Q-net to enhance
the recognition ability of the algorithm. Experimentally, we chose five
lowrelevant American stocks to test the model. The result demonstrates that the
DQN based strategy outperforms the ten other traditional strategies. The profit
of DQN algorithm is 30% more than the profit of other strategies. Moreover, the
Sharpe ratio associated with Max Drawdown demonstrates that the risk of policy
made with DQN is the lowest.
"
2003.08450,2020-03-20,A Variational Analysis Approach to Solving the Merton Problem,"  We address the Merton problem of maximizing the expected utility of terminal
wealth using techniques from variational analysis. Under a general continuous
semimartingale market model with stochastic parameters, we obtain a
characterization of the optimal portfolio for general utility functions in
terms of a forward-backward stochastic differential equation (FBSDE) and derive
solutions for a number of well-known utility functions. Our results complement
a previous studies conducted on optimal strategies in markets driven by
Brownian noise with random drift and volatility parameters.
"
2003.10419,2021-04-07,"Equity Factors: To Short Or Not To Short, That Is The Question","  What is the best market-neutral implementation of classical Equity Factors?
Should one use the specific predictability of the short-leg to build a zero
beta Long-Short portfolio, in spite of the specific costs associated to
shorting, or is it preferable to ban the shorts and hedge the long-leg with --
say -- an index future? We revisit this question by focusing on the relative
predictability of the two legs, the issue of diversification, and various
sources of costs. Our conclusion is that, using the same Factors, a Long-Short
implementation leads to superior risk-adjusted returns than its Hedged
Long-Only counterpart, at least when Assets Under Management are not too large.
"
2003.13360,2020-09-08,A Framework for Online Investment Algorithms,"  The artificial segmentation of an investment management process into a
workflow with silos of offline human operators can restrict silos from
collectively and adaptively pursuing a unified optimal investment goal. To meet
the investor's objectives, an online algorithm can provide an explicit
incremental approach that makes sequential updates as data arrives at the
process level. This is in stark contrast to offline (or batch) processes that
are focused on making component level decisions prior to process level
integration. Here we present and report results for an integrated, and online
framework for algorithmic portfolio management. This article provides a
workflow that can in-turn be embedded into a process level learning framework.
The workflow can be enhanced to refine signal generation and asset-class
evolution and definitions. Our results confirm that we can use our framework in
conjunction with resampling methods to outperform naive market capitalisation
benchmarks while making clear the extent of back-test over-fitting. We consider
such an online update framework to be a crucial step towards developing
intelligent portfolio selection algorithms that integrate financial theory,
investor views, and data analysis with process-level learning.
"
2003.14359,2020-04-07,A Knightian Irreversible Investment Problem,"  In this paper, we study an irreversible investment problem under Knightian
uncertainty. In a general framework, in which Knightian uncertainty is modeled
through a set of multiple priors, we prove existence and uniqueness of the
optimal investment plan, and derive necessary and sufficient conditions for
optimality. This allows us to construct the optimal policy in terms of the
solution to a stochastic backward equation under the worst-case scenario. In a
time-homogeneous setting - where risk is driven by a geometric Brownian motion
and Knightian uncertainty is realized through a so-called ""k-ignorance"" - we
are able to provide the explicit form of the optimal irreversible investment
plan.
"
2004.01506,2020-04-06,"Asymptotically Optimal Management of Heterogeneous Collectivised
  Investment Funds","  A collectivised fund is a proposed form of pension investment, in which all
investors agree that any funds associated with deceased members should be split
among survivors. For this to be a viable financial product, it is necessary to
know how to manage the fund even when it is heterogeneous: that is when
different investors have different preferences, wealth and mortality. There is
no obvious way to define a single objective for a heterogeneous fund, so this
is not an optimal control problem. In lieu of an objective function, we take an
axiomatic approach. Subject to our axioms on the management of the fund, we
find an upper bound on the utility that can be achieved for each investor,
assuming a complete markets and the absence of systematic longevity risk. We
give a strategy for the management of such heterogeneous funds which achieves
this bound asymptotically as the number of investors tends to infinity.
"
2004.02670,2020-04-07,"Spanning analysis of stock market anomalies under Prospect Stochastic
  Dominance","  We develop and implement methods for determining whether introducing new
securities or relaxing investment constraints improves the investment
opportunity set for prospect investors. We formulate a new testing procedure
for prospect spanning for two nested portfolio sets based on subsampling and
Linear Programming. In an application, we use the prospect spanning framework
to evaluate whether well-known anomalies are spanned by standard factors. We
find that of the strategies considered, many expand the opportunity set of the
prospect type investors, thus have real economic value for them. In-sample and
out-of-sample results prove remarkably consistent in identifying genuine
anomalies for prospect investors.
"
2004.03445,2020-07-01,QuantNet: Transferring Learning Across Systematic Trading Strategies,"  Systematic financial trading strategies account for over 80% of trade volume
in equities and a large chunk of the foreign exchange market. In spite of the
availability of data from multiple markets, current approaches in trading rely
mainly on learning trading strategies per individual market. In this paper, we
take a step towards developing fully end-to-end global trading strategies that
leverage systematic trends to produce superior market-specific trading
strategies. We introduce QuantNet: an architecture that learns market-agnostic
trends and use these to learn superior market-specific trading strategies. Each
market-specific model is composed of an encoder-decoder pair. The encoder
transforms market-specific data into an abstract latent representation that is
processed by a global model shared by all markets, while the decoder learns a
market-specific trading strategy based on both local and global information
from the market-specific encoder and the global model. QuantNet uses recent
advances in transfer and meta-learning, where market-specific parameters are
free to specialize on the problem at hand, whilst market-agnostic parameters
are driven to capture signals from all markets. By integrating over
idiosyncratic market data we can learn general transferable dynamics, avoiding
the problem of overfitting to produce strategies with superior returns. We
evaluate QuantNet on historical data across 3103 assets in 58 global equity
markets. Against the top performing baseline, QuantNet yielded 51% higher
Sharpe and 69% Calmar ratios. In addition we show the benefits of our approach
over the non-transfer learning variant, with improvements of 15% and 41% in
Sharpe and Calmar ratios. Code available in appendix.
"
2004.05322,2020-07-14,"Holding-Based Evaluation upon Actively Managed Stock Mutual Funds in
  China","  We analyze actively managed mutual funds in China from 2005 to 2017. We
develop performance measures for asset allocation and selection. We find that
stock selection ability from holding-based model is positively correlated with
selection ability estimated from Fama-French three-factor model, which is
price-based regression model. We also find that industry allocation from
holding-based model is positively correlated with timing ability estimated from
price-based Treynor-Mazuy model most of the time. We conclude that most
actively managed funds have positive stock selection ability but not asset
allocation ability, which is due to the difficulty in predicting policy
changes.
"
2004.08124,2020-04-20,Minimizing the Ruin Probability under the Sparre Andersen Model,"  In this paper, we consider the problem of minimizing the ruin probability of
an insurance company in which the surplus process follows the Sparre Andersen
model. Similar to Bai et al. \cite{bai2017optimal}, we recast this problem in a
Markovian framework by adding another dimension representing the time elapsed
since the last claim. After Markovization, We investigate the regularity
properties of the value function and state the dynamic programming principle.
Furthermore, we show that the value function is the unique constrained
viscosity solution to the associated Hamilton-Jacobi-Bellman equation. It
should be noted that there is no discount factor in our paper, which makes it
tricky to prove the uniqueness. To overcome this difficulty, we construct the
strict viscosity supersolution. Then instead of comparing the usual viscosity
supersolution and subsolution, we compare the supersolution and the strict
subsolution. Eventually we show that all viscosity subsolution is less than the
supersolution.
"
2004.09042,2020-04-21,"Consistent Calibration of Economic Scenario Generators: The Case for
  Conditional Simulation","  Economic Scenario Generators (ESGs) simulate economic and financial variables
forward in time for risk management and asset allocation purposes. It is often
not feasible to calibrate the dynamics of all variables within the ESG to
historical data alone. Calibration to forward-information such as future
scenarios and return expectations is needed for stress testing and portfolio
optimization, but no generally accepted methodology is available. This paper
introduces the Conditional Scenario Simulator, which is a framework for
consistently calibrating simulations and projections of economic and financial
variables both to historical data and forward-looking information. The
framework can be viewed as a multi-period, multi-factor generalization of the
Black-Litterman model, and can embed a wide array of financial and
macroeconomic models. Two practical examples demonstrate this in a frequentist
and Bayesian setting.
"
2004.09432,2020-04-21,Robust Arbitrage Conditions for Financial Markets,"  This paper investigates arbitrage properties of financial markets under
distributional uncertainty using Wasserstein distance as the ambiguity measure.
The weak and strong forms of the classical arbitrage conditions are considered.
A relaxation is introduced for which we coin the term statistical arbitrage.
The simpler dual formulations of the robust arbitrage conditions are derived. A
number of interesting questions arise in this context. One question is: can we
compute a critical Wasserstein radius beyond which an arbitrage opportunity
exists? What is the shape of the curve mapping the degree of ambiguity to
statistical arbitrage levels? Other questions arise regarding the structure of
best (worst) case distributions and optimal portfolios. Towards answering these
questions, some theory is developed and computational experiments are conducted
for specific problem instances. Finally some open questions and suggestions for
future research are discussed.
"
2004.10096,2021-08-27,Wealth Effect on Portfolio Allocation in Incomplete Markets,"  We develop a novel five-component decomposition of optimal dynamic portfolio
choice, which reveals the simultaneous impacts from market incompleteness and
wealth-dependent utilities. Under the HARA utility and a nonrandom interest
rate, we can explicitly solve for the optimal policy as a combination of a bond
holding scheme and the corresponding simpler CRRA strategy. Under a stochastic
volatility model estimated on US equity data, we use closed-form solution to
demonstrate the sophisticated impacts from the wealth-dependent utilities,
including cycle-dependence and hysteresis effect in optimal portfolio
allocation, as well as a risk-return trade-off in investment performance.
"
2004.10631,2020-04-24,"The new methods for equity fund selection and optimal portfolio
  construction","  We relook at the classic equity fund selection and portfolio construction
problems from a new perspective and propose an easy-to-implement framework to
tackle the problem in practical investment. Rather than the conventional way by
constructing a long only portfolio from a big universe of stocks or macro
factors, we show how to produce a long-short portfolio from a smaller pool of
stocks from mutual fund top holdings and generate impressive results. As these
methods are based on statistical evidence, we need closely monitoring the model
validity, and prepare repair strategies.
"
2004.12099,2020-07-23,"Necessary and Sufficient Conditions for Frequency-Based Kelly Optimal
  Portfolio","  In this paper, we consider a discrete-time portfolio with $m \geq 2$ assets
optimization problem which includes the rebalancing~frequency as an additional
parameter in the maximization. The so-called Kelly Criterion is used as the
performance metric; i.e., maximizing the expected logarithmic growth of a
trader's account, and the portfolio obtained is called the frequency-based
Kelly optimal portfolio. The focal point of this paper is to extend upon the
results of our previous work to obtain various optimality characterizations on
the portfolio. To be more specific, using Kelly's criterion in our
frequency-based formulation, we first prove necessary and sufficient conditions
for the frequency-based Kelly optimal portfolio. With the aid of these
conditions, we then show several new optimality characterizations such as
expected ratio optimality and asymptotic relative optimality, and a result
which we call the Extended Dominant Asset Theorem. That is, we prove that the
$i$th asset is dominant in the portfolio if and only if the Kelly optimal
portfolio consists of that asset only. The word ""extended"" on the theorem comes
from the fact that it was only a sufficiency result that was proved in our
previous work. Hence, in this paper, we improve it to involve a proof of the
necessity part. In addition, the trader's survivability issue (no bankruptcy
consideration) is also studied in detail in our frequency-based trading
framework. Finally, to bridge the theory and practice, we propose a simple
trading algorithm using the notion called dominant asset condition to decide
when should one triggers a trade. The corresponding trading performance using
historical price data is reported as supporting evidence.
"
2004.12400,2020-04-28,A dynamic conditional approach to portfolio weights forecasting,"  We build the time series of optimal realized portfolio weights from
high-frequency data and we suggest a novel Dynamic Conditional Weights (DCW)
model for their dynamics. DCW is benchmarked against popular model-based and
model-free specifications in terms of weights forecasts and portfolio
allocations. Next to portfolio variance, certainty equivalent and turnover, we
introduce the break-even transaction costs as an additional measure that
identifies the range of transaction costs for which one allocation is preferred
to another. By comparing minimum-variance portfolios built on the components of
the Dow Jones 30 Index, the proposed DCW overall attains the best allocations
with respect to the measures considered, for any degree of risk-aversion,
transaction costs and exposure.
"
2004.13347,2020-07-21,RM-CVaR: Regularized Multiple $\beta$-CVaR Portfolio,"  The problem of finding the optimal portfolio for investors is called the
portfolio optimization problem. Such problem mainly concerns the expectation
and variability of return (i.e., mean and variance). Although the variance
would be the most fundamental risk measure to be minimized, it has several
drawbacks. Conditional Value-at-Risk (CVaR) is a relatively new risk measure
that addresses some of the shortcomings of well-known variance-related risk
measures, and because of its computational efficiencies, it has gained
popularity. CVaR is defined as the expected value of the loss that occurs
beyond a certain probability level ($\beta$). However, portfolio optimization
problems that use CVaR as a risk measure are formulated with a single $\beta$
and may output significantly different portfolios depending on how the $\beta$
is selected. We confirm even small changes in $\beta$ can result in huge
changes in the whole portfolio structure. In order to improve this problem, we
propose RM-CVaR: Regularized Multiple $\beta$-CVaR Portfolio. We perform
experiments on well-known benchmarks to evaluate the proposed portfolio.
Compared with various portfolios, RM-CVaR demonstrates a superior performance
of having both higher risk-adjusted returns and lower maximum drawdown.
"
2004.13601,2020-04-29,"Ruin probability in a two-dimensional model with correlated Brownian
  motions","  We consider two insurance companies with endowment processes given by
Brownian motions with drift. The firms can collaborate by transfer payments in
order to maximize the probability that none of them goes bankrupt. We show that
pushing maximally the company with less endowment is the optimal strategy for
the collaboration if the Brownian motions are correlated and the transfer rate
can exceed the drift rates. Moreover, we obtain an explicit formula for the
minimal ruin probability in case of perfectly positively correlated Brownian
motions where we also allow for different diffusion coefficients.
"
2004.13919,2022-03-29,"Technological improvement rate estimates for all technologies: Use of
  patent data and an extended domain description","  In this work, we attempt to provide a comprehensive granular account of the
pace of technological change. More specifically, we survey estimated yearly
performance improvement rates for nearly all definable technologies for the
first time. We do this by creating a correspondence of all patents within the
US patent system to a set of technology domains. A technology domain is a body
of patented inventions achieving the same technological function using the same
knowledge and scientific principles. We obtain a set of 1757 domains using an
extension of the previously defined classification overlap method (COM). These
domains contain 97.14% of all patents within the entire US patent system. From
the identified patent sets, we calculated the average centrality of the patents
in each domain to estimate their improvement rates, following a methodology
tested in prior work. The estimated improvement rates vary from a low of 1.9%
per year for the Mechanical Skin treatment - Hair Removal and wrinkles domain
to a high of 228.8% per year for the Network management - client-server
applications domain. We developed a one-line descriptor identifying the
technological function achieved and the underlying knowledge base for the
largest 50, fastest 20 as well as slowest 20 of these domains, which cover more
than forty percent of the patent system. In general, the rates of improvement
were not a strong function of the patent set size and the fastest improving
domains are predominantly software-based. We make available an online system
that allows for automated searching for domains and improvement rates
corresponding to any technology of interest to researchers, strategists and
policy formulators.
"
2005.01904,2020-07-24,Bellman type strategy for the continuous time mean-variance model,"  To investigate a time-consistent optimal strategy for the continuous time
mean-variance model, we develop a new method to establish the Bellman
principle. Based on this new method, we obtain a time-consistent dynamic
optimal strategy that differs from the pre-committed and game-theoretic
strategies. A comparison with the existing results on the continuous time
mean-variance model shows that our method has several advantages. The explicit
solutions of the dynamic optimal strategy and optimal wealth are given. When
the dynamic optimal strategy is given at the initial time, we do not change it
in the following investment time interval.
"
2005.04761,2023-04-19,Statistical inference for the EU portfolio in high dimensions,"  In this paper, using the shrinkage-based approach for portfolio weights and
modern results from random matrix theory we construct an effective procedure
for testing the efficiency of the expected utility (EU) portfolio and discuss
the asymptotic behavior of the proposed test statistic under the
high-dimensional asymptotic regime, namely when the number of assets $p$
increases at the same rate as the sample size $n$ such that their ratio $p/n$
approaches a positive constant $c\in(0,1)$ as $n\to\infty$. We provide an
extensive simulation study where the power function and receiver operating
characteristic curves of the test are analyzed. In the empirical study, the
methodology is applied to the returns of S\&P 500 constituents.
"
2005.06015,2020-12-07,"Quadratic Hedging for Sequential Claims with Random Weights in Discrete
  Time","  We study a quadratic hedging problem for a sequence of contingent claims with
random weights in discrete time. We obtain the optimal hedging strategy
explicitly in a recursive representation, without imposing the non-degeneracy
(ND) condition on the model and square integrability on hedging strategies. We
relate the general results to hedging under random horizon and fair pricing in
the quadratic sense. We illustrate the significance of our results in an
example in which the ND condition fails.
"
2005.06171,2020-05-19,Inference on Achieved Signal Noise Ratio,"  We describe a procedure to perform approximate inference on the achieved
signal-noise ratio of the Markowitz Portfolio under Gaussian i.i.d. returns.
The procedure relies on a statistic similar to the Sharpe Ratio Information
Criterion. Testing indicates the procedure is somewhat conservative, but
otherwise works well for reasonable values of sample and asset universe sizes.
We adapt the procedure to deal with generalizations of the portfolio
optimization problem.
"
2005.06576,2020-05-15,Short-Term Investments and Indices of Risk,"  We study various decision problems regarding short-term investments in risky
assets whose returns evolve continuously in time. We show that in each problem,
all risk-averse decision makers have the same (problem-dependent) ranking over
short-term risky assets. Moreover, in each problem, the ranking is represented
by the same risk index as in the case of CARA utility agents and normally
distributed risky assets.
"
2005.08703,2023-03-10,"Reactive Global Minimum Variance Portfolios with $k-$BAHC covariance
  cleaning","  We introduce a $k$-fold boosted version of our Boostrapped Average
Hierarchical Clustering cleaning procedure for correlation and covariance
matrices. We then apply this method to global minimum variance portfolios for
various values of $k$ and compare their performance with other state-of-the-art
methods. Generally, we find that our method yields better Sharpe ratios after
transaction costs than competing filtering methods, despite requiring a larger
turnover.
"
2005.09461,2020-09-09,"Forward utilities and Mean-field games under relative performance
  concerns","  We introduce the concept of mean field games for agents using Forward
utilities of CARA type to study a family of portfolio management problems under
relative performance concerns. Under asset specialization of the fund managers,
we solve the forward-utility finite player game and the forward-utility
mean-field game. We study best response and equilibrium strategies in the
single common stock asset and the asset specialization with common noise. As an
application, we draw on the core features of the forward utility paradigm and
discuss a problem of time-consistent mean-field dynamic model selection in
sequential time-horizons.
"
2005.09794,2020-05-21,Pairs Trading with Nonlinear and Non-Gaussian State Space Models,"  This paper studies pairs trading using a nonlinear and non-Gaussian
state-space model framework. We model the spread between the prices of two
assets as an unobservable state variable and assume that it follows a
mean-reverting process. This new model has two distinctive features: (1) The
innovations to the spread is non-Gaussianity and heteroskedastic. (2) The mean
reversion of the spread is nonlinear. We show how to use the filtered spread as
the trading indicator to carry out statistical arbitrage. We also propose a new
trading strategy and present a Monte Carlo based approach to select the optimal
trading rule. As the first empirical application, we apply the new model and
the new trading strategy to two examples: PEP vs KO and EWT vs EWH. The results
show that the new approach can achieve a 21.86% annualized return for the
PEP/KO pair and a 31.84% annualized return for the EWT/EWH pair. As the second
empirical application, we consider all the possible pairs among the largest and
the smallest five US banks listed on the NYSE. For these pairs, we compare the
performance of the proposed approach with that of the existing popular
approaches, both in-sample and out-of-sample. Interestingly, we find that our
approach can significantly improve the return and the Sharpe ratio in almost
all the cases considered.
"
2005.10660,2021-05-05,"A game theoretical approach to homothetic robust forward investment
  performance processes in stochastic factor models","  This paper studies an optimal forward investment problem in an incomplete
market with model uncertainty, in which the underlying stocks depend on the
correlated stochastic factors. The uncertainty stems from the probability
measure chosen by an investor to evaluate the performance. We obtain directly
the representation of the homothetic robust forward performance processes in
factor-form by combining the zero-sum stochastic differential game and ergodic
BSDE approach. We also establish the connections with the risk-sensitive
zero-sum stochastic differential games over an infinite horizon with ergodic
payoff criteria, as well as with the classical robust expected utilities for
long time horizons. Finally, we give an example to illustrate that our approach
can be applied to address a type of robust forward investment performance
processes with negative realization processes.
"
2005.10661,2020-05-22,"The optimal investment strategy of a DC pension plan under deposit loan
  spread and the O-U process","  This paper is devoted to invest an optimal investment strategy for a
defined-contribution (DC) pension plan under the Ornstein-Uhlenbeck (O-U)
process and the loan. By considering risk-free asset, a risky asset driven by
O-U process and a loan in the financial market, we firstly set up the dynamic
equation and the asset market model which are instrumental in achieving the
expected utility of ultimate wealth at retirement. Secondly, the corresponding
Hamilton-Jacobi-Bellman(HJB) equation is derived by means of dynamic
programming principle. The explicit expression for the optimal investment
strategy is obtained by Legendre transform method. Finally, different
parameters are selected to simulate the explicit solution and the financial
interpretation of the optimal investment strategy is given.
"
2005.12774,2020-12-10,Mean-Variance Portfolio Management with Functional Optimization,"  This paper introduces a new functional optimization approach to portfolio
optimization problems by treating the unknown weight vector as a function of
past values instead of treating them as fixed unknown coefficients in the
majority of studies. We first show that the optimal solution, in general, is
not a constant function. We give the optimal conditions for a vector function
to be the solution, and hence give the conditions for a plug-in solution
(replacing the unknown mean and variance by certain estimates based on past
values) to be optimal. After showing that the plug-in solutions are sub-optimal
in general, we propose gradient-ascent algorithms to solve the functional
optimization for mean-variance portfolio management with theorems for
convergence provided. Simulations and empirical studies show that our approach
can perform significantly better than the plug-in approach.
"
2005.13665,2021-01-26,Deep Learning for Portfolio Optimization,"  We adopt deep learning models to directly optimise the portfolio Sharpe
ratio. The framework we present circumvents the requirements for forecasting
expected returns and allows us to directly optimise portfolio weights by
updating model parameters. Instead of selecting individual assets, we trade
Exchange-Traded Funds (ETFs) of market indices to form a portfolio. Indices of
different asset classes show robust correlations and trading them substantially
reduces the spectrum of available assets to choose from. We compare our method
with a wide range of algorithms with results showing that our model obtains the
best performance over the testing period, from 2011 to the end of April 2020,
including the financial instabilities of the first quarter of 2020. A
sensitivity analysis is included to understand the relevance of input features
and we further study the performance of our approach under different cost rates
and different risk levels via volatility scaling.
"
2005.13741,2022-02-16,A Portfolio Choice Problem Under Risk Capacity Constraint,"  This paper studies an optimal investing problem for a retiree facing
longevity risk and living standard risk. We formulate the investing problem as
a portfolio choice problem under a time-varying risk capacity constraint. We
derive the optimal investment strategy under the specific condition on model
parameters in terms of second-order ordinary differential equations. We
demonstrate an endogenous number that measures the expected value to sustain
the spending post-retirement. The optimal portfolio is nearly neutral to the
stock market movement if the portfolio's value is higher than this number; but,
if the portfolio is not worth enough to sustain the retirement spending, the
retiree actively invests in the stock market for the higher expected return.
Besides, we solve an optimal portfolio choice problem under a leverage
constraint and show that the optimal portfolio would lose significantly in
stressed markets. This paper shows that the time-varying risk capacity
constraint has important implications for asset allocation in retirement.
"
2005.13831,2021-10-14,Non-concave expected utility optimization with uncertain time horizon,"  We consider an expected utility maximization problem where the utility
function is not necessarily concave and the time horizon is uncertain. We
establish a necessary and sufficient condition for the optimality for general
non-concave utility function in a complete financial market. We show that the
general concavification approach of the utility function to deal with
non-concavity, while being still applicable when the time horizon is a stopping
time with respect to the financial market filtration, leads to sub-optimality
when the time horizon is independent of the financial risk, and hence can not
be directly applied. For the latter case, we suggest a recursive procedure
which is based on the dynamic programming principle. We illustrate our findings
by carrying out a multi-period numerical analysis for optimal investment
problem under a convex option compensation scheme with random time horizon. We
observe that the distribution of the non-concave portfolio in both certain and
uncertain random time horizon is right-skewed with a long right tail,
indicating that the investor expects frequent small losses and a few large
gains from the investment. While the (certain) average time horizon portfolio
at a premature stopping date is unimodal, the random time horizon portfolio is
multimodal distributed which provides the investor a certain flexibility of
switching between the local maximizers, depending on the market performance.
The multimodal structure with multiple peaks of different heights can be
explained by the concavification procedure, whereas the distribution of the
time horizon has significant impact on the amplitude between the modes.
"
2006.00949,2020-06-02,"Changes in Household Net Financial Assets After the Great Recession: Did
  Financial Planners Make a Difference?","  This study utilized the 2007-2009 Survey of Consumer Finances (SCF) panel
dataset to examine the impact of financial planner use on household net
financial asset level during the Great recession. Data included 3,862
respondents who completed the SCF survey and a follow up interview. The results
indicated that starting to use a financial planner during the Great Recession
had a positive impact on preserving and increasing the value of households' net
financial assets, while curtailing the use of a financial planner during this
time had a negative impact on preserving the value of households' financial
assets. Thus, study findings indicated that the benefit of using a financial
planner maybe particularly high during a major financial downturn.
"
2006.01979,2020-06-04,"Consistent Investment of Sophisticated Rank-Dependent Utility Agents in
  Continuous Time","  We study portfolio selection in a complete continuous-time market where the
preference is dictated by the rank-dependent utility. As such a model is
inherently time inconsistent due to the underlying probability weighting, we
study the investment behavior of sophisticated consistent planners who seek
(subgame perfect) intra-personal equilibrium strategies. We provide sufficient
conditions under which an equilibrium strategy is a replicating portfolio of a
final wealth. We derive this final wealth profile explicitly, which turns out
to be in the same form as in the classical Merton model with the market price
of risk process properly scaled by a deterministic function in time. We present
this scaling function explicitly through the solution to a highly nonlinear and
singular ordinary differential equation, whose existence of solutions is
established. Finally, we give a necessary and sufficient condition for the
scaling function to be smaller than 1 corresponding to an effective reduction
in risk premium due to probability weighting.
"
2006.02857,2020-06-05,Optimal Control of Investment for an Insurer in Two Currency Markets,"  In this paper, we study the optimal investment problem of an insurer whose
surplus process follows the diffusion approximation of the classical
Cramer-Lundberg model. Investment in the foreign market is allowed, and
therefore, the foreign exchange rate model is considered and incorporated. It
is assumed that the instantaneous mean growth rate of foreign exchange rate
price follows an Ornstein-Uhlenbeck process. Dynamic programming method is
employed to study the problem of maximizing the expected exponential utility of
terminal wealth. By soloving the correspoding Hamilton-Jacobi-Bellman
equations, the optimal investment strategies and the value functions are
obtained. Finally, numerical analysis is presented.
"
2006.04687,2021-12-21,"Duality for optimal consumption under no unbounded profit with bounded
  risk","  We give a definitive treatment of duality for optimal consumption over the
infinite horizon, in a semimartingale incomplete market satisfying no unbounded
profit with bounded risk (NUPBR). Rather than base the dual domain on (local)
martingale deflators, we use a class of supermartingale deflators such that
deflated wealth plus cumulative deflated consumption is a supermartingale for
all admissible consumption plans. This yields a strong duality, because the
enlarged dual domain of processes dominated by deflators is naturally closed,
without invoking its closure. In this way we automatically reach the bipolar of
the set of deflators. We complete this picture by proving that the set of
processes dominated by local martingale deflators is dense in our dual domain,
confirming that we have identified the natural dual space. In addition to the
optimal consumption and deflator, we characterise the optimal wealth process.
At the optimum, deflated wealth is a supermartingale and a potential, while
deflated wealth plus cumulative deflated consumption is a uniformly integrable
martingale. This is the natural generalisation of the corresponding feature in
the terminal wealth problem, where deflated wealth at the optimum is a
uniformly integrable martingale. We use no constructions involving equivalent
local martingale measures. This is natural, given that such measures typically
do not exist over the infinite horizon and that we are working under NUPBR,
which does not require their existence. The structure of the duality proof
reveals an interesting feature compared with the terminal wealth problem.
There, the dual domain is $L^{1}$-bounded, but here the primal domain has this
property, and hence many steps in the duality proof show a marked reversal of
roles for the primal and dual domains, compared with the proofs of Kramkov and
Schachermayer.
"
2006.04992,2021-06-14,Deep Stock Predictions,"  Forecasting stock prices can be interpreted as a time series prediction
problem, for which Long Short Term Memory (LSTM) neural networks are often used
due to their architecture specifically built to solve such problems. In this
paper, we consider the design of a trading strategy that performs portfolio
optimization using the LSTM stock price prediction for four different
companies. We then customize the loss function used to train the LSTM to
increase the profit earned. Moreover, we propose a data driven approach for
optimal selection of window length and multi-step prediction length, and
consider the addition of analyst calls as technical indicators to a multi-stack
Bidirectional LSTM strengthened by the addition of Attention units. We find the
LSTM model with the customized loss function to have an improved performance in
the training bot over a regressive baseline such as ARIMA, while the addition
of analyst call does improve the performance for certain datasets.
"
2006.05204,2020-06-11,Relative utility bounds for empirically optimal portfolios,"  We consider a single-period portfolio selection problem for an investor,
maximizing the expected ratio of the portfolio utility and the utility of a
best asset taken in hindsight. The decision rules are based on the history of
stock returns with unknown distribution. Assuming that the utility function is
Lipschitz or H\""{o}lder continuous (the concavity is not required), we obtain
high probability utility bounds under the sole assumption that the returns are
independent and identically distributed. These bounds depend only on the
utility function, the number of assets and the number of observations. For
concave utilities similar bounds are obtained for the portfolios produced by
the exponentiated gradient method. Also we use statistical experiments to study
risk and generalization properties of empirically optimal portfolios. Herein we
consider a model with one risky asset and a dataset, containing the stock
prices from NYSE.
"
2006.05260,2021-03-31,An elementary approach to the Merton problem,"  In this article we consider the infinite-horizon Merton
investment-consumption problem in a constant-parameter Black - Scholes - Merton
market for an agent with constant relative risk aversion R. The classical
primal approach is to write down a candidate value function and to use a
verification argument to prove that this is the solution to the problem.
However, features of the problem take it outside the standard settings of
stochastic control, and the existing primal verification proofs rely on
parameter restrictions (especially, but not only, R<1), restrictions on the
space of admissible strategies, or intricate approximation arguments.
  The purpose of this paper is to show that these complications can be overcome
using a simple and elegant argument involving a stochastic perturbation of the
utility function.
"
2006.05632,2020-07-24,Quant Bust 2020,"  We explain in a nontechnical fashion why dollar-neutral quant trading
strategies, such as equities Statistical Arbitrage, suffered substantial losses
(drawdowns) during the COVID-19 market selloff. We discuss: (i) why these
strategies work during ""normal"" times; (ii) the market regimes when they work
best; and (iii) their limitations and the reasons for why they ""break"" during
extreme market events. An accompanying appendix (with a link to freely
accessible source code) includes backtests for various strategies, which put
flesh on and illustrate the discussion in the main text.
"
2006.07456,2022-09-23,Evidence of Crowding on Russell 3000 Reconstitution Events,"  We develop a methodology which replicates in great accuracy the FTSE Russell
indexes reconstitutions, including the quarterly rebalancings due to new
initial public offerings (IPOs). While using only data available in the CRSP US
Stock database for our index reconstruction, we demonstrate the accuracy of
this methodology by comparing it to the original Russell US indexes for the
time period between 1989 to 2019. A python package that generates the
replicated indexes is also provided.
  As an application, we use our index reconstruction protocol to compute the
permanent and temporary price impact on the Russell 3000 annual additions and
deletions, and on the quarterly additions of new IPOs . We find that the index
portfolios following the Russell 3000 index and rebalanced on an annual basis
are overall more crowded than those following the index on a quarterly basis.
This phenomenon implies that transaction costs of indexing strategies could be
significantly reduced by buying new IPOs additions in proximity to quarterly
rebalance dates.
"
2006.07847,2021-07-26,"Trends, Reversion, and Critical Phenomena in Financial Markets","  Financial markets across all asset classes are known to exhibit trends. These
trends have been exploited by traders for decades. Here, we empirically measure
when trends revert, based on 30 years of daily futures prices for equity
indices, interest rates, currencies and commodities. We find that trends tend
to revert once they reach a critical level of statistical significance. Based
on polynomial regression, we carefully measure this critical level. We find
that it is universal across asset classes and has a universal scaling behavior,
as the trend's time horizon runs from a few days to several years. The
corresponding regression coefficients are small, but statistically highly
significant, as confirmed by bootstrapping and out-of-sample testing. Our
results signal to investors when to exit a trend. They also reveal how markets
have become more efficient over the decades. Moreover, they point towards a
potential deep analogy between financial markets and critical phenomena: our
analysis supports the conjecture that financial markets can be modeled as
statistical mechanical ensembles of Buy/Sell orders near critical points. In
this analogy, the trend strength plays the role of an order parameter, whose
dynamcis is described by a Langevin equation with a quartic potential.
"
2006.11279,2020-06-23,Distributionally Robust Profit Opportunities,"  This paper expands the notion of robust profit opportunities in financial
markets to incorporate distributional uncertainty using Wasserstein distance as
the ambiguity measure. Financial markets with risky and risk-free assets are
considered. The infinite dimensional primal problems are formulated, leading to
their simpler finite dimensional dual problems. A principal motivating question
is how does distributional uncertainty help or hurt the robustness of the
profit opportunity. Towards answering this question, some theory is developed
and computational experiments are conducted. Finally some open questions and
suggestions for future research are discussed.
"
2006.11888,2020-06-23,"Tri-criterion model for constructing low-carbon mutual fund portfolios:
  a preference-based multi-objective genetic algorithm approach","  Sustainable finance, which integrates environmental, social and governance
(ESG) criteria on financial decisions rests on the fact that money should be
used for good purposes. Thus, the financial sector is also expected to play a
more important role to decarbonise the global economy. To align financial flows
with a pathway towards a low-carbon economy, investors should be able to
integrate in their financial decisions additional criteria beyond return and
risk to manage climate risk. We propose a tri-criterion portfolio selection
model to extend the classical Markowitz mean-variance approach in order to
include investors preferences on the portfolio carbon risk exposure as an
additional criterion. To approximate the 3D Pareto front we apply an efficient
multi-objective genetic algorithm called ev-MOGA which is based on the concept
of e-dominance. Furthermore, we introduce an a posteriori approach to
incorporate the investor's preferences into the solution process regarding
their sustainability preferences measured by the carbon risk exposure and
his/her loss-adverse attitude. We test the performance of the proposed
algorithm in a cross section of European SRI open-end funds to assess the
extent to which climate related risk could be embedded in the portfolio
according to the investor's preferences.
"
2006.13661,2021-05-03,Optimal Tracking Portfolio with A Ratcheting Capital Benchmark,"  This paper studies the finite horizon portfolio management by optimally
tracking a ratcheting capital benchmark process. It is assumed that the fund
manager can dynamically inject capital into the portfolio account such that the
total capital dominates a non-decreasing benchmark floor process at each
intermediate time. The tracking problem is formulated to minimize the cost of
accumulated capital injection. We first transform the original problem with
floor constraints into an unconstrained control problem, however, under a
running maximum cost. By identifying a controlled state process with
reflection, the problem is further shown to be equivalent to an auxiliary
problem, which leads to a nonlinear Hamilton-Jacobi-Bellman (HJB) equation with
a Neumann boundary condition. By employing the dual transform, the
probabilistic representation and some stochastic flow analysis, the existence
of the unique classical solution to the HJB equation is established. The
verification theorem is carefully proved, which gives the complete
characterization of the feedback optimal portfolio. The application to market
index tracking is also discussed when the index process is modeled by a
geometric Brownian motion.
"
2006.13934,2020-06-29,Investor Emotions and Earnings Announcements,"  Armed with a decade of social media data, I explore the impact of investor
emotions on earnings announcements. In particular, I test whether the emotional
content of firm-specific messages posted on social media just prior to a firm's
earnings announcement predicts its earnings and announcement returns. I find
that investors are typically excited about firms that end up exceeding
expectations, yet their enthusiasm results in lower announcement returns.
Specifically, a standard deviation increase in excitement is associated with an
7.8 basis points lower announcement return, which translates into an
approximately -5.8% annualized loss. My findings confirm that emotions and
market dynamics are closely related and highlight the importance of considering
investor emotions when assessing a firm's short-term value.
"
2006.14402,2020-06-26,Deeply Equal-Weighted Subset Portfolios,"  The high sensitivity of optimized portfolios to estimation errors has
prevented their practical application. To mitigate this sensitivity, we propose
a new portfolio model called a Deeply Equal-Weighted Subset Portfolio (DEWSP).
DEWSP is a subset of top-N ranked assets in an asset universe, the members of
which are selected based on the predicted returns from deep learning algorithms
and are equally weighted. Herein, we evaluate the performance of DEWSPs of
different sizes N in comparison with the performance of other types of
portfolios such as optimized portfolios and historically equal-weighed subset
portfolios (HEWSPs), which are subsets of top-N ranked assets based on the
historical mean returns. We found the following advantages of DEWSPs: First,
DEWSPs provides an improvement rate of 0.24% to 5.15% in terms of monthly
Sharpe ratio compared to the benchmark, HEWSPs. In addition, DEWSPs are built
using a purely data-driven approach rather than relying on the efforts of
experts. DEWSPs can also target the relative risk and return to the baseline of
the EWP of an asset universe by adjusting the size N. Finally, the DEWSP
allocation mechanism is transparent and intuitive. These advantages make DEWSP
competitive in practice.
"
2007.01194,2020-07-03,Risk Management and Return Prediction,"  With the good development in the financial industry, the market starts to
catch people's eyes, not only by the diversified investing choices ranging from
bonds and stocks to futures and options but also by the general ""high-risk,
high-reward"" mindset prompting people to put money in the financial market.
People are interested in reducing risk at a given level of return since there
is no way of having both high returns and low risk. Many researchers have been
studying this issue, and the most pioneering one is Harry Markowitz's Modern
Portfolio Theory developed in 1952, which is the cornerstone of investment
portfolio management and aims at ""maximum the return at the given risk"". In
contrast to that, fifty years later, E. Robert Fernholz's Stochastic Portfolio
Theory, as opposed to the normative assumption served as the basis of earlier
modern portfolio theory, is consistent with the observable characteristics of
actual portfolios and markets. In this paper, after introducing some basic
theories of Markowitz's MPT and Fernholz's SPT, then we step across to the
application side, trying to figure out under four basic models based on
Markowitz Efficient Frontier, including Markowitz Model, Constant Correlation
Model, Single Index Model, and Multi-Factor Model, which portfolios will be
selected and how do these portfolios perform in the real world. Here we also
involve universal Portfolio Algorithmby Thomas M. Cover to select portfolios as
a comparison. Besides, each portfolio value at Risk, Expected Shortfall, and
corresponding bootstrap confidence interval for risk management will be
evaluated. Finally, by utilizing factor analysis and time series models, we
could predict the future performance of our four models.
"
2007.01672,2020-07-06,"A fully data-driven approach to minimizing CVaR for portfolio of assets
  via SGLD with discontinuous updating","  A new approach in stochastic optimization via the use of stochastic gradient
Langevin dynamics (SGLD) algorithms, which is a variant of stochastic gradient
decent (SGD) methods, allows us to efficiently approximate global minimizers of
possibly complicated, high-dimensional landscapes. With this in mind, we extend
here the non-asymptotic analysis of SGLD to the case of discontinuous
stochastic gradients. We are thus able to provide theoretical guarantees for
the algorithm's convergence in (standard) Wasserstein distances for both convex
and non-convex objective functions. We also provide explicit upper estimates of
the expected excess risk associated with the approximation of global minimizers
of these objective functions. All these findings allow us to devise and present
a fully data-driven approach for the optimal allocation of weights for the
minimization of CVaR of portfolio of assets with complete theoretical
guarantees for its performance. Numerical results illustrate our main findings.
"
2007.04203,2020-07-09,A Natural Actor-Critic Algorithm with Downside Risk Constraints,"  Existing work on risk-sensitive reinforcement learning - both for symmetric
and downside risk measures - has typically used direct Monte-Carlo estimation
of policy gradients. While this approach yields unbiased gradient estimates, it
also suffers from high variance and decreased sample efficiency compared to
temporal-difference methods. In this paper, we study prediction and control
with aversion to downside risk which we gauge by the lower partial moment of
the return. We introduce a new Bellman equation that upper bounds the lower
partial moment, circumventing its non-linearity. We prove that this proxy for
the lower partial moment is a contraction, and provide intuition into the
stability of the algorithm by variance decomposition. This allows
sample-efficient, on-line estimation of partial moments. For risk-sensitive
control, we instantiate Reward Constrained Policy Optimization, a recent
actor-critic method for finding constrained policies, with our proxy for the
lower partial moment. We extend the method to use natural policy gradients and
demonstrate the effectiveness of our approach on three benchmark problems for
risk-sensitive reinforcement learning.
"
2007.04838,2020-07-10,"Improving the Robustness of Trading Strategy Backtesting with Boltzmann
  Machines and Generative Adversarial Networks","  This article explores the use of machine learning models to build a market
generator. The underlying idea is to simulate artificial multi-dimensional
financial time series, whose statistical properties are the same as those
observed in the financial markets. In particular, these synthetic data must
preserve the probability distribution of asset returns, the stochastic
dependence between the different assets and the autocorrelation across time.
The article proposes then a new approach for estimating the probability
distribution of backtest statistics. The final objective is to develop a
framework for improving the risk management of quantitative investment
strategies, in particular in the space of smart beta, factor investing and
alternative risk premia.
"
2007.06460,2020-07-14,Optimal allocation using the Sortino ratio,"  In this paper we present an asset allocation strategy based on the
maximization of the Sortino ratio. Unlike the Sharpe ratio, the Sortino ratio
penalizes negative return variances only. The resulting allocation is valid for
any time horizon unlike. The returns of a strategy based on such an allocation
are empirically illustrated using historical Dow Jones data and display a
significant upgrade on more traditional allocation strategies such as the Kelly
criterion.
"
2007.06510,2020-08-11,"Mean-variance-utility portfolio selection with time and state dependent
  risk aversion","  Under mean-variance-utility framework, we propose a new portfolio selection
model, which allows wealth and time both have influences on risk aversion in
the process of investment. We solved the model under a game theoretic framework
and analytically derived the equilibrium investment (consumption) policy. The
results conform with the facts that optimal investment strategy heavily depends
on the investor's wealth and future income-consumption balance as well as the
continuous optimally consumption process is highly dependent on the consumption
preference of the investor.
"
2007.06848,2020-07-15,"Modeling Financial Time Series using LSTM with Trainable Initial Hidden
  States","  Extracting previously unknown patterns and information in time series is
central to many real-world applications. In this study, we introduce a novel
approach to modeling financial time series using a deep learning model. We use
a Long Short-Term Memory (LSTM) network equipped with the trainable initial
hidden states. By learning to reconstruct time series, the proposed model can
represent high-dimensional time series data with its parameters. An experiment
with the Korean stock market data showed that the model was able to capture the
relative similarity between a large number of stock prices in its latent space.
Besides, the model was also able to predict the future stock trends from the
latent space. The proposed method can help to identify relationships among many
time series, and it could be applied to financial applications, such as
optimizing the investment portfolios.
"
2007.11781,2020-07-24,"Relative wealth concerns with partial information and heterogeneous
  priors","  We establish a Nash equilibrium in a market with $ N $ agents with the
performance criteria of relative wealth level when the market return is
unobservable. Each investor has a random prior belief on the return rate of the
risky asset. The investors can be heterogeneous in both the mean and variance
of the prior. By a separation result and a martingale argument, we show that
the optimal investment strategy under a stochastic return rate model can be
characterized by a fully-coupled linear FBSDE. Two sets of deep neural networks
are used for the numerical computation to first find each investor's estimate
of the mean return rate and then solve the FBSDEs. We establish the existence
and uniqueness result for the class of FBSDEs with stochastic coefficients and
solve the utility game under partial information using deep neural network
function approximators. We demonstrate the efficiency and accuracy by a
base-case comparison with the solution from the finite difference scheme in the
linear case and apply the algorithm to the general case of nonlinear hidden
variable process. Simulations of investment strategies show a herd effect that
investors trade more aggressively under relativeness concerns. Statistical
properties of the investment strategies and the portfolio performance,
including the Sharpe ratios and the Variance Risk ratios (VRRs) are examed. We
observe that the agent with the most accurate prior estimate is likely to lead
the herd, and the effect of competition on heterogeneous agents varies more
with market characteristics compared to the homogeneous case.
"
2007.13879,2021-04-28,Advanced Strategies of Portfolio Management in the Heston Market Model,"  There is a great number of factors to take into account when building and
managing an investment portfolio. It is widely believed that a proper set-up of
the portfolio combined with a good, robust management strategy is the key to
successful investment. In this paper, we aim at an analysis of two aspects that
may have an impact on investment performance: diversity of assets and inclusion
of cash in the portfolio. We also propose two new management strategies based
on the MACD and RSI factors known from technical analysis. Monte Carlo
simulations within the Heston model of a market are used to perform numerical
experiments.
"
2007.13972,2020-09-22,"Portfolio Optimization on the Dispersion Risk and the Asymmetric Tail
  Risk","  In this paper, we propose a market model with returns assumed to follow a
multivariate normal tempered stable distribution defined by a mixture of the
multivariate normal distribution and the tempered stable subordinator. This
distribution is able to capture two stylized facts: fat-tails and asymmetry,
that have been empirically observed for asset return distributions. On the new
market model, we discuss a new portfolio optimization method, which is an
extension of Markowitz's mean-variance optimization. The new optimization
method considers not only reward and dispersion but also asymmetry. The
efficient frontier is also extended to a curved surface on three-dimensional
space of reward, dispersion, and asymmetry. We also propose a new performance
measure which is an extension of the Sharpe Ratio. Moreover, we derive
closed-form solutions for two important measures used by portfolio managers in
portfolio construction: the marginal Value-at-Risk (VaR) and the marginal
Conditional VaR (CVaR). We illustrate the proposed model using stocks
comprising the Dow Jones Industrial Average. First, perform the new portfolio
optimization and then demonstrating how the marginal VaR and marginal CVaR can
be used for portfolio optimization under the model. Based on the empirical
evidence presented in this paper, our framework offers realistic portfolio
optimization and tractable methods for portfolio risk management.
"
2007.14069,2021-09-02,"Convergence of the Kiefer-Wolfowitz algorithm in the presence of
  discontinuities","  In this paper we estimate the expected error of a stochastic approximation
algorithm where the maximum of a function is found using finite differences of
a stochastic representation of that function. An error estimate of
$O(n^{-1/5})$ for the $n$th iteration is achieved using suitable parameters.
The novelty with respect to previous studies is that we allow the stochastic
representation to be discontinuous and to consist of possibly dependent random
variables (satisfying a mixing condition).
"
2007.15980,2020-08-05,The Hansen ratio in mean--variance portfolio theory,"  It is shown that the ratio between the mean and the $L^2$-norm leads to a
particularly parsimonious description of the mean-variance efficient frontier
and the dual pricing kernel restrictions known as the Hansen-Jagannathan (HJ)
bounds. Because this ratio has not appeared in economic theory previously, it
seems appropriate to name it the Hansen ratio. The initial treatment of the
mean-variance theory via the Hansen ratio is extended in two directions, to
monotone mean-variance preferences and to arbitrary Hilbert space setting. A
multiperiod example with IID returns is also discussed.
"
2008.00392,2022-06-09,"Optimal Investment, Heterogeneous Consumption and Best Time for
  Retirement","  This paper studies an optimal investment and consumption problem with
heterogeneous consumption of basic and luxury goods, together with the choice
of time for retirement. The utility for luxury goods is not necessarily a
concave function. The optimal heterogeneous consumption strategies for a class
of non-homothetic utility maximizer are shown to consume only basic goods when
the wealth is small, to consume basic goods and make savings when the wealth is
intermediate, and to consume almost all in luxury goods when the wealth is
large. The optimal retirement policy is shown to be both universal, in the
sense that all individuals should retire at the same level of marginal utility
that is determined only by income, labor cost, discount factor as well as
market parameters, and not universal, in the sense that all individuals can
achieve the same marginal utility with different utility and wealth. It is also
shown that individuals prefer to retire as time goes by if the marginal labor
cost increases faster than that of income. The main tools used in analyzing the
problem are from PDE and stochastic control theory including variational
inequality and dual transformation. We finally conduct the simulation analysis
for the featured model parameters to investigate practical and economic
implications by providing their figures.
"
2008.00863,2020-08-04,"Solving High-Order Portfolios via Successive Convex Approximation
  Algorithms","  The first moment and second central moments of the portfolio return, a.k.a.
mean and variance, have been widely employed to assess the expected profit and
risk of the portfolio. Investors pursue higher mean and lower variance when
designing the portfolios. The two moments can well describe the distribution of
the portfolio return when it follows the Gaussian distribution. However, the
real world distribution of assets return is usually asymmetric and
heavy-tailed, which is far from being a Gaussian distribution. The asymmetry
and the heavy-tailedness are characterized by the third and fourth central
moments, i.e., skewness and kurtosis, respectively. Higher skewness and lower
kurtosis are preferred to reduce the probability of extreme losses. However,
incorporating high-order moments in the portfolio design is very difficult due
to their non-convexity and rapidly increasing computational cost with the
dimension. In this paper, we propose a very efficient and convergence-provable
algorithm framework based on the successive convex approximation (SCA)
algorithm to solve high-order portfolios. The efficiency of the proposed
algorithm framework is demonstrated by the numerical experiments.
"
2008.04985,2021-02-23,Tax-Aware Portfolio Construction via Convex Optimization,"  We describe an optimization-based tax-aware portfolio construction method
that adds tax liability to standard Markowitz-based portfolio construction. Our
method produces a trade list that specifies the number of shares to buy of each
asset and the number of shares to sell from each tax lot held. To avoid wash
sales (in which some realized capital losses are disallowed), we assume that we
trade monthly, and cannot simultaneously buy and sell the same asset.
  The tax-aware portfolio construction problem is not convex, but it becomes
convex when we specify, for each asset, whether we buy or sell it. It can be
solved using standard mixed-integer convex optimization methods at the cost of
very long solve times for some problem instances. We present a custom convex
relaxation of the problem that borrows curvature from the risk model. This
relaxation can provide a good approximation of the true tax liability, while
greatly enhancing computational tractability. This method requires the solution
of only two convex optimization problems: the first determines whether we buy
or sell each asset, and the second generates the final trade list. In our
numerical experiments, our method almost always solves the nonconvex problem to
optimality, and when it does not, it produces a trade list very close to
optimal. Backtests show that the performance of our method is indistinguishable
from that obtained using a globally optimal solution, but with significantly
reduced computational effort.
"
2008.06598,2020-08-18,"A Stochastic Control Approach to Defined Contribution Plan Decumulation:
  ""The Nastiest, Hardest Problem in Finance""","  We pose the decumulation strategy for a Defined Contribution (DC) pension
plan as a problem in optimal stochastic control. The controls are the
withdrawal amounts and the asset allocation strategy. We impose maximum and
minimum constraints on the withdrawal amounts, and impose no-shorting
no-leverage constraints on the asset allocation strategy. Our objective
function measures reward as the expected total withdrawals over the
decumulation horizon, and risk is measured by Expected Shortfall (ES) at the
end of the decumulation period. We solve the stochastic control problem
numerically, based on a parametric model of market stochastic processes. We
find that, compared to a fixed constant withdrawal strategy, with minimum
withdrawal set to the constant withdrawal amount, the optimal strategy has a
significantly higher expected average withdrawal, at the cost of a very small
increase in ES risk. Tests on bootstrapped resampled historical market data
indicate that this strategy is robust to parametric model misspecification.
"
2008.07907,2024-06-18,Volatility Depends on Market Trades and Macro Theory,"  We consider the randomness of market trade as the origin of price and return
stochasticity. We look at time series of trade values and volumes as random
variables during the averaging interval {\Delta} and describe the dependences
of market-based volatilities of price and return on the volatilities and
correlations of market trade values and volumes. We describe the market-based
origin of the lower boundaries of the accuracy of macroeconomic variables and
consider, as an example, the accuracy of macroeconomic investments. We
highlight that current macroeconomic models describe relations between the 1st
order variables determined by sums of trade values or volumes. To predict
market-based volatilities of price, return, and volatilities of macroeconomic
variables, one should develop econometric methodologies, collect data, and
elaborate macroeconomic theories of the 2nd order that model the mutual
dependence of the 1st and 2nd order economic variables. The absence of
macroeconomic theories of the 2nd order means no economic basis for predictions
of market-based volatilities of price and return, as well as volatilities of
any macroeconomic variables. In turn, that limits the accuracy of forecasting
probabilities of price, return, and the accuracy of macroeconomic variables in
the best case by Gaussian distributions.
"
2008.09818,2020-08-25,"Optimizing tail risks using an importance sampling based extrapolation
  for heavy-tailed objectives","  Motivated by the prominence of Conditional Value-at-Risk (CVaR) as a measure
for tail risk in settings affected by uncertainty, we develop a new formula for
approximating CVaR based optimization objectives and their gradients from
limited samples. A key difficulty that limits the widespread practical use of
these optimization formulations is the large amount of data required by the
state-of-the-art sample average approximation schemes to approximate the CVaR
objective with high fidelity. Unlike the state-of-the-art sample average
approximations which require impractically large amounts of data in tail
probability regions, the proposed approximation scheme exploits the
self-similarity of heavy-tailed distributions to extrapolate data from suitable
lower quantiles. The resulting approximations are shown to be statistically
consistent and are amenable for optimization by means of conventional gradient
descent. The approximation is guided by means of a systematic
importance-sampling scheme whose asymptotic variance reduction properties are
rigorously examined. Numerical experiments demonstrate the superiority of the
proposed approximations and the ease of implementation points to the
versatility of settings to which the approximation scheme can be applied.
"
2008.10257,2021-03-31,Portfolio Selection under Median and Quantile Maximization,"  Although maximizing median and quantiles is intuitively appealing and has an
axiomatic foundation, it is difficult to study the optimal portfolio strategy
due to the discontinuity and time inconsistency in the objective function. We
use the intra-personal equilibrium approach to study the problem.
Interestingly, we find that the only viable outcome is from the median
maximization, because for other quantiles either the equilibrium does not exist
or there is no investment in the risky assets. The median maximization strategy
gives a simple explanation to why wealthier people invest more percentage of
their wealth in risky assets.
"
2008.10952,2020-08-26,"A Data Envelopment Analysis Approach to Benchmark the Performance of
  Mutual Funds in India","  As the Indian economy grows digitally and becomes more financially inclusive,
more and more investors have started to invest in the Indian capital markets.
The number of retail and institutional folios with Indian mutual fund schemes
have continued to rise for the 74th consecutive month. This study considers 139
mutual fund schemes (98 equity schemes) and aims to ascertain the various
metrics and parameters, retail and institutional investors continue to rely on
to make investment recommendations. We compare these with the results from a
data envelopment analysis model that generates an efficiency frontier based on
an optimal risk, cost, and return trade-off. We further put forth an iteration
of the DEA model, not only considering risk, cost, and return characteristics
but also incorporating metrics such as the information ratio which hold
significance for retail and institutional investors. We compare these results
with traditional metrics and fund rankings published by established industry
rating agencies.
"
2008.12050,2021-10-22,Hybrid quantum-classical optimization for financial index tracking,"  Tracking a financial index boils down to replicating its trajectory of
returns for a well-defined time span by investing in a weighted subset of the
securities included in the benchmark. Picking the optimal combination of assets
becomes a challenging NP-hard problem even for moderately large indices
consisting of dozens or hundreds of assets, thereby requiring heuristic methods
to find approximate solutions. Hybrid quantum-classical optimization with
variational gate-based quantum circuits arises as a plausible method to improve
performance of current schemes. In this work we introduce a heuristic pruning
algorithm to find weighted combinations of assets subject to cardinality
constraints. We further consider different strategies to respect such
constraints and compare the performance of relevant quantum ans\""{a}tze and
classical optimizers through numerical simulations.
"
2008.12953,2021-06-11,Sparse High-Order Portfolios via Proximal DCA and SCA,"  In this paper, we aim at solving the cardinality constrained high-order
portfolio optimization, i.e., mean-variance-skewness-kurtosis model with
cardinality constraint (MVSKC). Optimization for the MVSKC model is of great
difficulty in two parts. One is that the objective function is non-convex, the
other is the combinational nature of the cardinality constraint, leading to
non-convexity as well dis-continuity. Based on the observation that cardinality
constraint has the difference-of-convex (DC) property, we transform the
cardinality constraint into a penalty term and then propose three algorithms
including the proximal difference of convex algorithm (pDCA), pDCA with
extrapolation (pDCAe) and the successive convex approximation (SCA) to handle
the resulting penalized MVSK (PMVSK) formulation. Moreover, theoretical
convergence results of these algorithms are established respectively. Numerical
experiments on the real datasets demonstrate the superiority of our proposed
methods in obtaining high utility and sparse solutions as well as efficiency in
terms of time usage.
"
2008.13198,2020-09-01,Measuring and Managing Carbon Risk in Investment Portfolios,"  This article studies the impact of carbon risk on stock pricing. To address
this, we consider the seminal approach of G\""orgen \textsl{et al.} (2019), who
proposed estimating the carbon financial risk of equities by their carbon beta.
To achieve this, the primary task is to develop a brown-minus-green (or BMG)
risk factor, similar to Fama and French (1992). Secondly, we must estimate the
carbon beta using a multi-factor model. While G\""orgen \textsl{et al.} (2019)
considered that the carbon beta is constant, we propose a time-varying
estimation model to assess the dynamics of the carbon risk. Moreover, we test
several specifications of the BMG factor to understand which climate
change-related dimensions are priced in by the stock market. In the second part
of the article, we focus on the carbon risk management of investment
portfolios. First, we analyze how carbon risk impacts the construction of a
minimum variance portfolio. As the goal of this portfolio is to reduce
unrewarded financial risks of an investment, incorporating the carbon risk into
this approach fulfils this objective. Second, we propose a new framework for
building enhanced index portfolios with a lower exposure to carbon risk than
capitalization-weighted stock indices. Finally, we explore how carbon
sensitivities can improve the robustness of factor investing portfolios.
"
2009.00972,2020-10-13,Infinite horizon utility maximisation from inter-temporal wealth,"  We develop a duality theory for the problem of maximising expected lifetime
utility from inter-temporal wealth over an infinite horizon, under the minimal
no-arbitrage assumption of No Unbounded Profit with Bounded Risk (NUPBR). We
use only deflators, with no arguments involving equivalent martingale measures,
so do not require the stronger condition of No Free Lunch with Vanishing Risk
(NFLVR). Our formalism also works without alteration for the finite horizon
version of the problem. As well as extending work of Bouchard and Pham to any
horizon and to a weaker no-arbitrage setting, we obtain a stronger duality
statement, because we do not assume by definition that the dual domain is the
polar set of the primal space. Instead, we adopt a method akin to that used for
inter-temporal consumption problems, developing a supermartingale property of
the deflated wealth and its path that yields an infinite horizon budget
constraint and serves to define the correct dual variables. The structure of
our dual space allows us to show that it is convex, without forcing this
property by assumption. We proceed to enlarge the primal and dual domains to
confer solidity to them, and use supermartingale convergence results which
exploit Fatou convergence, to establish that the enlarged dual domain is the
bipolar of the original dual space. The resulting duality theorem shows that
all the classical tenets of convex duality hold. Moreover, at the optimum, the
deflated wealth process is a potential converging to zero. We work out
examples, including a case with a stock whose market price of risk is a
three-dimensional Bessel process, so satisfying NUPBR but not NFLVR.
"
2009.03362,2020-09-09,Topological Data Analysis for Portfolio Management of Cryptocurrencies,"  Portfolio management is essential for any investment decision. Yet,
traditional methods in the literature are ill-suited for the characteristics
and dynamics of cryptocurrencies. This work presents a method to build an
investment portfolio consisting of more than 1500 cryptocurrencies covering 6
years of market data. It is centred around Topological Data Analysis (TDA), a
recent approach to analyze data sets from the perspective of their topological
structure. This publication proposes a system combining persistence landscapes
to identify suitable investment opportunities in cryptocurrencies. Using a
novel and comprehensive data set of cryptocurrency prices, this research shows
that the proposed system enables analysts to outperform a classic method from
the literature without requiring any feature engineering or domain knowledge in
TDA. This work thus introduces TDA-based portfolio management of
cryptocurrencies as a viable tool for the practitioner.
"
2009.03394,2021-07-22,"Deep Learning, Predictability, and Optimal Portfolio Returns","  We study dynamic portfolio choice of a long-horizon investor who uses deep
learning methods to predict equity returns when forming optimal portfolios. Our
results show statistically and economically significant benefits from using
deep learning to form optimal portfolios through certainty equivalent returns
and Sharpe ratios. We demonstrate that a long-short-term-memory recurrent
neural network, which excels in learning complex time-series dependencies,
generates a superior performance among a variety of networks considered. Return
predictability via deep learning generates substantially improved portfolio
performance across different subsamples, particularly during recessionary
periods. These gains are robust to including transaction costs, short-selling
and borrowing constraints.
"
2009.04461,2020-09-18,"Investing with Cryptocurrencies -- evaluating their potential for
  portfolio allocation strategies","  Cryptocurrencies (CCs) have risen rapidly in market capitalization over the
last years. Despite striking price volatility, their high average returns have
drawn attention to CCs as alternative investment assets for portfolio and risk
management. We investigate the utility gains for different types of investors
when they consider cryptocurrencies as an addition to their portfolio of
traditional assets. We consider risk-averse, return-seeking as well as
diversificationpreferring investors who trade along different allocation
frequencies, namely daily, weekly or monthly. Out-of-sample performance and
diversification benefits are studied for the most popular
portfolio-construction rules, including mean-variance optimization,
risk-parity, and maximum-diversification strategies, as well as combined
strategies. To account for low liquidity in CC markets, we incorporate
liquidity constraints via the LIBRO method. Our results show that CCs can
improve the risk-return profile of portfolios. In particular, a
maximum-diversification strategy (maximizing the Portfolio Diversification
Index, PDI) draws appreciably on CCs, and spanning tests clearly indicate that
CC returns are non-redundant additions to the investment universe. Though our
analysis also shows that illiquidity of CCs potentially reverses the results.
"
2009.07086,2021-05-27,Optimal Bidding Strategy for Maker Auctions,"  The Maker Protocol is a decentralized finance application that enables
collateralized lending. The application uses open-bid, second-price auctions to
complete its loan liquidation process. In this paper, we develop a bidding
function for these auctions, focusing on the costs incurred to participate in
the auctions. We then optimize these costs using parameters from historical
auction data, and compare our optimal bidding prices to the historical auction
prices. We find that the majority of auctions end at higher prices than our
recommended optimal prices, and we propose several theories for these results.
"
2009.07200,2020-11-10,"Detecting and adapting to crisis pattern with context based Deep
  Reinforcement Learning","  Deep reinforcement learning (DRL) has reached super human levels in complex
tasks like game solving (Go and autonomous driving). However, it remains an
open question whether DRL can reach human level in applications to financial
problems and in particular in detecting pattern crisis and consequently
dis-investing. In this paper, we present an innovative DRL framework consisting
in two sub-networks fed respectively with portfolio strategies past
performances and standard deviations as well as additional contextual features.
The second sub network plays an important role as it captures dependencies with
common financial indicators features like risk aversion, economic surprise
index and correlations between assets that allows taking into account context
based information. We compare different network architectures either using
layers of convolutions to reduce network's complexity or LSTM block to capture
time dependency and whether previous allocations is important in the modeling.
We also use adversarial training to make the final model more robust. Results
on test set show this approach substantially over-performs traditional
portfolio optimization methods like Markowitz and is able to detect and
anticipate crisis like the current Covid one.
"
2009.07892,2020-10-06,"Optimal Order Execution in Intraday Markets: Minimizing Costs in Trade
  Trajectories","  Optimal execution, i.e., the determination of the most cost-effective way to
trade volumes in continuous trading sessions, has been a topic of interest in
the equity trading world for years. Electricity intraday trading slowly follows
this trend but is far from being well-researched. The underlying problem is a
very complex one. Energy traders, producers, and electricity wholesale
companies receive various position updates from customer businesses, renewable
energy production, or plant outages and need to trade these positions in
intraday markets. They have a variety of options when it comes to position
sizing or timing. Is it better to trade all amounts at once? Should they split
orders into smaller pieces? Taking the German continuous hourly intraday market
as an example, this paper derives an appropriate model for electricity trading.
We present our results from an out-of-sample study and differentiate between
simple benchmark models and our more refined optimization approach that takes
into account order book depth, time to delivery, and different trading regimes
like XBID (Cross-Border Intraday Project) trading. Our paper is highly relevant
as it contributes further insight into the academic discussion of algorithmic
execution in continuous intraday markets and serves as an orientation for
practitioners. Our initial results suggest that optimal execution strategies
have a considerable monetary impact.
"
2009.08412,2020-09-18,"Solving the Optimal Trading Trajectory Problem Using Simulated
  Bifurcation","  We use an optimization procedure based on simulated bifurcation (SB) to solve
the integer portfolio and trading trajectory problem with an unprecedented
computational speed. The underlying algorithm is based on a classical
description of quantum adiabatic evolutions of a network of non-linearly
interacting oscillators. This formulation has already proven to beat state of
the art computation times for other NP-hard problems and is expected to show
similar performance for certain portfolio optimization problems. Inspired by
such we apply the SB approach to the portfolio integer optimization problem
with quantity constraints and trading activities. We show first numerical
results for portfolios of up to 1000 assets, which already confirm the power of
the SB algorithm for its novel use-case as a portfolio and trading trajectory
optimizer.
"
2009.08533,2021-08-12,"Robust Asymptotic Growth in Stochastic Portfolio Theory under Long-Only
  Constraints","  We consider the problem of maximizing the asymptotic growth rate of an
investor under drift uncertainty in the setting of stochastic portfolio theory
(SPT). As in the work of Kardaras and Robertson we take as inputs (i) a
Markovian volatility matrix $c(x)$ and (ii) an invariant density $p(x)$ for the
market weights, but we additionally impose long-only constraints on the
investor. Our principal contribution is proving a uniqueness and existence
result for the class of concave functionally generated portfolios and
developing a finite dimensional approximation, which can be used to numerically
find the optimum. In addition to the general results outlined above, we propose
the use of a broad class of models for the volatility matrix $c(x)$, which can
be calibrated to data and, under which, we obtain explicit formulas of the
optimal unconstrained portfolio for any invariant density.
"
2009.08794,2020-09-21,"Simplicial persistence of financial markets: filtering, generative
  processes and portfolio risk","  We introduce simplicial persistence, a measure of time evolution of network
motifs in subsequent temporal layers. We observe long memory in the evolution
of structures from correlation filtering, with a two regime power law decay in
the number of persistent simplicial complexes. Null models of the underlying
time series are tested to investigate properties of the generative process and
its evolutional constraints. Networks are generated with both TMFG filtering
technique and thresholding showing that embedding-based filtering methods
(TMFG) are able to identify higher order structures throughout the market
sample, where thresholding methods fail. The decay exponents of these long
memory processes are used to characterise financial markets based on their
stage of development and liquidity. We find that more liquid markets tend to
have a slower persistence decay. This is in contrast with the common
understanding that developed markets are more random. We find that they are
indeed less predictable for what concerns the dynamics of each single variable
but they are more predictable for what concerns the collective evolution of the
variables. This could imply higher fragility to systemic shocks.
"
2009.08826,2020-09-21,"Generalized distance to a simplex and a new geometrical method for
  portfolio optimization","  Risk aversion plays a significant and central role in investors' decisions in
the process of developing a portfolio. In this framework of portfolio
optimization we determine the portfolio that possesses the minimal risk by
using a new geometrical method. For this purpose, we elaborate an algorithm
that enables us to compute any generalized Euclidean distance to a standard
simplex. With this new approach, we are able to treat the case of portfolio
optimization without short-selling in its entirety, and we also recover in
geometrical terms the well-known results on portfolio optimization with allowed
short-selling. Then, we apply our results in order to determine which convex
combination of the CAC 40 stocks possesses the lowest risk: not only we get a
very low risk compared to the index, but we also get a return rate that is
almost three times better than the one of the index.
"
2009.10852,2020-09-24,Efficient Portfolios,"  Given two random realized returns on an investment, which is to be preferred?
This is a fundamental problem in finance that has no definitive solution except
in the case one investment always returns more than the other. In 1952
Markowitz and Roy introduced the following criterion for risk vs. return in
portfolio selection: if two portfolios have the same expected realized return
then prefer the one with smaller variance. An efficient portfolio has the least
variance among all portfolios having the same expected realized return.
  The primary contribution of this short note is observation that the CAPM
formula holds for realized returns as random variables, not just their
expectations. This follows directly from writing down a mathematical model for
one period investments.
"
2009.11189,2020-09-24,Qlib: An AI-oriented Quantitative Investment Platform,"  Quantitative investment aims to maximize the return and minimize the risk in
a sequential trading period over a set of financial instruments. Recently,
inspired by rapid development and great potential of AI technologies in
generating remarkable innovation in quantitative investment, there has been
increasing adoption of AI-driven workflow for quantitative research and
practical investment. In the meantime of enriching the quantitative investment
methodology, AI technologies have raised new challenges to the quantitative
investment system. Particularly, the new learning paradigms for quantitative
investment call for an infrastructure upgrade to accommodate the renovated
workflow; moreover, the data-driven nature of AI technologies indeed indicates
a requirement of the infrastructure with more powerful performance;
additionally, there exist some unique challenges for applying AI technologies
to solve different tasks in the financial scenarios. To address these
challenges and bridge the gap between AI technologies and quantitative
investment, we design and develop Qlib that aims to realize the potential,
empower the research, and create the value of AI technologies in quantitative
investment.
"
2009.11367,2023-02-03,"Portfolio Optimization on Multivariate Regime Switching GARCH Model with
  Normal Tempered Stable Innovation","  This paper uses simulation-based portfolio optimization to mitigate the left
tail risk of the portfolio. The contribution is twofold. (i) We propose the
Markov regime-switching GARCH model with multivariate normal tempered stable
innovation (MRS-MNTS-GARCH) to accommodate fat tails, volatility clustering and
regime switch. The volatility of each asset independently follows the
regime-switch GARCH model, while the correlation of joint innovation of the
GARCH models follows the Hidden Markov Model. (ii) We use tail risk measures,
namely conditional value-at-risk (CVaR) and conditional drawdown-at-risk
(CDaR), in the portfolio optimization. The optimization is performed with the
sample paths simulated by the MRS-MNTS-GARCH model. We conduct an empirical
study on the performance of optimal portfolios. Out-of-sample tests show that
the optimal portfolios with tail measures outperform the optimal portfolio with
standard deviation measure and the equally weighted portfolio in various
performance measures. The out-of-sample performance of the optimal portfolios
is also more robust to suboptimality on the efficient frontier.
"
2009.14136,2020-11-10,Time your hedge with Deep Reinforcement Learning,"  Can an asset manager plan the optimal timing for her/his hedging strategies
given market conditions? The standard approach based on Markowitz or other more
or less sophisticated financial rules aims to find the best portfolio
allocation thanks to forecasted expected returns and risk but fails to fully
relate market conditions to hedging strategies decision. In contrast, Deep
Reinforcement Learning (DRL) can tackle this challenge by creating a dynamic
dependency between market information and hedging strategies allocation
decisions. In this paper, we present a realistic and augmented DRL framework
that: (i) uses additional contextual information to decide an action, (ii) has
a one period lag between observations and actions to account for one day lag
turnover of common asset managers to rebalance their hedge, (iii) is fully
tested in terms of stability and robustness thanks to a repetitive train test
method called anchored walk forward training, similar in spirit to k fold cross
validation for time series and (iv) allows managing leverage of our hedging
strategy. Our experiment for an augmented asset manager interested in sizing
and timing his hedges shows that our approach achieves superior returns and
lower risk.
"
2009.14559,2021-11-04,"Robust Utility Maximization in a Multivariate Financial Market with
  Stochastic Drift","  We study a utility maximization problem in a financial market with a
stochastic drift process, combining a worst-case approach with filtering
techniques. Drift processes are difficult to estimate from asset prices, and at
the same time optimal strategies in portfolio optimization problems depend
crucially on the drift. We approach this problem by setting up a worst-case
optimization problem with a time-dependent uncertainty set for the drift.
Investors assume that the worst possible drift process with values in the
uncertainty set will occur. This leads to local optimization problems, and the
resulting optimal strategy needs to be updated continuously in time. We prove a
minimax theorem for the local optimization problems and derive the optimal
strategy. Further, we show how an ellipsoidal uncertainty set can be defined
based on filtering techniques and demonstrate that investors need to choose a
robust strategy to be able to profit from additional information.
"
2009.14561,2020-10-01,Are cryptocurrencies becoming more interconnected?,"  This paper studies the dynamic market linkages among cryptocurrencies during
August 2015 - July 2020 and finds a substantial increase in market linkages for
both returns and volatilities. We use different methodologies to check the
different aspects of market linkages. Financial and regulatory implications are
discussed.
"
2010.01687,2021-02-15,"Learning Risk Preferences from Investment Portfolios Using Inverse
  Optimization","  The fundamental principle in Modern Portfolio Theory (MPT) is based on the
quantification of the portfolio's risk related to performance. Although MPT has
made huge impacts on the investment world and prompted the success and
prevalence of passive investing, it still has shortcomings in real-world
applications. One of the main challenges is that the level of risk an investor
can endure, known as \emph{risk-preference}, is a subjective choice that is
tightly related to psychology and behavioral science in decision making. This
paper presents a novel approach of measuring risk preference from existing
portfolios using inverse optimization on the mean-variance portfolio allocation
framework. Our approach allows the learner to continuously estimate real-time
risk preferences using concurrent observed portfolios and market price data. We
demonstrate our methods on real market data that consists of 20 years of asset
pricing and 10 years of mutual fund portfolio holdings. Moreover, the
quantified risk preference parameters are validated with two well-known risk
measurements currently applied in the field. The proposed methods could lead to
practical and fruitful innovations in automated/personalized portfolio
management, such as Robo-advising, to augment financial advisors' decision
intelligence in a long-term investment horizon.
"
2010.04404,2020-10-12,Deep Reinforcement Learning for Asset Allocation in US Equities,"  Reinforcement learning is a machine learning approach concerned with solving
dynamic optimization problems in an almost model-free way by maximizing a
reward function in state and action spaces. This property makes it an exciting
area of research for financial problems. Asset allocation, where the goal is to
obtain the weights of the assets that maximize the rewards in a given state of
the market considering risk and transaction costs, is a problem easily framed
using a reinforcement learning framework. It is first a prediction problem for
expected returns and covariance matrix and then an optimization problem for
returns, risk, and market impact. Investors and financial researchers have been
working with approaches like mean-variance optimization, minimum variance, risk
parity, and equally weighted and several methods to make expected returns and
covariance matrices' predictions more robust. This paper demonstrates the
application of reinforcement learning to create a financial model-free solution
to the asset allocation problem, learning to solve the problem using time
series and deep neural networks. We demonstrate this on daily data for the top
24 stocks in the US equities universe with daily rebalancing. We use a deep
reinforcement model on US stocks using different architectures. We use Long
Short Term Memory networks, Convolutional Neural Networks, and Recurrent Neural
Networks and compare them with more traditional portfolio management. The Deep
Reinforcement Learning approach shows better results than traditional
approaches using a simple reward function and only being given the time series
of stocks. In Finance, no training to test error generalization results come
guaranteed. We can say that the modeling framework can deal with time series
prediction and asset allocation, including transaction costs.
"
2010.08900,2021-08-10,"Cryptocurrency portfolio optimization with multivariate normal tempered
  stable processes and Foster-Hart risk","  We study portfolio optimization of four major cryptocurrencies. Our time
series model is a generalized autoregressive conditional heteroscedasticity
(GARCH) model with multivariate normal tempered stable (MNTS) distributed
residuals used to capture the non-Gaussian cryptocurrency return dynamics.
Based on the time series model, we optimize the portfolio in terms of
Foster-Hart risk. Those sophisticated techniques are not yet documented in the
context of cryptocurrency. Statistical tests suggest that the MNTS distributed
GARCH model fits better with cryptocurrency returns than the competing
GARCH-type models. We find that Foster-Hart optimization yields a more
profitable portfolio with better risk-return balance than the prevailing
approach.
"
2010.08985,2020-10-20,"Scenario-decomposition Solution Framework for Nonseparable Stochastic
  Control Problems","  When stochastic control problems do not possess separability and/or
monotonicity, the dynamic programming pioneered by Bellman in 1950s fails to
work as a time-decomposition solution method. Such cases have posted a great
challenge to the control society in both theoretical foundation and solution
methodologies for many years. With the help of the progressive hedging
algorithm proposed by Rockafellar and Wets in 1991, we develop a novel
scenario-decomposition solution framework for stochastic control problems which
could be nonseparable and/or non-monotonic, thus extending the reach of
stochastic optimal control. We discuss then some of its promising applications,
including online quadratic programming problems and dynamic portfolio selection
problems with smoothing properties.
"
2010.09108,2020-10-20,"Bridging the gap between Markowitz planning and deep reinforcement
  learning","  While researchers in the asset management industry have mostly focused on
techniques based on financial and risk planning techniques like Markowitz
efficient frontier, minimum variance, maximum diversification or equal risk
parity, in parallel, another community in machine learning has started working
on reinforcement learning and more particularly deep reinforcement learning to
solve other decision making problems for challenging task like autonomous
driving, robot learning, and on a more conceptual side games solving like Go.
This paper aims to bridge the gap between these two approaches by showing Deep
Reinforcement Learning (DRL) techniques can shed new lights on portfolio
allocation thanks to a more general optimization setting that casts portfolio
allocation as an optimal control problem that is not just a one-step
optimization, but rather a continuous control optimization with a delayed
reward. The advantages are numerous: (i) DRL maps directly market conditions to
actions by design and hence should adapt to changing environment, (ii) DRL does
not rely on any traditional financial risk assumptions like that risk is
represented by variance, (iii) DRL can incorporate additional data and be a
multi inputs method as opposed to more traditional optimization methods. We
present on an experiment some encouraging results using convolution networks.
"
2010.12158,2020-10-26,"Optimal per-loss reinsurance and investment to minimize the probability
  of drawdown","  In this paper, we study an optimal reinsurance-investment problem in a risk
model with two dependent classes of insurance business, where the two claim
number processes are correlated through a common shock component. We assume
that the insurer can purchase per-loss reinsurance for each line of business
and invest its surplus in a financial market consisting of a risk-free asset
and a risky asset. Under the criterion of minimizing the probability of
drawdown, the closed-form expressions of the optimal reinsurance-investment
strategy and the corresponding value function are obtained. We show that the
optimal reinsurance strategy is in the form of pure excess-of-loss reinsurance
strategy under the expected value principle, and under the variance premium
principle, the optimal reinsurance strategy is in the form of pure quota-share
reinsurance. Furthermore, we extend our model to the case where the insurance
company involves $n$ $(n\geq3)$ dependent classes of insurance business and the
optimal results are derived explicitly as well.
"
2010.13397,2020-10-28,"Robust Optimization Approaches for Portfolio Selection: A Computational
  and Comparative Analysis","  The field of portfolio selection is an active research topic, which combines
elements and methodologies from various fields, such as optimization, decision
analysis, risk management, data science, forecasting, etc. The modeling and
treatment of deep uncertainties for future asset returns is a major issue for
the success of analytical portfolio selection models. Recently, robust
optimization (RO) models have attracted a lot of interest in this area. RO
provides a computationally tractable framework for portfolio optimization based
on relatively general assumptions on the probability distributions of the
uncertain risk parameters. Thus, RO extends the framework of traditional linear
and non-linear models (e.g., the well-known mean-variance model), incorporating
uncertainty through a formal and analytical approach into the modeling process.
Robust counterparts of existing models can be considered as worst-case
re-formulations as far as deviations of the uncertain parameters from their
nominal values are concerned. Although several RO models have been proposed in
the literature focusing on various risk measures and different types of
uncertainty sets about asset returns, analytical empirical assessments of their
performance have not been performed in a comprehensive manner. The objective of
this study is to fill in this gap in the literature. More specifically, we
consider different types of RO models based on popular risk measures and
conduct an extensive comparative analysis of their performance using data from
the US market during the period 2005-2016.
"
2010.13928,2020-10-28,Risk Preferences and Efficiency of Household Portfolios,"  We propose a novel approach to infer investors' risk preferences from their
portfolio choices, and then use the implied risk preferences to measure the
efficiency of investment portfolios. We analyze a dataset spanning a period of
six years, consisting of end of month stock trading records, along with
investors' demographic information and self-assessed financial knowledge.
Unlike estimates of risk aversion based on the share of risky assets, our
statistical analysis suggests that the implied risk aversion coefficient of an
investor increases with her wealth and financial literacy. Portfolio
diversification, Sharpe ratio, and expected portfolio returns correlate
positively with the efficiency of the portfolio, whereas a higher standard
deviation reduces the efficiency of the portfolio. We find that affluent and
financially educated investors as well as those holding retirement related
accounts hold more efficient portfolios.
"
2010.15223,2020-10-30,"Design Diversity for Improving Efficiency and Reducing Risk in Oil and
  Gas Well Stimulation under Uncertain Reservoir Conditions","  Hydraulic fracturing stimulates fracture swarm in reservoir formation though
pressurized injection fluid. However restricted by the availability of
formation data, the variability embraced by reservoir keeps uncertain, driving
unstable gas recovery along with low resource efficiency, being responsible for
resource scarcity, contaminated water, and injection-induced earthquake.
Resource efficiency is qualified though new determined energy efficiency, a
scale of recovery and associated environmental footprint. To maximize energy
efficiency while minimize its' variation, we issue picked designs at reservoir
conditions dependent optimal probabilities, assembling high efficiency
portfolios and low risk portfolios for portfolio combination, which balance the
variation and efficiency at optimal by adjusting the proportion of each
portfolio. Relative to regular design for one well, the optimal portfolio
combination applied in multiple wells receive remarkable variation reduction
meanwhile substantial energy efficiency increase, in response to the call of
more recovery per unit investment and less environment cost per unit nature gas
extracted.
"
2010.15779,2020-11-02,"Discrete-time portfolio optimization under maximum drawdown constraint
  with partial information and deep learning resolution","  We study a discrete-time portfolio selection problem with partial information
and maxi\-mum drawdown constraint. Drift uncertainty in the multidimensional
framework is modeled by a prior probability distribution. In this Bayesian
framework, we derive the dynamic programming equation using an appropriate
change of measure, and obtain semi-explicit results in the Gaussian case. The
latter case, with a CRRA utility function is completely solved numerically
using recent deep learning techniques for stochastic optimal control problems.
We emphasize the informative value of the learning strategy versus the
non-learning one by providing empirical performance and sensitivity analysis
with respect to the uncertainty of the drift. Furthermore, we show numerical
evidence of the close relationship between the non-learning strategy and a no
short-sale constrained Merton problem, by illustrating the convergence of the
former towards the latter as the maximum drawdown constraint vanishes.
"
2010.16102,2020-11-02,"Optimal control of multiple Markov switching stochastic system with
  application to portfolio decision","  In this paper we set up an optimal control framework for a hybrid stochastic
system with dual or multiple Markov switching diffusion processes, while Markov
chains governing these switching diffusions are not identical as assumed by the
existing literature. As an application and illustration of this model, we solve
a portfolio choice problem for an investor facing financial and labor markets
that are both regime switching. In continuous time context we combine two
separate Markov chains into one synthetic Markov chain and derive its
corresponding generator matrix, then state the HJB equations for the optimal
control problem with the newly synthesized Markov switching diffusion.
Furthermore, we derive explicit solutions and value functions under some
reasonable specifications.
"
2011.00435,2023-04-04,Optimal Portfolio Using Factor Graphical Lasso,"  Graphical models are a powerful tool to estimate a high-dimensional inverse
covariance (precision) matrix, which has been applied for a portfolio
allocation problem. The assumption made by these models is a sparsity of the
precision matrix. However, when stock returns are driven by common factors,
such assumption does not hold. We address this limitation and develop a
framework, Factor Graphical Lasso (FGL), which integrates graphical models with
the factor structure in the context of portfolio allocation by decomposing a
precision matrix into low-rank and sparse components. Our theoretical results
and simulations show that FGL consistently estimates the portfolio weights and
risk exposure and also that FGL is robust to heavy-tailed distributions which
makes our method suitable for financial applications. FGL-based portfolios are
shown to exhibit superior performance over several prominent competitors
including equal-weighted and Index portfolios in the empirical application for
the S&P500 constituents.
"
2011.00572,2020-11-24,"Asset Allocation via Machine Learning and Applications to Equity
  Portfolio Management","  In this paper, we document a novel machine learning based bottom-up approach
for static and dynamic portfolio optimization on, potentially, a large number
of assets. The methodology applies to general constrained optimization problems
and overcomes many major difficulties arising in current optimization schemes.
Taking mean-variance optimization as an example, we no longer need to compute
the covariance matrix and its inverse, therefore the method is immune from the
estimation error on this quantity. Moreover, no explicit calls of optimization
routines are needed. Applications to equity portfolio management in U.S. and
China equity markets are studied and we document significant excess returns to
the selected benchmarks.
"
2011.00838,2020-11-03,Competition in Fund Management and Forward Relative Performance Criteria,"  In an Ito-diffusion market, two fund managers trade under relative
performance concerns. For both the asset specialization and diversification
settings, we analyze the passive and competitive cases. We measure the
performance of the managers' strategies via forward relative performance
criteria, leading to the respective notions of forward best-response criterion
and forward Nash equilibrium. The motivation to develop such criteria comes
from the need to relax various crucial, but quite stringent, existing
assumptions -- such as, the a priori choices of both the market model and the
investment horizon, the commonality of the latter for both managers as well as
the full a priori knowledge of the competitor's policies for the best-response
case. We focus on locally riskless criteria and deduce the random forward
equations. We solve the CRRA cases, thus also extending the related results in
the classical setting. An important by-product of the work herein is the
development of forward performance criteria for investment problems in
Ito-diffusion markets under the presence of correlated random endowment process
for both the perfectly and the incomplete market cases.
"
2011.01308,2020-11-04,"Picking Efficient Portfolios from 3,171 US Common Stocks with New
  Quantum and Classical Solvers","  We analyze 3,171 US common stocks to create an efficient portfolio based on
the Chicago Quantum Net Score (CQNS) and portfolio optimization. We begin with
classical solvers and incorporate quantum annealing. We add a simulated
bifurcator as a new classical solver and the new D-Wave Advantage(TM) quantum
annealing computer as our new quantum solver.
"
2011.02596,2021-06-02,Rule-based Strategies for Dynamic Life Cycle Investment,"  In this work, we consider rule-based investment strategies for managing a
defined contribution saving scheme under the Dutch pension fund testing model.
We found that dynamic rule-based investment can outperform traditional static
strategies, by which we mean that the pensioner can achieve the target
retirement income with higher probability and limit the shortfall when target
is not met. In comparison with the popular dynamic programming technique, the
rule-based strategy has a more stable asset allocation throughout time and
avoid excessive transactions, which may be hard to explain to the investor. We
also study a combined strategy of rule based target and dynamic programming in
this work. Another key feature of this work is that there is no risk-free asset
under our setting, instead, a matching portfolio is introduced for the investor
to avoid unnecessary risk.
"
2011.03314,2020-11-09,"The importance of dynamic risk constraints for limited liability
  operators","  Previous literature shows that prevalent risk measures such as Value at Risk
or Expected Shortfall are ineffective to curb excessive risk-taking by a
tail-risk-seeking trader with S-shaped utility function in the context of
portfolio optimisation. However, these conclusions hold only when the
constraints are static in the sense that the risk measure is just applied to
the terminal portfolio value. In this paper, we consider a portfolio
optimisation problem featuring S-shaped utility and a dynamic risk constraint
which is imposed throughout the entire trading horizon. Provided that the risk
control policy is sufficiently strict relative to the asset performance, the
trader's portfolio strategies and the resulting maximal expected utility can be
effectively constrained by a dynamic risk measure. Finally, we argue that
dynamic risk constraints might still be ineffective if the trader has access to
a derivatives market.
"
2011.04278,2021-04-27,A Basket Half Full: Sparse Portfolios,"  The existing approaches to sparse wealth allocations (1) are limited to
low-dimensional setup when the number of assets is less than the sample size;
(2) lack theoretical analysis of sparse wealth allocations and their impact on
portfolio exposure; (3) are suboptimal due to the bias induced by an
$\ell_1$-penalty. We address these shortcomings and develop an approach to
construct sparse portfolios in high dimensions. Our contribution is twofold:
from the theoretical perspective, we establish the oracle bounds of sparse
weight estimators and provide guidance regarding their distribution. From the
empirical perspective, we examine the merit of sparse portfolios during
different market scenarios. We find that in contrast to non-sparse
counterparts, our strategy is robust to recessions and can be used as a hedging
vehicle during such times.
"
2011.05117,2020-11-11,Startup & Unicorn Growth Valuation,"  How do you value companies which have IPOed recently? How do you compare them
amongst their peers? Valuing companies using a linear extrapolation of their
revenues and profits leads to an ingenious method to benchmark stocks against
each other. Here we present such a method, dubbed the growth average U1.
"
2011.05381,2021-06-28,Dirichlet policies for reinforced factor portfolios,"  This article aims to combine factor investing and reinforcement learning
(RL). The agent learns through sequential random allocations which rely on
firms' characteristics. Using Dirichlet distributions as the driving policy, we
derive closed forms for the policy gradients and analytical properties of the
performance measure. This enables the implementation of REINFORCE methods,
which we perform on a large dataset of US equities. Across a large range of
parametric choices, our result indicates that RL-based portfolios are very
close to the equally-weighted (1/N) allocation. This implies that the agent
learns to be *agnostic* with regard to factors, which can partly be explained
by cross-sectional regressions showing a strong time variation in the
relationship between returns and firm characteristics.
"
2011.07871,2020-11-17,Implicit Incentives for Fund Managers with Partial Information,"  We study the optimal asset allocation problem for a fund manager whose
compensation depends on the performance of her portfolio with respect to a
benchmark. The objective of the manager is to maximise the expected utility of
her final wealth. The manager observes the prices but not the values of the
market price of risk that drives the expected returns. The estimates of the
market price of risk get more precise as more observations are available. We
formulate the problem as an optimization
  under partial information. The particular structure of the incentives makes
the objective function not concave. We solve the problem via the martingale
method and, with a concavification procedure, we obtain the optimal wealth and
the investment strategy. A numerical example shows the effect of learning on
the optimal strategy.
"
2011.10113,2021-09-16,Price Impact on Term Structure,"  We introduce a first theory of price impact in presence of an interest-rates
term structure. We explain how one can formulate instantaneous and transient
price impact on bonds with different maturities, including a cross price impact
that is endogenous to the term structure. We connect the introduced impact to
classic no-arbitrage theory for interest rate markets, showing that impact can
be embedded in the pricing measure and that no-arbitrage can be preserved. We
present pricing examples in presence of price impact and numerical examples of
how impact changes the shape of the term structure. Finally, to show that our
approach is applicable we solve an optimal execution problem in interest rate
markets with the type of price impact we developed in the paper.
"
2011.10166,2024-02-20,"Retirement decision with addictive habit persistence in a jump diffusion
  market","  This paper investigates the optimal retirement decision, investment, and
consumption strategies in a market with jump diffusion, taking into account
habit persistence and stock-wage correlation. Our analysis considers multiple
stocks and a finite time framework, intending to determine the retirement
boundary of the ``wealth-habit-wage"" triplet $(x, h, w)$. To achieve this, we
use the habit reduction method and a duality approach to obtain the retirement
boundary of the primal variables and feedback forms of optimal strategies. {
When dealing with the dual problem, we address technical challenges in the
proof of integral equation characterization of optimal retirement boundary
using a $C^1$ version of It$\hat{\rm o}$'s formula.} Our results show that when
the so-called ``de facto wealth"" exceeds a critical proportion of wage, an
immediate retirement is the optimal choice for the agent. Additionally, we find
that the introduction of jump risks allows for the possibility of discontinuous
investment strategies within the working region, which is a novel and
insightful finding. Our numerical results effectively illustrate these findings
by varying the parameters.
"
2011.13625,2020-11-30,An Equilibrium Model for the Cross-Section of Liquidity Premia,"  We study a risk-sharing economy where an arbitrary number of heterogenous
agents trades an arbitrary number of risky assets subject to quadratic
transaction costs. For linear state dynamics, the forward-backward stochastic
differential equations characterizing equilibrium asset prices and trading
strategies in this context reduce to a system of matrix-valued Riccati
equations. We prove the existence of a unique global solution and provide
explicit asymptotic expansions that allow us to approximate the corresponding
equilibrium for small transaction costs. These tractable approximation formulas
make it feasible to calibrate the model to time series of prices and trading
volume, and to study the cross-section of liquidity premia earned by assets
with higher and lower trading costs. This is illustrated by an empirical case
study.
"
2011.13637,2022-03-02,Fat Tailed Factors,"  Standard, PCA-based factor analysis suffers from a number of well known
problems due to the random nature of pairwise correlations of asset returns. We
analyse an alternative based on ICA, where factors are identified based on
their non-Gaussianity, instead of their variance. Generalizations of portfolio
construction to the ICA framework leads to two semi-optimal portfolio
construction methods: a fat-tailed portfolio, which maximises return per unit
of non-Gaussianity, and the hybrid portfolio, which asymptotically reduces
variance and non-Gaussianity in parallel. For fat-tailed portfolios, the
portfolio weights scale like performance to the power of $1/3$, as opposed to
linear scaling of Kelly portfolios; such portfolio construction significantly
reduces portfolio concentration, and the winner-takes-all problem inherent in
Kelly portfolios. For hybrid portfolios, the variance is diversified at the
same rate as Kelly PCA-based portfolios, but excess kurtosis is diversified
much faster than in Kelly, at the rate of $n^{-2}$ compared to Kelly
portfolios' $n^{-1}$ for increasing number of components $n$.
"
2012.01121,2020-12-03,Portfolio Optimisation Using the D-Wave Quantum Annealer,"  The first quantum computers are expected to perform well at quadratic
optimisation problems. In this paper a quadratic problem in finance is taken,
the Portfolio Optimisation problem. Here, a set of assets is chosen for
investment, such that the total risk is minimised, a minimum return is realised
and a budget constraint is met. This problem is solved for several instances in
two main indices, the Nikkei225 and the S\&P500 index, using the
state-of-the-art implementation of D-Wave's quantum annealer and its hybrid
solvers. The results are benchmarked against conventional, state-of-the-art,
commercially available tooling. Results show that for problems of the size of
the used instances, the D-Wave solution, in its current, still limited size,
comes already close to the performance of commercial solvers.
"
2012.01235,2022-03-07,"Forward utility and market adjustments in relative
  investment-consumption games of many players","  We study a portfolio management problem featuring many-player and mean field
competition, investment and consumption, and relative performance concerns
under the forward performance processes (FPP) framework. We focus on agents
using power (CRRA) type FPPs for their investment-consumption optimization
problem under a common noise Merton market model. We solve both the many-player
and mean field game providing closed-form expressions for the solutions where
the limit of the former yields the latter. In our case, the FPP framework
yields a continuum of solutions for the consumption component as indexed to a
market parameter we coin ""market-risk relative consumption preference"". The
parameter permits the agent to set a preference for their consumption going
forward in time that, in the competition case, reflects a common market
behaviour. We show the FPP framework, under both competition and
no-competition, allows the agent to disentangle her risk-tolerance and
elasticity of intertemporal substitution (EIS) just like Epstein-Zin
preferences under recursive utility framework and unlike the classical utility
theory one. This, in turn, allows a finer analysis on the agent's consumption
""income"" and ""substitution"" regimes, and, of independent interest, motivates a
new strand of economics research on EIS under the FPP framework. We find that
competition rescales the agent's perception of consumption in a non-trivial
manner. We provide numerical illustrations of our results.
"
2012.01819,2020-12-04,Bayesian Quantile-Based Portfolio Selection,"  We study the optimal portfolio allocation problem from a Bayesian perspective
using value at risk (VaR) and conditional value at risk (CVaR) as risk
measures. By applying the posterior predictive distribution for the future
portfolio return, we derive relevant quantiles needed in the computations of
VaR and CVaR, and express the optimal portfolio weights in terms of observed
data only. This is in contrast to the conventional method where the optimal
solution is based on unobserved quantities which are estimated, leading to
suboptimality. We also obtain the expressions for the weights of the global
minimum VaR and CVaR portfolios, and specify conditions for their existence. It
is shown that these portfolios may not exist if the confidence level used for
the VaR or CVaR computation are too low. Moreover, analytical expressions for
the mean-VaR and mean-CVaR efficient frontiers are presented and the extension
of theoretical results to general coherent risk measures is provided. One of
the main advantages of the suggested Bayesian approach is that the theoretical
results are derived in the finite-sample case and thus they are exact and can
be applied to large-dimensional portfolios.
  By using simulation and real market data, we compare the new Bayesian
approach to the conventional method by studying the performance and existence
of the global minimum VaR portfolio and by analysing the estimated efficient
frontiers. It is concluded that the Bayesian approach outperforms the
conventional one, in particular at predicting the out-of-sample VaR.
"
2012.02277,2022-10-20,"Optimal Consumption under a Habit-Formation Constraint: the
  Deterministic Case","  We formulate and solve a deterministic optimal consumption problem to
maximize the discounted CRRA utility of an individual's consumption-to-habit
process assuming she only invests in a riskless market and that she is
unwilling to consume at a rate below a certain proportion $\alpha\in(0,1]$ of
her consumption habit. Increasing $\alpha$, increases the degree of
addictiveness of habit formation, with $\alpha=0$ (respectively, $\alpha=1$)
corresponding to non-addictive (respectively, completely addictive) model. We
derive the optimal consumption policies explicitly in terms of the solution of
a nonlinear free-boundary problem, which we analyze in detail. Impatient
individuals (or, equivalently, those with more addictive habits) always consume
above the minimum rate; thus, they eventually attain the minimum
wealth-to-habit ratio. Patient individuals (or, equivalently, those with less
addictive habits) consume at the minimum rate if their wealth-to-habit ratio is
below a threshold, and above it otherwise. By consuming patiently, these
individuals maintain a wealth-to-habit ratio that is greater than the minimum
acceptable level. Additionally, we prove that the optimal consumption path is
hump-shaped if the initial wealth-to-habit ratio is either: (1) larger than a
high threshold; or (2) below a low threshold and the agent is more risk seeking
(that is, less risk averse). Thus, we provide a simple explanation for the
consumption hump observed by various empirical studies.
"
2012.04500,2022-06-22,Portfolio Optimisation within a Wasserstein Ball,"  We study the problem of active portfolio management where an investor aims to
outperform a benchmark strategy's risk profile while not deviating too far from
it. Specifically, an investor considers alternative strategies whose terminal
wealth lie within a Wasserstein ball surrounding a benchmark's -- being
distributionally close -- and that have a specified dependence/copula -- tying
state-by-state outcomes -- to it. The investor then chooses the alternative
strategy that minimises a distortion risk measure of terminal wealth. In a
general (complete) market model, we prove that an optimal dynamic strategy
exists and provide its characterisation through the notion of isotonic
projections.
  We further propose a simulation approach to calculate the optimal strategy's
terminal wealth, making our approach applicable to a wide range of market
models. Finally, we illustrate how investors with different copula and risk
preferences invest and improve upon the benchmark using the Tail Value-at-Risk,
inverse S-shaped, and lower- and upper-tail distortion risk measures as
examples. We find that investors' optimal terminal wealth distribution has
larger probability masses in regions that reduce their risk measure relative to
the benchmark while preserving the benchmark's structure.
"
2012.05088,2021-09-06,"Modeling asset allocation strategies and a new portfolio performance
  score","  We discuss and extend a powerful, geometric framework to represent the set of
portfolios, which identifies the space of asset allocations with the points
lying in a convex polytope. Based on this viewpoint, we survey certain
state-of-the-art tools from geometric and statistical computing in order to
handle important and difficult problems in digital finance. Although our tools
are quite general, in this paper we focus on two specific questions.
  The first concerns crisis detection, which is of prime interest for the
public in general and for policy makers in particular because of the
significant impact that crises have on the economy. Certain features in stock
markets lead to this type of anomaly detection: Given the assets' returns, we
describe the relationship between portfolios' return and volatility by means of
a copula, without making any assumption on investor strategies. We examine a
recent method relying on copulae to construct an appropriate indicator that
allows us to automate crisis detection. On real data, the indicator detects all
past crashes in the cryptocurrency market, whereas from the DJ600-Europe index,
from 1990 to 2008, the indicator identifies correctly 4 crises and issues one
false positive for which we offer an explanation.
  Our second contribution is to introduce an original computational framework
to model asset allocation strategies, which is of independent interest for
digital finance and its applications. Our approach addresses the crucial
question of evaluating portfolio management, and is relevant to individual
managers as well as financial institutions. To evaluate portfolio performance,
we provide a new portfolio score, based on the aforementioned framework and
concepts. In particular, our score relies on the statistical properties of
portfolios, and we show how they can be computed efficiently.
"
2012.06173,2020-12-14,Portfolio optimization with two quasiconvex risk measures,"  We study a static portfolio optimization problem with two risk measures: a
principle risk measure in the objective function and a secondary risk measure
whose value is controlled in the constraints. This problem is of interest when
it is necessary to consider the risk preferences of two parties, such as a
portfolio manager and a regulator, at the same time. A special case of this
problem where the risk measures are assumed to be coherent (positively
homogeneous) is studied recently in a joint work of the author. The present
paper extends the analysis to a more general setting by assuming that the two
risk measures are only quasiconvex. First, we study the case where the
principal risk measure is convex. We introduce a dual problem, show that there
is zero duality gap between the portfolio optimization problem and the dual
problem, and finally identify a condition under which the Lagrange multiplier
associated to the dual problem at optimality gives an optimal portfolio. Next,
we study the general case without the convexity assumption and show that an
approximately optimal solution with prescribed optimality gap can be achieved
by using the well-known bisection algorithm combined with a duality result that
we prove.
"
2012.06703,2021-05-27,"A Perturbation Approach to Optimal Investment, Liability Ratio, and
  Dividend Strategies","  We study an optimal dividend problem for an insurer who simultaneously
controls investment weights in a financial market, liability ratio in the
insurance business, and dividend payout rate. The insurer seeks an optimal
strategy to maximize her expected utility of dividend payments over an infinite
horizon. By applying a perturbation approach, we obtain the optimal strategy
and the value function in closed form for log and power utility. We conduct an
economic analysis to investigate the impact of various model parameters and
risk aversion on the insurer's optimal strategy.
"
2012.07149,2020-12-15,Building Cross-Sectional Systematic Strategies By Learning to Rank,"  The success of a cross-sectional systematic strategy depends critically on
accurately ranking assets prior to portfolio construction. Contemporary
techniques perform this ranking step either with simple heuristics or by
sorting outputs from standard regression or classification models, which have
been demonstrated to be sub-optimal for ranking in other domains (e.g.
information retrieval). To address this deficiency, we propose a framework to
enhance cross-sectional portfolios by incorporating learning-to-rank
algorithms, which lead to improvements of ranking accuracy by learning pairwise
and listwise structures across instruments. Using cross-sectional momentum as a
demonstrative case study, we show that the use of modern machine learning
ranking algorithms can substantially improve the trading performance of
cross-sectional strategies -- providing approximately threefold boosting of
Sharpe Ratios compared to traditional approaches.
"
2012.07245,2020-12-15,"Deep Portfolio Optimization via Distributional Prediction of Residual
  Factors","  Recent developments in deep learning techniques have motivated intensive
research in machine learning-aided stock trading strategies. However, since the
financial market has a highly non-stationary nature hindering the application
of typical data-hungry machine learning methods, leveraging financial inductive
biases is important to ensure better sample efficiency and robustness. In this
study, we propose a novel method of constructing a portfolio based on
predicting the distribution of a financial quantity called residual factors,
which is known to be generally useful for hedging the risk exposure to common
market factors. The key technical ingredients are twofold. First, we introduce
a computationally efficient extraction method for the residual information,
which can be easily combined with various prediction algorithms. Second, we
propose a novel neural network architecture that allows us to incorporate
widely acknowledged financial inductive biases such as amplitude invariance and
time-scale invariance. We demonstrate the efficacy of our method on U.S. and
Japanese stock market data. Through ablation experiments, we also verify that
each individual technique contributes to improving the performance of trading
strategies. We anticipate our techniques may have wide applications in various
financial problems.
"
2012.07368,2021-01-18,"Effective Algorithms for Optimal Portfolio Deleveraging Problem with
  Cross Impact","  We investigate the optimal portfolio deleveraging (OPD) problem with
permanent and temporary price impacts, where the objective is to maximize
equity while meeting a prescribed debt/equity requirement. We take the real
situation with cross impact among different assets into consideration. The
resulting problem is, however, a non-convex quadratic program with a quadratic
constraint and a box constraint, which is known to be NP-hard. In this paper,
we first develop a successive convex optimization (SCO) approach for solving
the OPD problem and show that the SCO algorithm converges to a KKT point of its
transformed problem. Second, we propose an effective global algorithm for the
OPD problem, which integrates the SCO method, simple convex relaxation and a
branch-and-bound framework, to identify a global optimal solution to the OPD
problem within a pre-specified $\epsilon$-tolerance. We establish the global
convergence of our algorithm and estimate its complexity. We also conduct
numerical experiments to demonstrate the effectiveness of our proposed
algorithms with both the real data and the randomly generated medium- and
large-scale OPD problem instances.
"
2012.10632,2020-12-22,Optimal ratcheting of dividends in a Brownian risk model,"  We study the problem of optimal dividend payout from a surplus process
governed by Brownian motion with drift under the additional constraint of
ratcheting, i.e. the dividend rate can never decrease. We solve the resulting
two-dimensional optimal control problem, identifying the value function to be
the unique viscosity solution of the corresponding Hamilton-Jacobi-Bellman
equation. For finitely many admissible dividend rates we prove that threshold
strategies are optimal, and for any finite continuum of admissible dividend
rates we establish the $\varepsilon$-optimality of curve strategies. This work
is a counterpart of Albrecher et al. (2020), where the ratcheting problem was
studied for a compound Poisson surplus process with drift. In the present
Brownian setup, calculus of variation techniques allow to obtain a much more
explicit analysis and description of the optimal dividend strategies. We also
give some numerical illustrations of the optimality results.
"
2012.11715,2020-12-23,"Off-Policy Optimization of Portfolio Allocation Policies under
  Constraints","  The dynamic portfolio optimization problem in finance frequently requires
learning policies that adhere to various constraints, driven by investor
preferences and risk. We motivate this problem of finding an allocation policy
within a sequential decision making framework and study the effects of: (a)
using data collected under previously employed policies, which may be
sub-optimal and constraint-violating, and (b) imposing desired constraints
while computing near-optimal policies with this data. Our framework relies on
solving a minimax objective, where one player evaluates policies via off-policy
estimators, and the opponent uses an online learning strategy to control
constraint violations. We extensively investigate various choices for
off-policy estimation and their corresponding optimization sub-routines, and
quantify their impact on computing constraint-aware allocation policies. Our
study shows promising results for constructing such policies when back-tested
on historical equities data, under various regimes of operation, dimensionality
and constraints.
"
2012.11972,2020-12-23,Acceptability maximization,"  The aim of this paper is to study the optimal investment problem by using
coherent acceptability indices (CAIs) as a tool to measure the portfolio
performance. We call this problem the acceptability maximization. First, we
study the one-period (static) case, and propose a numerical algorithm that
approximates the original problem by a sequence of risk minimization problems.
The results are applied to several important CAIs, such as the gain-to-loss
ratio, the risk-adjusted return on capital and the tail-value-at-risk based
CAI. In the second part of the paper we investigate the acceptability
maximization in a discrete time dynamic setup. Using robust representations of
CAIs in terms of a family of dynamic coherent risk measures (DCRMs), we
establish an intriguing dichotomy: if the corresponding family of DCRMs is
recursive (i.e. strongly time consistent) and assuming some recursive structure
of the market model, then the acceptability maximization problem reduces to
just a one period problem and the maximal acceptability is constant across all
states and times. On the other hand, if the family of DCRMs is not recursive,
which is often the case, then the acceptability maximization problem ordinarily
is a time-inconsistent stochastic control problem, similar to the classical
mean-variance criteria. To overcome this form of time-inconsistency, we adapt
to our setup the set-valued Bellman's principle recently proposed in
\cite{KovacovaRudloff2019} applied to two particular dynamic CAIs - the dynamic
risk-adjusted return on capital and the dynamic gain-to-loss ratio. The
obtained theoretical results are illustrated via numerical examples that
include, in particular, the computation of the intermediate mean-risk efficient
frontiers.
"
2012.13773,2025-03-18,Deep Reinforcement Learning for Long-Short Portfolio Optimization,"  With the rapid development of artificial intelligence, data-driven methods
effectively overcome limitations in traditional portfolio optimization.
Conventional models primarily employ long-only mechanisms, excluding highly
correlated assets to diversify risk. However, incorporating short-selling
enables low-risk arbitrage through hedging correlated assets. This paper
constructs a Deep Reinforcement Learning (DRL) portfolio management framework
with short-selling mechanisms conforming to actual trading rules, exploring
strategies for excess returns in China's A-share market. Key innovations
include: (1) Development of a comprehensive short-selling mechanism in
continuous trading that accounts for dynamic evolution of transactions across
time periods; (2) Design of a long-short optimization framework integrating
deep neural networks for processing multi-dimensional financial time series
with mean Sharpe ratio reward functions. Empirical results show the DRL model
with short-selling demonstrates significant optimization capabilities,
achieving consistent positive returns during backtesting periods. Compared to
traditional approaches, this model delivers superior risk-adjusted returns
while reducing maximum drawdown. From an allocation perspective, the DRL model
establishes a robust investment style, enhancing defensive capabilities through
strategic avoidance of underperforming assets and balanced capital allocation.
This research contributes to portfolio theory while providing novel
methodologies for quantitative investment practice.
"
2012.13830,2020-12-29,Calculated Boldness: Optimizing Financial Decisions with Illiquid Assets,"  We consider games of chance played by someone with external capital that
cannot be applied to the game and determine how this affects risk-adjusted
optimal betting. Specifically, we focus on Kelly optimization as a metric,
optimizing the expected logarithm of total capital including both capital in
play and the external capital. For games with multiple rounds, we determine the
optimal strategy through dynamic programming and construct a close
approximation through the WKB method. The strategy can be described in terms of
short-term utility functions, with risk aversion depending on the ratio of the
amount in the game to the external money. Thus, a rational player's behavior
varies between conservative play that approaches Kelly strategy as they are
able to invest a larger fraction of total wealth and extremely aggressive play
that maximizes linear expectation when a larger portion of their capital is
locked away. Because you always have expected future productivity to account
for as external resources, this goes counter to the conventional wisdom that
super-Kelly betting is a ruinous proposition.
"
2101.00648,2021-01-05,Governmental incentives for green bonds investment,"  Motivated by the recent studies on the green bond market, we build a model in
which an investor trades on a portfolio of green and conventional bonds, both
issued by the same governmental entity. The government provides incentives to
the bondholder in order to increase the amount invested in green bonds. These
incentives are, optimally, indexed on the prices of the bonds, their quadratic
variation and covariation. We show numerically on a set of French governmental
bonds that our methodology outperforms the current tax-incentives systems in
terms of green investments. Moreover, it is robust to model specification for
bond prices and can be applied to a large portfolio of bonds using classical
optimisation methods.
"
2101.01261,2021-08-11,"Hedging with Bitcoin Futures: The Effect of Liquidation Loss Aversion
  and Aggressive Trading","  We consider the hedging problem where a futures position can be automatically
liquidated by the exchange without notice. We derive a semi-closed form for an
optimal hedging strategy with dual objectives - to minimise both the variance
of the hedged portfolio and the probability of liquidations due to insufficient
collateral. The optimal solution depends on the statistical characteristics of
the spot and futures extreme returns and parameters that characterise the
hedger by loss aversion, choice of leverage and collateral management. An
empirical analysis of bitcoin shows that the optimal strategy combines superior
hedge effectiveness with a reduction in the probability of liquidation. We
compare the performance of seven major direct and inverse hedging instruments
traded on five different exchanges, based on minute-level data. We also link
this performance to novel speculative trading metrics, which differ markedly
between venues.
"
2101.02044,2022-02-16,Deep learning for efficient frontier calculation in finance,"  We propose deep neural network algorithms to calculate efficient frontier in
some Mean-Variance and Mean-CVaR portfolio optimization problems. We show that
we are able to deal with such problems when both the dimension of the state and
the dimension of the control are high. Adding some additional constraints, we
compare different formulations and show that a new projected feedforward
network is able to deal with some global constraints on the weights of the
portfolio while outperforming classical penalization methods. All developed
formulations are compared in between. Depending on the problem and its
dimension, some formulations may be preferred.
"
2101.02760,2021-01-11,"Optimal control of the decumulation of a retirement portfolio with
  variable spending and dynamic asset allocation","  We extend the Annually Recalculated Virtual Annuity (ARVA) spending rule for
retirement savings decumulation to include a cap and a floor on withdrawals.
With a minimum withdrawal constraint, the ARVA strategy runs the risk of
depleting the investment portfolio. We determine the dynamic asset allocation
strategy which maximizes a weighted combination of expected total withdrawals
(EW) and expected shortfall (ES), defined as the average of the worst five per
cent of the outcomes of real terminal wealth. We compare the performance of our
dynamic strategy to simpler alternatives which maintain constant asset
allocation weights over time accompanied by either our same modified ARVA
spending rule or withdrawals that are constant over time in real terms. Tests
are carried out using both a parametric model of historical asset returns as
well as bootstrap resampling of historical data. Consistent with previous
literature that has used different measures of reward and risk than EW and ES,
we find that allowing some variability in withdrawals leads to large
improvements in efficiency. However, unlike the prior literature, we also
demonstrate that further significant enhancements are possible through
incorporating a dynamic asset allocation strategy rather than simply keeping
asset allocation weights constant throughout retirement.
"
2101.03138,2021-01-11,Portfolio Optimization with 2D Relative-Attentional Gated Transformer,"  Portfolio optimization is one of the most attentive fields that have been
researched with machine learning approaches. Many researchers attempted to
solve this problem using deep reinforcement learning due to its efficient
inherence that can handle the property of financial markets. However, most of
them can hardly be applicable to real-world trading since they ignore or
extremely simplify the realistic constraints of transaction costs. These
constraints have a significantly negative impact on portfolio profitability. In
our research, a conservative level of transaction fees and slippage are
considered for the realistic experiment. To enhance the performance under those
constraints, we propose a novel Deterministic Policy Gradient with 2D
Relative-attentional Gated Transformer (DPGRGT) model. Applying learnable
relative positional embeddings for the time and assets axes, the model better
understands the peculiar structure of the financial data in the portfolio
optimization domain. Also, gating layers and layer reordering are employed for
stable convergence of Transformers in reinforcement learning. In our experiment
using U.S. stock market data of 20 years, our model outperformed baseline
models and demonstrated its effectiveness.
"
2101.03954,2021-01-12,"Mean-Variance Investment and Risk Control Strategies -- A
  Time-Consistent Approach via A Forward Auxiliary Process","  We consider an optimal investment and risk control problem for an insurer
under the mean-variance (MV) criterion. By introducing a deterministic
auxiliary process defined forward in time, we formulate an alternative
time-consistent problem related to the original MV problem, and obtain the
optimal strategy and the value function to the new problem in closed-form. We
compare our formulation and optimal strategy to those under the precommitment
and game-theoretic framework. Numerical studies show that, when the financial
market is negatively correlated with the risk process, optimal investment may
involve short selling the risky asset and, if that happens, a less risk averse
insurer short sells more risky asset.
"
2101.04113,2021-02-10,Portfolio Construction Using Stratified Models,"  In this paper we develop models of asset return mean and covariance that
depend on some observable market conditions, and use these to construct a
trading policy that depends on these conditions, and the current portfolio
holdings. After discretizing the market conditions, we fit Laplacian
regularized stratified models for the return mean and covariance. These models
have a different mean and covariance for each market condition, but are
regularized so that nearby market conditions have similar models. This
technique allows us to fit models for market conditions that have not occurred
in the training data, by borrowing strength from nearby market conditions for
which we do have data. These models are combined with a Markowitz-inspired
optimization method to yield a trading policy that is based on market
conditions. We illustrate our method on a small universe of 18 ETFs, using
three well known and publicly available market variables to construct 1000
market conditions, and show that it performs well out of sample. The method,
however, is general, and scales to much larger problems, that presumably would
use proprietary data sources and forecasts along with publicly available data.
"
2101.07084,2021-01-19,Beating the Market with Generalized Generating Portfolios,"  Stochastic portfolio theory aims at finding relative arbitrages, i.e. trading
strategies which outperform the market with probability one. Functionally
generated portfolios, which are deterministic functions of the market weights,
are an invaluable tool in doing so. Driven by a practitioner point of view,
where investment decisions are based upon consideration of various financial
variables, we generalize functionally generated portfolios and allow them to
depend on continuous-path semimartingales, in addition to the market weights.
By means of examples we demonstrate how the inclusion of additional processes
can reduce time horizons beyond which relative arbitrage is possible, boost
performance of generated portfolios, and how investor preferences and specific
investment views can be included in the context of stochastic portfolio theory.
Striking is also the construction of a relative arbitrage opportunity which is
generated by the volatility of the additional semimartingale. An in-depth
empirical analysis of the performance of the proposed strategies confirms our
theoretical findings and demonstrates that our portfolios represent profitable
investment opportunities even in the presence of transaction costs.
"
2101.08559,2024-04-30,"To VaR, or Not to VaR, That is the Question","  We consider economic obstacles that limit the reliability and accuracy of
value-at-risk (VaR). Investors who manage large market transactions should take
into account the impact of the randomness of large trade volumes on predictions
of price probability and VaR assessments. We introduce market-based
probabilities of price and return that depend on the randomness of market trade
values and volumes. Contrary to them, the conventional frequency-based price
probability describes the case of constant trade volumes. We derive the
dependence of market-based price volatility on the volatilities and correlation
of trade values and volumes. In the coming years, that will limit the accuracy
of price probability predictions to Gaussian approximations, and even the
forecasts of market-based price volatility will be inaccurate and highly
uncertain.
"
2101.10092,2022-07-12,"Beyond cost reduction: Improving the value of energy storage in
  electricity systems","  An energy storage technology is valuable if it makes energy systems cheaper.
Traditional ways to improve storage technologies are to reduce their costs;
however, the cheapest energy storage is not always the most valuable in energy
systems. Modern techno-economical evaluation methods try to address the cost
and value situation but do not judge the competitiveness of multiple
technologies simultaneously. This paper introduces the market potential method
as a new complementary valuation method guiding innovation of multiple energy
storage. The market potential method derives the value of technologies by
examining common deployment signals from energy system model outputs in a
structured way. We apply and compare this method to cost evaluation approaches
in a renewables-based European power system model, covering diverse energy
storage technologies. We find that characteristics of high-cost hydrogen
storage can be more valuable than low-cost hydrogen storage. Additionally, we
show that modifying the freedom of storage sizing and component interactions
can make the energy system 10% cheaper and impact the value of technologies.
The results suggest looking beyond the pure cost reduction paradigm and focus
on developing technologies with suitable value approaches that can lead to
cheaper electricity systems in future.
"
2101.10635,2021-01-27,"The Market Measure of Carbon Risk and its Impact on the Minimum Variance
  Portfolio","  Like ESG investing, climate change is an important concern for asset managers
and owners, and a new challenge for portfolio construction. Until now,
investors have mainly measured carbon risk using fundamental approaches, such
as with carbon intensity metrics. Nevertheless, it has not been proven that
asset prices are directly impacted by these fundamental-based measures. In this
paper, we focus on another approach, which consists in measuring the
sensitivity of stock prices with respect to a carbon risk factor. In our
opinion, carbon betas are market-based measures that are complementary to
carbon intensities or fundamental-based measures when managing investment
portfolios, because carbon betas may be viewed as an extension or
forward-looking measure of the current carbon footprint. In particular, we show
how this new metric can be used to build minimum variance strategies and how
they impact their portfolio construction.
"
2101.12387,2021-02-01,A deep learning algorithm for optimal investment strategies,"  This paper treats the Merton problem how to invest in safe assets and risky
assets to maximize an investor's utility, given by investment opportunities
modeled by a $d$-dimensional state process. The problem is represented by a
partial differential equation with optimizing term: the Hamilton-Jacobi-Bellman
equation. The main purpose of this paper is to solve partial differential
equations derived from the Hamilton-Jacobi-Bellman equations with a deep
learning algorithm: the Deep Galerkin method, first suggested by Sirignano and
Spiliopoulos (2018). We then apply the algorithm to get the solution of the PDE
based on some model settings and compare with the one from the finite
difference method.
"
2102.03502,2022-02-22,"MSPM: A Modularized and Scalable Multi-Agent Reinforcement
  Learning-based System for Financial Portfolio Management","  Financial portfolio management (PM) is one of the most applicable problems in
reinforcement learning (RL) owing to its sequential decision-making nature.
However, existing RL-based approaches rarely focus on scalability or
reusability to adapt to the ever-changing markets. These approaches are rigid
and unscalable to accommodate the varying number of assets of portfolios and
increasing need for heterogeneous data. Also, RL agents in the existing systems
are ad-hoc trained and hardly reusable for different portfolios. To confront
the above problems, a modular design is desired for the systems to be
compatible with reusable asset-dedicated agents. In this paper, we propose a
multi-agent RL-based system for PM (MSPM). MSPM involves two types of
asynchronously-updated modules: Evolving Agent Module (EAM) and Strategic Agent
Module (SAM). An EAM is an information-generating module with a DQN agent, and
it receives heterogeneous data and generates signal-comprised information for a
particular asset. An SAM is a decision-making module with a PPO agent for
portfolio optimization, and it connects to EAMs to reallocate the assets in a
portfolio. Trained EAMs can be connected to any SAM at will. With its
modularized architecture, the multi-step condensation of volatile market
information, and the reusable design of EAM, MSPM simultaneously addresses the
two challenges in RL-based PM: scalability and reusability. Experiments on
8-year U.S. stock market data prove the effectiveness of MSPM in profit
accumulation by its outperformance over five baselines in terms of accumulated
rate of return (ARR), daily rate of return, and Sortino ratio. MSPM improves
ARR by at least 186.5% compared to CRP, a widely-used PM strategy. To validate
the indispensability of EAM, we back-test and compare MSPMs on four portfolios.
EAM-enabled MSPMs improve ARR by at least 1341.8% compared to EAM-disabled
MSPMs.
"
2102.05398,2021-02-11,FRM Financial Risk Meter for Emerging Markets,"  The fast-growing Emerging Market (EM) economies and their improved
transparency and liquidity have attracted international investors. However, the
external price shocks can result in a higher level of volatility as well as
domestic policy instability. Therefore, an efficient risk measure and hedging
strategies are needed to help investors protect their investments against this
risk. In this paper, a daily systemic risk measure, called FRM (Financial Risk
Meter) is proposed. The FRM-EM is applied to capture systemic risk behavior
embedded in the returns of the 25 largest EMs FIs, covering the BRIMST (Brazil,
Russia, India, Mexico, South Africa, and Turkey), and thereby reflects the
financial linkages between these economies. Concerning the Macro factors, in
addition to the Adrian and Brunnermeier (2016) Macro, we include the EM
sovereign yield spread over respective US Treasuries and the above-mentioned
countries currencies. The results indicated that the FRM of EMs FIs reached its
maximum during the US financial crisis following by COVID 19 crisis and the
Macro factors explain the BRIMST FIs with various degrees of sensibility. We
then study the relationship between those factors and the tail event network
behavior to build our policy recommendations to help the investors to choose
the suitable market for in-vestment and tail-event optimized portfolios. For
that purpose, an overlapping region between portfolio optimization strategies
and FRM network centrality is developed. We propose a robust and
well-diversified tail-event and cluster risk-sensitive portfolio allocation
model and compare it to more classical approaches
"
2102.06233,2021-02-15,"Deep Reinforcement Learning for Portfolio Optimization using Latent
  Feature State Space (LFSS) Module","  Dynamic Portfolio optimization is the process of distribution and rebalancing
of a fund into different financial assets such as stocks, cryptocurrencies,
etc, in consecutive trading periods to maximize accumulated profits or minimize
risks over a time horizon. This field saw huge developments in recent years,
because of the increased computational power and increased research in
sequential decision making through control theory. Recently Reinforcement
Learning(RL) has been an important tool in the development of sequential and
dynamic portfolio optimization theory. In this paper, we design a Deep
Reinforcement Learning(DRL) framework as an autonomous portfolio optimization
agent consisting of a Latent Feature State Space(LFSS) Module for filtering and
feature extraction of financial data which is used as a state space for deep RL
model. We develop an extensive RL agent with high efficiency and performance
advantages over several benchmarks and model-free RL agents used in prior work.
The noisy and non-stationary behaviour of daily asset prices in the financial
market is addressed through Kalman Filter. Autoencoders, ZoomSVD, and
restricted Boltzmann machines were the models used and compared in the module
to extract relevant time series features as state space. We simulate weekly
data, with practical constraints and transaction costs, on a portfolio of S&P
500 stocks. We introduce a new benchmark based on technical indicator Kd-Index
and Mean-Variance Model as compared to equal weighted portfolio used in most of
the prior work. The study confirms that the proposed RL portfolio agent with
state space function in the form of LFSS module gives robust results with an
attractive performance profile over baseline RL agents and given benchmarks.
"
2102.09287,2022-12-01,Integrating prediction in mean-variance portfolio optimization,"  Prediction models are traditionally optimized independently from their use in
the asset allocation decision-making process. We address this shortcoming and
present a framework for integrating regression prediction models in a
mean-variance optimization (MVO) setting. Closed-form analytical solutions are
provided for the unconstrained and equality constrained MVO case. For the
general inequality constrained case, we make use of recent advances in
neural-network architecture for efficient optimization of batch
quadratic-programs. To our knowledge, this is the first rigorous study of
integrating prediction in a mean-variance portfolio optimization setting. We
present several historical simulations using both synthetic and global futures
data to demonstrate the benefits of the integrated approach.
"
2102.10691,2021-06-01,"Climate Change Valuation Adjustment (CCVA) using parameterized climate
  change impacts","  We introduce Climate Change Valuation Adjustment (CCVA) to capture climate
change impacts on CVA+FVA that are currently invisible assuming typical market
practice. To discuss such impacts on CVA+FVA from changes to instantaneous
hazard rates we introduce a flexible and expressive parameterization to capture
the path of this impact to climate change endpoints, and transient transition
effects. Finally we provide quantification of examples of typical interest
where there is risk of economic stress from sea level change up to 2101, and
from transformations of business models. We find that even with the slowest
possible uniform approach to a climate change impact in 2101 there can still be
significant CVA+FVA impacts on interest rate swaps of 20 years or more
maturity. Transformation effects on CVA+FVA are strongly dependent on timing
and duration of business model transformation. Using a parameterized approach
enables discussion with stakeholders of economic impacts on CVA+FVA, whatever
the details behind the climate impact.
"
2102.12601,2021-02-26,"Optimal Dynamic Futures Portfolios Under a Multiscale Central Tendency
  Ornstein-Uhlenbeck Model","  We study the problem of dynamically trading multiple futures whose underlying
asset price follows a multiscale central tendency Ornstein-Uhlenbeck (MCTOU)
model. Under this model, we derive the closed-form no-arbitrage prices for the
futures contracts. Applying a utility maximization approach, we solve for the
optimal trading strategies under different portfolio configurations by
examining the associated system of Hamilton-Jacobi-Bellman (HJB) equations. The
optimal strategies depend on not only the parameters of the underlying asset
price process but also the risk premia embedded in the futures prices.
Numerical examples are provided to illustrate the investor's optimal positions
and optimal wealth over time.
"
2102.12783,2022-02-17,"Next Generation Models for Portfolio Risk Management: An Approach Using
  Financial Big Data","  This paper proposes a dynamic process of portfolio risk measurement to
address potential information loss. The proposed model takes advantage of
financial big data to incorporate out-of-target-portfolio information that may
be missed when one considers the Value at Risk (VaR) measures only from certain
assets of the portfolio. We investigate how the curse of dimensionality can be
overcome in the use of financial big data and discuss where and when benefits
occur from a large number of assets. In this regard, the proposed approach is
the first to suggest the use of financial big data to improve the accuracy of
risk analysis. We compare the proposed model with benchmark approaches and
empirically show that the use of financial big data improves small portfolio
risk analysis. Our findings are useful for portfolio managers and financial
regulators, who may seek for an innovation to improve the accuracy of portfolio
risk estimation.
"
2103.01123,2021-03-03,"A combinatorial optimization approach to scenario filtering in portfolio
  selection","  Recent studies stressed the fact that covariance matrices computed from
empirical financial time series appear to contain a high amount of noise. This
makes the classical Markowitz Mean-Variance Optimization model unable to
correctly evaluate the performance associated to selected portfolios. Since the
Markowitz model is still one of the most used practitioner-oriented tool,
several filtering methods have been proposed in the literature to fix the
problem. Among them, the two most promising ones refer to the Random Matrix
Theory or to the Power Mapping strategy. The basic idea of these methods is to
transform the correlation matrix maintaining the Mean-Variance Optimization
model. However, experimental analysis shows that these two strategies are not
adequately effective when applied to real financial datasets.
  In this paper we propose an alternative filtering method based on
Combinatorial Optimization. We advance a new Mixed Integer Quadratic
Programming model to filter those observations that may influence the
performance of a portfolio in the future. We discuss the properties of this new
model and we test it on some real financial datasets. We compare the
out-of-sample performance of our portfolios with the one of the portfolios
provided by the two above mentioned alternative strategies. We show that our
method outperforms them. Although our model can be solved efficiently with
standard optimization solvers the computational burden increases for large
datasets. To overcome this issue we also propose a heuristic procedure that
empirically showed to be both efficient and effective.
"
2103.01775,2023-10-10,"No-Transaction Band Network: A Neural Network Architecture for Efficient
  Deep Hedging","  Deep hedging (Buehler et al. 2019) is a versatile framework to compute the
optimal hedging strategy of derivatives in incomplete markets. However, this
optimal strategy is hard to train due to action dependence, that is, the
appropriate hedging action at the next step depends on the current action. To
overcome this issue, we leverage the idea of a no-transaction band strategy,
which is an existing technique that gives optimal hedging strategies for
European options and the exponential utility. We theoretically prove that this
strategy is also optimal for a wider class of utilities and derivatives
including exotics. Based on this result, we propose a no-transaction band
network, a neural network architecture that facilitates fast training and
precise evaluation of the optimal hedging strategy. We experimentally
demonstrate that for European and lookback options, our architecture quickly
attains a better hedging strategy in comparison to a standard feed-forward
network.
"
2103.03275,2022-04-12,The Climate Extended Risk Model (CERM),"  This paper addresses estimates of climate risk embedded within a bank credit
portfolio. The proposed Climate Extended Risk Model (CERM) adapts well known
credit risk models and makes it possible to calculate incremental credit losses
on a loan portfolio that are rooted into physical and transition risks. The
paper provides detailed description of the model hypotheses and steps.
"
2103.04375,2021-05-05,"Optimizing Expected Shortfall under an $\ell_1$ constraint -- an
  analytic approach","  Expected Shortfall (ES), the average loss above a high quantile, is the
current financial regulatory market risk measure. Its estimation and
optimization are highly unstable against sample fluctuations and become
impossible above a critical ratio $r=N/T$, where $N$ is the number of different
assets in the portfolio, and $T$ is the length of the available time series.
The critical ratio depends on the confidence level $\alpha$, which means we
have a line of critical points on the $\alpha-r$ plane. The large fluctuations
in the estimation of ES can be attenuated by the application of regularizers.
In this paper, we calculate ES analytically under an $\ell_1$ regularizer by
the method of replicas borrowed from the statistical physics of random systems.
The ban on short selling, i.e. a constraint rendering all the portfolio weights
non-negative, is a special case of an asymmetric $\ell_1$ regularizer. Results
are presented for the out-of-sample and the in-sample estimator of the
regularized ES, the estimation error, the distribution of the optimal portfolio
weights and the density of the assets eliminated from the portfolio by the
regularizer. It is shown that the no-short constraint acts as a high volatility
cutoff, in the sense that it sets the weights of the high volatility elements
to zero with higher probability than those of the low volatility items. This
cutoff renormalizes the aspect ratio $r=N/T$, thereby extending the range of
the feasibility of optimization. We find that there is a nontrivial mapping
between the regularized and unregularized problems, corresponding to a
renormalization of the order parameters.
"
2103.04432,2021-03-09,Portfolio Optimization Constrained by Performance Attribution,"  This paper investigates performance attribution measures as a basis for
constraining portfolio optimization. We employ optimizations that minimize
expected tail loss and investigate both asset allocation (AA) and the selection
effect (SE) as hard constraints on asset weights. The test portfolio consists
of stocks from the Dow Jones Industrial Average index; the benchmark is an
equi-weighted portfolio of the same stocks. Performance of the optimized
portfolios is judged using comparisons of cumulative price and the
risk-measures maximum drawdown, Sharpe ratio, and Rachev ratio. The results
suggest a positive role in price and risk-measure performance for the
imposition of constraints on AA and SE, with SE constraints producing the
larger performance enhancement.
"
2103.04898,2023-03-22,On Asymptotic Log-Optimal Buy-and-Hold Strategy,"  In this paper, we consider a frequency-based portfolio optimization problem
with $m \geq 2$ assets when the expected logarithmic growth (ELG) rate of
wealth is used as the performance metric. With the aid of the notion called
dominant asset, it is known that the optimal ELG level is achieved by investing
all available funds on that asset. However, such an ""all-in"" strategy is
arguably too risky to implement in practice. Motivated by this issue, we study
the case where the portfolio weights are chosen in a rather ad-hoc manner and a
buy-and-hold strategy is subsequently used. Then we show that, if the
underlying portfolio contains a dominant asset, buy and hold on that specific
asset is asymptotically log-optimal with a sublinear rate of convergence. This
result also extends to the scenario where a trader either does not have a
probabilistic model for the returns or does not trust a model obtained from
historical data. To be more specific, we show that if a market contains a
dominant asset, buy and hold a market portfolio involving nonzero weights for
each asset is asymptotically log-optimal. Additionally, this paper also
includes a conjecture regarding the property called high-frequency maximality.
That is, in the absence of transaction costs, high-frequency rebalancing is
unbeatable in the ELG sense. Support for the conjecture, involving a lemma for
a weak version of the conjecture, is provided. This conjecture, if true,
enables us to improve the log-optimality result obtained previously. Finally, a
result that indicates a way regarding an issue about when should one to
rebalance their portfolio if needed, is also provided. Examples, some involving
simulations with historical data, are also provided along the way to illustrate
the~theory.
"
2103.05455,2022-07-04,Portfolio Construction as Linearly Constrained Separable Optimization,"  Mean-variance portfolio optimization problems often involve separable
nonconvex terms, including penalties on capital gains, integer share
constraints, and minimum position and trade sizes. We propose a heuristic
algorithm for such problems based on the alternating direction method of
multipliers (ADMM). This method allows for solve times in tens to hundreds of
milliseconds with around 1000 securities and 100 risk factors. We also obtain a
bound on the achievable performance. Our heuristic and bound are both derived
from similar results for other optimization problems with a separable objective
and affine equality constraints. We discuss a concrete implementation in the
case where the separable terms in the objective are piecewise quadratic, and we
empirically demonstrate its effectiveness for tax-aware portfolio construction.
"
2103.05777,2023-11-14,"Bayesian optimal investment and reinsurance with dependent financial and
  insurance risks","  Major events like natural catastrophes or the COVID-19 crisis have impact
both on the financial market and on claim arrival intensities and claim sizes
of insurers. Thus, when optimal investment and reinsurance strategies have to
be determined it is important to consider models which reflect this dependence.
In this paper we make a proposal how to generate dependence between the
financial market and claim sizes in times of crisis and determine via a
stochastic control approach an optimal investment and reinsurance strategy
which maximizes the expected exponential utility of terminal wealth. Moreover,
we also allow that the claim size distribution may be learned in the model. We
give comparisons and bounds on the optimal strategy using simple models. What
turns out to be very surprising is that numerical results indicate that even a
minimal dependence which is created in this model has a huge impact on the
control in the sense that the insurer is much more prudent then.
"
2103.05880,2022-03-08,"A Bayesian Graphical Approach for Large-Scale Portfolio Management with
  Fewer Historical Data","  Managing a large-scale portfolio with many assets is one of the most
challenging tasks in the field of finance. It is partly because estimation of
either covariance or precision matrix of asset returns tends to be unstable or
even infeasible when the number of assets $p$ exceeds the number of
observations $n$. For this reason, most of the previous studies on portfolio
management have focused on the case of$ p < n$. To deal with the case of $p >
n$, we propose to use a new Bayesian framework based on adaptive graphical
LASSO for estimating the precision matrix of asset returns in a large-scale
portfolio. Unlike the previous studies on graphical LASSO in the literature,
our approach utilizes a Bayesian estimation method for the precision matrix
proposed by Oya and Nakatsuma (2022) so that the positive definiteness of the
precision matrix should be always guaranteed. As an empirical application, we
construct the global minimum variance portfolio of $p = 100$ for various values
of n with the proposed approach as well as the non-Bayesian graphical LASSO
approach, and compare their out-of-sample performance with the equal weight
portfolio as the benchmark. In this comparison, the proposed approach produces
more stable results than the non-Bayesian approach in terms of Sharpe ratio,
portfolio composition and turnover. Furthermore, the proposed approach succeeds
in estimating the precision matrix even if $n$ is much smaller than $p$ and the
non-Bayesian approach fails to do so.
"
2103.09987,2021-03-19,Statistical Arbitrage Risk Premium by Machine Learning,"  How to hedge factor risks without knowing the identities of the factors? We
first prove a general theoretical result: even if the exact set of factors
cannot be identified, any risky asset can use some portfolio of similar peer
assets to hedge against its own factor exposures. A long position of a risky
asset and a short position of a ""replicate portfolio"" of its peers represent
that asset's factor residual risk. We coin the expected return of an asset's
factor residual risk as its Statistical Arbitrage Risk Premium (SARP). The
challenge in empirically estimating SARP is finding the peers for each asset
and constructing the replicate portfolios. We use the elastic-net, a machine
learning method, to project each stock's past returns onto that of every other
stock. The resulting high-dimensional but sparse projection vector serves as
investment weights in constructing the stocks' replicate portfolios. We say a
stock has high (low) Statistical Arbitrage Risk (SAR) if it has low (high)
R-squared with its peers. The key finding is that ""unique"" stocks have both a
higher SARP and higher excess returns than ""ubiquitous"" stocks: in the
cross-section, high SAR stocks have a monthly SARP (monthly excess returns)
that is 1.101% (0.710%) greater than low SAR stocks. The average SAR across all
stocks is countercyclical. Our results are robust to controlling for various
known priced factors and characteristics.
"
2103.10813,2021-03-22,"Multi-Period Portfolio Optimization using Model Predictive Control with
  Mean-Variance and Risk Parity Frameworks","  We employ model predictive control for a multi-period portfolio optimization
problem. In addition to the mean-variance objective, we construct a portfolio
whose allocation is given by model predictive control with a risk-parity
objective, and provide a successive convex program algorithm that provides 30
times faster and robust solutions in the experiments. Computational results on
the multi-asset universe show that multi-period models perform better than
their single period counterparts in out-of-sample period, 2006-2020. The
out-of-sample risk-adjusted performance of both mean-variance and risk-parity
formulations beat the fix-mix benchmark, and achieve Sharpe ratio of 0.64 and
0.97, respectively.
"
2103.10925,2021-10-12,Functional portfolio optimization in stochastic portfolio theory,"  In this paper we develop a concrete and fully implementable approach to the
optimization of functionally generated portfolios in stochastic portfolio
theory. The main idea is to optimize over a family of rank-based portfolios
parameterized by an exponentially concave function on the unit interval. This
choice can be motivated by the long term stability of the capital distribution
observed in large equity markets, and allows us to circumvent the curse of
dimensionality. The resulting optimization problem, which is convex, allows for
various regularizations and constraints to be imposed on the generating
function. We prove an existence and uniqueness result for our optimization
problem and provide a stability estimate in terms of a Wasserstein metric of
the input measure. Then, we formulate a discretization which can be implemented
numerically using available software packages and analyze its approximation
error. Finally, we present empirical examples using CRSP data from the US stock
market, including the performance of the portfolios allowing for dividends,
defaults, and transaction costs.
"
2103.10958,2021-03-23,Multicriteria asset allocation in practice,"  In this paper we consider the strategic asset allocation of an insurance
company. This task can be seen as a special case of portfolio optimization. In
the 1950s, Markowitz proposed to formulate portfolio optimization as a
bicriteria optimization problem considering risk and return as objectives.
However, recent developments in the field of insurance require four and more
objectives to be considered, among them the so-called solvency ratio that stems
from the Solvency II directive of the European Union issued in 2009. Moreover,
the distance to the current portfolio plays an important role. While literature
on portfolio optimization with three objectives is already scarce, applications
with four and more objectives have not yet been solved so far by
multi-objective approaches based on scalarizations. However, recent algorithmic
improvements in the field of exact multi-objective methods allow the
incorporation of many objectives and the generation of well-spread
representations within few iterations. We describe the implementation of such
an algorithm for a strategic asset allocation with four objective functions and
demonstrate its usefulness for the practitioner. Our approach is in operative
use in a German insurance company. Our partners report a significant
improvement in their decision making process since, due to the proper
integration of the new objectives, the software proposes portfolios of much
better quality than before within short running time.
"
2103.10989,2021-03-23,"Risk aggregation and capital allocation using a new generalized
  Archimedean copula","  In this paper, we address risk aggregation and capital allocation problems in
the presence of dependence between risks. The dependence structure is defined
by a mixed Bernstein copula which represents a generalization of the well-known
Archimedean copulas. Using this new copula, the probability density function
and the cumulative distribution function of the aggregate risk are obtained.
Then, closed-form expressions for basic risk measures, such as tail
value-at-risk(TVaR) and TVaR-based allocations, are derived.
"
2103.11455,2021-03-23,"A Deep Deterministic Policy Gradient-based Strategy for Stocks Portfolio
  Management","  With the improvement of computer performance and the development of
GPU-accelerated technology, trading with machine learning algorithms has
attracted the attention of many researchers and practitioners. In this
research, we propose a novel portfolio management strategy based on the
framework of Deep Deterministic Policy Gradient, a policy-based reinforcement
learning framework, and compare its performance to that of other trading
strategies. In our framework, two Long Short-Term Memory neural networks and
two fully connected neural networks are constructed. We also investigate the
performance of our strategy with and without transaction costs. Experimentally,
we choose eight US stocks consisting of four low-volatility stocks and four
high-volatility stocks. We compare the compound annual return rate of our
strategy against seven other strategies, e.g., Uniform Buy and Hold,
Exponential Gradient and Universal Portfolios. In our case, the compound annual
return rate is 14.12%, outperforming all other strategies. Furthermore, in
terms of Sharpe Ratio (0.5988), our strategy is nearly 33% higher than that of
the second-best performing strategy.
"
2103.12345,2021-03-24,The Success of AdaBoost and Its Application in Portfolio Management,"  We develop a novel approach to explain why AdaBoost is a successful
classifier. By introducing a measure of the influence of the noise points (ION)
in the training data for the binary classification problem, we prove that there
is a strong connection between the ION and the test error. We further identify
that the ION of AdaBoost decreases as the iteration number or the complexity of
the base learners increases. We confirm that it is impossible to obtain a
consistent classifier without deep trees as the base learners of AdaBoost in
some complicated situations. We apply AdaBoost in portfolio management via
empirical studies in the Chinese market, which corroborates our theoretical
propositions.
"
2103.13806,2022-01-13,Robust Portfolio Selection Problems: A Comprehensive Review,"  In this paper, we provide a comprehensive review of recent advances in robust
portfolio selection problems and their extensions, from both operational
research and financial perspectives. A multi-dimensional classification of the
models and methods proposed in the literature is presented, based on the types
of financial problems, uncertainty sets, robust optimization approaches, and
mathematical formulations. Several open questions and potential future research
directions are identified.
"
2103.14506,2021-08-16,Asset Selection via Correlation Blockmodel Clustering,"  We aim to cluster financial assets in order to identify a small set of stocks
to approximate the level of diversification of the whole universe of stocks. We
develop a data-driven approach to clustering based on a correlation blockmodel
in which assets in the same cluster are highly correlated with each other and,
at the same time, have the same correlations with all other assets. We devise
an algorithm to detect the clusters, with theoretical analysis and practical
guidance. Finally, we conduct an empirical analysis to verify the performance
of the algorithm.
"
2103.15232,2021-03-30,Portfolio Optimization with Sparse Multivariate Modelling,"  Portfolio optimization approaches inevitably rely on multivariate modeling of
markets and the economy. In this paper, we address three sources of error
related to the modeling of these complex systems: 1. oversimplifying
hypothesis; 2. uncertainties resulting from parameters' sampling error; 3.
intrinsic non-stationarity of these systems. For what concerns point 1. we
propose a L0-norm sparse elliptical modeling and show that sparsification is
effective. The effects of points 2. and 3. are quantifified by studying the
models' likelihood in- and out-of-sample for parameters estimated over train
sets of different lengths. We show that models with larger off-sample
likelihoods lead to better performing portfolios up to when two to three years
of daily observations are included in the train set. For larger train sets, we
found that portfolio performances deteriorate and detach from the models'
likelihood, highlighting the role of non-stationarity. We further investigate
this phenomenon by studying the out-of-sample likelihood of individual
observations showing that the system changes significantly through time. Larger
estimation windows lead to stable likelihood in the long run, but at the cost
of lower likelihood in the short-term: the `optimal' fit in finance needs to be
defined in terms of the holding period. Lastly, we show that sparse models
outperform full-models in that they deliver higher out of sample likelihood,
lower realized portfolio volatility and improved portfolios' stability,
avoiding typical pitfalls of the Mean-Variance optimization.
"
2103.16451,2024-04-10,Robustifying Conditional Portfolio Decisions via Optimal Transport,"  We propose a data-driven portfolio selection model that integrates side
information, conditional estimation and robustness using the framework of
distributionally robust optimization. Conditioning on the observed side
information, the portfolio manager solves an allocation problem that minimizes
the worst-case conditional risk-return trade-off, subject to all possible
perturbations of the covariate-return probability distribution in an optimal
transport ambiguity set. Despite the non-linearity of the objective function in
the probability measure, we show that the distributionally robust portfolio
allocation with side information problem can be reformulated as a
finite-dimensional optimization problem. If portfolio decisions are made based
on either the mean-variance or the mean-Conditional Value-at-Risk criterion,
the resulting reformulation can be further simplified to second-order or
semi-definite cone programs. Empirical studies in the US equity market
demonstrate the advantage of our integrative framework against other
benchmarks.
"
2103.16800,2021-04-01,"Optimal Retirement Time and Consumption with the Variation in Habitual
  Persistence","  In this paper,we study the individual's optimal retirement time and optimal
consumption under habitual persistence. Because the individual feels equally
satisfied with a lower habitual level and is more reluctant to change the
habitual level after retirement, we assume that both the level and the
sensitivity of the habitual consumption decline at the time of retirement. We
establish the concise form of the habitual evolutions, and obtain the optimal
retirement time and consumption policy based on martingale and duality methods.
The optimal consumption experiences a sharp decline at retirement, but the
excess consumption raises because of the reduced sensitivity of the habitual
level. This result contributes to explain the ""retirement consumption puzzle"".
Particularly, the optimal retirement and consumption policies are balanced
between the wealth effect and the habitual effect. Larger wealth increases
consumption, and larger growth inertia (sensitivity) of the habitual level
decreases consumption and brings forward the retirement time.
"
2104.00446,2021-04-02,Optimal Fees for Geometric Mean Market Makers,"  Constant Function Market Makers (CFMMs) are a family of automated market
makers that enable censorship-resistant decentralized exchange on public
blockchains. Arbitrage trades have been shown to align the prices reported by
CFMMs with those of external markets. These trades impose costs on Liquidity
Providers (LPs) who supply reserves to CFMMs. Trading fees have been proposed
as a mechanism for compensating LPs for arbitrage losses. However, large fees
reduce the accuracy of the prices reported by CFMMs and can cause reserves to
deviate from desirable asset compositions. CFMM designers are therefore faced
with the problem of how to optimally select fees to attract liquidity. We
develop a framework for determining the value to LPs of supplying liquidity to
a CFMM with fees when the underlying process follows a general diffusion.
Focusing on a popular class of CFMMs which we call Geometric Mean Market Makers
(G3Ms), our approach also allows one to select optimal fees for maximizing LP
value. We illustrate our methodology by showing that an LP with mean-variance
utility will prefer a G3M over all alternative trading strategies as fees
approach zero.
"
2104.00668,2021-10-22,A new spin on optimal portfolios and ecological equilibria,"  We consider the classical problem of optimal portfolio construction with the
constraint that no short position is allowed, or equivalently the valid
equilibria of multispecies Lotka-Volterra equations with self-regulation in the
special case where the interaction matrix is of unit rank, corresponding to
species competing for a common resource. We compute the average number of
solutions and show that its logarithm grows as $N^\alpha$, where $N$ is the
number of assets or species and $\alpha \leq 2/3$ depends on the interaction
matrix distribution. We conjecture that the most likely number of solutions is
much smaller and related to the typical sparsity $m(N)$ of the solutions, which
we compute explicitly. We also find that the solution landscape is similar to
that of spin-glasses, i.e. very different configurations are quasi-degenerate.
Correspondingly, ""disorder chaos"" is also present in our problem. We discuss
the consequence of such a property for portfolio construction and ecologies,
and question the meaning of rational decisions when there is a very large
number ""satisficing"" solutions.
"
2104.00911,2021-04-05,"Influence of risk tolerance on long-term investments: A Malliavin
  calculus approach","  This study investigates the influence of risk tolerance on the expected
utility in the long run. We estimate the extent to which the expected utility
of optimal portfolios is affected by small changes in the risk tolerance. For
this purpose, we adopt the Malliavin calculus method and the Hansen--Scheinkman
decomposition, through which the expected utility is expressed in terms of the
eigenvalues and eigenfunctions of an operator. We conclude that the influence
of risk aversion on the expected utility is determined by these eigenvalues and
eigenfunctions in the long run.
"
2104.02694,2021-05-04,"Merton Investment Problems in Finance and Insurance for the Hawkes-based
  Models","  We show how to solve Merton optimal investment stochastic control problem for
Hawkes-based models in finance and insurance, i.e., for a wealth portfolio X(t)
consisting of a bond and a stock price described by general compound Hawkes
process (GCHP), and for a capital R(t) of an insurance company with the amount
of claims described by the risk model based on GCHP. The novelty of the results
consists of the new Hawkes-based models and in the new optimal investment
results in finance and insurance for those models.
"
2104.05844,2021-04-14,Time is Money: The Equilibrium Trading Horizon and Optimal Arrival Price,"  Executing even moderately large derivatives orders can be expensive and
risky; it's hard to balance the uncertainty of working an order over time
versus paying a liquidity premium for immediate execution. Here, we introduce
the Time Is Money model, which calculates the Equilibrium Trading Horizon over
which to execute an order within the adversarial forces of variance risk and
liquidity premium. We construct a hypothetical at-the-money option within
Arithmetic Brownian Motion and invert the Bachelier model to compute an
inflection point between implied variance and liquidity cost as governed by a
central limit order book, each in real time as they evolve. As a result, we
demonstrate a novel, continuous-time Arrival Price framework. Further, we argue
that traders should be indifferent to choosing between variance risk and
liquidity cost, unless they have a predetermined bias or an exogenous position
with a convex payoff. We, therefore, introduce half-life factor asymptotics to
the model based on a convexity factor and compare results to existing models.
We also describe a specialization of the model for trading a basket of
correlated instruments, as exemplified by a futures calendar spread. Finally,
we establish groundwork for microstructure optimizations as well as explore
short term drift and conditional expected slippage within the Equilibrium
Horizon framework.
"
2104.06293,2022-01-26,"Analysis of optimal portfolio on finite and small time horizons for a
  stochastic volatility market model","  In this paper, we consider the portfolio optimization problem in a financial
market under a general utility function. Empirical results suggest that if a
significant market fluctuation occurs, invested wealth tends to have a notable
change from its current value. We consider an incomplete stochastic volatility
market model, that is driven by both a Brownian motion and a jump process. At
first, we obtain a closed-form formula for an approximation to the optimal
portfolio in a small-time horizon. This is obtained by finding the associated
Hamilton-Jacobi-Bellman integro-differential equation and then approximating
the value function by constructing appropriate super-solution and sub-solution.
It is shown that the true value function can be obtained by sandwiching the
constructed super-solution and sub-solution. We also prove the accuracy of the
approximation formulas. Finally, we provide a procedure for generating a
close-to-optimal portfolio for a finite time horizon.
"
2104.07976,2022-05-20,Power-law Portfolios,"  Portfolio optimization methods suffer from a catalogue of known problems,
mainly due to the facts that pair correlations of asset returns are unstable,
and that extremal risk measures such as maximum drawdown are difficult to
predict due to the non-Gaussianity of portfolio returns. \\ In order to look at
optimal portfolios for arbitrary risk penalty functions, we construct portfolio
shapes where the penalty is proportional to a moment of the returns of
arbitrary order $p>2$. \\ The resulting component weight in the portfolio
scales sub-linearly with its return, with the power-law $w \propto
\mu^{1/(p-1)}$. This leads to significantly improved diversification when
compared to Kelly portfolios, due to the dilution of the winner-takes-all
effect.\\ In the limit of penalty order $p\rightarrow\infty$, we recover the
simple trading heuristic whereby assets are allocated a fixed positive weight
when their return exceeds the hurdle rate, and zero otherwise. Infinite order
power-law portfolios thus fall into the class of perfectly diversified
portfolios.
"
2104.08956,2021-04-20,On the Investment Strategies in Occupational Pension Plans,"  Demographic changes increase the necessity to base the pension system more
and more on the second and the third pillar, namely the occupational and
private pension plans; this paper deals with Target Date Funds (TDFs), which
are a typical investment opportunity for occupational pension planners. TDFs
are usually identified with a decreasing fraction of wealth invested in equity
(a so-called glide path) as retirement comes closer, i.e., wealth is invested
more risky the younger the saver is. We investigate whether this is actually
optimal in the presence of non-tradable income risk in a stochastic volatility
environment. The retirement planning procedure is formulated as a stochastic
optimization problem. We find it is the (random) contributions that induce the
optimal path exhibiting a glide path structure, both in the constant and
stochastic volatility environment. Moreover, the initial wealth and the initial
contribution made to a retirement account strongly influence the fractional
amount of wealth to be invested in risky assets. The risk aversion of an
individual mainly determines the steepness of the glide path.
"
2104.09700,2021-04-21,"Stock Market Trend Analysis Using Hidden Markov Model and Long Short
  Term Memory","  This paper intends to apply the Hidden Markov Model into stock market and and
make predictions. Moreover, four different methods of improvement, which are
GMM-HMM, XGB-HMM, GMM-HMM+LSTM and XGB-HMM+LSTM, will be discussed later with
the results of experiment respectively. After that we will analyze the pros and
cons of different models. And finally, one of the best will be used into stock
market for timing strategy.
"
2104.09988,2021-07-06,"Inferring Multi-Period Optimal Portfolios via Detrending Moving Average
  Cluster Entropy","  Despite half a century of research, there is still no general agreement about
the optimal approach to build a robust multi-period portfolio. We address this
question by proposing the detrended cluster entropy approach to estimate the
portfolio weights of high-frequency market indices. The information measure
produces reliable estimates of the portfolio weights gathered from the
real-world market data at varying temporal horizons. The portfolio exhibits a
high level of diversity, robustness and stability as it is not affected by the
drawbacks of traditional mean-variance approaches.
"
2104.10483,2021-04-23,"Adaptive learning for financial markets mixing model-based and
  model-free RL for volatility targeting","  Model-Free Reinforcement Learning has achieved meaningful results in stable
environments but, to this day, it remains problematic in regime changing
environments like financial markets. In contrast, model-based RL is able to
capture some fundamental and dynamical concepts of the environment but suffer
from cognitive bias. In this work, we propose to combine the best of the two
techniques by selecting various model-based approaches thanks to Model-Free
Deep Reinforcement Learning. Using not only past performance and volatility, we
include additional contextual information such as macro and risk appetite
signals to account for implicit regime changes. We also adapt traditional RL
methods to real-life situations by considering only past data for the training
sets. Hence, we cannot use future information in our training data set as
implied by K-fold cross validation. Building on traditional statistical
methods, we use the traditional ""walk-forward analysis"", which is defined by
successive training and testing based on expanding periods, to assert the
robustness of the resulting agent.
  Finally, we present the concept of statistical difference's significance
based on a two-tailed T-test, to highlight the ways in which our models differ
from more traditional ones. Our experimental results show that our approach
outperforms traditional financial baseline portfolio models such as the
Markowitz model in almost all evaluation metrics commonly used in financial
mathematics, namely net performance, Sharpe and Sortino ratios, maximum
drawdown, maximum drawdown over volatility.
"
2104.11594,2021-04-26,"Dynamic investment portfolio optimization using a Multivariate Merton
  Model with Correlated Jump Risk","  In this paper, we are concerned with the optimization of a dynamic investment
portfolio when the securities which follow a multivariate Merton model with
dependent jumps are periodically invested and proceed by approximating the
Condition-Value-at-Risk (CVaR) by comonotonic bounds and maximize the expected
terminal wealth. Numerical studies as well as applications of our results to
real datasets are also provided.
"
2104.12484,2021-04-27,"Constructing long-short stock portfolio with a new listwise
  learn-to-rank algorithm","  Factor strategies have gained growing popularity in industry with the fast
development of machine learning. Usually, multi-factors are fed to an algorithm
for some cross-sectional return predictions, which are further used to
construct a long-short portfolio. Instead of predicting the value of the stock
return, emerging studies predict a ranked stock list using the mature
learn-to-rank technology. In this study, we propose a new listwise
learn-to-rank loss function which aims to emphasize both the top and the bottom
of a rank list. Our loss function, motivated by the long-short strategy, is
endogenously shift-invariant and can be viewed as a direct generalization of
ListMLE. Under different transformation functions, our loss can lead to
consistency with binary classification loss or permutation level 0-1 loss. A
probabilistic explanation for our model is also given as a generalized
Plackett-Luce model. Based on a dataset of 68 factors in China A-share market
from 2006 to 2019, our empirical study has demonstrated the strength of our
method which achieves an out-of-sample annual return of 38% with the Sharpe
ratio being 2.
"
2104.14204,2023-04-12,"Optimal bidding in hourly and quarter-hourly electricity price auctions:
  trading large volumes of power with market impact and transaction costs","  This paper addresses the question of how much to bid to maximize the profit
when trading in two electricity markets: the hourly Day-Ahead Auction and the
quarter-hourly Intraday Auction. For optimal coordinated bidding many price
scenarios are examined, the own non-linear market impact is estimated by
considering empirical supply and demand curves, and a number of trading
strategies is used. Additionally, we provide theoretical results for risk
neutral agents. The application study is conducted using the German market
data, but the presented methods can be easily utilized with other two
consecutive auctions. This paper contributes to the existing literature by
evaluating the costs of electricity trading, i.e. the price impact and the
transaction costs. The empirical results for the German EPEX market show that
it is far more profitable to minimize the price impact rather than maximize the
arbitrage.
"
2104.14683,2023-05-19,Deep Reinforcement Trading with Predictable Returns,"  Classical portfolio optimization often requires forecasting asset returns and
their corresponding variances in spite of the low signal-to-noise ratio
provided in the financial markets. Modern deep reinforcement learning (DRL)
offers a framework for optimizing sequential trader decisions but lacks
theoretical guarantees of convergence. On the other hand, the performances on
real financial trading problems are strongly affected by the goodness of the
signal used to predict returns. To disentangle the effects coming from return
unpredictability from those coming from algorithm un-trainability, we
investigate the performance of model-free DRL traders in a market environment
with different known mean-reverting factors driving the dynamics. When the
framework admits an exact dynamic programming solution, we can assess the
limits and capabilities of different value-based algorithms to retrieve
meaningful trading signals in a data-driven manner. We consider DRL agents that
leverage classical strategies to increase their performances and we show that
this approach guarantees flexibility, outperforming the benchmark strategy when
the price dynamics is misspecified and some original assumptions on the market
environment are violated with the presence of extreme events and volatility
clustering.
"
2105.04395,2021-07-02,Aspects of a phase transition in high-dimensional random geometry,"  A phase transition in high-dimensional random geometry is analyzed as it
arises in a variety of problems. A prominent example is the feasibility of a
minimax problem that represents the extremal case of a class of financial risk
measures, among them the current regulatory market risk measure Expected
Shortfall. Others include portfolio optimization with a ban on short selling,
the storage capacity of the perceptron, the solvability of a set of linear
equations with random coefficients, and competition for resources in an
ecological system. These examples shed light on various aspects of the
underlying geometric phase transition, create links between problems belonging
to seemingly distant fields and offer the possibility for further
ramifications.
"
2105.07524,2021-05-18,"Optimal Reinsurance and Investment under Common Shock Dependence Between
  Financial and Actuarial Markets","  We study optimal proportional reinsurance and investment strategies for an
insurance company which experiences both ordinary and catastrophic claims and
wishes to maximize the expected exponential utility of its terminal wealth. We
propose a model where the insurance framework is affected by environmental
factors, and aggregate claims and stock prices are subject to common shocks,
i.e. drastic events such as earthquakes, extreme weather conditions, or even
pandemics, that have an immediate impact on the financial market and
simultaneously induce insurance claims. Using the classical stochastic control
approach based on the Hamilton-Jacobi-Bellman equation, we provide a
verification result for the value function via classical solutions to two
backward partial differential equations and characterize the optimal
reinsurance and investment strategies. Finally, we make a comparison analysis
to discuss the effect of common shock dependence.
"
2105.08139,2021-07-23,Optimal Portfolio with Power Utility of Absolute and Relative Wealth,"  Portfolio managers often evaluate performance relative to benchmark, usually
taken to be the Standard & Poor 500 stock index fund. This relative portfolio
wealth is defined as the absolute portfolio wealth divided by wealth from
investing in the benchmark (including reinvested dividends). The classic Merton
problem for portfolio optimization considers absolute portfolio wealth. We
combine absolute and relative wealth in our new utility function. We also
consider the case of multiple benchmarks. To both absolute and relative wealth,
we apply power utility functions, possibly with different exponents. We obtain
an explicit solution and compare it to the classic Merton solution. We apply
our results to the Capital Asset Pricing Model setting.
"
2105.08377,2021-05-19,"Liquidity Stress Testing in Asset Management -- Part 2. Modeling the
  Asset Liquidity Risk","  This article is part of a comprehensive research project on liquidity risk in
asset management, which can be divided into three dimensions. The first
dimension covers liability liquidity risk (or funding liquidity) modeling, the
second dimension focuses on asset liquidity risk (or market liquidity)
modeling, and the third dimension considers the asset-liability management of
the liquidity gap risk (or asset-liability matching). The purpose of this
research is to propose a methodological and practical framework in order to
perform liquidity stress testing programs, which comply with regulatory
guidelines (ESMA, 2019, 2020) and are useful for fund managers. The review of
the academic literature and professional research studies shows that there is a
lack of standardized and analytical models. The aim of this research project is
then to fill the gap with the goal of developing mathematical and statistical
approaches, and providing appropriate answers.
  In this second article focused on asset liquidity risk modeling, we propose a
market impact model to estimate transaction costs. After presenting a toy model
that helps to understand the main concepts of asset liquidity, we consider a
two-regime model, which is based on the power-law property of price impact.
Then, we define several asset liquidity measures such as liquidity cost,
liquidation ratio and shortfall or time to liquidation in order to assess the
different dimensions of asset liquidity. Finally, we apply this asset liquidity
framework to stocks and bonds and discuss the issues of calibrating the
transaction cost model.
"
2105.09140,2021-09-02,Forecasting with fractional Brownian motion: a financial perspective,"  The fractional Brownian motion (fBm) extends the standard Brownian motion by
introducing some dependence between non-overlapping increments. Consequently,
if one considers for example that log-prices follow an fBm, one can exploit the
non-Markovian nature of the fBm to forecast future states of the process and
make statistical arbitrages. We provide new insights into forecasting an fBm,
by proposing theoretical formulas for accuracy metrics relevant to a systematic
trader, from the hit ratio to the expected gain and risk of a simple strategy.
In addition, we answer some key questions about optimizing trading strategies
in the fBm framework: Which lagged increments of the fBm, observed in discrete
time, are to be considered? If the predicted increment is close to zero, up to
which threshold is it more profitable not to invest? We also propose empirical
applications on high-frequency FX rates, as well as on realized volatility
series, exploring the rough volatility concept in a forecasting perspective.
"
2105.09264,2021-05-20,"Robo-Advising: Enhancing Investment with Inverse Optimization and Deep
  Reinforcement Learning","  Machine Learning (ML) has been embraced as a powerful tool by the financial
industry, with notable applications spreading in various domains including
investment management. In this work, we propose a full-cycle data-driven
investment robo-advising framework, consisting of two ML agents. The first
agent, an inverse portfolio optimization agent, infers an investor's risk
preference and expected return directly from historical allocation data using
online inverse optimization. The second agent, a deep reinforcement learning
(RL) agent, aggregates the inferred sequence of expected returns to formulate a
new multi-period mean-variance portfolio optimization problem that can be
solved using deep RL approaches. The proposed investment pipeline is applied on
real market data from April 1, 2016 to February 1, 2021 and has shown to
consistently outperform the S&P 500 benchmark portfolio that represents the
aggregate market optimal allocation. The outperformance may be attributed to
the the multi-period planning (versus single-period planning) and the
data-driven RL approach (versus classical estimation approach).
"
2105.10019,2022-01-31,"Enhancing Cross-Sectional Currency Strategies by Context-Aware Learning
  to Rank with Self-Attention","  The performance of a cross-sectional currency strategy depends crucially on
accurately ranking instruments prior to portfolio construction. While this
ranking step is traditionally performed using heuristics, or by sorting the
outputs produced by pointwise regression or classification techniques,
strategies using Learning to Rank algorithms have recently presented themselves
as competitive and viable alternatives. Although the rankers at the core of
these strategies are learned globally and improve ranking accuracy on average,
they ignore the differences between the distributions of asset features over
the times when the portfolio is rebalanced. This flaw renders them susceptible
to producing sub-optimal rankings, possibly at important periods when accuracy
is actually needed the most. For example, this might happen during critical
risk-off episodes, which consequently exposes the portfolio to substantial,
unwanted drawdowns. We tackle this shortcoming with an analogous idea from
information retrieval: that a query's top retrieved documents or the local
ranking context provide vital information about the query's own
characteristics, which can then be used to refine the initial ranked list. In
this work, we use a context-aware Learning-to-rank model that is based on the
Transformer architecture to encode top/bottom ranked assets, learn the context
and exploit this information to re-rank the initial results. Backtesting on a
slate of 31 currencies, our proposed methodology increases the Sharpe ratio by
around 30% and significantly enhances various performance metrics.
Additionally, this approach also improves the Sharpe ratio when separately
conditioning on normal and risk-off market states.
"
2105.10252,2021-05-24,A note on the CAPM with endogenously consistent market returns,"  I demonstrate that with the market return determined by the equilibrium
returns of the CAPM, expected returns of an asset are affected by the risks of
all assets jointly. Another implication is that the range of feasible market
returns will be limited and dependent on the distribution of weights in the
market portfolio. A large and well diversified market with no dominating asset
will only return zero while a market dominated by a small number of assets will
only return the risk-free rate. In the limiting case of atomistic assets, we
recover the properties of the standard CAPM.
"
2105.10306,2021-05-24,Turnover-Adjusted Information Ratio,"  In this paper, we study the behavior of information ratio (IR) as determined
by the fundamental law of active investment management. We extend the classic
relationship between IR and its two determinants (i.e., information coefficient
and investment ""breadth"") by explicitly and simultaneously taking into account
the volatility of IC and the cost from portfolio turnover. Through mathematical
derivations and simulations, we show that - for both mean-variance and quintile
portfolios - a turnover-adjusted IR is always lower than an IR that ignores the
cost from turnover; more importantly, we find that, contrary to the implication
from the fundamental low but consistent with available empirical evidence,
investment managers may improve their investment performance or IR by
limiting/optimizing trade or portfolio turnover.
"
2105.10991,2021-05-28,"Evaluating the Effect of Credit Collection Policy on Portfolio Quality
  of Micro-Finance Bank","  This study evaluates the effect of collection policy on portfolio quality of
microfinance banks in Adamawa State, Nigeria. Real data were collected from 51
credit officers, then a multi-stage sampling method was used to select a sample
of 21 respondents from the population (i.e., 51 credit officers). In addition,
we used regression analysis and descriptive statistics to analyze the data
collected and to also test our proposed hypothesis. Based on the evaluation
performed, the results showed that collection policy has a higher effect on
portfolio quality. Hence, the study showed that microfinance banks should
adhere to strict or stiff debt collection policy as strictness in collection
policy help the banks to recover their loans, thereby improving the portfolio
quality of the bank.
"
2105.12336,2022-05-25,"Bitcoin: Like a Satellite or Always Hardcore? A Core-Satellite
  Identification in the Cryptocurrency Market","  Cryptocurrencies (CCs) become more interesting for institutional investors'
strategic asset allocation and will be a fixed component of professional
portfolios in future. This asset class differs from established assets
especially in terms of the severe manifestation of statistical parameters. The
question arises whether CCs with similar statistical key figures exist. On this
basis, a core market incorporating CCs with comparable properties enables the
implementation of a tracking error approach. A prerequisite for this is the
segmentation of the CC market into a core and a satellite, the latter
comprising the accumulation of the residual CCs remaining in the complement.
Using a concrete example, we segment the CC market into these components, based
on modern methods from image / pattern recognition.
"
2105.13126,2021-05-28,"An Introduction To Regret Minimization In Algorithmic Trading: A Survey
  of Universal Portfolio Techniques","  In financial investing, universal portfolios are a means of constructing
portfolios which guarantee a certain level of performance relative to a
baseline, while making no statistical assumptions about the future market data.
They fall under the broad category of regret minimization algorithms. This
document covers an introduction and survey to universal portfolio techniques,
covering some of the basic concepts and proofs in the area. Topics include:
Constant Rebalanced Portfolios, Cover's Algorithm, Incorporating Transaction
Costs, Efficient Computation of Portfolios, Including Side Information, and
Follow The Leader Algorithm.
"
2105.13891,2023-01-18,SoK: Yield Aggregators in DeFi,"  Yield farming has been an immensely popular activity for cryptocurrency
holders since the explosion of Decentralized Finance (DeFi) in the summer of
2020. In this Systematization of Knowledge (SoK), we study a general framework
for yield farming strategies with empirical analysis. First, we summarize the
fundamentals of yield farming by focusing on the protocols and tokens used by
aggregators. We then examine the sources of yield and translate those into
three example yield farming strategies, followed by the simulations of yield
farming performance, based on these strategies. We further compare four major
yield aggregrators -- Idle, Pickle, Harvest and Yearn -- in the ecosystem,
along with brief introductions of others. We systematize their strategies and
revenue models, and conduct an empirical analysis with on-chain data from
example vaults, to find a plausible connection between data anomalies and
historical events. Finally, we discuss the benefits and risks of yield
aggregators.
"
2106.02131,2023-04-19,"Dynamic Shrinkage Estimation of the High-Dimensional Minimum-Variance
  Portfolio","  In this paper, new results in random matrix theory are derived which allow us
to construct a shrinkage estimator of the global minimum variance (GMV)
portfolio when the shrinkage target is a random object. More specifically, the
shrinkage target is determined as the holding portfolio estimated from previous
data. The theoretical findings are applied to develop theory for dynamic
estimation of the GMV portfolio, where the new estimator of its weights is
shrunk to the holding portfolio at each time of reconstruction. Both cases with
and without overlapping samples are considered in the paper. The
non-overlapping samples corresponds to the case when different data of the
asset returns are used to construct the traditional estimator of the GMV
portfolio weights and to determine the target portfolio, while the overlapping
case allows intersections between the samples. The theoretical results are
derived under weak assumptions imposed on the data-generating process. No
specific distribution is assumed for the asset returns except from the
assumption of finite $4+\varepsilon$, $\varepsilon>0$, moments. Also, the
population covariance matrix with unbounded spectrum can be considered. The
performance of new trading strategies is investigated via an extensive
simulation. Finally, the theoretical findings are implemented in an empirical
illustration based on the returns on stocks included in the S\&P 500 index.
"
2106.03417,2021-06-08,"Dynamic Portfolio Cuts: A Spectral Approach to Graph-Theoretic
  Diversification","  Stock market returns are typically analyzed using standard regression, yet
they reside on irregular domains which is a natural scenario for graph signal
processing. To this end, we consider a market graph as an intuitive way to
represent the relationships between financial assets. Traditional methods for
estimating asset-return covariance operate under the assumption of statistical
time-invariance, and are thus unable to appropriately infer the underlying true
structure of the market graph. This work introduces a class of graph spectral
estimators which cater for the nonstationarity inherent to asset price
movements, and serve as a basis to represent the time-varying interactions
between assets through a dynamic spectral market graph. Such an account of the
time-varying nature of the asset-return covariance allows us to introduce the
notion of dynamic spectral portfolio cuts, whereby the graph is partitioned
into time-evolving clusters, allowing for online and robust asset allocation.
The advantages of the proposed framework over traditional methods are
demonstrated through numerical case studies using real-world price data.
"
2106.04028,2022-10-11,Deep Learning Statistical Arbitrage,"  Statistical arbitrage exploits temporal price differences between similar
assets. We develop a unifying conceptual framework for statistical arbitrage
and a novel data driven solution. First, we construct arbitrage portfolios of
similar assets as residual portfolios from conditional latent asset pricing
factors. Second, we extract their time series signals with a powerful
machine-learning time-series solution, a convolutional transformer. Lastly, we
use these signals to form an optimal trading policy, that maximizes
risk-adjusted returns under constraints. Our comprehensive empirical study on
daily US equities shows a high compensation for arbitrageurs to enforce the law
of one price. Our arbitrage strategies obtain consistently high out-of-sample
mean returns and Sharpe ratios, and substantially outperform all benchmark
approaches.
"
2106.04114,2022-12-23,"Theoretically Motivated Data Augmentation and Regularization for
  Portfolio Construction","  The task we consider is portfolio construction in a speculative market, a
fundamental problem in modern finance. While various empirical works now exist
to explore deep learning in finance, the theory side is almost non-existent. In
this work, we focus on developing a theoretical framework for understanding the
use of data augmentation for deep-learning-based approaches to quantitative
finance. The proposed theory clarifies the role and necessity of data
augmentation for finance; moreover, our theory implies that a simple algorithm
of injecting a random noise of strength $\sqrt{|r_{t-1}|}$ to the observed
return $r_{t}$ is better than not injecting any noise and a few other
financially irrelevant data augmentation techniques.
"
2106.04218,2021-06-09,Modeling Portfolios with Leptokurtic and Dependent Risk Factors,"  Recently, an approach to modeling portfolio distribution with risk factors
distributed as Gram-Charlier (GC) expansions of the Gaussian law, has been
conceived. GC expansions prove effective when dealing with moderately
leptokurtic data. In order to cover the case of possibly severe leptokurtosis,
the so-called GC-like expansions have been devised by reshaping parent
leptokurtic distributions by means of orthogonal polynomials specific to them.
In this paper, we focus on the hyperbolic-secant (HS) law as parent
distribution whose GC-like expansions fit with kurtosis levels up to 19.4. A
portfolio distribution has been obtained with risk factors modeled as GClike
expansions of the HS law which duly account for excess kurtosis. Empirical
evidence of the workings of the approach dealt with in the paper is included.
"
2106.06735,2021-08-23,"Quantum Portfolio Optimization with Investment Bands and Target
  Volatility","  In this paper we show how to implement in a simple way some complex real-life
constraints on the portfolio optimization problem, so that it becomes amenable
to quantum optimization algorithms. Specifically, first we explain how to
obtain the best investment portfolio with a given target risk. This is
important in order to produce portfolios with different risk profiles, as
typically offered by financial institutions. Second, we show how to implement
individual investment bands, i.e., minimum and maximum possible investments for
each asset. This is also important in order to impose diversification and avoid
corner solutions. Quite remarkably, we show how to build the constrained cost
function as a quadratic binary optimization (QUBO) problem, this being the
natural input of quantum annealers. The validity of our implementation is
proven by finding the optimal portfolios, using D-Wave Hybrid and its Advantage
quantum processor, on portfolios built with all the assets from S&P100 and
S&P500. Our results show how practical daily constraints found in quantitative
finance can be implemented in a simple way in current NISQ quantum processors,
with real data, and under realistic market conditions. In combination with
clustering algorithms, our methods would allow to replicate the behaviour of
more complex indexes, such as Nasdaq Composite or others, in turn being
particularly useful to build and replicate Exchange Traded Funds (ETF).
"
2106.09055,2022-09-30,Diversified reward-risk parity in portfolio construction,"  We introduce diversified risk parity embedded with various reward-risk
measures and more generic allocation rules for portfolio construction. We
empirically test the proposed reward-risk parity strategies and compare their
performance with an equally-weighted risk portfolio in various asset universes.
The reward-risk parity strategies we tested exhibit consistent outperformance
evidenced by higher average returns, Sharpe ratios, and Calmar ratios. The
alternative allocations also reflect less downside risks in Value-at-Risk,
conditional Value-at-Risk, and maximum drawdown. In addition to the enhanced
performance and reward-risk profile, transaction costs can be reduced by
lowering turnover rates. The diversified reward-risk parity allocations gain
superior performance in the Carhart four-factor analysis.
"
2106.09132,2021-06-18,Multivariate Pair Trading by Volatility & Model Adaption Trade-off,"  Pair trading is one of the most discussed topics among financial researches.
Despite a growing base of work, portfolio management for multivariate time
series is rarely discussed. On the other hand, most researches focus on
refining strategy rules instead of finding the optimal portfolio weight. In
this paper, we brought up a simple yet profitable strategy called Volatility &
Model Adaption Trade-off (VMAT) to leverage the issues. Experiment studies show
its superior profit performance over baselines.
"
2106.10030,2022-10-24,Universal Risk Budgeting,"  I juxtapose Cover's vaunted universal portfolio selection algorithm (Cover
1991) with the modern representation (Qian 2016; Roncalli 2013) of a portfolio
as a certain allocation of risk among the available assets, rather than a mere
allocation of capital. Thus, I define a Universal Risk Budgeting scheme that
weights each risk budget (instead of each capital budget) by its historical
performance record (a la Cover). I prove that my scheme is mathematically
equivalent to a novel type of Cover and Ordentlich 1996 universal portfolio
that uses a new family of prior densities that have hitherto not appeared in
the literature on universal portfolio theory. I argue that my universal risk
budget, so-defined, is a potentially more perspicuous and flexible type of
universal portfolio; it allows the algorithmic trader to incorporate, with
advantage, his prior knowledge (or beliefs) about the particular covariance
structure of instantaneous asset returns. Say, if there is some dispersion in
the volatilities of the available assets, then the uniform (or Dirichlet)
priors that are standard in the literature will generate a dangerously lopsided
prior distribution over the possible risk budgets. In the author's opinion, the
proposed ""Garivaltis prior"" makes for a nice improvement on Cover's timeless
expert system (Cover 1991), that is properly agnostic and open (from the very
get-go) to different risk budgets. Inspired by Jamshidian 1992, the universal
risk budget is formulated as a new kind of exotic option in the continuous time
Black and Scholes 1973 market, with all the pleasure, elegance, and convenience
that that entails.
"
2106.10033,2022-05-04,Chances for the honest in honest versus insider trading,"  We study a Black-Scholes market with a finite time horizon and two investors:
an honest and an insider trader. We analyze it with anticipating stochastic
calculus in two steps. First, we recover the classical result on portfolio
optimization that shows that the expected logarithmic utility of the insider is
strictly greater than that of the honest trader. Then, we prove that, whenever
the market is viable, the honest trader can get a higher logarithmic utility,
and therefore more wealth, than the insider with a strictly positive
probability. Our proof relies on the analysis of a sort of forward integral
variant of the Dol\'eans-Dade exponential process. The main financial
conclusion is that the logarithmic utility is perhaps too conservative for some
insiders.
"
2106.10491,2022-05-03,"The efficient frontiers of mean-variance portfolio rules under
  distribution misspecification","  Mean-variance portfolio decisions that combine prediction and optimisation
have been shown to have poor empirical performance. Here, we consider the
performance of various shrinkage methods by their efficient frontiers under
different distributional assumptions to study the impact of reasonable
departures from Normality. Namely, we investigate the impact of first-order
auto-correlation, second-order auto-correlation, skewness, and excess kurtosis.
We show that the shrinkage methods tend to re-scale the sample efficient
frontier, which can change based on the nature of local perturbations from
Normality. This re-scaling implies that the standard approach of comparing
decision rules for a fixed level of risk aversion is problematic, and more so
in a dynamic market setting. Our results suggest that comparing efficient
frontiers has serious implications which oppose the prevailing thinking in the
literature. Namely, that sample estimators out-perform Stein type estimators of
the mean, and that improving the prediction of the covariance has greater
importance than improving that of the means.
"
2106.11484,2023-01-23,"Sectoral portfolio optimization by judicious selection of financial
  ratios via PCA","  Embedding value investment in portfolio optimization models has always been a
challenge. In this paper, we attempt to incorporate it by employing principal
component analysis to filter out dominant financial ratios from each sector and
thereafter, use the portfolio optimization model incorporating second-order
stochastic dominance criteria to derive an optimal investment. We consider a
total of $11$ financial ratios corresponding to each sector representing four
categories of ratios, namely liquidity, solvency, profitability, and valuation.
PCA is then applied over a period of 10 years to extract dominant ratios from
each sector in two ways, one from the component solution and the other from
each category on the basis of their communalities. The two-step Sectoral
Portfolio Optimization (SPO) model is then utilized to build an optimal
portfolio. The strategy formed using the formerly extracted ratios is termed
PCA-SPO(A) and the latter PCA-SPO(B). The results obtained from the proposed
strategies are compared with those from mean-variance, minimum variance, SPO,
and nominal SSD models, with and without financial ratios. The empirical
performance of proposed strategies is analyzed in two ways, viz., using a
rolling window scheme and using market trend scenarios for S\&P BSE 500 (India)
and S\&P 500 (U.S.) markets. We observe that the proposed strategy PCA-SPO(B)
outperforms all other models in terms of downside deviation, CVaR, VaR,
Sortino, Rachev, and STARR ratios over almost all out-of-sample periods. This
highlights the importance of value investment where ratios are carefully
selected and embedded quantitatively in portfolio selection process.
"
2106.11510,2021-10-15,"Sub- and Super-solution Approach to Accuracy Analysis of Portfolio
  Optimization Asymptotics in Multiscale Stochastic Factor Market","  The problem of portfolio optimization when stochastic factors drive returns
and volatilities has been studied in previous works by the authors. In
particular, they proposed asymptotic approximations for value functions and
optimal strategies in the regime where these factors are running on both slow
and fast timescales. However, the rigorous justification of the accuracy of
these approximations has been limited to power utilities and a single factor.
In this paper, we provide an accurate analysis for cases with general utility
functions and two timescale factors by constructing sub- and super-solutions to
the fully nonlinear problem so that their difference is at the desired level of
accuracy. This approach will be valuable in various related stochastic control
problems.
"
2106.12292,2021-12-16,"Dispersion indices based on Kerridge inaccuracy and Kullback-Leibler
  divergence","  The concept of varentropy has been recently introduced as a dispersion index
of the reliability of measure of information. In this paper, we introduce new
measures of variability for two measures of uncertainty, the Kerridge
inaccuracy measure and the Kullback-Leibler divergence. These new definitions
and related properties, bounds and examples are presented. Finally we show an
application of Kullback-Leibler divergence and its dispersion index using the
mean-variance rule.
"
2106.12425,2021-06-24,"Portfolio Allocation under Asymmetric Dependence in Asset Returns using
  Local Gaussian Correlations","  It is well known that there are asymmetric dependence structures between
financial returns. In this paper we use a new nonparametric measure of local
dependence, the local Gaussian correlation, to improve portfolio allocation. We
extend the classical mean-variance framework, and show that the portfolio
optimization is straightforward using our new approach, only relying on a
tuning parameter (the bandwidth). The new method is shown to outperform the
equally weighted (1/N) portfolio and the classical Markowitz portfolio for
monthly asset returns data.
"
2106.13888,2021-06-29,"Optimal investment and proportional reinsurance in a regime-switching
  market model under forward preferences","  In this paper we study the optimal investment and reinsurance problem of an
insurance company whose investment preferences are described via a forward
dynamic exponential utility in a regime-switching market model. Financial and
actuarial frameworks are dependent since stock prices and insurance claims vary
according to a common factor given by a continuous time finite state Markov
chain. We construct the value function and we prove that it is a forward
dynamic utility. Then, we characterize the investment strategy and the optimal
proportional level of reinsurance. We also perform numerical experiments and
provide sensitivity analyses with respect to some model parameters.
"
2106.14404,2021-06-29,UNISWAP: Impermanent Loss and Risk Profile of a Liquidity Provider,"  Uniswap is a decentralized exchange (DEX) and was first launched on November
2, 2018 on the Ethereum mainnet [1] and is part of an Ecosystem of products in
Decentralized Finance (DeFi). It replaces a traditional order book type of
trading common on centralized exchanges (CEX) with a deterministic model that
swaps currencies (or tokens/assets) along a fixed price function determined by
the amount of currencies supplied by the liquidity providers. Liquidity
providers can be regarded as investors in the decentralized exchange and earn
fixed commissions per trade. They lock up funds in liquidity pools for distinct
pairs of currencies allowing market participants to swap them using the fixed
price function. Liquidity providers take on market risk as a liquidity provider
in exchange for earning commissions on each trade. Here we analyze the risk
profile of a liquidity provider and the so called impermanent (unrealized) loss
in particular. We provide an improved version of the commonly denoted
impermanent loss function for Uniswap v2 on the semi-infinite domain. The
differences between Uniswap v2 and v3 are also discussed.
"
2106.14820,2022-10-24,Rational Pricing of Leveraged ETF Expense Ratios,"  This paper studies the general relationship between the gearing ratio of a
Leveraged ETF and its corresponding expense ratio, viz., the investment
management fees that are charged for the provision of this levered financial
service. It must not be possible for an investor to combine two or more LETFs
in such a way that his (continuously-rebalanced) LETF portfolio can match the
gearing ratio of a given, professionally managed product and, at the same time,
enjoy lower weighted-average expenses than the existing LETF. Given a finite
set of LETFs that exist in the marketplace, I give necessary and sufficient
conditions for these products to be undominated in the price-gearing plane. In
a beautiful application of the duality theorem of linear programming, I prove a
kind of two-fund theorem for LETFs: given a target gearing ratio for the
investor, the cheapest way to achieve it is to combine (uniquely) the two
nearest undominated LETF products that bracket it on the leverage axis. This
also happens to be the implementation that has the lowest annual turnover. For
the writer's enjoyment, we supply a second proof of the Main Theorem on LETFs
that is based on Carath\'eodory's theorem in convex geometry. Thus, say, a
triple-leveraged (""UltraPro"") exchange-traded product should never be mixed
with cash, if the investor is able to trade in the underlying index. In terms
of financial innovation, our two-fund theorem for LETFs implies that the
introduction of new, undominated 2.5x products would increase the welfare of
all investors whose preferred gearing ratios lie between 2x (""Ultra"") and 3x
(""UltraPro""). Similarly for a 1.5x product.
"
2106.15208,2024-07-16,"The insider problem in the trinomial model: a discrete-time jump process
  approach","  In an incomplete market underpinned by the trinomial model, we consider two
investors : an ordinary agent whose decisions are driven by public information
and an insider who possesses from the beginning a surplus of information
encoded through a random variable for which he or she knows the outcome.
Through the definition of an auxiliary model based on a marked binomial
process, we handle the trinomial model as a volatility one, and use the
stochastic analysis and Malliavin calculus toolboxes available in that context.
In particular, we connect the information drift, the drift to eliminate in
order to preserve the martingale property within an initial enlargement of
filtration in terms of the Malliavin derivative. We solve explicitly the agent
and the insider expected logarithmic utility maximisation problems and provide
a hedging formula for replicable claims. We identify the insider expected
additional utility with the Shannon entropy of the extra information, and
examine then the existence of arbitrage opportunities for the insider.
"
2106.15426,2021-06-30,Effect of Labour Income on the Optimal Bankruptcy Problem,"  In this paper we deal with the optimal bankruptcy problem for an agent who
can optimally allocate her consumption rate, the amount of capital invested in
the risky asset as well as her leisure time. In our framework, the agent is
endowed by an initial debt, and she is required to repay her debt continuously.
Declaring bankruptcy, the debt repayment is exempted at the cost of a wealth
shrinkage. We implement the duality method to solve the problem analytically
and conduct a sensitivity analysis to the cost and benefit parameters of
bankruptcy. Introducing the flexible leisure/working rate, and therefore the
labour income, into the bankruptcy model, we investigate its effect on the
optimal strategies.
"
2107.00427,2021-07-02,Feasible Implied Correlation Matrices from Factor Structures,"  Forward-looking correlations are of interest in different financial
applications, including factor-based asset pricing, forecasting stock-price
movements or pricing index options. With a focus on non-FX markets, this paper
defines necessary conditions for option implied correlation matrices to be
mathematically and economically feasible and argues, that existing models are
typically not capable of guaranteeing so. To overcome this difficulty, the
problem is addressed from the underlying factor structure and introduces two
approaches to solve it. Under the quantitative approach, the puzzle is
reformulated into a nearest correlation matrix problem which can be used either
as a stand-alone estimate or to re-establish positive-semi-definiteness of any
other model's estimate. From an economic approach, it is discussed how expected
correlations between stocks and risk factors (like CAPM, Fama-French) can be
translated into a feasible implied correlation matrix. Empirical experiments
are carried out on monthly option data of the S\&P 100 and S\&P 500 index
(1996-2020).
"
2107.01352,2022-04-06,Cleaning large-dimensional covariance matrices for correlated samples,"  We elucidate the problem of estimating large-dimensional covariance matrices
in the presence of correlations between samples. To this end, we generalize the
Marcenko-Pastur equation and the Ledoit-Peche shrinkage estimator using methods
of random matrix theory and free probability. We develop an efficient algorithm
that implements the corresponding analytic formulas, based on the Ledoit-Wolf
kernel estimation technique. We also provide an associated open-source Python
library, called ""shrinkage"", with a user-friendly API to assist in practical
tasks of estimation of large covariance matrices. We present an example of its
usage for synthetic data generated according to exponentially-decaying
auto-correlations.
"
2107.03340,2022-10-04,"Pseudo-Model-Free Hedging for Variable Annuities via Deep Reinforcement
  Learning","  This paper proposes a two-phase deep reinforcement learning approach, for
hedging variable annuity contracts with both GMMB and GMDB riders, which can
address model miscalibration in Black-Scholes financial and constant force of
mortality actuarial market environments. In the training phase, an infant
reinforcement learning agent interacts with a pre-designed training
environment, collects sequential anchor-hedging reward signals, and gradually
learns how to hedge the contracts. As expected, after a sufficient number of
training steps, the trained reinforcement learning agent hedges, in the
training environment, equally well as the correct Delta while outperforms
misspecified Deltas. In the online learning phase, the trained reinforcement
learning agent interacts with the market environment in real time, collects
single terminal reward signals, and self-revises its hedging strategy. The
hedging performance of the further trained reinforcement learning agent is
demonstrated via an illustrative example on a rolling basis to reveal the
self-revision capability on the hedging strategy by online learning.
"
2107.04636,2021-07-13,End-to-End Risk Budgeting Portfolio Optimization with Neural Networks,"  Portfolio optimization has been a central problem in finance, often
approached with two steps: calibrating the parameters and then solving an
optimization problem. Yet, the two-step procedure sometimes encounter the
""error maximization"" problem where inaccuracy in parameter estimation
translates to unwise allocation decisions. In this paper, we combine the
prediction and optimization tasks in a single feed-forward neural network and
implement an end-to-end approach, where we learn the portfolio allocation
directly from the input features. Two end-to-end portfolio constructions are
included: a model-free network and a model-based network. The model-free
approach is seen as a black-box, whereas in the model-based approach, we learn
the optimal risk contribution on the assets and solve the allocation with an
implicit optimization layer embedded in the neural network. The model-based
end-to-end framework provides robust performance in the out-of-sample
(2017-2021) tests when maximizing Sharpe ratio is used as the training
objective function, achieving a Sharpe ratio of 1.16 when nominal risk parity
yields 0.79 and equal-weight fix-mix yields 0.83. Noticing that risk-based
portfolios can be sensitive to the underlying asset universe, we develop an
asset selection mechanism embedded in the neural network with stochastic gates,
in order to prevent the portfolio being hurt by the low-volatility assets with
low returns. The gated end-to-end with filter outperforms the nominal
risk-parity benchmarks with naive filtering mechanism, boosting the Sharpe
ratio of the out-of-sample period (2017-2021) to 1.24 in the market data.
"
2107.04698,2022-10-24,Waiting to Borrow From a 457(b) Plan,"  This paper formulates and solves the optimal stopping problem for a loan made
to one's self from a tax-advantaged retirement account such as a 401(k),
403(b), or 457(b) plan. If the plan participant has access to an external asset
with a higher expected rate of return than the investment funds and indices
that are available within the retirement account, then he must decide how long
to wait before exercising the loan option. On the one hand, taking the loan
quickly will result in many years of exponential capital growth at the higher
(external) rate; on the other hand, if we wait to accumulate more funds in the
457(b), then we can make a larger deposit into the external asset (albeit for a
shorter period of time). I derive a variety of cutoff rules for optimal loan
control; in general, the investor must wait until he accumulates a certain
amount of money (measured in contribution-years) that depends on the disparate
yields, the loan parameters, and the date certain at which he will liquidate
the retirement account. Letting the horizon tend to infinity, the optimal
(horizon-free) policy gains in elegance, simplicity, and practical robustness
to different life outcomes. When asset prices and returns are stochastic, the
(continuous time) cutoff rule turns into a ""wait region,"" whereby the mean of
terminal wealth is rising and the variance of terminal wealth is falling. After
his sojourn through the wait region is over, the participant finds himself on
the mean-variance frontier, at which point his subsequent behavior is a matter
of personal risk preference.
"
2107.05359,2021-07-13,Debt Swapping for Risk Mitigation in Financial Networks,"  We study financial networks where banks are connected by debt contracts. We
consider the operation of debt swapping when two creditor banks decide to
exchange an incoming payment obligation, thus leading to a locally different
network structure. We say that a swap is positive if it is beneficial for both
of the banks involved; we can interpret this notion either with respect to the
amount of assets received by the banks, or their exposure to different shocks
that might hit the system.
  We analyze various properties of these swapping operations in financial
networks. We first show that there can be no positive swap for any pair of
banks in a static financial system, or when a shock hits each bank in the
network proportionally. We then study worst-case shock models, when a shock of
given size is distributed in the worst possible way for a specific bank. If the
goal of banks is to minimize their losses in such a worst-case setting, then a
positive swap can indeed exist. We analyze the effects of such a positive swap
on other banks of the system, the computational complexity of finding a swap,
and special cases where a swap can be found efficiently. Finally, we also
present some results for more complex swapping operations when the banks swap
multiple contracts, or when more than two banks participate in the swap.
"
2107.05535,2021-07-13,"Predicting Risk-adjusted Returns using an Asset Independent
  Regime-switching Model","  Financial markets tend to switch between various market regimes over time,
making stationarity-based models unsustainable. We construct a regime-switching
model independent of asset classes for risk-adjusted return predictions based
on hidden Markov models. This framework can distinguish between market regimes
in a wide range of financial markets such as the commodity, currency, stock,
and fixed income market. The proposed method employs sticky features that
directly affect the regime stickiness and thereby changing turnover levels. An
investigation of our metric for risk-adjusted return predictions is conducted
by analyzing daily financial market changes for almost twenty years. Empirical
demonstrations of out-of-sample observations obtain an accurate detection of
bull, bear, and high volatility periods, improving risk-adjusted returns while
keeping a preferable turnover level.
"
2107.06194,2024-12-03,Geometric insights into robust portfolio construction,"  We investigate and extend the result that an alpha-weight angle from
unconstrained quadratic portfolio optimisations has an upper bound dependent on
the condition number of the covariance matrix. This is known to imply that
better conditioned covariance matrices produce weights from unconstrained
mean-variance optimisations that are better aligned with each assets expected
return. Here we relate the inequality between the alpha-weight angle and the
condition number to extend the result to include portfolio optimisations with
gearing constraints to provide an extended family of robust optimisations. We
use this to argue that in general the equally weighted portfolio is not
preferable to the mean-variance portfolio even with poor forecast ability and a
badly conditioned covariance matrix. We confirm the distribution free
theoretical arguments with a simple Gaussian simulation.
"
2107.06460,2023-10-11,"A Unified Formula of the Optimal Portfolio for Piecewise Hyperbolic
  Absolute Risk Aversion Utilities","  We propose a general family of piecewise hyperbolic absolute risk aversion
(PHARA) utilities, including many classic and non-standard utilities as
examples. A typical application is the composition of a HARA preference and a
piecewise linear payoff in asset allocation. We derive a unified closed-form
formula of the optimal portfolio, which is a four-term division. The formula
has clear economic meanings, reflecting the behavior of risk aversion, risk
seeking, loss aversion and first-order risk aversion. We conduct a general
asymptotic analysis to the optimal portfolio, which directly serves as an
analytical tool for financial analysis. We compare this PHARA portfolio with
those of other utility families both analytically and numerically. One main
finding is that risk-taking behaviors are greatly increased by non-concavity
and reduced by non-differentiability of the PHARA utility. Finally, we use
financial data to test the performance of the PHARA portfolio in the market.
"
2107.06593,2021-07-15,"The Infinite Horizon Investment-Consumption Problem for Epstein-Zin
  Stochastic Differential Utility","  In this article we consider the optimal investment-consumption problem for an
agent with preferences governed by Epstein-Zin stochastic differential utility
who invests in a constant-parameter Black-Scholes-Merton market.
  The paper has three main goals: first, to provide a detailed introduction to
infinite-horizon Epstein-Zin stochastic differential utility, including a
discussion of which parameter combinations lead to a well-formulated problem;
second, to prove existence and uniqueness of infinite horizon Epstein-Zin
stochastic differential utility under a restriction on the parameters governing
the agent's risk aversion and temporal variance aversion; and third, to provide
a verification argument for the candidate optimal solution to the
investment-consumption problem among all admissible consumption streams.
  To achieve these goals, we introduce a slightly different formulation of
Epstein-Zin stochastic differential utility to that which is traditionally used
in the literature. This formulation highlights the necessity and
appropriateness of certain restrictions on the parameters governing the
stochastic differential utility function.
"
2107.07339,2021-07-16,"Computing near-optimal Value-at-Risk portfolios using Integer
  Programming techniques","  Value-at-Risk (VaR) is one of the main regulatory tools used for risk
management purposes. However, it is difficult to compute optimal VaR
portfolios; that is, an optimal risk-reward portfolio allocation using VaR as
the risk measure. This is due to VaR being non-convex and of combinatorial
nature. In particular, it is well known that the VaR portfolio problem can be
formulated as a mixed integer linear program (MILP) that is difficult to solve
with current MILP solvers for medium to large-scale instances of the problem.
Here, we present an algorithm to compute near-optimal VaR portfolios that takes
advantage of this MILP formulation and provides a guarantee of the solution's
near-optimality. As a byproduct, we obtain an algorithm to compute tight lower
bounds on the VaR portfolio problem that outperform related algorithms proposed
in the literature for this purpose. The near-optimality guarantee provided by
the proposed algorithm is obtained thanks to the relation between minimum risk
portfolios satisfying a reward benchmark and the corresponding maximum reward
portfolios satisfying a risk benchmark. These alternate formulations of the
portfolio allocation problem have been frequently studied in the case of convex
risk measures and concave reward functions. Here, this relationship is
considered for general risk measures and reward functions. To illustrate the
efficiency of the presented algorithm, numerical results are presented using
historical asset returns from the US financial market.
"
2107.08721,2021-07-20,"Stock Movement Prediction with Financial News using Contextualized
  Embedding from BERT","  News events can greatly influence equity markets. In this paper, we are
interested in predicting the short-term movement of stock prices after
financial news events using only the headlines of the news. To achieve this
goal, we introduce a new text mining method called Fine-Tuned
Contextualized-Embedding Recurrent Neural Network (FT-CE-RNN). Compared with
previous approaches which use static vector representations of the news (static
embedding), our model uses contextualized vector representations of the
headlines (contextualized embeddings) generated from Bidirectional Encoder
Representations from Transformers (BERT). Our model obtains the
state-of-the-art result on this stock movement prediction task. It shows
significant improvement compared with other baseline models, in both accuracy
and trading simulations. Through various trading simulations based on millions
of headlines from Bloomberg News, we demonstrate the ability of this model in
real scenarios.
"
2107.08827,2021-07-20,Optimal sports betting strategies in practice: an experimental review,"  We investigate the most popular approaches to the problem of sports betting
investment based on modern portfolio theory and the Kelly criterion. We define
the problem setting, the formal investment strategies, and review their common
modifications used in practice. The underlying purpose of the reviewed
modifications is to mitigate the additional risk stemming from the unrealistic
mathematical assumptions of the formal strategies. We test the resulting
methods using a unified evaluation protocol for three sports: horse racing,
basketball and soccer. The results show the practical necessity of the
additional risk-control methods and demonstrate their individual benefits.
Particularly, we show that an adaptive variant of the popular ``fractional
Kelly'' method is a very suitable choice across a wide range of settings.
"
2107.11371,2021-07-26,"Optimum Risk Portfolio and Eigen Portfolio: A Comparative Analysis Using
  Selected Stocks from the Indian Stock Market","  Designing an optimum portfolio that allocates weights to its constituent
stocks in a way that achieves the best trade-off between the return and the
risk is a challenging research problem. The classical mean-variance theory of
portfolio proposed by Markowitz is found to perform sub-optimally on the
real-world stock market data since the error in estimation for the expected
returns adversely affects the performance of the portfolio. This paper presents
three approaches to portfolio design, viz, the minimum risk portfolio, the
optimum risk portfolio, and the Eigen portfolio, for seven important sectors of
the Indian stock market. The daily historical prices of the stocks are scraped
from Yahoo Finance website from January 1, 2016, to December 31, 2020. Three
portfolios are built for each of the seven sectors chosen for this study, and
the portfolios are analyzed on the training data based on several metrics such
as annualized return and risk, weights assigned to the constituent stocks, the
correlation heatmaps, and the principal components of the Eigen portfolios.
Finally, the optimum risk portfolios and the Eigen portfolios for all sectors
are tested on their return over a period of a six-month period. The
performances of the portfolios are compared and the portfolio yielding the
higher return for each sector is identified.
"
2107.12041,2022-10-18,Inverse and Quanto Inverse Options in a Black-Scholes World,"  Over 90% of exchange trading on crypto options has always been on the Deribit
platform. This centralised crypto exchange only lists inverse products because
they do not accept fiat currency. Currently, fiat-based traders can only make
deposits in bitcoin, although they can withdraw both bitcoin and ether to their
on-chain wallets. Likewise, other major crypto options platforms only list
crypto--stablecoin trading pairs in so-called direct options, which are similar
to the standard crypto options listed by the CME except the U.S. dollar is
replaced by a stablecoin version. Until now a clear mathematical exposition of
these products has been lacking. We discuss the sources of market
incompleteness in direct and inverse options and compare their pricing and
hedging characteristics. Then we discuss the useful applications of currency
protected ""quanto"" direct and inverse options for fiat-based traders and
describe their pricing and hedging characteristics, all in the Black-Scholes
setting.
"
2107.13866,2021-07-30,Machine Learning and Factor-Based Portfolio Optimization,"  We examine machine learning and factor-based portfolio optimization. We find
that factors based on autoencoder neural networks exhibit a weaker relationship
with commonly used characteristic-sorted portfolios than popular dimensionality
reduction techniques. Machine learning methods also lead to covariance and
portfolio weight structures that diverge from simpler estimators.
Minimum-variance portfolios using latent factors derived from autoencoders and
sparse methods outperform simpler benchmarks in terms of risk minimization.
These effects are amplified for investors with an increased sensitivity to
risk-adjusted returns, during high volatility periods or when accounting for
tail risk.
"
2108.02283,2021-08-06,"Machine Learning Classification Methods and Portfolio Allocation: An
  Examination of Market Efficiency","  We design a novel framework to examine market efficiency through
out-of-sample (OOS) predictability. We frame the asset pricing problem as a
machine learning classification problem and construct classification models to
predict return states. The prediction-based portfolios beat the market with
significant OOS economic gains. We measure prediction accuracies directly. For
each model, we introduce a novel application of binomial test to test the
accuracy of 3.34 million return state predictions. The tests show that our
models can extract useful contents from historical information to predict
future return states. We provide unique economic insights about OOS
predictability and machine learning models.
"
2108.02633,2021-08-06,"The impact of model risk on dynamic portfolio selection under
  multi-period mean-standard-deviation criterion","  We quantify model risk of a financial portfolio whereby a multi-period
mean-standard-deviation criterion is used as a selection criterion. In this
work, model risk is defined as the loss due to uncertainty of the underlying
distribution of the returns of the assets in the portfolio. The uncertainty is
measured by the Kullback-Leibler divergence, i.e., the relative entropy. In the
worst case scenario, the optimal robust strategy can be obtained in a
semi-analytical form as a solution of a system of nonlinear equations. Several
numerical results are presented which allow us to compare the performance of
this robust strategy with the optimal non-robust strategy. For illustration, we
also quantify the model risk associated with an empirical dataset.
"
2108.03092,2021-12-06,Approximating Optimal Asset Allocations using Simulated Bifurcation,"  This paper investigates the application of Simulated Bifurcation algorithms
to approximate optimal asset allocations. It will provide the reader with an
explanation of the physical principles underlying the method and a Python
implementation of the latter applied to 441 assets belonging to the S&P500
index. In addition, the paper tackles the problem of the selection of an
optimal sub-allocation; in this particular case, we find an adequate solution
in an unrivaled timescale.
"
2108.04019,2021-08-10,"Identification in Bayesian Estimation of the Skewness Matrix in a
  Multivariate Skew-Elliptical Distribution","  Harvey et al. (2010) extended the Bayesian estimation method by Sahu et al.
(2003) to a multivariate skew-elliptical distribution with a general skewness
matrix, and applied it to Bayesian portfolio optimization with higher moments.
Although their method is epochal in the sense that it can handle the skewness
dependency among asset returns and incorporate higher moments into portfolio
optimization, it cannot identify all elements in the skewness matrix due to
label switching in the Gibbs sampler. To deal with this identification issue,
we propose to modify their sampling algorithm by imposing a positive
lower-triangular constraint on the skewness matrix of the multivariate skew-
elliptical distribution and improved interpretability. Furthermore, we propose
a Bayesian sparse estimation of the skewness matrix with the horseshoe prior to
further improve the accuracy. In the simulation study, we demonstrate that the
proposed method with the identification constraint can successfully estimate
the true structure of the skewness dependency while the existing method suffers
from the identification issue.
"
2108.04464,2022-01-06,"Distributionally robust goal-reaching optimization in the presence of
  background risk","  In this paper, we examine the effect of background risk on portfolio
selection and optimal reinsurance design under the criterion of maximizing the
probability of reaching a goal. Following the literature, we adopt dependence
uncertainty to model the dependence ambiguity between financial risk (or
insurable risk) and background risk. Because the goal-reaching objective
function is non-concave, these two problems bring highly unconventional and
challenging issues for which classical optimization techniques often fail.
Using quantile formulation method, we derive the optimal solutions explicitly.
The results show that the presence of background risk does not alter the shape
of the solution but instead changes the parameter value of the solution.
Finally, numerical examples are given to illustrate the results and verify the
robustness of our solutions.
"
2108.05721,2021-10-19,Networks of News and Cross-Sectional Returns,"  We uncover networks from news articles to study cross-sectional stock
returns. By analyzing a huge dataset of more than 1 million news articles
collected from the internet, we construct time-varying directed networks of the
S&P500 stocks. The well-defined directed news networks are formed based on a
modest assumption about firm-specific news structure, and we propose an
algorithm to tackle type-I errors in identifying the stock tickers. We find
strong evidence for the comovement effect between the news-linked stocks
returns and reversal effect from the lead stock return on the 1-day ahead
follower stock return, after controlling for many known effects. Furthermore, a
series of portfolio tests reveal that the news network attention proxy, network
degree, provides a robust and significant cross-sectional predictability of the
monthly stock returns. Among different types of news linkages, the linkages of
within-sector stocks, large size lead firms, and lead firms with lower stock
liquidity are crucial for cross-sectional predictability.
"
2108.05801,2021-08-13,"A Hybrid Learning Approach to Detecting Regime Switches in Financial
  Markets","  Financial markets are of much interest to researchers due to their dynamic
and stochastic nature. With their relations to world populations, global
economies and asset valuations, understanding, identifying and forecasting
trends and regimes are highly important. Attempts have been made to forecast
market trends by employing machine learning methodologies, while statistical
techniques have been the primary methods used in developing market regime
switching models used for trading and hedging. In this paper we present a novel
framework for the detection of regime switches within the US financial markets.
Principal component analysis is applied for dimensionality reduction and the
k-means algorithm is used as a clustering technique. Using a combination of
cluster analysis and classification, we identify regimes in financial markets
based on publicly available economic data. We display the efficacy of the
framework by constructing and assessing the performance of two trading
strategies based on detected regimes.
"
2108.06593,2022-06-08,G3M Impermanent Loss Dynamics,"  Geometric Mean Market Makers (G3M) such as Uniswap, Sushiswap or Balancer are
key building blocks of the nascent Decentralised Finance system. We establish
non-arbitrage bounds for the wealth process of such Automated Market Makers in
the presence of transaction fees and highlight the dynamic of their so-called
Impermanent Losses, which are incurred due to negative convexity and
essentially void the benefits of portfolio diversification within G3Ms.
  We then turn to empirical data to establish if transaction fee income has
historically been high enough to offset Impermanent Losses and allow G3M
investments to outperform their continually rebalanced constant-mix portfolio
counterparts. It appears that the median liquidity pool had a net nil ROI when
taking Impermanent Losses into account. The cross-sectional dispersion of ROI
has however been high and the pool net ROI ranking has been significantly
autocorrelated for several weeks. This suggests that G3M pools are not yet
efficiently arbitraged as agents may access ex-ante knowledge of which G3M
pools are likely to be far better investment proposals than others.
  We finally focus on the UniswapV3 protocol, which introduced the notion of
concentrated liquidity ranges and show that such a position can be replicated
by leveraging a classic UniswapV2 pool while simultaneously hedging part of the
underlying token price exposition. As such, the herein described Impermanent
Loss dynamics also apply to UniswapV3 pools.
"
2108.09035,2021-08-23,Sensitivity of Optimal Retirement Problem to Liquidity Constraints,"  In this work we analytically solve an optimal retirement problem, in which
the agent optimally allocates the risky investment, consumption and leisure
rate to maximise a gain function characterised by a power utility function of
consumption and leisure, through the duality method. We impose different
liquidity constraints over different time spans and conduct a sensitivity
analysis to discover the effect of this kind of constraint.
"
2108.09985,2022-03-08,Continuous-time Portfolio Optimization for Absolute Return Funds,"  This paper investigates a continuous-time portfolio optimization problem with
the following features: (i) a no-short selling constraint; (ii) a leverage
constraint, that is, an upper limit for the sum of portfolio weights; and (iii)
a performance criterion based on the lower mean square error between the
investor's wealth and a predetermined target wealth level. Since the target
level is defined by a deterministic function independent of market indices, it
corresponds to the criterion of absolute return funds. The model is formulated
using the stochastic control framework with explicit boundary conditions. The
corresponding Hamilton-Jacobi-Bellman equation is solved numerically using the
kernel-based collocation method. However, a straightforward implementation does
not offer a stable and acceptable investment strategy; thus, some techniques to
address this shortcoming are proposed. By applying the proposed methodology,
two numerical results are obtained: one uses artificial data, and the other
uses empirical data from Japanese organizations. There are two implications
from the first result: how to stabilize the numerical solution, and a technique
to circumvent the plummeting achievement rate close to the terminal time. The
second result implies that leverage is inevitable to achieve the target level
in the setting discussed in this paper.
"
2108.10403,2021-12-16,Robust Risk-Aware Reinforcement Learning,"  We present a reinforcement learning (RL) approach for robust optimisation of
risk-aware performance criteria. To allow agents to express a wide variety of
risk-reward profiles, we assess the value of a policy using rank dependent
expected utility (RDEU). RDEU allows the agent to seek gains, while
simultaneously protecting themselves against downside risk. To robustify
optimal policies against model uncertainty, we assess a policy not by its
distribution, but rather, by the worst possible distribution that lies within a
Wasserstein ball around it. Thus, our problem formulation may be viewed as an
actor/agent choosing a policy (the outer problem), and the adversary then
acting to worsen the performance of that strategy (the inner problem). We
develop explicit policy gradient formulae for the inner and outer problems, and
show its efficacy on three prototypical financial problems: robust portfolio
allocation, optimising a benchmark, and statistical arbitrage.
"
2109.00130,2021-09-02,"Evaluation of the importance of criteria for the selection of
  cryptocurrencies","  In recent years, cryptocurrencies have gone from an obscure niche to a
prominent place, with investment in these assets becoming increasingly popular.
However, cryptocurrencies carry a high risk due to their high volatility. In
this paper, criteria based on historical cryptocurrency data are defined in
order to characterize returns and risks in different ways, in short time
windows (7 and 15 days); then, the importance of criteria is analyzed by
various methods and their impact is evaluated. Finally, the future plan is
projected to use the knowledge obtained for the selection of investment
portfolios by applying multi-criteria methods.
"
2109.00433,2021-09-02,Closed-form portfolio optimization under GARCH models,"  This paper develops the first closed-form optimal portfolio allocation
formula for a spot asset whose variance follows a GARCH(1,1) process. We
consider an investor with constant relative risk aversion (CRRA) utility who
wants to maximize the expected utility from terminal wealth under a Heston and
Nandi (2000) GARCH (HN-GARCH) model. We obtain closed formulas for the optimal
investment strategy, the value function and the optimal terminal wealth. We
find the optimal strategy is independent of the development of the risky asset,
and the solution converges to that of a continuous-time Heston stochastic
volatility model, albeit under additional conditions. For a daily trading
scenario, the optimal solutions are quite robust to variations in the
parameters, while the numerical wealth equivalent loss (WEL) analysis shows
good performance of the Heston solution, with a quite inferior performance of
the Merton solution.
"
2109.06378,2021-12-28,"A consumption-investment model with state-dependent lower bound
  constraint on consumption","  This paper studies a life-time consumption-investment problem under the
Black-Scholes framework, where the consumption rate is subject to a lower bound
constraint that linearly depends on her wealth. It is a stochastic control
problem with state-dependent control constraint to which the standard
stochastic control theory cannot be directly applied. We overcome this by
transforming it into an equivalent stochastic control problem in which the
control constraint is state-independent so that the standard theory can be
applied. We give an explicit optimal consumption-investment strategy when the
constraint is homogeneous. When the constraint is non-homogeneous, it is shown
that the value function is third-order continuously differentiable by
differential equation approach, and a feedback form optimal
consumption-investment strategy is provided. According to our findings, if one
is concerned with long-term more than short-term consumption, then she should
always consume as few as possible; otherwise, she should consume optimally when
her wealth is above a threshold, and consume as few as possible when her wealth
is below the threshold.
"
2109.07005,2021-09-29,"WaveCorr: Correlation-savvy Deep Reinforcement Learning for Portfolio
  Management","  The problem of portfolio management represents an important and challenging
class of dynamic decision making problems, where rebalancing decisions need to
be made over time with the consideration of many factors such as investors
preferences, trading environments, and market conditions. In this paper, we
present a new portfolio policy network architecture for deep reinforcement
learning (DRL)that can exploit more effectively cross-asset dependency
information and achieve better performance than state-of-the-art architectures.
In particular, we introduce a new property, referred to as \textit{asset
permutation invariance}, for portfolio policy networks that exploit multi-asset
time series data, and design the first portfolio policy network, named
WaveCorr, that preserves this invariance property when treating asset
correlation information. At the core of our design is an innovative permutation
invariant correlation processing layer. An extensive set of experiments are
conducted using data from both Canadian (TSX) and American stock markets (S&P
500), and WaveCorr consistently outperforms other architectures with an
impressive 3%-25% absolute improvement in terms of average annual return, and
up to more than 200% relative improvement in average Sharpe ratio. We also
measured an improvement of a factor of up to 5 in the stability of performance
under random choices of initial asset ordering and weights. The stability of
the network has been found as particularly valuable by our industrial partner.
"
2109.10814,2021-09-23,Fractional Growth Portfolio Investment,"  We review some fundamental concepts of investment from a mathematical
perspective, concentrating specifically on fractional-Kelly portfolios, which
allocate a fraction of wealth to a growth-optimal portfolio while the remainder
collects (or pays) interest at a risk-free rate. We elucidate a coherent
continuous-parameter time-series framework for analysis of these portfolios,
explaining relationships between Sharpe ratios, growth rates, and leverage. We
see how Kelly's criterion prescribes the same leverage as Markowitz
mean-variance optimization. Furthermore, for fractional Kelly portfolios, we
state a simple distributional relationship between portfolio Sharpe ratio, the
fractional coefficient, and portfolio log-returns. These results provide
critical insight into realistic expectations of growth for different classes of
investors, from individuals to quantitative trading operations.
  We then illustrate application of the results by analyzing performance of
various bond and equity mixes for an investor. We also demonstrate how the
relationships can be exploited by a simple method-of-moments calculation to
estimate portfolio Sharpe ratios and levels of risk deployment, given a fund's
reported returns.
"
2109.10958,2021-09-24,"Who are the arbitrageurs? Empirical evidence from Bitcoin traders in the
  Mt. Gox exchange platform","  We mine the leaked history of trades on Mt. Gox, the dominant Bitcoin
exchange from 2011 to early 2014, to detect the triangular arbitrage activity
conducted within the platform. The availability of user identifiers per trade
allows us to focus on the historical record of 440 investors, detected as
arbitrageurs, and consequently to describe their trading behavior. We begin by
showing that a considerable difference appears between arbitrageurs when
indicators of their expertise are taken into account. In particular, we
distinguish between those who conducted arbitrage in a single or in multiple
markets: using this element as a proxy for trade ability, we find that
arbitrage actions performed by expert users are on average non-profitable when
transaction costs are accounted for, while skilled investors conduct arbitrage
at a positive and statistically significant premium. Next, we show that
specific trading strategies, such as splitting orders or conducting arbitrage
non aggressively, are further indicators of expertise that increase the
profitability of arbitrage. Most importantly, we exploit within-user (across
hours and markets) variation and document that expert users make profits on
arbitrage by reacting quickly to plausible exogenous variations on the official
exchange rates. We present further evidence that such differences are chiefly
due to a better ability of the latter in incorporating information, both on the
transactions costs and on the exchange rates volatility, eventually resulting
in a better timing choice at small time scale intervals. Our results support
the hypothesis that arbitrageurs are few and sophisticated users.
"
2109.13633,2021-09-29,High-dimensional Portfolio Optimization using Joint Shrinkage,"  We consider the problem of optimizing a portfolio of financial assets, where
the number of assets can be much larger than the number of observations. The
optimal portfolio weights require estimating the inverse covariance matrix of
excess asset returns, classical solutions of which behave badly in
high-dimensional scenarios. We propose to use a regression-based joint
shrinkage method for estimating the partial correlation among the assets.
Extensive simulation studies illustrate the superior performance of the
proposed method with respect to variance, weight, and risk estimation errors
compared with competing methods for both the global minimum variance portfolios
and Markowitz mean-variance portfolios. We also demonstrate the excellent
empirical performances of our method on daily and monthly returns of the
components of the S&P 500 index.
"
2110.01302,2021-10-05,"Liquidity Stress Testing in Asset Management -- Part 3. Managing the
  Asset-Liability Liquidity Risk","  This article is part of a comprehensive research project on liquidity risk in
asset management, which can be divided into three dimensions. The first
dimension covers the modeling of the liability liquidity risk (or funding
liquidity), the second dimension is dedicated to the modeling of the asset
liquidity risk (or market liquidity), whereas the third dimension considers the
management of the asset-liability liquidity risk (or asset-liability matching).
The purpose of this research is to propose a methodological and practical
framework in order to perform liquidity stress testing programs, which comply
with regulatory guidelines (ESMA, 2019, 2020) and are useful for fund managers.
In this third and last research paper focused on managing the asset-liability
liquidity risk, we explore the ALM tools that can be put in place to control
the liquidity gap. These ALM tools can be split into three categories:
measurement tools, management tools and monitoring tools. In terms of
measurement tools, we focus on the computation of the redemption coverage ratio
(RCR), which is the central instrument of liquidity stress testing programs. We
also study the redemption liquidation policy and the different implementation
methodologies, and we show how reverse stress testing can be developed. In
terms of liquidity management tools, we study the calibration of liquidity
buffers, the pros and cons of special arrangements (redemption suspensions,
gates, side pockets and in-kind redemptions) and the effectiveness of swing
pricing. In terms of liquidity monitoring tools, we compare the macro- and
micro-approaches of liquidity monitoring in order to identify the transmission
channels of liquidity risk.
"
2110.06464,2021-10-14,Data-driven distributionally robust risk parity portfolio optimization,"  We propose a distributionally robust formulation of the traditional risk
parity portfolio optimization problem. Distributional robustness is introduced
by targeting the discrete probabilities attached to each observation used
during parameter estimation. Instead of assuming that all observations are
equally likely, we consider an ambiguity set that provides us with the
flexibility to find the most adversarial probability distribution based on the
investor's desired degree of robustness. This allows us to derive robust
estimates to parametrize the distribution of asset returns without having to
impose any particular structure on the data. The resulting distributionally
robust optimization problem is a constrained convex-concave minimax problem.
Our approach is financially meaningful and attempts to attain full risk
diversification with respect to the worst-case instance of the portfolio risk
measure. We propose a novel algorithmic approach to solve this minimax problem,
which blends projected gradient ascent with sequential convex programming. By
design, this algorithm is highly flexible and allows the user to choose among
alternative statistical distance measures to define the ambiguity set.
Moreover, the algorithm is highly tractable and scalable. Our numerical
experiments suggest that a distributionally robust risk parity portfolio can
yield a higher risk-adjusted rate of return when compared against the nominal
portfolio.
"
2110.07138,2021-11-05,ETF Risk Models,"  We discuss how to build ETF risk models. Our approach anchors on i) first
building a multilevel (non-)binary classification/taxonomy for ETFs, which is
utilized in order to define the risk factors, and ii) then building the risk
models based on these risk factors by utilizing the heterotic risk model
construction of https://ssrn.com/abstract=2600798 (for binary classifications)
or general risk model construction of https://ssrn.com/abstract=2722093 (for
non-binary classifications). We discuss how to build an ETF taxonomy using ETF
constituent data. A multilevel ETF taxonomy can also be constructed by
appropriately augmenting and expanding well-built and granular third-party
single-level ETF groupings.
"
2110.09416,2024-05-14,"Numeraire-invariant quadratic hedging and mean--variance portfolio
  allocation","  The paper investigates quadratic hedging in a semimartingale market that does
not necessarily contain a risk-free asset. An equivalence result for hedging
with and without numeraire change is established (Proposition 3.16). This
permits direct computation of the optimal strategy without choosing a reference
asset and/or performing a numeraire change (Theorem 4.1). New explicit
expressions for optimal strategies are obtained, featuring the use of oblique
projections that provide unified treatment of the case with and without a
risk-free asset (Theorem 4.3). The analysis yields a streamlined computation of
the efficient frontier for the pure investment problem in terms of three easily
interpreted processes (Equation~1.1). The main result advances our
understanding of the efficient frontier formation in the most general case
where a risk-free asset may not be present. Several illustrations of the
numeraire-invariant approach are given.
"
2110.09417,2021-10-19,Mean-Variance Portfolio Selection in Contagious Markets,"  We consider a mean-variance portfolio selection problem in a financial market
with contagion risk. The risky assets follow a jump-diffusion model, in which
jumps are driven by a multivariate Hawkes process with mutual-excitation
effect. The mutual-excitation feature of the Hawkes process captures the
contagion risk in the sense that each price jump of an asset increases the
likelihood of future jumps not only in the same asset but also in other assets.
We apply the stochastic maximum principle, backward stochastic differential
equation theory, and linear-quadratic control technique to solve the problem
and obtain the efficient strategy and efficient frontier in semi-closed form,
subject to a non-local partial differential equation. Numerical examples are
provided to illustrate our results.
"
2110.09516,2024-11-27,Keep it Tighter -- A Story on Analytical Mean Embeddings,"  Kernel techniques are among the most popular and flexible approaches in data
science allowing to represent probability measures without loss of information
under mild conditions. The resulting mapping called mean embedding gives rise
to a divergence measure referred to as maximum mean discrepancy (MMD) with
existing quadratic-time estimators (w.r.t. the sample size) and known
convergence properties for bounded kernels. In this paper we focus on the
problem of MMD estimation when the mean embedding of one of the underlying
distributions is available analytically. Particularly, we consider
distributions on the real line (motivated by financial applications) and prove
tighter concentration for the proposed estimator under this semi-explicit
setting; we also extend the result to the case of unbounded (exponential)
kernel with minimax-optimal lower bounds. We demonstrate the efficiency of our
approach beyond synthetic example in three real-world examples relying on
one-dimensional random variables: index replication and calibration on
loss-given-default ratios and on S&P 500 data.
"
2110.11751,2021-10-25,"Forecasting Financial Market Structure from Network Features using
  Machine Learning","  We propose a model that forecasts market correlation structure from link- and
node-based financial network features using machine learning. For such, market
structure is modeled as a dynamic asset network by quantifying time-dependent
co-movement of asset price returns across company constituents of major global
market indices. We provide empirical evidence using three different network
filtering methods to estimate market structure, namely Dynamic Asset Graph
(DAG), Dynamic Minimal Spanning Tree (DMST) and Dynamic Threshold Networks
(DTN). Experimental results show that the proposed model can forecast market
structure with high predictive performance with up to $40\%$ improvement over a
time-invariant correlation-based benchmark. Non-pair-wise correlation features
showed to be important compared to traditionally used pair-wise correlation
measures for all markets studied, particularly in the long-term forecasting of
stock market structure. Evidence is provided for stock constituents of the
DAX30, EUROSTOXX50, FTSE100, HANGSENG50, NASDAQ100 and NIFTY50 market indices.
Findings can be useful to improve portfolio selection and risk management
methods, which commonly rely on a backward-looking covariance matrix to
estimate portfolio risk.
"
2110.12282,2024-01-19,MAD Risk Parity Portfolios,"  In this paper, we investigate the features and the performance of the Risk
Parity (RP) portfolios using the Mean Absolute Deviation (MAD) as a risk
measure. The RP model is a recent strategy for asset allocation that aims at
equally sharing the global portfolio risk among all the assets of an investment
universe. We discuss here some existing and new results about the properties of
MAD that are useful for the RP approach. We propose several formulations for
finding MAD-RP portfolios computationally, and compare them in terms of
accuracy and efficiency. Furthermore, we provide extensive empirical analysis
based on three real-world datasets, showing that the performances of the RP
approaches generally tend to place both in terms of risk and profitability
between those obtained from the minimum risk and the Equally Weighted
strategies.
"
2110.15239,2021-10-29,Costly Trading,"  We revisit optimal execution of an active portfolio in the presence of
slippage (aka linear, proportional, or absolute-value) costs. Market efficiency
implies a close balance between active alphas and trading costs, so even small
changes to trading optimization can make a big difference. It has been observed
for some time that optimal trading involves a pattern of a no-trade zone with
width $\Delta$ increasing with slippage cost parameter $c$. In a setting of a
reasonably stable (non-stochastic) forecast of future returns and a quadratic
risk aversion, it is shown that $\Delta\sim c^{1/2}$, which differs from the
$\Delta\sim c^{1/3}$ scaling reported for stochastic settings. Analysis of
optimal trading employs maximization of a utility including projected
alpha-based profits, slippage costs, and risk aversion and borrows from a
physical analogy of forced motion in the presence of friction.
"
2111.00451,2022-01-07,"Utility Indifference Pricing with High Risk Aversion and Small Linear
  Price Impact","  We consider the Bachelier model with linear price impact. Exponential utility
indifference prices are studied for vanilla European options and we compute
their non-trivial scaling limit for a vanishing price impact which is inversely
proportional to the risk aversion. Moreover, we find explicitly a family of
portfolios which are asymptotically optimal.
"
2111.00526,2021-11-22,FinEAS: Financial Embedding Analysis of Sentiment,"  We introduce a new language representation model in finance called Financial
Embedding Analysis of Sentiment (FinEAS). In financial markets, news and
investor sentiment are significant drivers of security prices. Thus, leveraging
the capabilities of modern NLP approaches for financial sentiment analysis is a
crucial component in identifying patterns and trends that are useful for market
participants and regulators. In recent years, methods that use transfer
learning from large Transformer-based language models like BERT, have achieved
state-of-the-art results in text classification tasks, including sentiment
analysis using labelled datasets. Researchers have quickly adopted these
approaches to financial texts, but best practices in this domain are not
well-established. In this work, we propose a new model for financial sentiment
analysis based on supervised fine-tuned sentence embeddings from a standard
BERT model. We demonstrate our approach achieves significant improvements in
comparison to vanilla BERT, LSTM, and FinBERT, a financial domain specific
BERT.
"
2111.01234,2021-11-03,Optimal allocation to deferred income annuities,"  In this paper we employ a lifecycle model that uses utility of consumption
and bequest to determine an optimal Deferred Income Annuity (DIA) purchase
policy. We lay out a mathematical framework to formalize the optimization
process. The method and implementation of the optimization is explained, and
the results are then analyzed. We extend our model to control for asset
allocation and show how the purchase policy changes when one is allowed to vary
asset allocation. Our results indicate that (i.) refundable DIAs are less
appealing than non-refundable DIAs because of the loss of mortality credits;
(ii.) the DIA allocation region is larger under the fixed asset allocation
strategy due to it becoming a proxy for fixed-income allocation; and (iii.)
when the investor is allowed to change asset-allocation, DIA allocation becomes
less appealing. However, a case for higher DIA allocation can be made for those
individuals who perceive their longevity to be higher than the population.
"
2111.01931,2022-12-29,Deep Learning Algorithms for Hedging with Frictions,"  This work studies the deep learning-based numerical algorithms for optimal
hedging problems in markets with general convex transaction costs on the
trading rates, focusing on their scalability of trading time horizon. Based on
the comparison results of the FBSDE solver by Han, Jentzen, and E (2018) and
the Deep Hedging algorithm by Buehler, Gonon, Teichmann, and Wood (2019), we
propose a Stable Transfer Hedging (ST-Hedging) algorithm, to aggregate the
convenience of the leading-order approximation formulas and the accuracy of the
deep learning-based algorithms. Our ST-Hedging algorithm achieves the same
state-of-the-art performance in short and moderately long time horizon as FBSDE
solver and Deep Hedging, and generalize well to long time horizon when previous
algorithms become suboptimal. With the transfer learning technique, ST-Hedging
drastically reduce the training time, and shows great scalability to
high-dimensional settings. This opens up new possibilities in model-based deep
learning algorithms in economics, finance, and operational research, which
takes advantages of the domain expert knowledge and the accuracy of the
learning-based methods.
"
2111.02834,2021-11-05,Optimal Pairs Trading with Time-Varying Volatility,"  We propose a pairs trading model that incorporates a time-varying volatility
of the Constant Elasticity of Variance type. Our approach is based on
stochastic control techniques; given a fixed time horizon and a portfolio of
two co-integrated assets, we define the trading strategies as the portfolio
weights maximizing the expected power utility from terminal wealth. We compute
the optimal pairs strategies by using a Finite Difference method. Finally, we
illustrate our results by conducting tests on historical market data at daily
frequency. The parameters are estimated by the Generalized Method of Moments.
"
2111.03603,2025-05-21,"Decrease of capital guarantees in life insurance products: can
  reinsurance stop it?","  We analyze the potential of reinsurance for reversing the current trend of
decreasing capital guarantees in life insurance products. Providing an insurer
with an opportunity to shift part of the financial risk to a reinsurer, we
solve the insurer's dynamic investment-reinsurance optimization problem under
simultaneous Value-at-Risk and no-short-selling constraints. We introduce the
concept of guarantee-equivalent utility gain and use it to compare life
insurance products with and without reinsurance. Our numerical studies indicate
that the optimally managed reinsurance allows the insurer to offer
significantly higher capital guarantees to clients without any loss in the
insurer's expected utility. The longer the investment horizon and the less
risk-averse the insurer, the more prominent the reinsurance benefit.
"
2111.03995,2021-12-21,"Explainable Deep Reinforcement Learning for Portfolio Management: An
  Empirical Approach","  Deep reinforcement learning (DRL) has been widely studied in the portfolio
management task. However, it is challenging to understand a DRL-based trading
strategy because of the black-box nature of deep neural networks. In this
paper, we propose an empirical approach to explain the strategies of DRL agents
for the portfolio management task. First, we use a linear model in hindsight as
the reference model, which finds the best portfolio weights by assuming knowing
actual stock returns in foresight. In particular, we use the coefficients of a
linear model in hindsight as the reference feature weights. Secondly, for DRL
agents, we use integrated gradients to define the feature weights, which are
the coefficients between reward and features under a linear regression model.
Thirdly, we study the prediction power in two cases, single-step prediction and
multi-step prediction. In particular, we quantify the prediction power by
calculating the linear correlations between the feature weights of a DRL agent
and the reference feature weights, and similarly for machine learning methods.
Finally, we evaluate a portfolio management task on Dow Jones 30 constituent
stocks during 01/01/2009 to 09/01/2021. Our approach empirically reveals that a
DRL agent exhibits a stronger multi-step prediction power than machine learning
methods.
"
2111.04311,2023-02-20,"Portfolio analysis with mean-CVaR and mean-CVaR-skewness criteria based
  on mean-variance mixture models","  The paper Zhao et al. (2015) shows that mean-CVaR-skewness portfolio
optimization problems based on asymetric Laplace (AL) distributions can be
transformed into quadratic optimization problems under which closed form
solutions can be found. In this note, we show that such result also holds for
mean-risk-skewness portfolio optimization problems when the underlying
distribution is a larger class of normal mean-variance mixture (NMVM) models
than the class of AL distributions. We then study the value at risk (VaR) and
conditional value at risk (CVaR) risk measures on portfolios of returns with
NMVM distributions. They have closed form expressions for portfolios of normal
and more generally elliptically distributed returns as discussed in Rockafellar
& Uryasev (2000) and in Landsman & Valdez (2003). When the returns have general
NMVM distributions, these risk measures do not give closed form expressions. In
this note, we give approximate closed form expressions for VaR and CVaR of
portfolios of returns with NMVM distributions. Numerical tests show that our
closed form formulas give accurate values for VaR and CVaR and shortens the
computational time for portfolio optimization problems associated with VaR and
CVaR considerably.
"
2111.04709,2021-12-24,Stock Portfolio Optimization Using a Deep Learning LSTM Model,"  Predicting future stock prices and their movement patterns is a complex
problem. Hence, building a portfolio of capital assets using the predicted
prices to achieve the optimization between its return and risk is an even more
difficult task. This work has carried out an analysis of the time series of the
historical prices of the top five stocks from the nine different sectors of the
Indian stock market from January 1, 2016, to December 31, 2020. Optimum
portfolios are built for each of these sectors. For predicting future stock
prices, a long-and-short-term memory (LSTM) model is also designed and
fine-tuned. After five months of the portfolio construction, the actual and the
predicted returns and risks of each portfolio are computed. The predicted and
the actual returns of each portfolio are found to be high, indicating the high
precision of the LSTM model.
"
2111.05935,2022-06-02,"A Meta-Method for Portfolio Management Using Machine Learning for
  Adaptive Strategy Selection","  This work proposes a novel portfolio management technique, the Meta Portfolio
Method (MPM), inspired by the successes of meta approaches in the field of
bioinformatics and elsewhere. The MPM uses XGBoost to learn how to switch
between two risk-based portfolio allocation strategies, the Hierarchical Risk
Parity (HRP) and more classical Na\""ive Risk Parity (NRP). It is demonstrated
that the MPM is able to successfully take advantage of the best characteristics
of each strategy (the NRP's fast growth during market uptrends, and the HRP's
protection against drawdowns during market turmoil). As a result, the MPM is
shown to possess an excellent out-of-sample risk-reward profile, as measured by
the Sharpe ratio, and in addition offers a high degree of interpretability of
its asset allocation decisions.
"
2111.06655,2021-11-15,Profit warnings and stock returns: Evidence from moroccan stock exchange,"  There is an important literature focused on profit warnings and its impact on
stock returns. We provide evidence from Moroccan stock market which aims to
become an African financial hub. Despite this practical improvement, academic
researches that focused on this market are scarce and our study is a first
investigation in this context. Using the event study methodology and a sample
of companies listed in Casablanca Stock Exchange for the period of 2009 to
2016, we examined whether the effect of qualitative warning is more negative
compared to quantitative warnings in a short event window. Our empirical
findings show that the average abnormal return on the date of announcement is
negative and statistically significant. The magnitude of this negative abnormal
return is greater for qualitative warnings than quantitative ones.
"
2111.06886,2021-11-17,Performance vs Persistence : Assess the alpha to identify outperformers,"  The number of pension funds has multiplied exponentially over the last
decade. Active portfolio management requires a precise analysis of the
performance drivers. Several risk and performance attribution metrics have been
developed since the 70s to guide investors in their investment choices. Based
on the study made by Fama and French (2010) we reproduce the experiment they
had carried out in order to complete their work using additionnal features.
Throughout this study we draw a parallel between the results obtained by Fama
and French (2010) with the 3-factor model. The aim of this paper is to assess
the usefulness of two additional factors in the analysis of the persistence of
alphas. We also look at the quality of the manager through his investment
choices in order to generate alpha considering the environment in which he
operates.
"
2111.09170,2021-11-18,"A Universal End-to-End Approach to Portfolio Optimization via Deep
  Learning","  We propose a universal end-to-end framework for portfolio optimization where
asset distributions are directly obtained. The designed framework circumvents
the traditional forecasting step and avoids the estimation of the covariance
matrix, lifting the bottleneck for generalizing to a large amount of
instruments. Our framework has the flexibility of optimizing various objective
functions including Sharpe ratio, mean-variance trade-off etc. Further, we
allow for short selling and study several constraints attached to objective
functions. In particular, we consider cardinality, maximum position for
individual instrument and leverage. These constraints are formulated into
objective functions by utilizing several neural layers and gradient ascent can
be adopted for optimization. To ensure the robustness of our framework, we test
our methods on two datasets. Firstly, we look at a synthetic dataset where we
demonstrate that weights obtained from our end-to-end approach are better than
classical predictive methods. Secondly, we apply our framework on a real-life
dataset with historical observations of hundreds of instruments with a testing
period of more than 20 years.
"
2111.09192,2021-11-18,Impermanent Loss in Uniswap v3,"  AMMs are autonomous smart contracts deployed on a blockchain that make
markets between different assets that live on that chain. In this paper we are
examining a specific class of AMMs called Constant Function Market Makers whose
trading profile, ignoring fees, is determined by their bonding curve. This
class of AMM suffers from what is commonly referred to as Impermanent Loss,
which we have previously identified as the Gamma component of the associated
self-financing trading strategy and which is the risk that LP providers wager
against potential fee earnings.
  The recent Uniswap v3 release has popularized the concept of leveraged
liquidity provision - wherein the trading range in which liquidity is provided
is reduced and achieves a higher degree of capital efficiency through
elimination of unused collateral. This leverage increases the fees earned, but
it also increases the risk taken, ie the IL. Fee levels on Uniswap v3 are well
publicized so, in this paper, we focus on calculating the IL.
  We found that for the 17 pools we analyzed, covering 43% of TVL and chosen by
size, composite tokens and data availability, total fees earned since inception
until the cut-off date was $199.3m. We also found that the total IL suffered by
LPs during this period was USD 260.1m, meaning that in aggregate those LPs
would have been better off by USD 60.8m had they simply HODLd.
"
2111.09773,2021-11-19,Mean-Variance-VaR portfolios: MIQP formulation and performance analysis,"  Value-at-Risk is one of the most popular risk management tools in the
financial industry. Over the past 20 years several attempts to include VaR in
the portfolio selection process have been proposed. However, using VaR as a
risk measure in portfolio optimization models leads to problems that are
computationally hard to solve. In view of this, few practical applications of
VaR in portfolio selection have appeared in the literature up to now. In this
paper, we propose to add the VaR criterion to the classical Mean-Variance
approach in order to better address the typical regulatory constraints of the
financial industry. We thus obtain a portfolio selection model characterized by
three criteria: expected return, variance, and VaR at a specified confidence
level. The resulting optimization problem consists in minimizing variance with
parametric constraints on the levels of expected return and VaR. This model can
be formulated as a Mixed-Integer Quadratic Programming (MIQP) problem. An
extensive empirical analysis on seven real-world datasets demonstrates the
practical applicability of the proposed approach. Furthermore, the
out-of-sample performance of the optimal Mean-Variance-VaR portfolios seems to
be generally better than that of the optimal Mean-Variance and Mean-VaR
portfolios.
"
2111.11232,2022-07-26,"Policy Gradient and Actor-Critic Learning in Continuous Time and Space:
  Theory and Algorithms","  We study policy gradient (PG) for reinforcement learning in continuous time
and space under the regularized exploratory formulation developed by Wang et
al. (2020). We represent the gradient of the value function with respect to a
given parameterized stochastic policy as the expected integration of an
auxiliary running reward function that can be evaluated using samples and the
current value function. This effectively turns PG into a policy evaluation (PE)
problem, enabling us to apply the martingale approach recently developed by Jia
and Zhou (2021) for PE to solve our PG problem. Based on this analysis, we
propose two types of the actor-critic algorithms for RL, where we learn and
update value functions and policies simultaneously and alternatingly. The first
type is based directly on the aforementioned representation which involves
future trajectories and hence is offline. The second type, designed for online
learning, employs the first-order condition of the policy gradient and turns it
into martingale orthogonality conditions. These conditions are then
incorporated using stochastic approximation when updating policies. Finally, we
demonstrate the algorithms by simulations in two concrete examples.
"
2111.11286,2021-11-23,"Portfolio optimization with idiosyncratic and systemic risks for
  financial networks","  In this study, we propose a new multi-objective portfolio optimization with
idiosyncratic and systemic risks for financial networks. The two risks are
measured by the idiosyncratic variance and the network clustering coefficient
derived from the asset correlation networks, respectively. We construct three
types of financial networks in which nodes indicate assets and edges are based
on three correlation measures. Starting from the multi-objective model, we
formulate and solve the asset allocation problem. We find that the optimal
portfolios obtained through the multi-objective with networked approach have a
significant over-performance in terms of return measures in an out-of-sample
framework. This is further supported by the less drawdown during the periods of
the stock market fluctuating downward. According to analyzing different
datasets, we also show that improvements made to portfolio strategies are
robust.
"
2111.12532,2023-04-19,"Is the empirical out-of-sample variance an informative risk measure for
  the high-dimensional portfolios?","  The main contribution of this paper is the derivation of the asymptotic
behaviour of the out-of-sample variance, the out-of-sample relative loss, and
of their empirical counterparts in the high-dimensional setting, i.e., when
both ratios $p/n$ and $p/m$ tend to some positive constants as $m\to\infty$ and
$n\to\infty$, where $p$ is the portfolio dimension, while $n$ and $m$ are the
sample sizes from the in-sample and out-of-sample periods, respectively. The
results are obtained for the traditional estimator of the global minimum
variance (GMV) portfolio, for the two shrinkage estimators introduced by
\cite{frahm2010} and \cite{bodnar2018estimation}, and for the equally-weighted
portfolio, which is used as a target portfolio in the specification of the two
considered shrinkage estimators. We show that the behaviour of the empirical
out-of-sample variance may be misleading is many practical situations. On the
other hand, this will never happen with the empirical out-of-sample relative
loss, which seems to provide a natural normalization of the out-of-sample
variance in the high-dimensional setup. As a result, an important question
arises if this risk measure can safely be used in practice for portfolios
constructed from a large asset universe.
"
2111.12658,2024-09-10,Portfolio optimisation with options,"  We develop a new analysis for portfolio optimisation with options, tackling
the three fundamental issues with this problem: asymmetric options'
distributions, high dimensionality and dependence structure. To do so, we
propose a new dependency matrix, built upon conditional probabilities between
options' payoffs, and show how it can be computed in closed form given a copula
structure of the underlying asset prices. The empirical evidence we provide
highlights that this approach is efficient, fast and easily scalable to large
portfolios of (mixed) options.
"
2111.14631,2021-11-30,Model Risk in Credit Portfolio Models,"  Model risk in credit portfolio models is a serious issue for banks but has so
far not been tackled comprehensively. We will demonstrate how to deal with
uncertainty in all model parameters in an all-embracing, yet easy-to-implement
way.
"
2111.15365,2023-07-07,Expert Aggregation for Financial Forecasting,"  Machine learning algorithms dedicated to financial time series forecasting
have gained a lot of interest. But choosing between several algorithms can be
challenging, as their estimation accuracy may be unstable over time. Online
aggregation of experts combine the forecasts of a finite set of models in a
single approach without making any assumption about the models. In this paper,
a Bernstein Online Aggregation (BOA) procedure is applied to the construction
of long-short strategies built from individual stock return forecasts coming
from different machine learning models. The online mixture of experts leads to
attractive portfolio performances even in environments characterised by
non-stationarity. The aggregation outperforms individual algorithms, offering a
higher portfolio Sharpe Ratio, lower shortfall, with a similar turnover.
Extensions to expert and aggregation specialisations are also proposed to
improve the overall mixture on a family of portfolio evaluation metrics.
"
2111.15634,2021-12-01,RPS: Portfolio Asset Selection using Graph based Representation Learning,"  Portfolio optimization is one of the essential fields of focus in finance.
There has been an increasing demand for novel computational methods in this
area to compute portfolios with better returns and lower risks in recent years.
We present a novel computational method called Representation Portfolio
Selection (RPS) by redefining the distance matrix of financial assets using
Representation Learning and Clustering algorithms for portfolio selection to
increase diversification. RPS proposes a heuristic for getting closer to the
optimal subset of assets. Using empirical results in this paper, we demonstrate
that widely used portfolio optimization algorithms, such as MVO, CLA, and HRP,
can benefit from our asset subset selection.
"
2112.02944,2022-04-08,Deep differentiable reinforcement learning and optimal trading,"  In many reinforcement learning applications, the underlying environment
reward and transition functions are explicitly known differentiable functions.
This enables us to use recent research which applies machine learning tools to
stochastic control to find optimal action functions. In this paper, we define
differentiable reinforcement learning as a particular case of this research. We
find that incorporating deep learning in this framework leads to more accurate
and stable solutions than those obtained from more generic actor critic
algorithms. We apply this deep differentiable reinforcement learning (DDRL)
algorithm to the problem of one asset optimal trading strategies in various
environments where the market dynamics are known. Thanks to the stability of
this method, we are able to efficiently find optimal strategies for complex
multi-scale market models. We also extend these methods to simultaneously find
optimal action functions for a wide range of environment parameters. This makes
it applicable to real life financial signals and portfolio optimization where
the expected return has multiple time scales. In the case of a slow and a fast
alpha signal, we find that the optimal trading strategy consists in using the
fast signal to time the trades associated to the slow signal.
"
2112.04181,2021-12-09,"Sustainability Manifesto for Financial Products: Carbon Equivalence
  Principle","  Sustainability is a key point for financial markets and the label ""Green"" is
an attempt to address this. Acquisition of the label ""Green"" for financial
products carries potential benefits, hence the controversy and attractiveness
of the label. However, such a binary label inadequately represents the carbon
impact - we use carbon as a useful simplification of sustainability. Carbon
impact has a range either size of zero. Both carbon emissions, and
sequestration of carbon, are possible results of financial products. A binary
label does not allow differentiation between a carbon neutral investment and a
coal power plant. Carbon impact has timing and duration, a planted forest takes
time to grow, a coal power plant takes time to emit. Hence we propose the
Carbon Equivalence Principle (CEP) for financial products: that the carbon
effect of a financial product shall be included as a linked term sheet
compatible with existing bank systems. This can either be a single flow, i.e.,
a summary carbon flow, or a linked termsheet describing the carbon impacts in
volume and time. The CEP means that the carbon impact of investment follows the
money. Making carbon impacts consistent with existing bank systems enables
direct alignment of financial product use and sustainability, improving on
non-compatible disclosure proposals.
"
2112.04755,2021-12-10,"High-Dimensional Stock Portfolio Trading with Deep Reinforcement
  Learning","  This paper proposes a Deep Reinforcement Learning algorithm for financial
portfolio trading based on Deep Q-learning. The algorithm is capable of trading
high-dimensional portfolios from cross-sectional datasets of any size which may
include data gaps and non-unique history lengths in the assets. We sequentially
set up environments by sampling one asset for each environment while rewarding
investments with the resulting asset's return and cash reservation with the
average return of the set of assets. This enforces the agent to strategically
assign capital to assets that it predicts to perform above-average. We apply
our methodology in an out-of-sample analysis to 48 US stock portfolio setups,
varying in the number of stocks from ten up to 500 stocks, in the selection
criteria and in the level of transaction costs. The algorithm on average
outperforms all considered passive and active benchmark investment strategies
by a large margin using only one hyperparameter setup for all portfolios.
"
2112.06544,2024-12-24,Mesoscopic Structure of the Stock Market and Portfolio Optimization,"  The idiosyncratic (microscopic) and systemic (macroscopic) components of
market structure have been shown to be responsible for the departure of the
optimal mean-variance allocation from the heuristic `equally-weighted'
portfolio. In this paper, we exploit clustering techniques derived from Random
Matrix Theory (RMT) to study a third, intermediate (mesoscopic) market
structure that turns out to be the most stable over time and provides important
practical insights from a portfolio management perspective. First, we
illustrate the benefits, in terms of predicted and realized risk profiles, of
constructing portfolios by filtering out both random and systemic co-movements
from the correlation matrix. Second, we redefine the portfolio optimization
problem in terms of stock clusters that emerge after filtering. Finally, we
propose a new wealth allocation scheme that attaches equal importance to stocks
belonging to the same community and show that it further increases the
reliability of the constructed portfolios. Results are robust across different
time spans, cross-sectional dimensions and set of constraints defining the
optimization problem
"
2112.07016,2022-11-30,Data-driven integration of norm-penalized mean-variance portfolios,"  Mean-variance optimization (MVO) is known to be sensitive to estimation error
in its inputs. Norm penalization of MVO programs is a regularization technique
that can mitigate the adverse effects of estimation error. We augment the
standard MVO program with a convex combination of parameterized $L_1$ and
$L_2$-norm penalty functions. The resulting program is a parameterized
quadratic program (QP) whose dual is a box-constrained QP. We make use of
recent advances in neural network architecture for differentiable QPs and
present a data-driven framework for optimizing parameterized norm-penalties to
minimize the downstream MVO objective. We present a novel technique for
computing the derivative of the optimal primal solution with respect to the
parameterized $L_1$-norm penalty by implicit differentiation of the dual
program. The primal solution is then recovered from the optimal dual variables.
Historical simulations using US stocks and global futures data demonstrate the
benefit of the data-driven optimization approach.
"
2112.07464,2021-12-15,Efficient differentiable quadratic programming layers: an ADMM approach,"  Recent advances in neural-network architecture allow for seamless integration
of convex optimization problems as differentiable layers in an end-to-end
trainable neural network. Integrating medium and large scale quadratic programs
into a deep neural network architecture, however, is challenging as solving
quadratic programs exactly by interior-point methods has worst-case cubic
complexity in the number of variables. In this paper, we present an alternative
network layer architecture based on the alternating direction method of
multipliers (ADMM) that is capable of scaling to problems with a moderately
large number of variables. Backward differentiation is performed by implicit
differentiation of the residual map of a modified fixed-point iteration.
Simulated results demonstrate the computational advantage of the ADMM layer,
which for medium scaled problems is approximately an order of magnitude faster
than the OptNet quadratic programming layer. Furthermore, our novel
backward-pass routine is efficient, from both a memory and computation
standpoint, in comparison to the standard approach based on unrolled
differentiation or implicit differentiation of the KKT optimality conditions.
We conclude with examples from portfolio optimization in the integrated
prediction and optimization paradigm.
"
2112.07521,2022-10-14,"Non-linear shrinkage of the price return covariance matrix is far from
  optimal for portfolio optimisation","  Portfolio optimization requires sophisticated covariance estimators that are
able to filter out estimation noise. Non-linear shrinkage is a popular
estimator based on how the Oracle eigenvalues can be computed using only data
from the calibration window. Contrary to common belief, NLS is not optimal for
portfolio optimization because it does not minimize the right cost function
when the asset dependence structure is non-stationary. We instead derive the
optimal target. Using historical data, we quantify by how much NLS can be
improved. Our findings reopen the question of how to build the covariance
matrix estimator for portfolio optimization in realistic conditions.
"
2112.09959,2023-12-01,Mean-Covariance Robust Risk Measurement,"  We introduce a universal framework for mean-covariance robust risk
measurement and portfolio optimization. We model uncertainty in terms of the
Gelbrich distance on the mean-covariance space, along with prior structural
information about the population distribution. Our approach is related to the
theory of optimal transport and exhibits superior statistical and computational
properties than existing models. We find that, for a large class of risk
measures, mean-covariance robust portfolio optimization boils down to the
Markowitz model, subject to a regularization term given in closed form. This
includes the finance standards, value-at-risk and conditional value-at-risk,
and can be solved highly efficiently.
"
2112.10084,2021-12-21,Neural Networks for Delta Hedging,"  The Black-Scholes model, defined under the assumption of a perfect financial
market, theoretically creates a flawless hedging strategy allowing the trader
to evade risks in a portfolio of options. However, the concept of a ""perfect
financial market,"" which requires zero transaction and continuous trading, is
challenging to meet in the real world. Despite such widely known limitations,
academics have failed to develop alternative models successful enough to be
long-established. In this paper, we explore the landscape of Deep Neural
Networks(DNN) based hedging systems by testing the hedging capacity of the
following neural architectures: Recurrent Neural Networks, Temporal
Convolutional Networks, Attention Networks, and Span Multi-Layer Perceptron
Networks. In addition, we attempt to achieve even more promising results by
combining traditional derivative hedging models with DNN based approaches.
Lastly, we construct \textbf{NNHedge}, a deep learning framework that provides
seamless pipelines for model development and assessment for the experiments.
"
2112.12031,2021-12-23,Optimal Portfolio Choice and Stock Centrality for Tail Risk Events,"  We propose a novel risk matrix to characterize the optimal portfolio choice
of an investor with tail concerns. The diagonal of the matrix contains the
Value-at-Risk of each asset in the portfolio and the off-diagonal the pairwise
Delta-CoVaR measures reflecting tail connections between assets. First, we
derive the conditions under which the associated quadratic risk function has a
closed-form solution. Second, we examine the relationship between portfolio
risk and eigenvector centrality. Third, we show that portfolio risk is not
necessarily increasing with respect to stock centrality. Forth, we demonstrate
under certain conditions that asset centrality increases the optimal weight
allocation of the asset to the portfolio. Overall, our empirical study
indicates that a network topology which exhibits low connectivity is
outperformed by high connectivity based on a Sharpe ratio test.
"
2112.13383,2021-12-28,Community detection and portfolio optimization,"  Community detection methods can be used to explore the structure of complex
systems. The well-known modular configurations in complex financial systems
indicate the existence of community structures. Here we analyze the community
properties of correlation-based networks in worldwide stock markets and use
community information to construct portfolios. Portfolios constructed using
community detection methods perform well. Our results can be used as new
portfolio optimization and risk management tools.
"
2112.14451,2021-12-30,Dynamic growth-optimum portfolio choice under risk control,"  This paper studies a mean-risk portfolio choice problem for log-returns in a
continuous-time, complete market. This is a growth-optimal problem with risk
control. The risk of log-returns is measured by weighted Value-at-Risk (WVaR),
which is a generalization of Value-at-Risk (VaR) and Expected Shortfall (ES).
We characterize the optimal terminal wealth up to the concave envelope of a
certain function, and obtain analytical expressions for the optimal wealth and
portfolio policy when the risk is measured by VaR or ES. In addition, we find
that the efficient frontier is a concave curve that connects the minimum-risk
portfolio with the growth optimal portfolio, as opposed to the vertical line
when WVaR is used on terminal wealth. Our results advocate the use of mean-WVaR
criterion for log-returns instead of terminal wealth in dynamic portfolio
choice.
"
2112.15499,2022-01-17,Dynamic Portfolio Optimization with Inverse Covariance Clustering,"  Market conditions change continuously. However, in portfolio's investment
strategies, it is hard to account for this intrinsic non-stationarity. In this
paper, we propose to address this issue by using the Inverse Covariance
Clustering (ICC) method to identify inherent market states and then integrate
such states into a dynamic portfolio optimization process. Extensive
experiments across three different markets, NASDAQ, FTSE and HS300, over a
period of ten years, demonstrate the advantages of our proposed algorithm,
termed Inverse Covariance Clustering-Portfolio Optimization (ICC-PO). The core
of the ICC-PO methodology concerns the identification and clustering of market
states from the analytics of past data and the forecasting of the future market
state. It is therefore agnostic to the specific portfolio optimization method
of choice. By applying the same portfolio optimization technique on a ICC
temporal cluster, instead of the whole train period, we show that one can
generate portfolios with substantially higher Sharpe Ratios, which are
statistically more robust and resilient with great reductions in maximum loss
in extreme situations. This is shown to be consistent across markets, periods,
optimization methods and selection of portfolio assets.
"
2201.00205,2022-01-04,Some connections between higher moments portfolio optimization methods,"  In this paper, different approaches to portfolio optimization having higher
moments such as skewness and kurtosis are classified so that the reader can
observe different paradigms and approaches in this field of research which is
essential for practitioners in Hedge Funds in particular. Several methods based
on different paradigms such as utility approach and multi-objective
optimization are reviewed and the advantage and disadvantageous of these ideas
are explained. Keywords: multi-objective optimization, portfolio optimization,
scalarization, utility
"
2201.00914,2023-05-31,"Continuous-time Markowitz's mean-variance model under different
  borrowing and saving rates","  We study Markowitz's mean-variance portfolio selection problem in a
continuous-time Black-Scholes market with different borrowing and saving rates.
The associated Hamilton-Jacobi-Bellman equation is fully nonlinear. Using a
delicate partial differential equation and verification argument, the value
function is proven to be $C^{3,2}$ smooth. It is also shown that there are a
borrowing boundary and a saving barrier which divide the entire trading area
into a borrowing-money region, an all-in-stock region, and a saving-money
region in ascending order. The optimal trading strategy is a mixture of
continuous-time strategy (as suggested by most continuous-time models) and
discontinuous-time strategy (as suggested by models with transaction costs):
one should put all her wealth in the stock in the middle all-in-stock region,
and continuously trade it in the other two regions in a feedback form of wealth
and time. It is never optimal to short sale the stock. Numerical examples are
also presented to verify the theoretical results and to give more financial
insights beyond them.
"
2201.01227,2022-01-07,Sparse Non-Convex Optimization For Higher Moment Portfolio Management,"  One of the reasons that higher order moment portfolio optimization methods
are not fully used by practitioners in investment decisions is the complexity
that these higher moments create by making the optimization problem nonconvex.
Many few methods and theoretical results exists in the literature, but the
present paper uses the method of successive convex approximation for the
mean-variance-skewness problem.
"
2201.01874,2022-01-07,"Combining Reinforcement Learning and Inverse Reinforcement Learning for
  Asset Allocation Recommendations","  We suggest a simple practical method to combine the human and artificial
intelligence to both learn best investment practices of fund managers, and
provide recommendations to improve them. Our approach is based on a combination
of Inverse Reinforcement Learning (IRL) and RL. First, the IRL component learns
the intent of fund managers as suggested by their trading history, and recovers
their implied reward function. At the second step, this reward function is used
by a direct RL algorithm to optimize asset allocation decisions. We show that
our method is able to improve over the performance of individual fund managers.
"
2201.02828,2022-01-11,"Discrete-time risk sensitive portfolio optimization with proportional
  transaction costs","  In this paper we consider a discrete-time risk sensitive portfolio
optimization over a long time horizon with proportional transaction costs. We
show that within the log-return i.i.d. framework the solution to a suitable
Bellman equation exists under minimal assumptions and can be used to
characterize the optimal strategies for both risk-averse and risk-seeking
cases. Moreover, using numerical examples, we show how a Bellman equation
analysis can be used to construct or refine optimal trading strategies in the
presence of transaction costs.
"
2201.02958,2023-10-12,"Smooth Nested Simulation: Bridging Cubic and Square Root Convergence
  Rates in High Dimensions","  Nested simulation concerns estimating functionals of a conditional
expectation via simulation. In this paper, we propose a new method based on
kernel ridge regression to exploit the smoothness of the conditional
expectation as a function of the multidimensional conditioning variable.
Asymptotic analysis shows that the proposed method can effectively alleviate
the curse of dimensionality on the convergence rate as the simulation budget
increases, provided that the conditional expectation is sufficiently smooth.
The smoothness bridges the gap between the cubic root convergence rate (that
is, the optimal rate for the standard nested simulation) and the square root
convergence rate (that is, the canonical rate for the standard Monte Carlo
simulation). We demonstrate the performance of the proposed method via
numerical examples from portfolio risk management and input uncertainty
quantification.
"
2201.02987,2022-07-26,"Portfolio selection models based on interval-valued conditional value at
  risk (ICVaR) and empirical analysis","  Risk management is very important for individual investors or companies.
There are many ways to measure the risk of investment. Prices of risky assets
vary rapidly and randomly due to the complexity of finance market. Random
interval is a good tool to describe uncertainty with both randomness and
imprecision. Considering the uncertainty of financial market, we employ random
intervals to describe the returns of a risk asset and consider the tail risk,
which is called the interval-valued Conditional Value at Risk (ICVaR, for
short). Such an ICVaR is a risk measure and satisfies subadditivity. Under the
new risk measure ICVaR, as a manner similar to the classical portfolio model of
Markowitz, optimal interval-valued portfolio selection models are built. Based
on the real data from mainland Chinese stock market, the case study shows that
our models are interpretable and consistent with the practical scenarios.
"
2201.03717,2022-01-12,Derivatives-based portfolio decisions. An expected utility insight,"  This paper challenges the use of stocks in portfolio construction, instead we
demonstrate that Asian derivatives, straddles, or baskets could be more
convenient substitutes. Our results are obtained under the assumptions of the
Black--Scholes--Merton setting, uncovering a hidden benefit of derivatives that
complements their well-known gains for hedging, risk management, and to
increase utility in market incompleteness. The new insights are also
transferable to more advanced stochastic settings. The analysis relies on the
infinite number of optimal choices of derivatives for a maximized expected
utility (EUT) agent; we propose risk exposure minimization as an additional
optimization criterion inspired by regulations. Working with two assets, for
simplicity, we demonstrate that only two derivatives are needed to maximize
utility while minimizing risky exposure. In a comparison among one-asset
options, e.g. American, European, Asian, Calls and Puts, we demonstrate that
the deepest out-of-the-money Asian products available are the best choices to
minimize exposure. We also explore optimal selections among straddles, which
are better practical choices than out-of-the-money Calls and Puts due to
liquidity and rebalancing needs. The optimality of multi-asset derivatives is
also considered, establishing that a basket option could be a better choice
than one-asset Asian call/put in many realistic situations.
"
2201.04393,2023-04-10,"Dissecting the explanatory power of ESG features on equity returns by
  sector, capitalization, and year with interpretable machine learning","  We systematically investigate the links between price returns and
Environment, Social and Governance (ESG) scores in the European equity market.
Using interpretable machine learning, we examine whether ESG scores can explain
the part of price returns not accounted for by classic equity factors,
especially the market one. We propose a cross-validation scheme with random
company-wise validation to mitigate the relative initial lack of quantity and
quality of ESG data, which allows us to use most of the latest and best data to
both train and validate our models. Gradient boosting models successfully
explain the part of annual price returns not accounted for by the market
factor. We check with benchmark features that ESG data explain significantly
better price returns than basic fundamental features alone. The most relevant
ESG score encodes controversies. Finally, we find the opposite effects of
better ESG scores on the price returns of small and large capitalization
companies: better ESG scores are generally associated with larger price returns
for the latter and reversely for the former.
"
2201.05375,2022-01-17,Strategic mean-variance investing under mean-reverting stock returns,"  In this report we derive the strategic (deterministic) allocation to bonds
and stocks resulting in the optimal mean-variance trade-off on a given
investment horizon. The underlying capital market features a mean-reverting
process for equity returns, and the primary question of interest is how
mean-reversion effects the optimal strategy and the resulting portfolio value
at the horizon. In particular, we are interested in knowing under which
assumptions and on which horizons, the risk-reward trade-off is so favourable
that the value of the portfolio is effectively bounded from below on the
horizon. In this case, we might think of the portfolio as providing a
stochastic excess return on top of a ""guarantee"" (the lower bound).
  Deriving optimal strategies is a well-known discipline in mathematical
finance. The modern approach is to derive and solve the Hamilton-Jacobi-Bellman
(HJB) differential equation characterizing the strategy leading to highest
expected utility, for given utility function. However, for two reasons we
approach the problem differently in this work. First, we wish to find the
optimal strategy depending on time only, i.e., we do not allow for dependencies
on capital market state variables, nor the value of the portfolio itself. This
constraint characterizes the strategic allocation of long-term investors.
Second, to gain insights on the role of mean-reversion, we wish to identify the
entire family of extremal strategies, not only the optimal strategies. To
derive the strategies we employ methods from calculus of variations, rather
than the usual HJB approach.
"
2201.05570,2022-01-17,"Precise Stock Price Prediction for Robust Portfolio Design from Selected
  Sectors of the Indian Stock Market","  Stock price prediction is a challenging task and a lot of propositions exist
in the literature in this area. Portfolio construction is a process of choosing
a group of stocks and investing in them optimally to maximize the return while
minimizing the risk. Since the time when Markowitz proposed the Modern
Portfolio Theory, several advancements have happened in the area of building
efficient portfolios. An investor can get the best benefit out of the stock
market if the investor invests in an efficient portfolio and could take the buy
or sell decision in advance, by estimating the future asset value of the
portfolio with a high level of precision. In this project, we have built an
efficient portfolio and to predict the future asset value by means of
individual stock price prediction of the stocks in the portfolio. As part of
building an efficient portfolio we have studied multiple portfolio optimization
methods beginning with the Modern Portfolio theory. We have built the minimum
variance portfolio and optimal risk portfolio for all the five chosen sectors
by using past daily stock prices over the past five years as the training data,
and have also conducted back testing to check the performance of the portfolio.
A comparative study of minimum variance portfolio and optimal risk portfolio
with equal weight portfolio is done by backtesting.
"
2201.05709,2023-04-17,"How easy is it for investment managers to deploy their talent in green
  and brown stocks?","  We explore the realized alpha-performance heterogeneity in green and brown
stocks' universes using the peer performance ratios of Ardia and Boudt (2018).
Focusing on S&P 500 index firms over 2014-2020 and defining peer groups in
terms of firms' greenhouse gas emission levels, we find that, on average, about
20% of the stocks differentiate themselves from their peers in terms of future
performance. We see a much higher time-variation in this opportunity set within
brown stocks. Furthermore, the performance heterogeneity has decreased over
time, especially for green stocks, implying that it is now more difficult for
investment managers to deploy their skills when choosing among low-GHG
intensity stocks.
"
2201.06183,2022-01-19,"Internal multi-portfolio rebalancing processes: Linking resource
  allocation models and biproportional matrix techniques to portfolio
  management","  This paper describes multi-portfolio `internal' rebalancing processes used in
the finance industry. Instead of trading with the market to `externally'
rebalance, these internal processes detail how portfolio managers buy and sell
between their portfolios to rebalance. We give an overview of currently used
internal rebalancing processes, including one known as the `banker' process and
another known as the `linear' process. We prove the banker process
disadvantages the nominated banker portfolio in volatile markets, while the
linear process may advantage or disadvantage portfolios.
  We describe an alternative process that uses the concept of
`market-invariance'. We give analytic solutions for small cases, while in
general show that the $n$-portfolio solution and its corresponding
`market-invariant' algorithm solve a system of nonlinear polynomial equations.
It turns out this algorithm is a rediscovery of the RAS algorithm (also called
the `iterative proportional fitting procedure') for biproportional matrices. We
show that this process is more equitable than the banker and linear processes,
and demonstrate this with empirical results.
  The market-invariant process has already been implemented by industry due to
the significance of these results.
"
2201.06635,2024-01-30,Optimal trend following portfolios,"  This paper derives an optimal portfolio that is based on trend-following
signal. Building on an earlier related article, it provides a unifying
theoretical setting to introduce an autocorrelation model with the covariance
matrix of trends and risk premia. We specify practically relevant models for
the covariance matrix of trends. The optimal portfolio is decomposed into four
basic components that yield four basic portfolios: Markowitz, risk parity,
agnostic risk parity, and trend following on risk parity. The overperformance
of the proposed optimal portfolio, applied to cross-asset trading universe, is
confirmed by empirical backtests. We provide thus a unifying framework to
describe and rationalize earlier developed portfolios.
"
2201.09406,2022-01-27,"Power Forward Performance in Semimartingale Markets with Stochastic
  Integrated Factors","  We study the forward investment performance process (FIPP) in an incomplete
semimartingale market model with closed and convex portfolio constraints, when
the investor's risk preferences are of the power form. We provide necessary and
sufficient conditions for the existence of such FIPP. In a semimartingale
factor model, we show that the FIPP can be recovered as a triplet of processes
which admit an integral representation with respect to semimartingales. Using
an integrated stochastic factor model, we relate the factor representation of
the triplet of processes to the smooth solution of an ill-posed partial
integro-differential Hamilton-Jacobi-Bellman (HJB) equation. We develop
explicit constructions for the class of time-monotone FIPPs, generalizing
existing results from Brownian to semimartingale market models.
"
2201.10846,2023-05-16,Fat Tails and Optimal Liability Driven Portfolios,"  We look at optimal liability-driven portfolios in a family of fat-tailed and
extremal risk measures, especially in the context of pension fund and insurance
fixed cashflow liability profiles, but also those arising in derivatives books
such as delta one books or options books in the presence of stochastic
volatilities. In the extremal limit, we recover a new tail risk measure,
Extreme Deviation (XD), an extremal risk measure significantly more sensitive
to extremal returns than CVaR. Resulting optimal portfolios optimize the return
per unit of XD, with portfolio weights consisting of a liability hedging
contribution, and a risk contribution seeking to generate positive
risk-adjusted return. The resulting allocations are analyzed qualitatively and
quantitatively in a number of different limits.
"
2202.02197,2022-02-07,"Evaluating conditional covariance estimates via a new targeting approach
  and a networks-based analysis","  Modeling and forecasting of dynamically varying covariances have received
much attention in the literature. The two most widely used conditional
covariances and correlations models are BEKK and DCC. In this paper, we advance
a new method to introduce targeting in both models to estimate matrices
associated with financial time series. Our approach is based on specific groups
of highly correlated assets in a financial market, and these relationships
remain unaltered over time. Based on the estimated parameters, we evaluate our
targeting method on simulated series by referring to two well-known loss
functions introduced in the literature and Network analysis. We find all the
maximal cliques in correlation graphs to evaluate the effectiveness of our
method. Results from an empirical case study are encouraging, mainly when the
number of assets is not large.
"
2202.02280,2022-02-07,"Portfolio Choice with Indivisible and Illiquid Housing Assets: The Case
  of Spain","  This paper studies the investment decision of the Spanish households using a
unique data set, the Spanish Survey of Household Finance (EFF). We propose a
theoretical model in which households, given a fixed investment in housing,
allocate their net wealth across bank time deposits, stocks, and mortgage.
Besides considering housing as an indivisible and illiquid asset that restricts
the portfolio choice decision, we take into account the financial constraints
that households face when they apply for external funding. For every
representative household in the EFF we solve this theoretical problem and
obtain the theoretically optimal portfolio that is compared with households'
actual choices. We find that households significantly underinvest in stocks and
deposits while the optimal and actual mortgage investments are alike.
Considering the three types of financial assets at once, we find that the
households headed by highly financially sophisticated, older, retired, richer,
and unconstrained persons are the ones investing more efficiently.
"
2202.02723,2022-02-08,"Portfolio Optimization on NIFTY Thematic Sector Stocks Using an LSTM
  Model","  Portfolio optimization has been a broad and intense area of interest for
quantitative and statistical finance researchers and financial analysts. It is
a challenging task to design a portfolio of stocks to arrive at the optimized
values of the return and risk. This paper presents an algorithmic approach for
designing optimum risk and eigen portfolios for five thematic sectors of the
NSE of India. The prices of the stocks are extracted from the web from Jan 1,
2016, to Dec 31, 2020. Optimum risk and eigen portfolios for each sector are
designed based on ten critical stocks from the sector. An LSTM model is
designed for predicting future stock prices. Seven months after the portfolios
were formed, on Aug 3, 2021, the actual returns of the portfolios are compared
with the LSTM-predicted returns. The predicted and the actual returns indicate
a very high-level accuracy of the LSTM model.
"
2202.02728,2022-02-14,"Hierarchical Risk Parity and Minimum Variance Portfolio Design on NIFTY
  50 Stocks","  Portfolio design and optimization have been always an area of research that
has attracted a lot of attention from researchers from the finance domain.
Designing an optimum portfolio is a complex task since it involves accurate
forecasting of future stock returns and risks and making a suitable tradeoff
between them. This paper proposes a systematic approach to designing portfolios
using two algorithms, the critical line algorithm, and the hierarchical risk
parity algorithm on eight sectors of the Indian stock market. While the
portfolios are designed using the stock price data from Jan 1, 2016, to Dec 31,
2020, they are tested on the data from Jan 1, 2021, to Aug 26, 2021. The
backtesting results of the portfolios indicate while the performance of the CLA
algorithm is superior on the training data, the HRP algorithm has outperformed
the CLA algorithm on the test data.
"
2202.03858,2023-10-16,"On Solving Robust Log-Optimal Portfolio: A Supporting Hyperplane
  Approximation Approach","  A {log-optimal} portfolio is any portfolio that maximizes the expected
logarithmic growth (ELG) of an investor's wealth. This maximization problem
typically assumes that the information of the true distribution of returns is
known to the trader in advance. However, in practice, the return distributions
are indeed {ambiguous}; i.e., the true distribution is unknown to the trader or
it is partially known at best. To this end, a {distributional robust
log-optimal portfolio problem} formulation arises naturally. While the problem
formulation takes into account the ambiguity on return distributions, the
problem needs not to be tractable in general. To address this, in this paper,
we propose a {supporting hyperplane approximation} approach that allows us to
reformulate a class of distributional robust log-optimal portfolio problems
into a linear program, which can be solved very efficiently. Our framework is
flexible enough to allow {transaction costs}, {leverage and shorting},
{survival trades}, and {diversification considerations}. In addition, given an
acceptable approximation error, an efficient algorithm for rapidly calculating
the optimal number of hyperplanes is provided. Some empirical studies using
historical stock price data are also provided to support our theory.
"
2202.04220,2022-02-10,Optimal annuitization post-retirement with labor income,"  Evidence shows that the labor participation rate of retirement age cohorts is
non-negligible, and it is a widespread phenomenon globally. In the United
States, the labor force participation rate for workers age 75 and older is
projected to be over 10 percent by 2026 as reported by the Bureau of Labor
Statistics. The prevalence of post-retirement work changes existing
considerations of optimal annuitization, a research question further
complicated by novel factors such as post-retirement labor rates, wage rates,
and capacity or willingness to work. To our knowledge, this poses a practical
and theoretical problem not previously investigated in actuarial literature. In
this paper, we study the problem of post-retirement annuitization with extra
labor income in the framework of stochastic control, optimal stopping, and
expected utility maximization. The utility functions are of the Cobb-Douglas
type. The martingale methodology and duality techniques are employed to obtain
closed-form solutions for the dual and primal problems. The effect of labor
income is investigated by exploiting the explicit solutions and Monte-Carlo
simulation. The latter reveals that the optimal annuitization time is strongly
linear with respect to the initial wealth, with or without labor income. When
it comes to optimal annuitization, we find that the wage and labor rates may
play opposite roles. However, their impact is mediated by the leverage ratio.
"
2202.05671,2024-10-22,Black-Scholes-Merton Option Pricing Revisited: Did we Find a Fatal Flaw?,"  The option pricing formula of Black and Scholes (1973) hinges on the
continuous-time self-financing condition, which is a special case of the
continuous-time budget equation of Merton (1971). The self-financing condition
is believed to formalize the economic concept of portfolio rebalancing without
inflows or outflows of external funds, but was never formally derived in
continuous time. Moreover, and even more problematically, we discover a timing
mistake in the model of Merton (1971) and show that his self-financing
condition is misspecified both in discrete and continuous time. Our results
invalidate seminal contributions to the literature, including the budget
equation of Merton (1971), the option pricing formula of Black and Scholes
(1973), the continuous trading model of Harrison and Pliska (1981), and the
binomial option pricing model of Cox, Ross and Rubinstein (1979). We also show
that Black and Scholes (1973) and alternative derivations of their formula
implicitly assumed the replication result.
"
2202.06666,2024-07-08,"Two is better than one: Regularized shrinkage of large minimum variance
  portfolio","  In this paper we construct a shrinkage estimator of the global minimum
variance (GMV) portfolio by a combination of two techniques: Tikhonov
regularization and direct shrinkage of portfolio weights. More specifically, we
employ a double shrinkage approach, where the covariance matrix and portfolio
weights are shrunk simultaneously. The ridge parameter controls the stability
of the covariance matrix, while the portfolio shrinkage intensity shrinks the
regularized portfolio weights to a predefined target. Both parameters
simultaneously minimize with probability one the out-of-sample variance as the
number of assets $p$ and the sample size $n$ tend to infinity, while their
ratio $p/n$ tends to a constant $c>0$. This method can also be seen as the
optimal combination of the well-established linear shrinkage approach of Ledoit
and Wolf (2004, JMVA) and the shrinkage of the portfolio weights by Bodnar et
al. (2018, EJOR). No specific distribution is assumed for the asset returns
except of the assumption of finite $4+\varepsilon$ moments. The performance of
the double shrinkage estimator is investigated via extensive simulation and
empirical studies. The suggested method significantly outperforms its
predecessor (without regularization) and the nonlinear shrinkage approach in
terms of the out-of-sample variance, Sharpe ratio and other empirical measures
in the majority of scenarios. Moreover, it obeys the most stable portfolio
weights with uniformly smallest turnover.
"
2202.06782,2022-02-15,"Wasserstein Solution Quality and the Quantum Approximate Optimization
  Algorithm: A Portfolio Optimization Case Study","  Optimizing of a portfolio of financial assets is a critical industrial
problem which can be approximately solved using algorithms suitable for quantum
processing units (QPUs). We benchmark the success of this approach using the
Quantum Approximate Optimization Algorithm (QAOA); an algorithm targeting
gate-model QPUs. Our focus is on the quality of solutions achieved as
determined by the Normalized and Complementary Wasserstein Distance, $\eta$,
which we present in a manner to expose the QAOA as a transporter of
probability. Using $\eta$ as an application specific benchmark of performance,
we measure it on selection of QPUs as a function of QAOA circuit depth $p$. At
$n = 2$ (2 qubits) we find peak solution quality at $p=5$ for most systems and
for $n = 3$ this peak is at $p=4$ on a trapped ion QPU. Increasing solution
quality with $p$ is also observed using variants of the more general Quantum
Alternating Operator Ans\""{a}tz at $p=2$ for $n = 2$ and $3$ which has not been
previously reported. In identical measurements, $\eta$ is observed to be
variable at a level exceeding the noise produced from the finite number of
shots. This suggests that variability itself should be regarded as a QPU
performance benchmark for given applications. While studying the ideal
execution of QAOA, we find that $p=1$ solution quality degrades when the
portfolio budget $B$ approaches $n/2$ and increases when $B \approx 1$ or
$n-1$. This trend directly corresponds to the binomial coefficient $nCB$ and is
connected with the recently reported phenomenon of reachability deficits.
Derivative-requiring and derivative-free classical optimizers are benchmarked
on the basis of the achieved $\eta$ beyond $p=1$ to find that derivative-free
optimizers are generally more effective for the given computational resources,
problem sizes and circuit depths.
"
2202.08148,2022-02-17,"Optimal market completion through financial derivatives with
  applications to volatility risk","  This paper investigates the optimal choices of financial derivatives to
complete a financial market in the framework of stochastic volatility (SV)
models. We introduce an efficient and accurate simulation-based method,
applicable to generalized diffusion models, to approximate the optimal
derivatives-based portfolio strategy. We build upon the double optimization
approach (i.e. expected utility maximization and risk exposure minimization)
proposed in Escobar-Anel et al. (2022); demonstrating that strangle options are
the best choices for market completion within equity options. Furthermore, we
explore the benefit of using volatility index derivatives and conclude that
they could be more convenient substitutes when only long-term maturity equity
options are available.
"
2202.08921,2023-09-07,"Portfolio Optimization based on Neural Networks Sensitivities from
  Assets Dynamics respect Common Drivers","  We present a framework for modeling asset and portfolio dynamics,
incorporating this information into portfolio optimization. For this framework,
we introduce the Commonality Principle, providing a solution for the optimal
selection of portfolio drivers as the common drivers. Portfolio constituent
dynamics are modeled by Partial Differential Equations, and solutions
approximated with neural networks. Sensitivities with respect to the common
drivers are obtained via Automatic Adjoint Differentiation. Information on
asset dynamics is incorporated via sensitivities into portfolio optimization.
Portfolio constituents are embedded into the space of sensitivities with
respect to their common drivers, and a distance matrix in this space called the
Sensitivity matrix is used to solve the convex optimization for
diversification. The sensitivity matrix measures the similarity of the
projections of portfolio constituents on a vector space formed by common
drivers' returns and is used to optimize for diversification on both
idiosyncratic and systematic risks while adding directionality and future
behavior information via returns dynamics. For portfolio optimization, we
perform hierarchical clustering on the sensitivity matrix. To the best of the
author's knowledge, this is the first time that sensitivities' dynamics
approximated with neural networks have been used for portfolio optimization.
Secondly, that hierarchical clustering on a matrix of sensitivities is used to
solve the convex optimization problem and incorporate the hierarchical
information of these sensitivities. Thirdly, public and listed variables can be
used to obtain maximum idiosyncratic and systematic diversification by means of
the sensitivity space with respect to optimal portfolio drivers. We reach
over-performance in many experiments with respect to all other out-of-sample
methods for different markets and real datasets.
"
2202.09939,2022-02-22,"Schr\""{o}dinger Risk Diversification Portfolio","  The mean-variance portfolio that considers the trade-off between expected
return and risk has been widely used in the problem of asset allocation for
multi-asset portfolios. However, since it is difficult to estimate the expected
return and the out-of-sample performance of the mean-variance portfolio is
poor, risk-based portfolio construction methods focusing only on risk have been
proposed, and are attracting attention mainly in practice. In terms of risk,
asset fluctuations that make up the portfolio are thought to have common
factors behind them, and principal component analysis, which is a dimension
reduction method, is applied to extract the factors. In this study, we propose
the Schr\""{o}dinger risk diversification portfolio as a factor risk
diversifying portfolio using Schr\""{o}dinger principal component analysis that
applies the Schr\""{o}dinger equation in quantum mechanics. The Schr\""{o}dinger
principal component analysis can accurately estimate the factors even if the
sample points are unequally spaced or in a small number, thus we can make
efficient risk diversification. The proposed method was verified to outperform
the conventional risk parity and other risk diversification portfolio
constructions.
"
2202.10265,2022-02-22,Yields: The Galapagos Syndrome Of Cryptofinance,"  In this chapter structures that generate yield in cryptofinance will be
analyzed and related to leverage. While the majority of crypto-assets do not
have intrinsic yields in and of themselves, similar to cash holdings of fiat
currency, revolutionary innovation based on smart contracts, which enable
decentralised finance, does generate return. Examples include lending or
providing liquidity to an automated market maker on a decentralised exchange,
as well as performing block formation in a proof of stake blockchain. On
centralised exchanges, perpetual and finite duration futures can trade at a
premium or discount to the spot market for extended periods with one side of
the transaction earning a yield. Disparities in yield exist between products
and venues as a result of market segmentation and risk profile differences.
Cryptofinance was initially shunned by legacy finance and developed
independently. This led to curious and imaginative adaptions, reminiscent of
Darwin's finches, including stable coins for dollar transfers, perpetuals for
leverage, and a new class of exchanges for trading and investment.
"
2202.10340,2022-02-22,Darwin Among the Cryptocurrencies,"  The paper highlights some commonalities between the development of
cryptocurrencies and the evolution of ecosystems. Concepts from evolutionary
finance embedded in toy models consistent with stylized facts are employed to
understand what survival of the fittest means in cryptofinance. Stylized facts
for ownership, trading volume and market capitalization of cryptocurrencies are
selectively presented in terms of scaling laws.
"
2202.10623,2022-06-22,"On financial market correlation structures and diversification benefits
  across and within equity sectors","  We study how to assess the potential benefit of diversifying an equity
portfolio by investing within and across equity sectors. We analyse 20 years of
US stock price data, which includes the global financial crisis (GFC) and the
COVID-19 market crash, as well as periods of financial stability, to determine
the `all weather' nature of equity portfolios. We establish that one may use
the leading eigenvalue of the cross-correlation matrix of log returns as well
as graph-theoretic diagnostics such as modularity to quantify the collective
behaviour of the market or a subset of it. We confirm that financial crises are
characterised by a high degree of collective behaviour of equities, whereas
periods of financial stability exhibit less collective behaviour. We argue that
during times of increased collective behaviour, risk reduction via sector-based
portfolio diversification is ineffective. Using the degree of collectivity as a
proxy for the benefit of diversification, we perform an extensive sampling of
equity portfolios to confirm the old financial adage that 30-40 stocks provide
sufficient diversification. Using hierarchical clustering, we discover a `best
value' equity portfolio for diversification consisting of 36 equities sampled
uniformly from 9 sectors. We further show that it is typically more beneficial
to diversify across sectors rather than within. Our findings have implications
for cost-conscious retail investors seeking broad diversification across equity
markets.
"
2202.10721,2022-02-23,"Risk Parity Portfolios with Skewness Risk: An Application to Factor
  Investing and Alternative Risk Premia","  This article develops a model that takes into account skewness risk in risk
parity portfolios. In this framework, asset returns are viewed as stochastic
processes with jumps or random variables generated by a Gaussian mixture
distribution. This dual representation allows us to show that skewness and jump
risks are equivalent. As the mixture representation is simple, we obtain
analytical formulas for computing asset risk contributions of a given
portfolio. Therefore, we define risk budgeting portfolios and derive existence
and uniqueness conditions. We then apply our model to the
equity/bond/volatility asset mix policy. When assets exhibit jump risks like
the short volatility strategy, we show that skewness-based risk parity
portfolios produce better allocation than volatility-based risk parity
portfolios. Finally, we illustrate how this model is suitable to manage the
skewness risk of long-only equity factor portfolios and to allocate between
alternative risk premia.
"
2202.10760,2022-02-23,"Crypto-assets better safe-havens than Gold during Covid-19: The case of
  European indices","  As the first crisis faced by Crypto-assets, Covid-19 updated the debate about
their safehaven properties. Our paper tries to analyze the safe-haven
properties of Crypto-assets and Gold for European assets. We find that Gold has
not been more efficient than Cryptoassets (Tether, Cardano and Dogecoin) as
safe-haven during the market crash due to Covid-19 in March 2020. We also found
that during the study period Bitcoin, Ethereum, Litecoin and Ripple were just
diversifiers for the European indices. Finally, Tether, Cardano and Dogecoin
showed hedging properties like Gold before and after the market crash.
"
2202.10817,2023-07-13,Canonical Portfolios: Optimal Asset and Signal Combination,"  This paper presents a novel framework for analyzing the optimal asset and
signal combination problem. Our approach builds upon the dynamic portfolio
selection problem introduced by Brandt and Santa-Clara (2006) and consists of
two stages. First, we reformulate their original investment problem into a
tractable one that allows us to derive a closed-form expression for the optimal
portfolio policy that is scalable to large cross-sectional financial
applications. Second, we recast the problem of selecting a portfolio of
correlated assets and signals into selecting a set of uncorrelated managed
portfolios through the lens of Canonical Correlation Analysis of Hotelling
(1936). The new investment environment of uncorrelated managed portfolios
offers unique economic insights into the joint correlation structure of our
optimal portfolio policy. We also operationalize our theoretical framework to
bridge the gap between theory and practice, showcasing the improved performance
of our proposed method over natural competing benchmarks.
"
2203.00148,2022-05-05,Improved iterative methods for solving risk parity portfolio,"  Risk parity, also known as equal risk contribution, has recently gained
increasing attention as a portfolio allocation method. However, solving
portfolio weights must resort to numerical methods as the analytic solution is
not available. This study improves two existing iterative methods: the cyclical
coordinate descent (CCD) and Newton methods. We enhance the CCD method by
simplifying the formulation using a correlation matrix and imposing an
additional rescaling step. We also suggest an improved initial guess inspired
by the CCD method for the Newton method. Numerical experiments show that the
improved CCD method performs the best and is approximately three times faster
than the original CCD method, saving more than 40% of the iterations.
"
2203.01326,2022-03-04,"Precise Stock Price Prediction for Optimized Portfolio Design Using an
  LSTM Model","  Accurate prediction of future prices of stocks is a difficult task to
perform. Even more challenging is to design an optimized portfolio of stocks
with the identification of proper weights of allocation to achieve the
optimized values of return and risk. We present optimized portfolios based on
the seven sectors of the Indian economy. The past prices of the stocks are
extracted from the web from January 1, 2016, to December 31, 2020. Optimum
portfolios are designed on the selected seven sectors. An LSTM regression model
is also designed for predicting future stock prices. Five months after the
construction of the portfolios, i.e., on June 1, 2021, the actual and predicted
returns and risks of each portfolio are computed. The predicted and the actual
returns indicate the very high accuracy of the LSTM model.
"
2203.04053,2025-05-21,"Risk sharing in equity-linked insurance products: Stackelberg
  equilibrium between an insurer and a reinsurer","  We study the optimal investment-reinsurance problem in the context of
equity-linked insurance products. Such products often have a capital guarantee,
which can motivate insurers to purchase reinsurance. Since a reinsurance
contract implies an interaction between the insurer and the reinsurer, we model
the optimization problem as a Stackelberg game. The reinsurer is the leader in
the game and maximizes its expected utility by selecting its optimal investment
strategy and a safety loading in the reinsurance contract it offers to the
insurer. The reinsurer can assess how the insurer will rationally react on each
action of the reinsurer. The insurance company is the follower and maximizes
its expected utility by choosing its investment strategy and the amount of
reinsurance the company purchases at the price offered by the reinsurer. In
this game, we derive the Stackelberg equilibrium for general utility functions.
For power utility functions, we calculate the equilibrium explicitly and find
that the reinsurer selects the largest reinsurance premium such that the
insurer may still buy the maximal amount of reinsurance. Since in the
equilibrium the insurer is indifferent in the amount of reinsurance, in
practice, the reinsurer should consider charging a smaller reinsurance premium
than the equilibrium one. Therefore, we propose several criteria for choosing
such a discount rate and investigate its wealth-equivalent impact on the
expected utility of each party.
"
2203.05673,2022-03-14,"Fusion of Sentiment and Asset Price Predictions for Portfolio
  Optimization","  The fusion of public sentiment data in the form of text with stock price
prediction is a topic of increasing interest within the financial community.
However, the research literature seldom explores the application of investor
sentiment in the Portfolio Selection problem. This paper aims to unpack and
develop an enhanced understanding of the sentiment aware portfolio selection
problem. To this end, the study uses a Semantic Attention Model to predict
sentiment towards an asset. We select the optimal portfolio through a
sentiment-aware Long Short Term Memory (LSTM) recurrent neural network for
price prediction and a mean-variance strategy. Our sentiment portfolio
strategies achieved on average a significant increase in revenue above the
non-sentiment aware models. However, the results show that our strategy does
not outperform traditional portfolio allocation strategies from a stability
perspective. We argue that an improved fusion of sentiment prediction with a
combination of price prediction and portfolio optimization leads to an enhanced
portfolio selection strategy.
"
2203.07865,2022-03-16,Characteristics-driven returns in equilibrium,"  We reverse-engineer the equilibrium construction process of asset prices in
order to obtain returns which depend on firm characteristics, possibly in a
linear fashion. One key requirement is that agents must have demands that rely
separately on firm characteristics and on the log-price of assets. Market
clearing via exogenous (non-factor driven) supply, combined with linear demands
in characteristics, yields the sought form. The coefficients in the resulting
linear expressions are scaled net aggregate demands for characteristics, as
well as their variations, and both can be jointly estimated via panel
regressions. Conditions underpinning asset pricing anomalies are derived and
underline the theoretical importance of the links between characteristics.
Empirically, when the number of characteristics is small, the value and
momentum anomalies are mostly driven by firm-specific fixed-effects, i.e.,
latent demands, which highlights the shortcomings of low-dimensional models.
"
2203.11318,2022-03-23,"Deep Reinforcement Learning and Convex Mean-Variance Optimisation for
  Portfolio Management","  Traditional portfolio management methods can incorporate specific investor
preferences but rely on accurate forecasts of asset returns and covariances.
Reinforcement learning (RL) methods do not rely on these explicit forecasts and
are better suited for multi-stage decision processes. To address limitations of
the evaluated research, experiments were conducted on three markets in
different economies with different overall trends. By incorporating specific
investor preferences into our RL models' reward functions, a more comprehensive
comparison could be made to traditional methods in risk-return space.
Transaction costs were also modelled more realistically by including nonlinear
changes introduced by market volatility and trading volume. The results of this
study suggest that there can be an advantage to using RL methods compared to
traditional convex mean-variance optimisation methods under certain market
conditions. Our RL models could significantly outperform traditional
single-period optimisation (SPO) and multi-period optimisation (MPO) models in
upward trending markets, but only up to specific risk limits. In sideways
trending markets, the performance of SPO and MPO models can be closely matched
by our RL models for the majority of the excess risk range tested. The specific
market conditions under which these models could outperform each other
highlight the importance of a more comprehensive comparison of Pareto optimal
frontiers in risk-return space. These frontiers give investors a more granular
view of which models might provide better performance for their specific risk
tolerance or return targets.
"
2203.13740,2022-03-28,"A generalized precision matrix for t-Student distributions in portfolio
  optimization","  The Markowitz model is still the cornerstone of modern portfolio theory. In
particular, when focusing on the minimum-variance portfolio, the covariance
matrix or better its inverse, the so-called precision matrix, is the only input
required. So far, most scholars worked on improving the estimation of the
input, however little attention has been given to the limitations of the
inverse covariance matrix when capturing the dependence structure in a
non-Gaussian setting. While the precision matrix allows to correctly understand
the conditional dependence structure of random vectors in a Gaussian setting,
the inverse of the covariance matrix might not necessarily result in a reliable
source of information when Gaussianity fails. In this paper, exploiting the
local dependence function, different definitions of the generalized precision
matrix (GPM), which holds for a general class of distributions, are provided.
In particular, we focus on the multivariate t-Student distribution and point
out that the interaction in random vectors does not depend only on the inverse
of the covariance matrix, but also on additional elements. We test the
performance of the proposed GPM using a minimum-variance portfolio set-up by
considering S\&P 100 and Fama and French industry data. We show that portfolios
relying on the GPM often generate statistically significant lower out-of-sample
variances than state-of-art methods.
"
2203.13766,2022-03-28,"Straightening skewed markets with an index tracking optimizationless
  portfolio","  Among professionals and academics alike, it is well known that active
portfolio management is unable to provide additional risk-adjusted returns
relative to their benchmarks. For this reason, passive wealth management has
emerged in recent decades to offer returns close to benchmarks at a lower cost.
In this article, we first refine the existing results on the theoretical
properties of oblique Brownian motion. Then, assuming that the returns follow
skew geometric Brownian motions and that they are correlated, we describe some
statistical properties for the \emph{ex-post}, the \emph{ex-ante} tracking
errors, and the forecasted tracking portfolio. To this end, we develop an
innovative statistical methodology, based on a benchmark-asset principal
component factorization, to determine a tracking portfolio that replicates the
performance of a benchmark by investing in a subset of the investable universe.
This strategy, named hybrid Principal Component Analysis (hPCA), is applied
both on normal and skew distributions. In the case of skew-normal returns, we
propose a framework for calibrating the model parameters, based on the maximum
likelihood estimation method. For testing and validation, we compare four
alternative models for index tracking. The first two are based on the hPCA when
returns are assumed to be normal or skew-normal. The third model adopts a
standard optimization-based approach and the last one is used in the financial
sector by some practitioners. For validation and testing, we present a thorough
comparison of these strategies on real-world data, both in terms of performance
and computational efficiency. A noticeable result is that, not only, the
suggested lean PCA-based portfolio selection approach compares well versus
cumbersome algorithms for optimization-based portfolios, but, also, it could
provide a better service to the asset management industry.
"
2203.13999,2022-05-06,Distributional Robust Portfolio Construction based on Investor Aversion,"  In behavioral finance, aversion affects investors' judgment of future
uncertainty when profit and loss occur. Considering investors' aversion to loss
and risk, and the ambiguous uncertainty characterizing asset returns, we
construct a distributional robust portfolio model (DRP) under the condition
that the distribution of risky asset returns is unknown. Specifically, our
objective is to find an optimal portfolio of assets that maximizes the
worst-case utility level on the Wasserstein ball, which is centered on the
empirical distribution of sample returns and the radius of the ball quantifies
the investor's ambiguity level. The model is also formulated as a mixed-integer
quadratic programming problem with cardinality constraints. In addition, we
propose a hybrid algorithm to improve the efficiency of the solution and make
it more suitable for large-scale problems. The distributional robust portfolio
model considering aversion is empirically tested for superior performance in
asset allocation, and we also compare common asset allocation strategies to
further enhance the credibility of the portfolio.
"
2204.00204,2022-04-04,"LoCoV: low dimension covariance voting algorithm for portfolio
  optimization","  Minimum-variance portfolio optimizations rely on accurate covariance
estimator to obtain optimal portfolios. However, it usually suffers from large
error from sample covariance matrix when the sample size $n$ is not
significantly larger than the number of assets $p$. We analyze the random
matrix aspects of portfolio optimization and identify the order of errors in
sample optimal portfolio weight and show portfolio risk are underestimated when
using samples. We also provide LoCoV (low dimension covariance voting)
algorithm to reduce error inherited from random samples. From various
experiments, LoCoV is shown to outperform the classical method by a large
margin.
"
2204.00530,2022-11-23,"Consumption-investment decisions with endogenous reference point and
  drawdown constraint","  We propose a consumption-investment decision model where past consumption
peak $h$ plays a crucial role. There are two important consumption levels: the
lowest constrained level and a reference level, at which the risk aversion in
terms of consumption rate is changed. We solve this stochastic control problem
and derive the value function, optimal consumption plan, and optimal investment
strategy in semi-explicit forms. We find five important thresholds of wealth,
all as functions of $h$, and most of them are nonlinear functions. As can be
seen from numerical results and theoretical analysis, this intuitive and simple
model has significant economic implications, and there are at least three
important predictions: the marginal propensity to consume out of wealth is
generally decreasing but can be increasing for intermediate wealth levels, and
it jumps inversely proportional to the risk aversion at the reference point;
the implied relative risk aversion is roughly a smile in wealth; the welfare of
the poor is more vulnerable to wealth shocks than the wealthy. Moreover,
locally changing the risk aversion influences the optimal strategies globally,
revealing some risk allocation behaviors.
"
2204.01850,2022-04-06,"Robust Portfolio Design and Stock Price Prediction Using an Optimized
  LSTM Model","  Accurate prediction of future prices of stocks is a difficult task to
perform. Even more challenging is to design an optimized portfolio with weights
allocated to the stocks in a way that optimizes its return and the risk. This
paper presents a systematic approach towards building two types of portfolios,
optimum risk, and eigen, for four critical economic sectors of India. The
prices of the stocks are extracted from the web from Jan 1, 2016, to Dec 31,
2020. Sector-wise portfolios are built based on their ten most significant
stocks. An LSTM model is also designed for predicting future stock prices. Six
months after the construction of the portfolios, i.e., on Jul 1, 2021, the
actual returns and the LSTM-predicted returns for the portfolios are computed.
A comparison of the predicted and the actual returns indicate a high accuracy
level of the LSTM model.
"
2204.02757,2023-06-13,Risk budget portfolios with convex Non-negative Matrix Factorization,"  We propose a portfolio allocation method based on risk factor budgeting using
convex Nonnegative Matrix Factorization (NMF). Unlike classical factor
analysis, PCA, or ICA, NMF ensures positive factor loadings to obtain
interpretable long-only portfolios. As the NMF factors represent separate
sources of risk, they have a quasi-diagonal correlation matrix, promoting
diversified portfolio allocations. We evaluate our method in the context of
volatility targeting on two long-only global portfolios of cryptocurrencies and
traditional assets. Our method outperforms classical portfolio allocations
regarding diversification and presents a better risk profile than hierarchical
risk parity (HRP). We assess the robustness of our findings using Monte Carlo
simulation.
"
2204.03798,2022-04-11,"Log-optimal portfolio after a random time: Existence, description and
  sensitivity analysis","  In this paper, we consider an informational market model with two flows of
informations. The smallest flow F, which is available to all agents, is the
filtration of the initial market model(S,F,P), where S is the assets' prices
and P is a probability measure. The largest flow G contains additional
information about the occurrence of a random time T. This setting covers credit
risk theory where T models the default time of a firm, and life insurance where
T represents the death time of an insured. For the model (S-S^T,G,P), we
address the log-optimal portfolio problem in many aspects. In particular, we
answer the following questions and beyond: 1) What are the necessary and
sufficient conditions for the existence of log-optimal portfolio of the model
under consideration? 2) what are the various type of risks induced by T that
affect this portfolio and how? 3) What are the factors that completely describe
the sensitivity of the log-portfolio to the parameters of T? The answers to
these questions and other related discussions definitely complement the work of
Choulli and Yansori [12] which deals with the stopped model (S^T,G).
"
2204.13398,2022-04-29,Portfolio Diversification Revisited,"  We relax a number of assumptions in Alexeev and Tapon (2012) in order to
account for non-normally distributed, skewed, multi-regime, and leptokurtic
asset return distributions. We calibrate a Markov-modulated Levy process model
to equity market data to demonstrate the merits of our approach, and show that
the calibrated models do a good job of matching the empirical moments. Finally,
we argue that much of the related literature on portfolio diversification
relies on assumptions that are in tension with certain observable regularities
and which, if ignored, may lead to underestimation of risk.
"
2205.01012,2022-05-03,Excess Out-of-Sample Risk and Fleeting Modes,"  Using Random Matrix Theory, we propose a universal and versatile tool to
reveal the existence of ""fleeting modes"", i.e. portfolios that carry
statistically significant excess risk, signalling ex-post a change in the
correlation structure in the underlying asset space. Our proposed test is
furthermore independent of the ""true"" (but unknown) underlying correlation
structure. We show empirically that such fleeting modes exist both in futures
markets and in equity markets. We proposed a metric to quantify the alignment
between known factors and fleeting modes and identify momentum as a source of
excess risk in the equity space.
"
2205.04563,2022-08-12,"Portfolio Construction with Gaussian Mixture Returns and Exponential
  Utility via Convex Optimization","  We consider the problem of choosing an optimal portfolio, assuming the asset
returns have a Gaussian mixture (GM) distribution, with the objective of
maximizing expected exponential utility. In this paper we show that this
problem is convex, and readily solved exactly using domain-specific languages
for convex optimization, without the need for sampling or scenarios. We then
show how the closely related problem of minimizing entropic value at risk can
also be formulated as a convex optimization problem.
"
2205.08614,2024-07-25,"Well Posedness of Utility Maximization Problems Under Partial
  Information in a Market with Gaussian Drift","  This paper investigates well posedness of utility maximization problems for
financial markets where stock returns depend on a hidden Gaussian mean
reverting drift process. Since that process is potentially unbounded, well
posedness cannot be guaranteed for utility functions which are not bounded from
above. For power utility with relative risk aversion smaller than that of
log-utility this leads to restrictions on the choice of model parameters such
as the investment horizon and parameters controlling the variance of the asset
price and drift processes. We derive sufficient conditions to the model
parameters leading to bounded maximum expected utility of terminal wealth for
models with full and partial information.
"
2205.08743,2022-05-19,"Mean-variance portfolio selection with dynamic attention behavior in a
  hidden Markov model","  In this paper, we study closed-loop equilibrium strategies for mean-variance
portfolio selection problem in a hidden Markov model with dynamic attention
behavior. In addition to the investment strategy, the investor's attention to
news is introduced as a control of the accuracy of the news signal process. The
objective is to find equilibrium strategies by numerically solving an extended
HJB equation by using Markov chain approximation method. An iterative algorithm
is constructed and its convergence is established. Numerical examples are also
provided to illustrate the results.
"
2205.08850,2023-03-14,Robust Distortion Risk Measures,"  The robustness of risk measures to changes in underlying loss distributions
(distributional uncertainty) is of crucial importance in making well-informed
decisions. In this paper, we quantify, for the class of distortion risk
measures with an absolutely continuous distortion function, its robustness to
distributional uncertainty by deriving its largest (smallest) value when the
underlying loss distribution has a known mean and variance and, furthermore,
lies within a ball - specified through the Wasserstein distance - around a
reference distribution. We employ the technique of isotonic projections to
provide for these distortion risk measures a complete characterisation of sharp
bounds on their value, and we obtain quasi-explicit bounds in the case of
Value-at-Risk and Range-Value-at-Risk. We extend our results to account for
uncertainty in the first two moments and provide applications to portfolio
optimisation and to model risk assessment.
"
2205.12242,2022-05-25,Fundamental Portfolio Outperforms the Market Portfolio,"  There is substantial empirical evidence showing the fundamental portfolio
outperforming the market portfolio. Here a theoretical foundation is laid that
supports this empirical research. Assuming stock prices revert around
fundamental prices with sufficient strength and symmetry, the fundamental
portfolio outperforms the market portfolio in expectation. If reversion toward
the fundamental price is not sufficiently strong, then the fundamental
portfolio underperforms the market portfolio in expectation.
"
2205.14699,2022-09-27,Managing Risk in DeFi Portfolios,"  Decentralized Finance (DeFi) is a new financial industry built on blockchain
technologies. Decentralized financial services have consequently increased the
ability to lend, borrow, and invest in decentralized investment vehicles,
allowing investors to bypass third party intermediaries. DeFi's promise is to
reduce the cost of transaction and management fees whilst increasing trust
between agents of the Financial Industry 3.0. This paper provides an overview
of the different components of DeFi, as well as the risks involved in investing
through these new vehicles. We will also propose an allocation methodology
which will integrate and quantify these risks.
"
2205.15056,2022-05-31,"Stock Trading Optimization through Model-based Reinforcement Learning
  with Resistance Support Relative Strength","  Reinforcement learning (RL) is gaining attention by more and more researchers
in quantitative finance as the agent-environment interaction framework is
aligned with decision making process in many business problems. Most of the
current financial applications using RL algorithms are based on model-free
method, which still faces stability and adaptivity challenges. As lots of
cutting-edge model-based reinforcement learning (MBRL) algorithms mature in
applications such as video games or robotics, we design a new approach that
leverages resistance and support (RS) level as regularization terms for action
in MBRL, to improve the algorithm's efficiency and stability. From the
experiment results, we can see RS level, as a market timing technique, enhances
the performance of pure MBRL models in terms of various measurements and
obtains better profit gain with less riskiness. Besides, our proposed method
even resists big drop (less maximum drawdown) during COVID-19 pandemic period
when the financial market got unpredictable crisis. Explanations on why control
of resistance and support level can boost MBRL is also investigated through
numerical experiments, such as loss of actor-critic network and prediction
error of the transition dynamical model. It shows that RS indicators indeed
help the MBRL algorithms to converge faster at early stage and obtain smaller
critic loss as training episodes increase.
"
2205.15905,2022-06-01,"Cone-constrained Monotone Mean-Variance Portfolio Selection Under
  Diffusion Models","  We consider monotone mean-variance (MMV) portfolio selection problems with a
conic convex constraint under diffusion models, and their counterpart problems
under mean-variance (MV) preferences. We obtain the precommitted optimal
strategies to both problems in closed form and find that they coincide, without
and with the presence of the conic constraint. This result generalizes the
equivalence between MMV and MV preferences from non-constrained cases to a
specific constrained case. A comparison analysis reveals that the orthogonality
property under the conic convex set is a key to ensuring the equivalence
result.
"
2206.01064,2022-06-03,Adaptive Robust Online Portfolio Selection,"  The online portfolio selection (OLPS) problem differs from classical
portfolio model problems, as it involves making sequential investment
decisions. Many OLPS strategies described in the literature capture market
movement based on various beliefs and are shown to be profitable. In this
paper, we propose a robust optimization (RO)-based strategy that takes
transaction costs into account. Moreover, unlike existing studies that
calibrate model parameters from benchmark data sets, we develop a novel
adaptive scheme that decides the parameters sequentially. With a wide range of
parameters as input, our scheme captures market uptrend and protects against
market downtrend while controlling trading frequency to avoid excessive
transaction costs. We numerically demonstrate the advantages of our adaptive
scheme against several benchmarks under various settings. Our adaptive scheme
may also be useful in general sequential decision-making problems. Finally, we
compare the performance of our strategy with that of existing OLPS strategies
using both benchmark and newly collected data sets. Our strategy outperforms
these existing OLPS strategies in terms of cumulative returns and competitive
Sharpe ratios across diversified data sets, demonstrating its
adaptability-driven superiority.
"
2206.02854,2022-06-08,ESG-Valued Portfolio Optimization and Dynamic Asset Pricing,"  ESG ratings provide a quantitative measure for socially responsible
investment. We present a unified framework for incorporating numeric ESG
ratings into dynamic pricing theory. Specifically, we introduce an ESG-valued
return that is a linearly constrained transformation of financial return and
ESG score. This leads to a more complex portfolio optimization problem in a
space governed by reward, risk and ESG score. The framework preserves the
traditional risk aversion parameter and introduces an ESG affinity parameter.
We apply this framework to develop ESG-valued: portfolio optimization; capital
market line; risk measures; option pricing; and the computation of shadow
riskless rates.
"
2206.03246,2022-06-08,Portfolio Transformer for Attention-Based Asset Allocation,"  Traditional approaches to financial asset allocation start with returns
forecasting followed by an optimization stage that decides the optimal asset
weights. Any errors made during the forecasting step reduce the accuracy of the
asset weightings, and hence the profitability of the overall portfolio. The
Portfolio Transformer (PT) network, introduced here, circumvents the need to
predict asset returns and instead directly optimizes the Sharpe ratio, a
risk-adjusted performance metric widely used in practice. The PT is a novel
end-to-end portfolio optimization framework, inspired by the numerous successes
of attention mechanisms in natural language processing. With its full
encoder-decoder architecture, specialized time encoding layers, and gating
components, the PT has a high capacity to learn long-term dependencies among
portfolio assets and hence can adapt more quickly to changing market conditions
such as the COVID-19 pandemic. To demonstrate its robustness, the PT is
compared against other algorithms, including the current LSTM-based state of
the art, on three different datasets, with results showing that it offers the
best risk-adjusted performance.
"
2206.03608,2022-09-22,Predictable Forward Performance Processes in Complete Markets,"  We establish existence of Predictable Forward Performance Processes (PFPPs)
in complete markets, which has been previously shown only in the binomial
setting. Our market model can be a discrete-time or a continuous-time model,
and the investment horizon can be finite or infinite. We show that the main
step in construction of PFPPs is solving a one-period problem involving an
integral equation, which is the counterpart of the functional equation found in
the binomial case. Although this integral equation has been partially studied
in the existing literature, we provide a new solution method using the Fourier
transform for tempered distributions. We also provide closed-form solutions for
PFPPs with inverse marginal functions that are completely monotonic and
establish uniqueness of PFPPs within this class. We apply our results to two
special cases. The first one is the binomial market and is included to relate
our work to the existing literature. The second example considers a generalized
Black-Scholes model which, to the best of our knowledge, is a new result.
"
2206.05134,2022-06-13,Distributionally Robust End-to-End Portfolio Construction,"  We propose an end-to-end distributionally robust system for portfolio
construction that integrates the asset return prediction model with a
distributionally robust portfolio optimization model. We also show how to learn
the risk-tolerance parameter and the degree of robustness directly from data.
End-to-end systems have an advantage in that information can be communicated
between the prediction and decision layers during training, allowing the
parameters to be trained for the final task rather than solely for predictive
performance. However, existing end-to-end systems are not able to quantify and
correct for the impact of model risk on the decision layer. Our proposed
distributionally robust end-to-end portfolio selection system explicitly
accounts for the impact of model risk. The decision layer chooses portfolios by
solving a minimax problem where the distribution of the asset returns is
assumed to belong to an ambiguity set centered around a nominal distribution.
Using convex duality, we recast the minimax problem in a form that allows for
efficient training of the end-to-end system.
"
2206.05835,2022-06-14,"Deep Reinforcement Learning for Optimal Investment and Saving Strategy
  Selection in Heterogeneous Profiles: Intelligent Agents working towards
  retirement","  The transition from defined benefit to defined contribution pension plans
shifts the responsibility for saving toward retirement from governments and
institutions to the individuals. Determining optimal saving and investment
strategy for individuals is paramount for stable financial stance and for
avoiding poverty during work-life and retirement, and it is a particularly
challenging task in a world where form of employment and income trajectory
experienced by different occupation groups are highly diversified. We introduce
a model in which agents learn optimal portfolio allocation and saving
strategies that are suitable for their heterogeneous profiles. We use deep
reinforcement learning to train agents. The environment is calibrated with
occupation and age dependent income evolution dynamics. The research focuses on
heterogeneous income trajectories dependent on agent profiles and incorporates
the behavioural parameterisation of agents. The model provides a flexible
methodology to estimate lifetime consumption and investment choices for
heterogeneous profiles under varying scenarios.
"
2206.05910,2022-06-14,"Safe-FinRL: A Low Bias and Variance Deep Reinforcement Learning
  Implementation for High-Freq Stock Trading","  In recent years, many practitioners in quantitative finance have attempted to
use Deep Reinforcement Learning (DRL) to build better quantitative trading (QT)
strategies. Nevertheless, many existing studies fail to address several serious
challenges, such as the non-stationary financial environment and the bias and
variance trade-off when applying DRL in the real financial market. In this
work, we proposed Safe-FinRL, a novel DRL-based high-freq stock trading
strategy enhanced by the near-stationary financial environment and low bias and
variance estimation. Our main contributions are twofold: firstly, we separate
the long financial time series into the near-stationary short environment;
secondly, we implement Trace-SAC in the near-stationary financial environment
by incorporating the general retrace operator into the Soft Actor-Critic.
Extensive experiments on the cryptocurrency market have demonstrated that
Safe-FinRL has provided a stable value estimation and a steady policy
improvement and reduced bias and variance significantly in the near-stationary
financial environment.
"
2206.06109,2023-01-06,Markov Decision Processes under Model Uncertainty,"  We introduce a general framework for Markov decision problems under model
uncertainty in a discrete-time infinite horizon setting. By providing a dynamic
programming principle we obtain a local-to-global paradigm, namely solving a
local, i.e., a one time-step robust optimization problem leads to an optimizer
of the global (i.e. infinite time-steps) robust stochastic optimal control
problem, as well as to a corresponding worst-case measure. Moreover, we apply
this framework to portfolio optimization involving data of the S&P 500. We
present two different types of ambiguity sets; one is fully data-driven given
by a Wasserstein-ball around the empirical measure, the second one is described
by a parametric set of multivariate normal distributions, where the
corresponding uncertainty sets of the parameters are estimated from the data.
It turns out that in scenarios where the market is volatile or bearish, the
optimal portfolio strategies from the corresponding robust optimization problem
outperforms the ones without model uncertainty, showcasing the importance of
taking model uncertainty into account.
"
2206.09235,2022-06-22,"Risk Filtering and Risk-Averse Control of Markovian Systems Subject to
  Model Uncertainty","  We consider a Markov decision process subject to model uncertainty in a
Bayesian framework, where we assume that the state process is observed but its
law is unknown to the observer. In addition, while the state process and the
controls are observed at time $t$, the actual cost that may depend on the
unknown parameter is not known at time $t$. The controller optimizes total cost
by using a family of special risk measures, that we call risk filters and that
are appropriately defined to take into account the model uncertainty of the
controlled system. These key features lead to non-standard and non-trivial
risk-averse control problems, for which we derive the Bellman principle of
optimality. We illustrate the general theory on two practical examples: optimal
investment and clinical trials.
"
2206.09877,2022-06-22,Efficient Pricing and Calibration of High-Dimensional Basket Options,"  This paper studies equity basket options -- i.e., multi-dimensional
derivatives whose payoffs depend on the value of a weighted sum of the
underlying stocks -- and develops a new and innovative approach to ensure
consistency between options on individual stocks and on the index comprising
them. Specifically, we show how to resolve a well-known problem that when
individual constituent distributions of an equity index are inferred from the
single-stock option markets and combined in a multi-dimensional
local/stochastic volatility model, the resulting basket option prices will not
generate a skew matching that of the options on the equity index corresponding
to the basket. To address this ``insufficient skewness'', we proceed in two
steps. First, we propose an ``effective'' local volatility model by mapping the
general multi-dimensional basket onto a collection of marginal distributions.
Second, we build a multivariate dependence structure between all the marginal
distributions assuming a jump-diffusion model for the effective projection
parameters, and show how to calibrate the basket to the index smile. Numerical
tests and calibration exercises demonstrate an excellent fit for a basket of as
many as 30 stocks with fast calculation time.
"
2206.10014,2022-06-22,Deep Partial Least Squares for Empirical Asset Pricing,"  We use deep partial least squares (DPLS) to estimate an asset pricing model
for individual stock returns that exploits conditioning information in a
flexible and dynamic way while attributing excess returns to a small set of
statistical risk factors. The novel contribution is to resolve the non-linear
factor structure, thus advancing the current paradigm of deep learning in
empirical asset pricing which uses linear stochastic discount factors under an
assumption of Gaussian asset returns and factors. This non-linear factor
structure is extracted by using projected least squares to jointly project firm
characteristics and asset returns on to a subspace of latent factors and using
deep learning to learn the non-linear map from the factor loadings to the asset
returns. The result of capturing this non-linear risk factor structure is to
characterize anomalies in asset returns by both linear risk factor exposure and
interaction effects. Thus the well known ability of deep learning to capture
outliers, shed lights on the role of convexity and higher order terms in the
latent factor structure on the factor risk premia. On the empirical side, we
implement our DPLS factor models and exhibit superior performance to LASSO and
plain vanilla deep learning models. Furthermore, our network training times are
significantly reduced due to the more parsimonious architecture of DPLS.
Specifically, using 3290 assets in the Russell 1000 index over a period of
December 1989 to January 2018, we assess our DPLS factor model and generate
information ratios that are approximately 1.2x greater than deep learning. DPLS
explains variation and pricing errors and identifies the most prominent latent
factors and firm characteristics.
"
2206.11105,2022-10-24,Recursive Overbetting of a Satellite Investment Account,"  This paper builds a core-satellite model of semi-static Kelly betting and
log-optimal investment. We study the problem of a saver whose core portfolio
consists in unlevered (1x) retirement plans with no access to margin debt.
However, the agent has a satellite investment account with recourse to
significant, but not unlimited, leverage; accordingly, we study optimal
controllers for the satellite gearing ratio. On a very short time horizon, the
best policy is to overbet the satellite, whereby the overriding objective is to
raise the aggregate beta toward a growth-optimal level. On an infinite horizon,
by contrast, the correct behavior is to blithely ignore the core and optimize
the exponential growth rate of the satellite, which will anyways come to
dominate the entire bankroll in the limit. For time horizons strictly between
zero and infinity, the optimal strategy is not so simple: there is a key
trade-off between the instantaneous growth rate of the composite bankroll, and
that of the satellite itself, which suffers ongoing volatility drag from the
overbetting. Thus, a very perspicacious policy is called for, since any losses
in the satellite will constrain the agent's access to leverage in the
continuation problem. We characterize the optimal feedback controller, and
compute it in earnest by solving the corresponding HJB equation recursively and
backward in time. This solution is then compared to the best open-loop
controller, which, in spite of its relative simplicity, is expected to perform
similarly in practical situations.
"
2206.12148,2023-03-22,On Data-Driven Log-Optimal Portfolio: A Sliding Window Approach,"  In this paper, we propose a data-driven sliding window approach to solve a
log-optimal portfolio problem. In contrast to many of the existing papers, this
approach leads to a trading strategy with time-varying portfolio weights rather
than fixed constant weights. We show, by conducting various empirical studies,
that the approach possesses a superior trading performance to the classical
log-optimal portfolio in the sense of having a higher cumulative rate of
returns.
"
2206.12282,2022-06-27,"A comparative study of the MACD-base trading strategies: evidence from
  the US stock market","  In recent years, more and more investors use technical analysis methods in
their own trading. Evaluating the effectiveness of technical analysis has
become more feasible due to increasing computing capability and blooming public
data, which indie investors can perform stock analysis and backtest their own
trading strategy conveniently. The Moving Average Convergence Divergence (MACD)
indicator is one of the popular technical indicators that are widely used in
different strategies. In order to verify the MACD effectiveness, in this
thesis, I use the MACD indicator with traditional parameters (12, 26, 9) to
build various trading strategies. Then, I apply these strategies to stocks
listed on three indices in the US stock market (i.e., Dow-Jones, Nasdaq, and
S&P 500) and evaluate its performance in terms of win rate, profitability,
Sharpe ratio, number of trades and maximum drawdown. The backtesting is
programmed using Python, covering the period between 01/01/2015 and 28-08-2021.
The result shows that the win-rate of the strategy with only the MACD indicator
is less than 50%. However, the win-rate is improved for the trading strategies
that combine the MACD indicator with other momentum indicators like the Money
Flow Index (MFI) and the Relative Strength Index (RSI). Based on this result, I
redesign the MACD mathematical formula by taking the trading volume and daily
price volatility into consideration to derive a new indicator called VPVMA. The
results show that the win-rate and risk-adjust performance of this new trading
strategy have been improved significantly. In general, the findings suggest
that while all the MACD trading strategies mentioned above can generate
positive returns, the performance is not good without using other momentum
indicators. Hence, the VPVMA indicator performs better.
"
2206.12511,2024-07-08,Cost-efficiency in Incomplete Markets,"  This paper studies the topic of cost-efficiency in incomplete markets. A
payoff is called cost-efficient if it achieves a given probability distribution
at some given investment horizon with a minimum initial budget. Extensive
literature exists for the case of a complete financial market. We show how the
problem can be extended to incomplete markets and how the main results from the
theory of complete markets still hold in adapted form. In particular, we find
that in incomplete markets, the optimal portfolio choice for non-decreasing
preferences that are diversification-loving (a notion introduced in this paper)
must be ""perfectly"" cost-efficient. This notion of perfect cost-efficiency is
shown to be equivalent to the fact that the payoff can be rationalized, i.e.,
it is the solution to an expected utility problem.
"
2206.14548,2022-06-30,"Environmental-Social-Governance Preferences and Investments in
  Crypto-Assets","  Individuals invest in Environmental-Social-Governance (ESG)-assets not only
because of (higher) expected returns but also driven by ethical and social
considerations. Less is known about ESG-conscious investor subjective beliefs
about crypto-assets and how do these compare to traditional assets.
Controversies surrounding the ESG footprint of certain crypto-asset classes -
mainly on grounds of their energy-intensive crypto mining - offer a potentially
informative object of inquiry. Leveraging a unique representative household
finance survey for the Austrian population, we examine whether investors' ESG
preferences can explain cross-sectional differences in individual portfolio
exposure to crypto-assets. We find a strong association between investors' ESG
preferences and the crypto-investment exposure. The ESG-conscious investor
attention is higher for crypto-assets compared to traditional asset classes
such as bonds and shares.
"
2206.14666,2023-05-02,"Conditionally Elicitable Dynamic Risk Measures for Deep Reinforcement
  Learning","  We propose a novel framework to solve risk-sensitive reinforcement learning
(RL) problems where the agent optimises time-consistent dynamic spectral risk
measures. Based on the notion of conditional elicitability, our methodology
constructs (strictly consistent) scoring functions that are used as penalizers
in the estimation procedure. Our contribution is threefold: we (i) devise an
efficient approach to estimate a class of dynamic spectral risk measures with
deep neural networks, (ii) prove that these dynamic spectral risk measures may
be approximated to any arbitrary accuracy using deep neural networks, and (iii)
develop a risk-sensitive actor-critic algorithm that uses full episodes and
does not require any additional nested transitions. We compare our conceptually
improved reinforcement learning algorithm with the nested simulation approach
and illustrate its performance in two settings: statistical arbitrage and
portfolio allocation on both simulated and real data.
"
2207.00436,2022-07-04,Shai-am: A Machine Learning Platform for Investment Strategies,"  The finance industry has adopted machine learning (ML) as a form of
quantitative research to support better investment decisions, yet there are
several challenges often overlooked in practice. (1) ML code tends to be
unstructured and ad hoc, which hinders cooperation with others. (2) Resource
requirements and dependencies vary depending on which algorithm is used, so a
flexible and scalable system is needed. (3) It is difficult for domain experts
in traditional finance to apply their experience and knowledge in ML-based
strategies unless they acquire expertise in recent technologies. This paper
presents Shai-am, an ML platform integrated with our own Python framework. The
platform leverages existing modern open-source technologies, managing
containerized pipelines for ML-based strategies with unified interfaces to
solve the aforementioned issues. Each strategy implements the interface defined
in the core framework. The framework is designed to enhance reusability and
readability, facilitating collaborative work in quantitative research. Shai-am
aims to be a pure AI asset manager for solving various tasks in financial
markets.
"
2207.02134,2022-07-06,"Balancing Profit, Risk, and Sustainability for Portfolio Management","  Stock portfolio optimization is the process of continuous reallocation of
funds to a selection of stocks. This is a particularly well-suited problem for
reinforcement learning, as daily rewards are compounding and objective
functions may include more than just profit, e.g., risk and sustainability. We
developed a novel utility function with the Sharpe ratio representing risk and
the environmental, social, and governance score (ESG) representing
sustainability. We show that a state-of-the-art policy gradient method -
multi-agent deep deterministic policy gradients (MADDPG) - fails to find the
optimum policy due to flat policy gradients and we therefore replaced gradient
descent with a genetic algorithm for parameter optimization. We show that our
system outperforms MADDPG while improving on deep Q-learning approaches by
allowing for continuous action spaces. Crucially, by incorporating risk and
sustainability criteria in the utility function, we improve on the
state-of-the-art in reinforcement learning for portfolio optimization; risk and
sustainability are essential in any modern trading strategy and we propose a
system that does not merely report these metrics, but that actively optimizes
the portfolio to improve on them.
"
2207.02948,2023-08-11,Cost-efficient Payoffs under Model Ambiguity,"  Dybvig (1988a,b) solves in a complete market setting the problem of finding a
payoff that is cheapest possible in reaching a given target distribution
(""cost-efficient payoff""). In the presence of ambiguity, the distribution of a
payoff is, however, no longer known with certainty. We study the problem of
finding the cheapest possible payoff whose worst-case distribution
stochastically dominates a given target distribution (""robust cost-efficient
payoff"") and determine solutions under certain conditions. We study the link
between ""robust cost-efficiency"" and the maxmin expected utility setting of
Gilboa and Schmeidler, as well as more generally with robust preferences in a
possibly non-expected utility setting. Specifically, we show that solutions to
maxmin robust expected utility are necessarily robust cost-efficient. We
illustrate our study with examples involving uncertainty both on the drift and
on the volatility of the risky asset.
"
2207.04595,2024-12-23,"A semi-parametric dynamic conditional correlation framework for risk
  forecasting","  We develop a novel multivariate semi-parametric framework for joint portfolio
Value-at-Risk (VaR) and Expected Shortfall (ES) forecasting. Unlike existing
univariate semi-parametric approaches, the proposed framework explicitly models
the dependence structure among portfolio asset returns through a dynamic
conditional correlation (DCC) parameterization. To estimate the model, a
two-step procedure based on the minimization of a strictly consistent VaR and
ES joint loss function is employed. This procedure allows to simultaneously
estimate the DCC parameters and the portfolio risk factors. The performance of
the proposed model in risk forecasting on various probability levels is
evaluated by means of a forecasting study on the components of the Dow Jones
index for an out-of-sample period from December 2016 to September 2021. The
empirical results support effectiveness of the proposed framework compared to a
variety of existing approaches.
"
2207.05701,2022-08-08,Autoencoding Conditional GAN for Portfolio Allocation Diversification,"  Over the decades, the Markowitz framework has been used extensively in
portfolio analysis though it puts too much emphasis on the analysis of the
market uncertainty rather than on the trend prediction. While generative
adversarial network (GAN) and conditional GAN (CGAN) have been explored to
generate financial time series and extract features that can help portfolio
analysis. The limitation of the CGAN framework stands in putting too much
emphasis on generating series rather than keeping features that can help this
generator. In this paper, we introduce an autoencoding CGAN (ACGAN) based on
deep generative models that learns the internal trend of historical data while
modeling market uncertainty and future trends. We evaluate the model on several
real-world datasets from both the US and Europe markets, and show that the
proposed ACGAN model leads to better portfolio allocation and generates series
that are closer to true data compared to the existing Markowitz and CGAN
approaches.
"
2207.07767,2022-07-19,Strategic Asset Allocation with Illiquid Alternatives,"  We address the problem of strategic asset allocation (SAA) with portfolios
that include illiquid alternative asset classes. The main challenge in
portfolio construction with illiquid asset classes is that we do not have
direct control over our positions, as we do in liquid asset classes. Instead we
can only make commitments; the position builds up over time as capital calls
come in, and reduces over time as distributions occur, neither of which the
investor has direct control over. The effect on positions of our commitments is
subject to a delay, typically of a few years, and is also unknown or
stochastic. A further challenge is the requirement that we can meet the capital
calls, with very high probability, with our liquid assets.
  We formulate the illiquid dynamics as a random linear system, and propose a
convex optimization based model predictive control (MPC) policy for allocating
liquid assets and making new illiquid commitments in each period. Despite the
challenges of time delay and uncertainty, we show that this policy attains
performance surprisingly close to a fictional setting where we pretend the
illiquid asset classes are completely liquid, and we can arbitrarily and
immediately adjust our positions. In this paper we focus on the growth problem,
with no external liabilities or income, but the method is readily extended to
handle this case.
"
2208.02573,2022-08-05,Estimation of growth in fund models,"  Fund models are statistical descriptions of markets where all asset returns
are spanned by the returns of a lower-dimensional collection of funds, modulo
orthogonal noise. Equivalently, they may be characterised as models where the
global growth-optimal portfolio only involves investment in the aforementioned
funds. The loss of growth due to estimation error in fund models under local
frequentist estimation is determined entirely by the number of funds.
Furthermore, under a general filtering framework for Bayesian estimation, the
loss of growth increases as the investment universe does. A shrinkage method
that targets maximal growth with the least amount of deviation is proposed.
Empirical evidence suggests that shrinkage gives a stable estimate that more
closely follows growth potential than an unrestricted Bayesian estimate.
"
2208.04205,2022-11-03,"A mean-variance optimized portfolio constructed for investment in a
  reference security, for an investor with a preference towards an accepted set
  of securities","  We consider a reference security, understood to be an attractive investment,
with the caveat that an investor is not willing to directly invest in the
security, for presence of constraints, either investor specific or pertaining
to the security itself. The investor, however, is open to a portfolio
constructed with an accepted set of securities, where returns could be
considered similar to the reference security. We demonstrate, under a measure
of similarity, such a portfolio could be selected with a mean-variance
characterization, as defined by Markowitz. Furthermore, we consider the
performance relative to the reference security, with the Sharpe Ratio. The
objective of the paper is to derive an optimal portfolio to address an investor
preference for the accepted set of securities.
"
2208.04382,2022-08-24,"Quantum Finance: a tutorial on quantum computing applied to the
  financial market","  Previously only considered a frontier area of Physics, nowadays quantum
computing is one of the fastest growing research field, precisely because of
its technological applications in optimization problems, machine learning,
information security and simulations. The goal of this article is to introduce
the fundamentals of quantum computing, focusing on a promising quantum
algorithm and its application to a financial market problem. More specifically,
we discuss the portfolio optimization problem using the \textit{Quantum
Approximate Optimization Algorithm} (QAOA). We not only describe the main
concepts involved but also consider simple practical examples, involving
financial assets available on the Brazilian stock exchange, with codes, both
classic and quantum, freely available as a Jupyter Notebook. We also analyze in
details the quality of the combinatorial portfolio optimization solutions
through QAOA using SENAI/CIMATEC's ATOS QLM quantum simulator.
"
2208.06046,2024-05-29,Automated Market Making and Loss-Versus-Rebalancing,"  We consider the market microstructure of automated market makers (AMMs) from
the perspective of liquidity providers (LPs). Our central contribution is a
``Black-Scholes formula for AMMs''. We identify the main adverse selection cost
incurred by LPs, which we call ``loss-versus-rebalancing'' (LVR, pronounced
``lever''). LVR captures costs incurred by AMM LPs due to stale prices that are
picked off by better informed arbitrageurs. We derive closed-form expressions
for LVR applicable to all automated market makers. Our model is quantitatively
realistic, matching actual LP returns empirically, and shows how CFMM protocols
can be redesigned to reduce or eliminate LVR.
"
2208.06549,2025-01-22,Exponential utility maximization in small/large financial markets,"  Obtaining utility maximizing optimal portfolios in closed form is a
challenging issue when the return vector follows a more general distribution
than the normal one. In this note, we give closed form expressions, in markets
based on finitely many assets, for optimal portfolios that maximize the
expected exponential utility when the return vector follows normal
mean-variance mixture models. We then consider large financial markets based on
normal mean-variance mixture models also and show that, under exponential
utility, the optimal utilities based on small markets converge to the optimal
utility in the large financial market. This result shows, in particular, that
to reach optimal utility level investors need to diversify their portfolios to
include infinitely many assets into their portfolio and with portfolios based
on any set of only finitely many assets, they never be able to reach optimum
level of utility. In this paper, we also consider portfolio optimization
problems with more general class of utility functions and provide an
easy-to-implement numerical procedure for locating optimal portfolios.
Especially, our approach in this part of the paper reduces a high dimensional
problem in locating optimal portfolio into a three dimensional problem for a
general class of utility functions.
"
2208.07158,2022-08-16,Asset Allocation: From Markowitz to Deep Reinforcement Learning,"  Asset allocation is an investment strategy that aims to balance risk and
reward by constantly redistributing the portfolio's assets according to certain
goals, risk tolerance, and investment horizon. Unfortunately, there is no
simple formula that can find the right allocation for every individual. As a
result, investors may use different asset allocations' strategy to try to
fulfil their financial objectives. In this work, we conduct an extensive
benchmark study to determine the efficacy and reliability of a number of
optimization techniques. In particular, we focus on traditional approaches
based on Modern Portfolio Theory, and on machine-learning approaches based on
deep reinforcement learning. We assess the model's performance under different
market tendency, i.e., both bullish and bearish markets. For reproducibility,
we provide the code implementation code in this repository.
"
2208.07159,2022-08-16,A Hybrid Approach on Conditional GAN for Portfolio Analysis,"  Over the decades, the Markowitz framework has been used extensively in
portfolio analysis though it puts too much emphasis on the analysis of the
market uncertainty rather than on the trend prediction. While generative
adversarial network (GAN), conditional GAN (CGAN), and autoencoding CGAN
(ACGAN) have been explored to generate financial time series and extract
features that can help portfolio analysis. The limitation of the CGAN or ACGAN
framework stands in putting too much emphasis on generating series and finding
the internal trends of the series rather than predicting the future trends. In
this paper, we introduce a hybrid approach on conditional GAN based on deep
generative models that learns the internal trend of historical data while
modeling market uncertainty and future trends. We evaluate the model on several
real-world datasets from both the US and Europe markets, and show that the
proposed HybridCGAN and HybridACGAN models lead to better portfolio allocation
compared to the existing Markowitz, CGAN, and ACGAN approaches.
"
2208.07163,2023-05-10,"Before and after default: information and optimal portfolio via
  anticipating calculus","  Default risk calculus plays a crucial role in portfolio optimization when the
risky asset is under threat of bankruptcy. However, traditional stochastic
control techniques are not applicable in this scenario, and additional
assumptions are required to obtain the optimal solution in a before-and-after
default context. We propose an alternative approach using forward integration,
which allows to avoid one of the restrictive assumptions, the Jacod density
hypothesis. We demonstrate that, in the case of logarithmic utility, the weaker
intensity hypothesis is the appropriate condition for optimality. Furthermore,
we establish the semimartingale decomposition of the risky asset in the
filtration that is progressively enlarged to accommodate the default process,
under the assumption of the existence of the optimal portfolio. This work aims
to provide valueable insights for developing effective risk management
strategies when facing default risk.
"
2208.07166,2022-08-23,"Stock Performance Evaluation for Portfolio Design from Different Sectors
  of the Indian Stock Market","  The stock market offers a platform where people buy and sell shares of
publicly listed companies. Generally, stock prices are quite volatile; hence
predicting them is a daunting task. There is still much research going to
develop more accuracy in stock price prediction. Portfolio construction refers
to the allocation of different sector stocks optimally to achieve a maximum
return by taking a minimum risk. A good portfolio can help investors earn
maximum profit by taking a minimum risk. Beginning with Dow Jones Theory a lot
of advancement has happened in the area of building efficient portfolios. In
this project, we have tried to predict the future value of a few stocks from
six important sectors of the Indian economy and also built a portfolio. As part
of the project, our team has conducted a study of the performance of various
Time series, machine learning, and deep learning models in stock price
prediction on selected stocks from the chosen six important sectors of the
economy. As part of building an efficient portfolio, we have studied multiple
portfolio optimization theories beginning with the Modern Portfolio theory. We
have built a minimum variance portfolio and optimal risk portfolio for all the
six chosen sectors by using the daily stock prices over the past five years as
training data and have also conducted back testing to check the performance of
the portfolio. We look forward to continuing our study in the area of stock
price prediction and asset allocation and consider this project as the first
stepping stone.
"
2208.09156,2023-02-10,Vine Copula based portfolio level conditional risk measure forecasting,"  Accurately estimating risk measures for financial portfolios is critical for
both financial institutions and regulators. However, many existing models
operate at the aggregate portfolio level and thus fail to capture the complex
cross-dependencies between portfolio components. To address this, a new
approach is presented that uses vine copulas in combination with univariate
ARMA-GARCH models for marginal modelling to compute conditional portfolio-level
risk measure estimates by simulating portfolio-level forecasts conditioned on a
stress factor. A quantile-based approach is then presented to observe the
behaviour of risk measures given a particular state of the conditioning
asset(s). In a case study of Spanish equities with different stress factors,
the results show that the portfolio is quite robust to a sharp downturn in the
American market. At the same time, there is no evidence of this behaviour with
respect to the European market.
"
2208.09895,2023-04-12,Stability of the Epstein-Zin problem,"  We investigate the stability of the Epstein-Zin problem with respect to small
distortions in the dynamics of the traded securities. We work in incomplete
market model settings, where our parametrization of perturbations allows for
joint distortions in returns and volatility of the risky assets and the
interest rate. Considering empirically the most relevant specifications of risk
aversion and elasticity of intertemporal substitution, we provide a condition
that guarantees the convexity of the domain of the underlying problem and
results in the existence and uniqueness of a solution to it. Then, we prove the
convergence of the optimal consumption streams, the associated wealth
processes, the indirect utility processes, and the value functions in the limit
when the model perturbations vanish.
"
2208.09898,2022-08-23,"Fair pricing and hedging under small perturbations of the num\'eraire on
  a finite probability space","  We consider the problem of fair pricing and hedging under small perturbations
of the num\'eraire. We show that for replicable claims, the change of
num\'eraire affects neither the fair price nor the hedging strategy. For
non-replicable claims, we demonstrate that is not the case. By reformulating
the key stochastic control problem in a more tractable form, we show that both
the fair price and optimal strategy are stable with respect to small
perturbations of the num\'eraire. Further, our approach allows for explicit
asymptotic formulas describing the fair price and hedging strategy's leading
order correction terms. Mathematically, our results constitute stability and
asymptotic analysis of a stochastic control problem under certain perturbations
of the integrator of the controlled process, where constraints make this
problem hard to analyze.
"
2208.09968,2023-02-22,"Transfer Ranking in Finance: Applications to Cross-Sectional Momentum
  with Data Scarcity","  Cross-sectional strategies are a classical and popular trading style, with
recent high performing variants incorporating sophisticated neural
architectures. While these strategies have been applied successfully to
data-rich settings involving mature assets with long histories, deploying them
on instruments with limited samples generally produce over-fitted models with
degraded performance. In this paper, we introduce Fused Encoder Networks -- a
novel and hybrid parameter-sharing transfer ranking model. The model fuses
information extracted using an encoder-attention module operated on a source
dataset with a similar but separate module focused on a smaller target dataset
of interest. This mitigates the issue of models with poor generalisability that
are a consequence of training on scarce target data. Additionally, the
self-attention mechanism enables interactions among instruments to be accounted
for, not just at the loss level during model training, but also at inference
time. Focusing on momentum applied to the top ten cryptocurrencies by market
capitalisation as a demonstrative use-case, the Fused Encoder Networks
outperforms the reference benchmarks on most performance measures, delivering a
three-fold boost in the Sharpe ratio over classical momentum as well as an
improvement of approximately 50% against the best benchmark model without
transaction costs. It continues outperforming baselines even after accounting
for the high transaction costs associated with trading cryptocurrencies.
"
2208.10435,2022-11-08,"Do diverse and inclusive workplaces benefit investors? An Empirical
  Analysis on Europe and the United States","  As the COVID-19 pandemic restrictions slow down, employees start to return to
their offices. Hence, the discussions on optimal workplaces and issues of
diversity and inclusion have peaked. Previous research has shown that employees
and companies benefit from positive workplace changes. This research questions
whether allowing for diversity and inclusion criteria in portfolio construction
is beneficial to investors. By considering the new Diversity & Inclusion (D&I)
score by Refinitiv, I find evidence that investors might suffer lower returns
and pay for investing in responsible (i.e., more diverse and inclusive)
employers in both the US and European market.
"
2208.11380,2022-08-25,"Financial Index Tracking via Quantum Computing with Cardinality
  Constraints","  In this work, we demonstrate how to apply non-linear cardinality constraints,
important for real-world asset management, to quantum portfolio optimization.
This enables us to tackle non-convex portfolio optimization problems using
quantum annealing that would otherwise be challenging for classical algorithms.
Being able to use cardinality constraints for portfolio optimization opens the
doors to new applications for creating innovative portfolios and
exchange-traded-funds (ETFs). We apply the methodology to the practical problem
of enhanced index tracking and are able to construct smaller portfolios that
significantly outperform the risk profile of the target index whilst retaining
high degrees of tracking.
"
2208.12541,2022-08-29,"Corporate Environmental Management Accounting Practicing and Reporting
  in Bangladesh","  In the management of environment the Environmental Management Accounting
(EMA) is essential for corporate or companies because corporate sectors are the
main parties of environmental humiliation as they are existed in the
environment and for protecting environment a branch of accounting is emerged
which is called environmental management accounting. The objective of the study
is to develop a compliance framework for EMA and appraise the ER practices in
selected industries in Bangladesh. In conducting the study, 50 environmental
sensitive industries were selected from DSE. A compliance checklist was
developed on 75 aspects of EMA and ER under 13 groups. In developing the
compliance index binary method is used i.e. 1= if ER practices; 0= if not
practices. Further the level of EMR/ER practices have been evaluated in terms
of selected independent variables of the company viz. total assets, total
sales, return on equity and size of board. The study found that the
environmental management accounting in the manufacturing companies is in poor
level. The maximum compliance is 67% and the lowest is 20%. The TA, TS BS and
SP have been considered to find out the explanatory variables. In most of the
cases board size does not play significant role in the practice of EMA in the
sampled firms.
"
2208.14152,2025-05-21,"Value-at-Risk constrained portfolios in incomplete markets: a dynamic
  programming approach to Heston's model","  We solve an expected utility-maximization problem with a Value-at-risk
constraint on the terminal portfolio value in an incomplete financial market
due to stochastic volatility. To derive the optimal investment strategy, we use
the dynamic programming approach. We demonstrate that the value function in the
constrained problem can be represented as the expected modified utility
function of a vega-neutral financial derivative on the optimal terminal wealth
in the unconstrained utility-maximization problem. Via the same financial
derivative, the optimal wealth and the optimal investment strategy in the
constrained problem are linked to the optimal wealth and the optimal investment
strategy in the unconstrained problem. In numerical studies, we substantiate
the impact of risk aversion levels and investment horizons on the optimal
investment strategy. We observe a 20% relative difference between the
constrained and unconstrained allocations for average parameters in a
low-risk-aversion short-horizon setting.
"
2209.00121,2022-09-02,150 Years of Return Predictability Around the World: A Holistic View,"  Using new annual data of 16 developed countries across bond, equity, and
housing markets, I study the return predictability using the payout-price
ratios, i.e., coupon price, dividend price, and rent price. None of the 48
country-asset combinations shows consistent in-sample and out-of-sample
performance with positive utility gain for the mean-variance investor. Only 3
(4/2) countries show positive economic gains in their equity (housing/bond)
markets. The return predictability for the representative agents' risky asset
portfolios and wealth portfolios is even weaker, suggesting that timing the
investment return of a country using payout-price ratios will not make the
investors better off. The predictive regressions based on the VAR analysis by
Cochrane (2008, 2011) suggest that 14 (5) countries have predictable payout
growth in the equity (housing) markets, ex., the dividend price predicts the
dividend growth in the US. The VAR simulation using data from all the countries
does not reject the null that the dividend growth is predictable. This paper
presents firm evidence against the return predictability based on payout
ratios.
"
2209.00780,2022-12-20,Index Tracking via Learning to Predict Market Sensitivities,"  Index funds are substantially preferred by investors nowadays, and market
sensitivities are instrumental in managing index funds. An index fund is a
mutual fund aiming to track the returns of a predefined market index (e.g., the
S&P 500). A basic strategy to manage an index fund is replicating the index's
constituents and weights identically, which is, however, cost-ineffective and
impractical. To address this issue, it is required to replicate the index
partially with accurately predicted market sensitivities. Accordingly, we
propose a novel partial-replication method via learning to predict market
sensitivities. We first examine deep-learning models to predict market
sensitivities in a supervised manner with our data-processing methods. Then, we
propose a partial-index-tracking optimization model controlling the net
predicted market sensitivities of the portfolios and index to be the same.
These processes' efficacy is corroborated by our experiments on the Korea Stock
Price Index 200. Our experiments show a significant reduction of the prediction
errors compared with historical estimations and competitive tracking errors of
replicating the index utilizing fewer than half of the entire constituents.
Therefore, we show that applying deep learning to predict market sensitivities
is promising and that our portfolio construction methods are practically
effective. Additionally, to our knowledge, this is the first study addressing
market sensitivities focused on deep learning.
"
2209.03461,2024-01-11,"Portfolio Optimization with Cumulative Prospect Theory Utility via
  Convex Optimization","  We consider the problem of choosing a portfolio that maximizes the cumulative
prospect theory (CPT) utility on an empirical distribution of asset returns. We
show that while CPT utility is not a concave function of the portfolio weights,
it can be expressed as a difference of two functions. The first term is the
composition of a convex function with concave arguments and the second term a
composition of a convex function with convex arguments. This structure allows
us to derive a global lower bound, or minorant, on the CPT utility, which we
can use in a minorization-maximization (MM) algorithm for maximizing CPT
utility. We further show that the problem is amenable to a simple
convex-concave (CC) procedure which iteratively maximizes a local
approximation. Both of these methods can handle small and medium size problems,
and complex (but convex) portfolio constraints. We also describe a simpler
method that scales to larger problems, but handles only simple portfolio
constraints.
"
2209.04685,2022-09-13,Systemic Risk of Optioned Portfolios: Controllability and Optimization,"  We investigate the portfolio selection problem against the systemic risk
which is measured by CoVaR. We first demonstrate that the systemic risk of pure
stock portfolios is essentially uncontrollable due to the contagion effect and
the seesaw effect. Next, we prove that it is necessary and sufficient to
introduce options to make the systemic risk controllable by the correlation
hedging and the extreme loss hedging. In addition to systemic risk control, we
show that using options can also enhance return-risk performance. Then, with a
reasonable approximation of the conditional distribution of optioned
portfolios, we show that the portfolio optimization problem can be formulated
as a second-order cone program (SOCP) that allows for efficient computation.
Finally, we carry out comprehensive simulations and empirical tests to
illustrate the theoretical findings and the performance of our method.
"
2209.05360,2022-09-13,Meta-CTA Trading Strategies and Rational Market Failures,"  Investors trade shifting prices, portfolio values, and in turn their ability
to borrow. Concentrated ownership, high price impact and low collateral
requirements are propitious for arbitrage.
"
2209.07411,2022-09-16,"Optimal portfolio selection of many players under relative performance
  criteria in the market model with random coefficients","  We study the optimal portfolio selection problem under relative performance
criteria in the market model with random coefficients from the perspective of
many players game theory. We consider five random coefficients which consist of
three market parameters which are used in the risky asset price modeling and
two preference parameters which are related to risk attitude and impact of
relative performance. We focus on two cases; either all agents have Constant
Absolute Risk Aversion (CARA) risk preferences or all agents have Constant
Relative Risk Aversion (CRRA) risk preferences for their investment
optimization problem. For each case, we show that the forward Nash equilibrium
and the mean field equilibrium exist for the n-agent game and the corresponding
mean field stochastic optimal control problem, respectively. To extend the
n-agent game to the continuum of players game, we introduce a measure dependent
forward relative performance process and apply an optimization over controlled
dynamics of McKean-Vlasov type. We conclude that our optimal portfolio formulas
extend the corresponding results of the market model with constant
coefficients.
"
2209.09878,2025-04-03,"A unifying view on the irreversible investment exercise boundary in a
  stochastic, time-inhomogeneous capacity expansion problem","  This paper devises a way to apply the Bank and El Karoui Representation
Theorem to find the investment boundary of a rich stochastic, continuous time
capacity expansion problem with irreversible investment on the finite time
interval $[0, T]$, despite the presence of a state dependent scrap value
associated with the production facility at the terminal time $T$. Standard
variational methods are not feasible for the proposed singular stochastic
control problem but it admits some first order conditions, complicated however
by an extra, non integral term involving the scrap value function and depending
on the initial capacity $y$, which are solved by devising a way to apply the
Representation Theorem. Such devise, new and of interest in its own right,
provides the existence of the base capacity $l^{\star}_y(t)$, a positive level
which the optimal investment process is shown to become active at. As far as we
know the Representation Theorem has never been applied to this extent. In the
special case of deterministic coefficients, under a further assumption specific
to the scrap value case, a unifying view on the curve at which it is optimal to
invest emerges: the base capacity equals the investment boundary ${\hat y}(t)$
obtained by variational methods.
"
2209.09956,2022-09-22,NFTs: The Game is Afoot,"  On the blockchain, NFT games have risen in popularity, spawning new types of
digital assets. We present a simplified version of well-known NFT games,
followed by a discussion of issues influencing the structure and stability of
generic games. Where applicable, ideas from quantitative finance are
incorporated, suggesting various design constraints. Following that, we explain
three distinct methods for extracting value from NFT games. The first is to
utilise NFT tokens as collateral outside of the game's walled garden; the
second is to construct mutual beneficial games based on the participants' risk
tolerance, and the third is to use Siegel's paradox in the case of multiple
numeraires.
"
2209.10458,2022-09-22,Model-Free Reinforcement Learning for Asset Allocation,"  Asset allocation (or portfolio management) is the task of determining how to
optimally allocate funds of a finite budget into a range of financial
instruments/assets such as stocks. This study investigated the performance of
reinforcement learning (RL) when applied to portfolio management using
model-free deep RL agents. We trained several RL agents on real-world stock
prices to learn how to perform asset allocation. We compared the performance of
these RL agents against some baseline agents. We also compared the RL agents
among themselves to understand which classes of agents performed better. From
our analysis, RL agents can perform the task of portfolio management since they
significantly outperformed two of the baseline agents (random allocation and
uniform allocation). Four RL agents (A2C, SAC, PPO, and TRPO) outperformed the
best baseline, MPT, overall. This shows the abilities of RL agents to uncover
more profitable trading strategies. Furthermore, there were no significant
performance differences between value-based and policy-based RL agents.
Actor-critic agents performed better than other types of agents. Also,
on-policy agents performed better than off-policy agents because they are
better at policy evaluation and sample efficiency is not a significant problem
in portfolio management. This study shows that RL agents can substantially
improve asset allocation since they outperform strong baselines. On-policy,
actor-critic RL agents showed the most promise based on our analysis.
"
2209.12636,2022-09-27,"Does limited liability reduce leveraged risk?: The case of loan
  portfolio management","  Return-risk models are the two pillars of modern portfolio theory, which are
widely used to make decisions in choosing the loan portfolio of a bank. Banks
and other financial institutions are subjected to limited liability protection.
However, in most of the model formulation, limited liability is not taken into
consideration. Accordingly, to address this, we have, in this article, analyzed
the effect of including it in the model formulation. We formulate four models,
two of them are maximizing the expected return with risk constraint, including
and excluding limited-liability, and other two are minimization of risk with
threshold level of return with and without limited-liability. Our theoretical
results show that the solutions of the models with limited-liability produce
better results than the others, in both minimizing risk and maximizing expected
return. It has less risky investment than the other portfolio that solves the
other model. Finally, an illustrative example is presented to support the
theoretical results obtained.
"
2209.13932,2025-03-11,Efficient and Near-Optimal Online Portfolio Selection,"  In the problem of online portfolio selection as formulated by Cover (1991),
the trader repeatedly distributes her capital over $ d $ assets in each of $ T
> 1 $ rounds, with the goal of maximizing the total return. Cover proposed an
algorithm, termed Universal Portfolios, that performs nearly as well as the
best (in hindsight) static assignment of a portfolio, with an $ O(d\log(T)) $
regret in terms of the logarithmic return. Without imposing any restrictions on
the market this guarantee is known to be worst-case optimal, and no other
algorithm attaining it has been discovered so far. Unfortunately, Cover's
algorithm crucially relies on computing certain $ d $-dimensional integral
which must be approximated in any implementation; this results in a prohibitive
$ \tilde O(d^4(T+d)^{14}) $ per-round runtime for the fastest known
implementation due to Kalai and Vempala (2002). We propose an algorithm for
online portfolio selection that admits essentially the same regret guarantee as
Universal Portfolios -- up to a constant factor and replacement of $ \log(T) $
with $ \log(T+d) $ -- yet has a drastically reduced runtime of $ \tilde
O(d^2(T+d)) $ per round. The selected portfolio minimizes the current
logarithmic loss regularized by the log-determinant of its Hessian --
equivalently, the hybrid logarithmic-volumetric barrier of the polytope
specified by the asset return vectors. As such, our work reveals surprising
connections of online portfolio selection with two classical topics in
optimization theory: cutting-plane and interior-point algorithms.
"
2210.00807,2022-10-04,Portfolio optimization with discrete simulated annealing,"  Portfolio optimization is an important process in finance that consists in
finding the optimal asset allocation that maximizes expected returns while
minimizing risk. When assets are allocated in discrete units, this is a
combinatorial optimization problem that can be addressed by quantum and
quantum-inspired algorithms. In this work we present an integer simulated
annealing method to find optimal portfolios in the presence of discretized
convex and non-convex cost functions. Our algorithm can deal with large size
portfolios with hundreds of assets. We introduce a performance metric, the time
to target, based on a lower bound to the cost function obtained with the
continuous relaxation of the combinatorial optimization problem. This metric
allows us to quantify the time required to achieve a solution with a given
quality. We carry out numerical experiments and we benchmark the algorithm in
two situations: (i) Monte Carlo instances are started at random, and (ii) the
algorithm is warm-started with an initial instance close to the continuous
relaxation of the problem. We find that in the case of warm-starting with
convex cost functions, the time to target does not grow with the size of the
optimization problem, so discretized versions of convex portfolio optimization
problems are not hard to solve using classical resources. We have applied our
method to the problem of re-balancing in the presence of non-convex transaction
costs, and we have found that our algorithm can efficiently minimize those
terms.
"
2210.00984,2022-10-04,"A Comparative Study of Hierarchical Risk Parity Portfolio and Eigen
  Portfolio on the NIFTY 50 Stocks","  Portfolio optimization has been an area of research that has attracted a lot
of attention from researchers and financial analysts. Designing an optimum
portfolio is a complex task since it not only involves accurate forecasting of
future stock returns and risks but also needs to optimize them. This paper
presents a systematic approach to portfolio optimization using two approaches,
the hierarchical risk parity algorithm and the Eigen portfolio on seven sectors
of the Indian stock market. The portfolios are built following the two
approaches to historical stock prices from Jan 1, 2016, to Dec 31, 2020. The
portfolio performances are evaluated on the test data from Jan 1, 2021, to Nov
1, 2021. The backtesting results of the portfolios indicate that the
performance of the HRP portfolio is superior to that of its Eigen counterpart
on both training and test data for the majority of the sectors studied.
"
2210.00997,2023-09-22,"Online Self-Concordant and Relatively Smooth Minimization, With
  Applications to Online Portfolio Selection and Learning Quantum States","  Consider an online convex optimization problem where the loss functions are
self-concordant barriers, smooth relative to a convex function $h$, and
possibly non-Lipschitz. We analyze the regret of online mirror descent with
$h$. Then, based on the result, we prove the following in a unified manner.
Denote by $T$ the time horizon and $d$ the parameter dimension. 1. For online
portfolio selection, the regret of $\widetilde{\text{EG}}$, a variant of
exponentiated gradient due to Helmbold et al., is $\tilde{O} ( T^{2/3} d^{1/3}
)$ when $T > 4 d / \log d$. This improves on the original $\tilde{O} ( T^{3/4}
d^{1/2} )$ regret bound for $\widetilde{\text{EG}}$. 2. For online portfolio
selection, the regret of online mirror descent with the logarithmic barrier is
$\tilde{O}(\sqrt{T d})$. The regret bound is the same as that of Soft-Bayes due
to Orseau et al. up to logarithmic terms. 3. For online learning quantum states
with the logarithmic loss, the regret of online mirror descent with the
log-determinant function is also $\tilde{O} ( \sqrt{T d} )$. Its per-iteration
time is shorter than all existing algorithms we know.
"
2210.01016,2023-12-08,"Smoothness of the Value Function for Optimal Consumption Model with
  Consumption-Wealth Utility and Borrowing Constraint","  This paper studies an optimal consumption-investment problem for an investor
whose instantaneous utility depends on both consumption and wealth, and the
investor faces a general borrowing constraint that the investment amount in the
risky asset does not exceed an exogenous function of the wealth. We show that
the value function is second-order smooth and present the optimal
consumption-investment policy in a feedback form. Moreover, when the risky
investment amount is bounded above by a fixed constant, we show that under
certain conditions, the constraint is binding if and only if an endogenous
threshold bounds the portfolio wealth, and we determine the endogenous wealth
threshold with the smooth fit condition. Our results encompass several
well-developed portfolio choice models and imply new applications.
"
2210.02633,2022-11-23,Shannon entropy: an econophysical approach to cryptocurrency portfolios,"  Cryptocurrency markets have attracted many interest for global investors
because of their novelty, wide online availability, increasing capitalization
and potential profits. In the econophysics tradition we show that many of the
most available cryptocurrencies have return statistics that do not follow
Gaussian distributions but heavy--tailed distributions instead. Entropy
measures are also applied showing that portfolio diversification is a
reasonable practice for decreasing return uncertainty.
"
2210.03917,2023-06-06,"Duality Theory for Exponential Utility--Based Hedging in the
  Almgren--Chriss Model","  In this paper, we obtain a duality result for the exponential utility
maximization problem where trading is subject to quadratic transaction costs
and the investor is required to liquidate her position at the maturity date. As
an application of the duality, we treat utility-based hedging in the Bachelier
model. For European contingent claims with a quadratic payoff, we compute
explicitly the optimal trading strategy.
"
2210.03943,2022-10-11,"Design and Analysis of Optimized Portfolios for Selected Sectors of the
  Indian Stock Market","  Portfolio optimization is a challenging problem that has attracted
considerable attention and effort from researchers. The optimization of stock
portfolios is a particularly hard problem since the stock prices are volatile
and estimation of their future volatilities and values, in most cases, is very
difficult, if not impossible. This work uses three ratios, the Sharpe ratio,
the Sortino ratio, and the Calmar ratio, for designing the mean-variance
optimized portfolios for six important sectors listed in the National Stock
Exchange (NSE) of India. Three portfolios are designed for each sector
maximizing the ratios based on the historical prices of the ten most important
stocks of each sector from Jan 1, 2017, to Dec 31, 2020. The evaluation of the
portfolios is done based on their cumulative returns over the test period from
Jan 1, 2021, to Dec 31, 2021. The ratio that yields the maximum cumulative
returns for both the training and the test periods for the majority of the
sectors is identified. The sectors that exhibit the maximum cumulative returns
for the same ratio are also identified. The results provide useful insights for
investors in the stock market in making their investment decisions based on the
current return and risks associated with the six sectors and their stocks.
"
2210.03988,2023-09-07,"A Clustering Algorithm for Correlation Quickest Hub Discovery Mixing
  Time Evolution and Random Matrix Theory","  We present a geometric version of Quickest Change Detection (QCD) and
Quickest Hub Discovery (QHD) tests in correlation structures that allows us to
include and combine new information with distance metrics. The topic falls
within the scope of sequential, nonparametric, high-dimensional QCD and QHD,
from which state-of-the-art settings developed global and local summary
statistics from asymptotic Random Matrix Theory (RMT) to detect changes in
random matrix law. These settings work only for uncorrelated pre-change
variables. With our geometric version of the tests via clustering, we can test
the hypothesis that we can improve state-of-the-art settings for QHD, by
combining QCD and QHD simultaneously, as well as including information about
pre-change time-evolution in correlations. We can work with correlated
pre-change variables and test if the time-evolution of correlation improves
performance. We prove test consistency and design test hypothesis based on
clustering performance. We apply this solution to financial time series
correlations. Future developments on this topic are highly relevant in finance
for Risk Management, Portfolio Management, and Market Shocks Forecasting which
can save billions of dollars for the global economy. We introduce the
Diversification Measure Distribution (DMD) for modeling the time-evolution of
correlations as a function of individual variables which consists of a
Dirichlet-Multinomial distribution from a distance matrix of rolling
correlations with a threshold. Finally, we are able to verify all these
hypotheses.
"
2210.04194,2022-12-16,Reap the Harvest on Blockchain: A Survey of Yield Farming Protocols,"  Yield farming represents an immensely popular asset management activity in
decentralized finance (DeFi). It involves supplying, borrowing, or staking
crypto assets to earn an income in forms of transaction fees, interest, or
participation rewards at different DeFi marketplaces. In this systematic
survey, we present yield farming protocols as an aggregation-layer constituent
of the wider DeFi ecosystem that interact with primitive-layer protocols such
as decentralized exchanges (DEXs) and protocols for loanable funds (PLFs). We
examine the yield farming mechanism by first studying the operations encoded in
the yield farming smart contracts, and then performing stylized, parameterized
simulations on various yield farming strategies. We conduct a thorough
literature review on related work, and establish a framework for yield farming
protocols that takes into account pool structure, accepted token types, and
implemented strategies. Using our framework, we characterize major yield
aggregators in the market including Yearn Finance, Beefy, and Badger DAO.
Moreover, we discuss anecdotal attacks against yield aggregators and generalize
a number of risks associated with yield farming.
"
2210.06255,2022-10-13,Retirement spending problem under Habit Formation Model,"  In this paper we consider the problem of optimizing lifetime consumption
under a habit formation model. Our work differs from previous results, because
we incorporate mortality and pension income. Lifetime utility of consumption
makes the problem time inhomogeneous, because of the effect of ageing.
Considering habit formation means increasing the dimension of the stochastic
control problem, because one must track smoothed-consumption using an
additional variable, habit $\bar c$. Including exogenous pension income $\pi$
means that we cannot rely on a kind of scaling transformation to reduce the
dimension of the problem as in earlier work, therefore we solve it numerically,
using a finite difference scheme. We also explore how consumption changes over
time based on habit if the retiree follows the optimal strategy. Finally, we
answer the question of whether it is reasonable to annuitize wealth at the time
of retirement or not by varying parameters, such as asset allocation $\theta$
and the smoothing factor $\eta$.
"
2210.08982,2022-12-05,Title Redacted,"  Abstract redacted by arXiv administrators.
"
2210.09302,2023-10-11,"The impact of big winners on passive and active equity investment
  strategies","  We investigate the impact of big winner stocks on the performance of active
and passive investment strategies using a combination of numerical and
analytical techniques. Our analysis is based on historical stock price data
from 2006 to 2021 for a large variety of global indexes. We show that the
log-normal distribution provides a reasonable fit for total returns for the
majority of world stock indexes but highlight the limitations of this model.
Using an analytical expression for a finite sum of log-normal random variables,
we show that the typical return of a concentrated portfolio is less than that
of an equally weighted index. This finding indicates that active managers face
a significant risk of underperforming due to the potential for missing out on
the substantial returns generated by big winner stocks. Our results suggest
that passive investing strategies, that do not involve the selection of
individual stocks, are likely to be more effective in achieving long-term
financial goals.
"
2210.10425,2022-10-20,Optimal investment and reinsurance under exponential forward preferences,"  We study the optimal investment and proportional reinsurance problem of an
insurance company, whose investment preferences are described via a forward
dynamic utility of exponential type in a stochastic factor model allowing for a
possible dependence between the financial and insurance markets. Specifically,
we assume that the asset price process dynamics and the claim arrival intensity
are both affected by a common stochastic process and we account for a possible
environmental contagion effect through the non-zero correlation parameter
between the underlying Brownian motions driving the asset price process and the
stochastic factor dynamics. By stochastic control techniques, we construct a
forward dynamic exponential utility, and we characterize the optimal investment
and reinsurance strategy. Moreover, we investigate in detail the
zero-volatility case and provide a comparison analysis with classical results
in an analogous setting under backward utility preferences. We also discuss an
extension of the conditional certainty equivalent. Finally, we perform a
numerical analysis to highlight some features of the optimal strategy.
"
2210.13833,2023-02-17,The continuous-time pre-commitment KMM problem in incomplete markets,"  This paper studies the continuous-time pre-commitment KMM problem proposed by
Klibanoff, Marinacci and Mukerji (2005) in incomplete financial markets, which
concerns with the portfolio selection under smooth ambiguity. The decision
maker (DM) is uncertain about the dominated priors of the financial market,
which are characterized by a second-order distribution (SOD). The KMM model
separates risk attitudes and ambiguity attitudes apart and the aim of the DM is
to maximize the two-fold utility of terminal wealth, which does not belong to
the classical subjective utility maximization problem. By constructing the
efficient frontier, the original KMM problem is first simplified as an one-fold
expected utility problem on the second-order space. In order to solve the
equivalent simplified problem, this paper imposes an assumption and introduces
a new distorted Legendre transformation to establish the bipolar relation and
the distorted duality theorem. Then, under a further assumption that the
asymptotic elasticity of the ambiguous attitude is less than 1, the uniqueness
and existence of the solution to the KMM problem are shown and we obtain the
semi-explicit forms of the optimal terminal wealth and the optimal strategy.
Explicit forms of optimal strategies are presented for CRRA, CARA and HARA
utilities in the case of Gaussian SOD in a Black-Scholes financial market,
which show that DM with higher ambiguity aversion tends to be more concerned
about extreme market conditions with larger bias. In the end of this work,
numerical comparisons with the DMs ignoring ambiguity are revealed to
illustrate the effects of ambiguity on the optimal strategies and value
functions.
"
2210.15329,2022-12-05,Measuring Transition Risk in Investment Funds,"  We develop a comprehensive framework to measure the impact of the climate
transition on investment portfolios. Our analysis is enriched by including
geographical, sectoral, company and ISIN-level data to assess transition risk.
We find that investment funds suffer a moderate 5.7% loss upon materialization
of a high transition risk scenario. However, the risk distribution is
significantly left-skewed, with the worst 1% funds experiencing an average loss
of 21.3%. In terms of asset classes, equities are the worst performers
(-12.7%), followed by corporate bonds (-5.6%) and government bonds (-4.8%). We
discriminate among financial instruments by considering the carbon footprint of
specific counterparties and the credit rating, duration, convexity and
volatility of individual exposures. We find that sustainable funds are less
exposed to transition risk and perform better than the overall fund sector in
the low-carbon transition, validating their choice as green investments.
"
2210.15613,2025-04-16,"The law of one price in quadratic hedging and mean-variance portfolio
  selection","  The law of one price (LOP) broadly asserts that identical financial flows
should command the same price. We show that, when properly formulated, LOP is
the minimal condition for a well-defined mean-variance portfolio selection
framework without degeneracy. Crucially, the paper identifies a new mechanism
through which LOP can fail in a continuous-time $L^2$ setting without
frictions, namely 'trading from just before a predictable stopping time', which
surprisingly identifies LOP violations even for continuous price processes.
  Closing this loophole allows to give a version of the ""Fundamental Theorem of
Asset Pricing"" appropriate in the quadratic context, establishing the
equivalence of the economic concept of LOP with the probabilistic property of
the existence of a local $\scr{E}$-martingale state price density. The latter
provides unique prices for all square-integrable claims in an extended market
and subsequently plays an important role in quadratic hedging and mean-variance
portfolio selection.
  Mathematically, we formulate a novel variant of the uniform boundedness
principle for conditionally linear functionals on the $L^0$ module of
conditionally square-integrable random variables. We then study the
representation of time-consistent families of such functionals in terms of
stochastic exponentials of a fixed local martingale.
"
2211.00420,2023-07-11,"Integrating multiple sources of ordinal information in portfolio
  optimization","  Active portfolio management tries to incorporate any source of meaningful
information into the asset selection process. In this contribution we consider
qualitative views specified as total orders of the expected asset returns and
discuss two different approaches for incorporating this input in a
mean-variance portfolio optimization model. In the robust optimization approach
we first compute a posterior expectation of asset returns for every given total
order by an extension of the Black-Litterman (BL) framework. Then these
expected asset returns are considered as possible input scenarios for robust
optimization variants of the mean-variance portfolio model (max-min robustness,
min regret robustness and soft robustness). In the order aggregation approach
rules from social choice theory (Borda, Footrule, Copeland, Best-of-k and MC4)
are used to aggregate the total order in a single ``consensus total order''.
Then expected asset returns are computed for this ``consensus total order'' by
the extended BL framework mentioned above. Finally, these expectations are used
as an input of the classical mean-variance optimization. Using data from
EUROSTOXX 50 and S&P 100 we empirically compare the success of the two
approaches in the context of portfolio performance analysis and observe that in
general aggregating orders by social choice methods outperforms robust
optimization based methods for both data sets.
"
2211.01240,2022-11-08,"On The Equivalence Of The Mean Variance Criterion And Stochastic
  Dominance Criteria","  We study the necessary and sufficient conditions under which the
Mean-Variance Criterion (MVC) is equivalent to the Maximum Expected Utility
Criterion (MEUC), for two lotteries. Based on Chamberlain (1983), we conclude
that the MVC is equivalent to the Second-order Stochastic Dominance Rule (SSDR)
under any symmetric Elliptical distribution. We then discuss the work of
Schuhmacher et al. (2021). Although their theoretical findings deduce that the
Mean-Variance Analysis remains valid under Skew-Elliptical distributions, we
argue that this does not entail that the MVC coincides with the SSDR. In fact,
generating multiple MV-pairs that follow a Skew-Normal distribution it becomes
evident that the MVC fails to coincide with the SSDR for some types of
risk-averse investors. In the second part of this work, we examine the premise
of Levy and Markowitz (1979) that ""the MVC deduces the maximization of the
expected utility of an investor, under any approximately quadratic utility
function, without making any further assumption on the distribution of the
lotteries"". Using Monte Carlo Simulations, we find out that the set of
approximately quadratic utility functions is too narrow. Specifically, our
simulations indicate that $\log{(a+Z)}$ and $(1+Z)^a$ are almost quadratic,
while $-e^{-a(1+Z)}$ and $-(1+Z)^{-a}$ fail to approximate a quadratic utility
function under either an Extreme Value or a Stable Pareto distribution.
"
2211.03604,2022-11-10,"Dynamic Estimates Of The Arrow-Pratt Absolute And Relative Risk Aversion
  Coefficients","  We derive a closed-form expression capturing the degree of Relative Risk
Aversion (RRA) of investors for non-""fair"" lotteries. We argue that our formula
is superior to earlier methods that have been proposed, as it is a function of
only three variables. Namely, the Treasury yields, the returns and the market
capitalization of a specific market index. Our formula, is tested on CAC 40,
EURO, S&P 500 and STOXX 600, with respect to the market capitalization of each
index, for different time periods. We deduce that the investors in these
markets exhibit Decreasing Absolute Risk Aversion (DARA) through all the
different time periods that we consider, while the degree of RRA has altered
between being constant, decreasing or increasing. Furthermore, we propose a
simple and intuitive way to measure the degree to which a wrong assumption with
respect to the utility function of an investor will affect the structure of his
portfolio. Our method is built on a two asset portfolio framework. Namely, a
portfolio consisting of one risky and one risk-free asset. Applying our method,
the empirical findings indicate that the weight invested in the risky asset
varies substantially even among utility functions with similar characteristics.
"
2211.05014,2024-11-27,"Randomization of Short-Rate Models, Analytic Pricing and Flexibility in
  Controlling Implied Volatilities","  We focus on extending existing short-rate models, enabling control of the
generated implied volatility while preserving analyticity. We achieve this goal
by applying the Randomized Affine Diffusion (RAnD) method to the class of
short-rate processes under the Heath-Jarrow-Morton framework. Under
arbitrage-free conditions, the model parameters can be exogenously stochastic,
thus facilitating additional degrees of freedom that enhance the calibration
procedure. We show that with the randomized short-rate models, the shapes of
implied volatility can be controlled and significantly improve the quality of
the model calibration, even for standard 1D variants. In particular, we
illustrate that randomization applied to the Hull-White model leads to dynamics
of the local volatility type, with the prices for standard volatility-sensitive
derivatives explicitly available. The randomized Hull-White (rHW) model offers
an almost perfect calibration fit to the swaption implied volatilities.
"
2211.05402,2022-11-11,Relative growth rate optimization under behavioral criterion,"  This paper studies a continuous-time optimal portfolio selection problem in
the complete market for a behavioral investor whose preference is of the
prospect type with probability distortion. The investor concerns about the
terminal relative growth rate (log-return) instead of absolute capital value.
This model can be regarded as an extension of the classical growth optimal
problem to the behavioral framework. It leads to a new type of M-shaped utility
maximization problem under nonlinear Choquet expectation. Due to the presence
of probability distortion, the classical stochastic control methods are not
applicable. By the martingale method, concavification and quantile optimization
techniques, we derive the closed-form optimal growth rate. We find that the
benchmark growth rate has a significant impact on investment behaviors.
Compared to Zhang et al where the same preference measure is applied to the
terminal relative wealth, we find a new phenomenon when the investor's risk
tolerance level is high and the market states are bad. In addition, our optimal
wealth in every scenario is less sensitive to the pricing kernel and thus more
stable than theirs.
"
2211.07080,2022-11-23,"Designing Efficient Pair-Trading Strategies Using Cointegration for the
  Indian Stock Market","  A pair-trading strategy is an approach that utilizes the fluctuations between
prices of a pair of stocks in a short-term time frame, while in the long-term
the pair may exhibit a strong association and co-movement pattern. When the
prices of the stocks exhibit significant divergence, the shares of the stock
that gains in price are sold (a short strategy) while the shares of the other
stock whose price falls are bought (a long strategy). This paper presents a
cointegration-based approach that identifies stocks listed in the five sectors
of the National Stock Exchange (NSE) of India for designing efficient
pair-trading portfolios. Based on the stock prices from Jan 1, 2018, to Dec 31,
2020, the cointegrated stocks are identified and the pairs are formed. The
pair-trading portfolios are evaluated on their annual returns for the year
2021. The results show that the pairs of stocks from the auto and the realty
sectors, in general, yielded the highest returns among the five sectors studied
in the work. However, two among the five pairs from the information technology
(IT) sector are found to have yielded negative returns.
"
2211.07212,2023-09-06,Risk Budgeting Portfolios: Existence and Computation,"  Modern portfolio theory has provided for decades the main framework for
optimizing portfolios. Because of its sensitivity to small changes in input
parameters, especially expected returns, the mean-variance framework proposed
by Markowitz (1952) has however been challenged by new construction methods
that are purely based on risk. Among risk-based methods, the most popular ones
are Minimum Variance, Maximum Diversification, and Risk Budgeting (especially
Equal Risk Contribution) portfolios. Despite some drawbacks, Risk Budgeting is
particularly attracting because of its versatility: based on Euler's
homogeneous function theorem, it can indeed be used with a wide range of risk
measures. This paper presents mathematical results regarding the existence and
the uniqueness of Risk Budgeting portfolios for a very wide spectrum of risk
measures and shows that, for many of them, computing the weights of Risk
Budgeting portfolios only requires a standard stochastic algorithm.
"
2211.07471,2024-12-17,"Optimal investment with insider information using Skorokhod &
  Russo-Vallois integration","  We study the maximization of the logarithmic utility for an insider with
different anticipating techniques. Our aim is to compare the utilization of
Russo-Vallois forward and Skorokhod integrals in this context. Theoretical
analysis and illustrative numerical examples showcase that the Skorokhod
insider outperforms the forward insider. This remarkable observation stands in
contrast to the scenario involving risk-neutral traders. Furthermore, an
ordinary trader could surpass both insiders if a significant negative
fluctuation in the driving stochastic process leads to a sufficiently negative
final value. These findings underline the intricate interplay between
anticipating stochastic calculus and nonlinear utilities, which may yield
non-intuitive results from the financial viewpoint.
"
2211.08281,2024-06-13,"Forecasting Bitcoin volatility spikes from whale transactions and
  CryptoQuant data using Synthesizer Transformer models","  The cryptocurrency market is highly volatile compared to traditional
financial markets. Hence, forecasting its volatility is crucial for risk
management. In this paper, we investigate CryptoQuant data (e.g. on-chain
analytics, exchange and miner data) and whale-alert tweets, and explore their
relationship to Bitcoin's next-day volatility, with a focus on extreme
volatility spikes. We propose a deep learning Synthesizer Transformer model for
forecasting volatility. Our results show that the model outperforms existing
state-of-the-art models when forecasting extreme volatility spikes for Bitcoin
using CryptoQuant data as well as whale-alert tweets. We analysed our model
with the Captum XAI library to investigate which features are most important.
We also backtested our prediction results with different baseline trading
strategies and the results show that we are able to minimize drawdown while
keeping steady profits. Our findings underscore that the proposed method is a
useful tool for forecasting extreme volatility movements in the Bitcoin market.
"
2211.08919,2022-11-17,"Efficient implementation of portfolio strategies involving
  cryptocurrencies and VIX INDEX and Gold","  This research mainly explores the characteristics of different strategies and
whether VIX INDEX positively influences the investment portfolio in any period.
Our portfolio has six significant cryptocurrencies, VIX INDEX and gold. We
perform parameter estimation on all raw data and bring the two types into
different investment strategies, complete them effectively according to other
characteristics, and compare the results. At the same time, we make two
different portfolios, one contains VIX INDEX, and one does not have VIX INDEX.
We use different portfolios in different portfolio strategies and find that VIX
INDEX can positively impact the investment portfolio of cryptocurrencies, no
matter in the standard market or the downward market. The research shows that
gold has the same attributes as VIX INDEX and should have a specific positive
effect, but no comparative experiment has been done.
"
2211.15260,2023-03-14,ETF construction on CRIX,"  Investments in cryptocurrencies (CCs) remain risky due to high volatility.
Exchange Traded Funds (ETFs) are a suitable tool to diversify risk and to
benefit from the growth of the whole CC sector. We construct an ETF on the
CRIX, the CRyptocurrency IndeX that maps the non-stationary CC dynamics closely
by adapting its constituents weights dynamically. The scenario analysis
considers the fee schedules of regulated CC exchanges, spreads obtained from
high-frequency order book data, and models capital deposits to the ETF
stochastically. The analysis yields valuable insights into the mechanisms,
costs and risks of this new financial product: i) although the composition of
the CRIX ETF changes frequently (from 5 to 30 constituents), it remains robust
in its core, as the weights of Bitcoin (BTC) and Ethereum (ETH) are robust over
time, ii) on average, a portion of 5.2% needed to be rebalanced at the
rebalancing dates, iii) trading costs are low compared to traditional assets,
iv) the liquidity of the CC sector has increased significantly during the
analysis period, spreads occur especially for altcoins and increase by the size
of the transactions. But since BTC and ETH are most affected by rebalancing,
the cost of spreads remains limited.
"
2211.17193,2022-12-01,Metaheuristic Approach to Solve Portfolio Selection Problem,"  In this paper, a heuristic method based on TabuSearch and TokenRing Search is
being used in order to solve the Portfolio Optimization Problem. The seminal
mean-variance model of Markowitz is being considered with the addition of
cardinality and quantity constraints to better capture the dynamics of the
trading procedure, the model becomes an NP-hard problem that can not be solved
using an exact method. The combination of three different neighborhood
relations is being explored with Tabu Search. In addition, a new constructive
method for the initial solution is proposed. Finally, I show how the proposed
techniques perform on public benchmarks
"
2212.00391,2023-03-14,"Dynamic and static fund separations and their stability for long-term
  optimal investments","  This paper investigates dynamic and static fund separations and their
stability for long-term optimal investments under three model classes. An
investor maximizes the expected utility with constant relative risk aversion
under an incomplete market consisting of a safe asset, several risky assets,
and a single state variable. The state variables in two of the model classes
follow a 3/2 process and an inverse Bessel process, respectively. The other
market model has the partially observed state variable modeled as an
Ornstein-Uhlenbeck state process. We show that the dynamic optimal portfolio of
this utility maximization consists of m+3 portfolios: the safe asset, the
myopic portfolio, the m time-independent portfolios, and the intertemporal
portfolio. Over time, the intertemporal portfolio eventually vanishes, leading
the dynamic portfolio to converge to m+2 portfolios, referred to as the static
portfolio. We also prove that the convergence is stable under model parameter
perturbations. In addition, sensitivities of the intertemporal portfolio with
respect to small parameters perturbations also vanish in the long run. The
convergence rate for the intertemporal portfolio and its sensitivities are
computed explicitly for the presented models.
"
2212.02307,2022-12-06,"Why do investors buy shares of actively managed equity mutual funds?
  Considering the Correct Reference Portfolio from an Uninformed Investor's
  Perspective 1, 2","  We use the Grossman \& Stiglitz (1980) framework to build a reference
portfolio for uninformed investors and employ this portfolio to assess the
performance of actively managed equity mutual funds. We propose an empirical
methodology to construct this reference portfolio using the information on
prices and supply. We show that mutual funds provide, on average, an
insignificant alpha of 23 basis points per year when considering this portfolio
as a reference. With the stock market index as a proxy for the market
portfolio, the average fund alpha is negative and highly significant, --128
basis points per year. The results are robust when considering various subsets
of funds based on their characteristics and their degree of selectivity. In
line with rational expectations equilibrium models considering asymmetrically
informed investors and partially revealing equilibrium prices, our study
supports that active management adds value for uniformed investors.
"
2212.02570,2024-01-11,"Robust Bond Portfolio Construction via Convex-Concave Saddle Point
  Optimization","  The minimum (worst case) value of a long-only portfolio of bonds, over a
convex set of yield curves and spreads, can be estimated by its sensitivities
to the points on the yield curve. We show that sensitivity based estimates are
conservative, \ie, underestimate the worst case value, and that the exact worst
case value can be found by solving a tractable convex optimization problem. We
then show how to construct a long-only bond portfolio that includes the worst
case value in its objective or as a constraint, using convex-concave saddle
point optimization.
"
2212.02721,2023-07-27,"A Novel Deep Reinforcement Learning Based Automated Stock Trading System
  Using Cascaded LSTM Networks","  More and more stock trading strategies are constructed using deep
reinforcement learning (DRL) algorithms, but DRL methods originally widely used
in the gaming community are not directly adaptable to financial data with low
signal-to-noise ratios and unevenness, and thus suffer from performance
shortcomings. In this paper, to capture the hidden information, we propose a
DRL based stock trading system using cascaded LSTM, which first uses LSTM to
extract the time-series features from stock daily data, and then the features
extracted are fed to the agent for training, while the strategy functions in
reinforcement learning also use another LSTM for training. Experiments in DJI
in the US market and SSE50 in the Chinese stock market show that our model
outperforms previous baseline models in terms of cumulative returns and Sharp
ratio, and this advantage is more significant in the Chinese stock market, a
merging market. It indicates that our proposed method is a promising way to
build a automated stock trading system.
"
2212.03443,2023-06-21,Bi-LSTM Price Prediction based on Attention Mechanism,"  With the increasing enrichment and development of the financial derivatives
market, the frequency of transactions is also faster and faster. Due to human
limitations, algorithms and automatic trading have recently become the focus of
discussion. In this paper, we propose a bidirectional LSTM neural network based
on an attention mechanism, which is based on two popular assets, gold and
bitcoin. In terms of Feature Engineering, on the one hand, we add traditional
technical factors, and at the same time, we combine time series models to
develop factors. In the selection of model parameters, we finally chose a
two-layer deep learning network. According to AUC measurement, the accuracy of
bitcoin and gold is 71.94% and 73.03% respectively. Using the forecast results,
we achieved a return of 1089.34% in two years. At the same time, we also
compare the attention Bi-LSTM model proposed in this paper with the traditional
model, and the results show that our model has the best performance in this
data set. Finally, we discuss the significance of the model and the
experimental results, as well as the possible improvement direction in the
future.
"
2212.07944,2022-12-22,Variable Clustering via Distributionally Robust Nodewise Regression,"  We study a multi-factor block model for variable clustering and connect it to
the regularized subspace clustering by formulating a distributionally robust
version of the nodewise regression. To solve the latter problem, we derive a
convex relaxation, provide guidance on selecting the size of the robust region,
and hence the regularization weighting parameter, based on the data, and
propose an ADMM algorithm for implementation. We validate our method in an
extensive simulation study. Finally, we propose and apply a variant of our
method to stock return data, obtain interpretable clusters that facilitate
portfolio selection and compare its out-of-sample performance with other
clustering methods in an empirical study.
"
2212.09473,2022-12-20,Graph theoretical models and algorithms of portfolio compression,"  In portfolio compression, market participants (banks, organizations,
companies, financial agents) sign contracts, creating liabilities between each
other, which increases the systemic risk. Large, dense markets commonly can be
compressed by reducing obligations without lowering the net notional of each
participant (an example is if liabilities make a cycle between agents, then it
is possible to reduce each of them without any net notional changing), and our
target is to eliminate as much excess notional as possible in practice (excess
is defined as the difference between gross and net notional). A limiting factor
that may reduce the effectiveness of the compression can be the preferences and
priorities of compression participants, who may individually define conditions
for the compression, which must be considered when designing the clearing
process, otherwise, a participant may bail out, resulting in the designed
clearing process to be impossible to execute. These markets can be
well-represented with edge-weighted graphs. In this paper, I examine cases when
preferences of participants on behalf of clearing are given, e.g., in what
order would they pay back their liabilities (a key factor can be the rate of
interest) and I show a clearing algorithm for these problems. On top of that,
since it is a common goal for the compression coordinating authority to
maximize the compressed amount, I also show a method to compute the maximum
volume conservative compression in a network. I further evaluate the
possibility of combining the two models. Examples and program code of the model
are also shown, also a0 pseudo-code of the clearing algorithms.
"
2212.10053,2022-12-21,Dynamic spending and portfolio decisions with a soft social norm,"  We explore the implications of a preference ordering for an investor-consumer
with a strong preference for keeping consumption above an exogenous social
norm, but who is willing to tolerate occasional dips below it. We do this by
splicing two CRRA preference orderings, one with high curvature below the norm
and the other with low curvature at or above it. We find this formulation
appealing for many endowment funds and sovereign wealth funds, including the
Norwegian Government Pension Fund Global, which inspired our research. We solve
this model analytically as well as numerically and find that annual spending
should not only be significantly lower than the expected financial return, but
mostly also procyclical. In particular, financial losses should, as a rule, be
followed by larger than proportional spending cuts, except when some smoothing
is needed to keep spending from falling too far below the social norm. Yet, at
very low wealth levels, spending should be kept particularly low in order to
build sufficient wealth to raise consumption above the social norm. Financial
risk taking should also be modest and procyclical, so that the investor
sometimes may want to ""buy at the top"" and ""sell at the bottom"". Many of these
features are shared by habitformation models and other models with some lower
bound for consumption. However, our specification is more flexible and thus
more easily adaptable to actual fund management. The nonlinearity of the policy
functions may present challenges regarding delegation to professional managers.
However, simpler rules of thumb with constant or slowly moving equity share and
consumption-wealth ratio can reach almost the same expected discounted utility.
However, the constant levels will then look very different from the
implications of expected CRRA utility or Epstein-Zin preferences in that
consumption is much lower.
"
2212.10844,2022-12-22,"Greenhouse gases emissions: estimating corporate non-reported emissions
  using interpretable machine learning","  As of 2022, greenhouse gases (GHG) emissions reporting and auditing are not
yet compulsory for all companies and methodologies of measurement and
estimation are not unified. We propose a machine learning-based model to
estimate scope 1 and scope 2 GHG emissions of companies not reporting them yet.
Our model, specifically designed to be transparent and completely adapted to
this use case, is able to estimate emissions for a large universe of companies.
It shows good out-of-sample global performances as well as good out-of-sample
granular performances when evaluating it by sectors, by countries or by
revenues buckets. We also compare our results to those of other providers and
find our estimates to be more accurate. Thanks to the proposed explainability
tools using Shapley values, our model is fully interpretable, the user being
able to understand which factors split explain the GHG emissions for each
particular company.
"
2212.13996,2022-12-29,Robustifying Markowitz,"  Markowitz mean-variance portfolios with sample mean and covariance as input
parameters feature numerous issues in practice. They perform poorly out of
sample due to estimation error, they experience extreme weights together with
high sensitivity to change in input parameters. The heavy-tail characteristics
of financial time series are in fact the cause for these erratic fluctuations
of weights that consequently create substantial transaction costs. In
robustifying the weights we present a toolbox for stabilizing costs and weights
for global minimum Markowitz portfolios. Utilizing a projected gradient descent
(PGD) technique, we avoid the estimation and inversion of the covariance
operator as a whole and concentrate on robust estimation of the gradient
descent increment. Using modern tools of robust statistics we construct a
computationally efficient estimator with almost Gaussian properties based on
median-of-means uniformly over weights. This robustified Markowitz approach is
confirmed by empirical studies on equity markets. We demonstrate that
robustified portfolios reach the lowest turnover compared to shrinkage-based
and constrained portfolios while preserving or slightly improving out-of-sample
performance.
"
2212.14327,2023-01-02,"A Stackelberg reinsurance-investment game under $\alpha$-maxmin
  mean-variance criterion and stochastic volatility","  This paper investigates a Stackelberg game between an insurer and a reinsurer
under the $\alpha$-maxmin mean-variance criterion. The insurer can purchase
per-loss reinsurance from the reinsurer. With the insurer's feedback
reinsurance strategy, the reinsurer optimizes the reinsurance premium in the
Stackelberg game. The financial market consists of cash and stock with Heston's
stochastic volatility. Both the insurer and reinsurer maximize their respective
$\alpha$-maxmin mean-variance preferences in the market. The criterion is
time-inconsistent and we derive the equilibrium strategies by the extended
Hamilton-Jacobi-Bellman equations. Similar to the non-robust case in Li and
Young (2022), excess-of-loss reinsurance is the optimal form of reinsurance
strategy for the insurer. The equilibrium investment strategy is determined by
a system of Riccati differential equations. Besides, the equations determining
the equilibrium reinsurance strategy and reinsurance premium rate are given
semi-explicitly, which is simplified to an algebraic equation in a specific
example. Numerical examples illustrate that the game between the insurer and
reinsurer makes the insurance more radical when the agents become more
ambiguity aversion or risk aversion. Furthermore, the level of ambiguity,
ambiguity attitude, and risk attitude of the insurer (reinsurer) have similar
effects on the equilibrium reinsurance strategy, reinsurance premium, and
investment strategy.
"
2212.14477,2023-01-02,"A Novel Experts Advice Aggregation Framework Using Deep Reinforcement
  Learning for Portfolio Management","  Solving portfolio management problems using deep reinforcement learning has
been getting much attention in finance for a few years. We have proposed a new
method using experts signals and historical price data to feed into our
reinforcement learning framework. Although experts signals have been used in
previous works in the field of finance, as far as we know, it is the first time
this method, in tandem with deep RL, is used to solve the financial portfolio
management problem. Our proposed framework consists of a convolutional network
for aggregating signals, another convolutional network for historical price
data, and a vanilla network. We used the Proximal Policy Optimization algorithm
as the agent to process the reward and take action in the environment. The
results suggested that, on average, our framework could gain 90 percent of the
profit earned by the best expert.
"
2301.02754,2023-01-10,On Frequency-Based Optimal Portfolio with Transaction Costs,"  The aim of this paper is to investigate the impact of rebalancing frequency
and transaction costs on the log-optimal portfolio, which is a portfolio that
maximizes the expected logarithmic growth rate of an investor's wealth. We
prove that the frequency-dependent log-optimal portfolio problem with costs is
equivalent to a concave program and provide a version of the dominance theorem
with costs to determine when an investor should invest all available funds in a
particular asset. Then, we show that transaction costs may cause a bankruptcy
issue for the frequency-dependent log-optimal portfolio. To address this issue,
we approximate the problem to obtain a quadratic concave program and derive
necessary and sufficient optimality conditions. Additionally, we prove a
version of the two-fund theorem, which states that any convex combination of
two optimal weights from the optimality conditions is still optimal. We test
our proposed methods using both intraday and daily price data. Finally, we
extend our empirical studies to an online trading scenario by implementing a
sliding window approach. This approach enables us to solve a sequence of
concave programs rather than a potentially computational complex stochastic
dynamic programming problem.
"
2301.04118,2023-01-11,"Achieving a Given Financial Goal with Optimal Deferred Term Insurance
  Purchasing Policy","  This paper researches the problem of purchasing deferred term insurance in
the context of financial planning to maximize the probability of achieving a
personal financial goal. Specifically, our study starts from the perspective of
hedging death risk and longevity risk, and considers the purchase of deferred
term life insurance and deferred term pure endowment to achieve a given
financial goal for the first time in both deterministic and stochastic
framework. In particular, we consider income, consumption and risky investment
in the stochastic framework, extending previous results in
\cite{Bayraktar2016}. The time cutoff m and n make the work more difficult.
However, by establishing new controls,``\emph{quasi-ideal value}""
and``\emph{ideal value}"", we solve the corresponding ordinary differential
equations or stochastic differential equations, and give the specific
expressions for the maximum probability. Then we provide the optimal life
insurance purchasing strategies and the optimal risk investment strategies. In
general, when m \geqslant 0, n>0, deferred term insurance or term life
insurance is a better choice for those who want to achieve their financial or
bequest goals but are not financially sound. In particular, if m >0, n
\rightarrow \infty, our viewpoint also sheds light on reaching a bequest goal
by purchasing deferred whole life insurance. It is worth noting that when m=0,
n \rightarrow \infty, our problem is equivalent to achieving the just mentioned
bequest goal by purchasing whole life insurance, at which point the maximum
probability and the life insurance purchasing strategies we provide are
consistent with those in \cite{Bayraktar2014, Bayraktar2016}.
"
2301.05300,2023-01-16,Deep Reinforcement Learning for Asset Allocation: Reward Clipping,"  Recently, there are many trials to apply reinforcement learning in asset
allocation for earning more stable profits. In this paper, we compare
performance between several reinforcement learning algorithms - actor-only,
actor-critic and PPO models. Furthermore, we analyze each models' character and
then introduce the advanced algorithm, so called Reward clipping model. It
seems that the Reward Clipping model is better than other existing models in
finance domain, especially portfolio optimization - it has strength both in
bull and bear markets. Finally, we compare the performance for these models
with traditional investment strategies during decreasing and increasing
markets.
"
2301.06847,2024-07-01,"Power Utility Maximization with Expert Opinions at Fixed Arrival Times
  in a Market with Hidden Gaussian Drift","  In this paper we study optimal trading strategies in a financial market in
which stock returns depend on a hidden Gaussian mean reverting drift process.
Investors obtain information on that drift by observing stock returns.
Moreover, expert opinions in the form of signals about the current state of the
drift arriving at fixed and known dates are included in the analysis. Drift
estimates are based on Kalman filter techniques. They are used to transform a
power utility maximization problem under partial information into an
optimization problem under full information where the state variable is the
filter of the drift. The dynamic programming equation for this problem is
studied and closed-form solutions for the value function and the optimal
trading strategy of an investor are derived. They allow to quantify the
monetary value of information delivered by the expert opinions. We illustrate
our theoretical findings by results of extensive numerical experiments.
"
2301.07318,2024-01-18,"Dynamic CVaR Portfolio Construction with Attention-Powered Generative
  Factor Learning","  The dynamic portfolio construction problem requires dynamic modeling of the
joint distribution of multivariate stock returns. To achieve this, we propose a
dynamic generative factor model which uses random variable transformation as an
implicit way of distribution modeling and relies on the Attention-GRU network
for dynamic learning and forecasting. The proposed model captures the dynamic
dependence among multivariate stock returns, especially focusing on the
tail-side properties. We also propose a two-step iterative algorithm to train
the model and then predict the time-varying model parameters, including the
time-invariant tail parameters. At each investment date, we can easily simulate
new samples from the learned generative model, and we further perform CVaR
portfolio optimization with the simulated samples to form a dynamic portfolio
strategy. The numerical experiment on stock data shows that our model leads to
wiser investments that promise higher reward-risk ratios and present lower tail
risks.
"
2301.13575,2023-02-01,"Utility-based indifference pricing of pure endowments in a
  Markov-modulated market model","  In this paper we study exponential utility indifference pricing of pure
endowment policies in a stochastic-factor model for an insurance company, which
can also invest in a financial market. Specifically, we propose a modeling
framework where the hazard rate is described by an observable general diffusion
process and the risky asset price evolves as a jump diffusion affected by a
continuous-time finite-state Markov chain representing regimes of the economy.
Using the classical stochastic control approach based on the
Hamilton-Jacobi-Bellman equation, we describe the optimal investment strategies
with and without the insurance derivative and characterize the indifference
price in terms of a classical solution to a linear PDE. We also provide its
probabilistic representation via an extension of the Feynman-Kac formula show
that it satisfies a final value problem. Furthermore, we also discuss the
indifference price for a portfolio of insurance policies and for a term life
insurance. Finally, some numerical experiments are performed to address
sensitivity analyses.
"
2301.13594,2023-02-01,"View fusion vis-\`a-vis a Bayesian interpretation of Black-Litterman for
  portfolio allocation","  The Black-Litterman model extends the framework of the Markowitz Modern
Portfolio Theory to incorporate investor views. We consider a case where
multiple view estimates, including uncertainties, are given for the same
underlying subset of assets at a point in time. This motivates our
consideration of data fusion techniques for combining information from multiple
sources. In particular, we consider consistency-based methods that yield fused
view and uncertainty pairs; such methods are not common to the quantitative
finance literature. We show a relevant, modern case of incorporating machine
learning model-derived view and uncertainty estimates, and the impact on
portfolio allocation, with an example subsuming Arbitrage Pricing Theory. Hence
we show the value of the Black-Litterman model in combination with information
fusion and artificial intelligence-grounded prediction methods.
"
2302.00452,2023-05-15,"f-Betas and Portfolio Optimization with f-Divergence induced Risk
  Measures","  In this paper, we build on using the class of f-divergence induced coherent
risk measures for portfolio optimization and derive its necessary optimality
conditions formulated in CAPM format. We derive a new f-Beta similar to the
Standard Betas and also extended it to previous works in Drawdown Betas. The
f-Beta evaluates portfolio performance under an optimally perturbed market
probability measure, and this family of Beta metrics gives various degrees of
flexibility and interpretability. We conduct numerical experiments using
selected stocks against a chosen S\&P 500 market index as the optimal portfolio
to demonstrate the new perspectives provided by Hellinger-Beta as compared with
Standard Beta and Drawdown Betas. In our experiments, the squared Hellinger
distance is chosen to be the particular choice of the f-divergence function in
the f-divergence induced risk measures and f-Betas. We calculate Hellinger-Beta
metrics based on deviation measures and further extend this approach to
calculate Hellinger-Betas based on drawdown measures, resulting in another new
metric which is termed Hellinger-Drawdown Beta. We compare the resulting
Hellinger-Beta values under various choices of the risk aversion parameter to
study their sensitivity to increasing stress levels.
"
2302.01196,2023-02-03,Risk Budgeting Portfolios from Simulations,"  Risk budgeting is a portfolio strategy where each asset contributes a
prespecified amount to the aggregate risk of the portfolio. In this work, we
propose an efficient numerical framework that uses only simulations of returns
for estimating risk budgeting portfolios. Besides a general cutting planes
algorithm for determining the weights of risk budgeting portfolios for
arbitrary coherent distortion risk measures, we provide a specialised version
for the Expected Shortfall, and a tailored Stochastic Gradient Descent (SGD)
algorithm, also for the Expected Shortfall. We compare our algorithm to
standard convex optimisation solvers and illustrate different risk budgeting
portfolios, constructed using an especially designed Julia package, on real
financial data and compare it to classical portfolio strategies.
"
2302.01816,2023-02-06,"Portfolio Optimisation via the Heston Model Calibrated to Real Asset
  Data","  The debate between active and passive investment strategies has been ongoing
for many years and is far from being over. In this paper, we show that the
choice of an optimal portfolio management strategy depends on an investment
climate, which we measure via the parameters of the Heston model calibrated to
the real stock market data. Depending on the values of those parameters, the
passive strategy may namely outperform the active ones or vice versa. The
method is tested on three stock market indices: S\&P500, DAX and WIG20.
"
2302.02269,2024-05-17,A Modified CTGAN-Plus-Features Based Method for Optimal Asset Allocation,"  We propose a new approach to portfolio optimization that utilizes a unique
combination of synthetic data generation and a CVaR-constraint. We formulate
the portfolio optimization problem as an asset allocation problem in which each
asset class is accessed through a passive (index) fund. The asset-class weights
are determined by solving an optimization problem which includes a
CVaR-constraint. The optimization is carried out by means of a Modified CTGAN
algorithm which incorporates features (contextual information) and is used to
generate synthetic return scenarios, which, in turn, are fed into the
optimization engine. For contextual information we rely on several points along
the U.S. Treasury yield curve. The merits of this approach are demonstrated
with an example based on ten asset classes (covering stocks, bonds, and
commodities) over a fourteen-and-half year period (January 2008-June 2022). We
also show that the synthetic generation process is able to capture well the key
characteristics of the original data, and the optimization scheme results in
portfolios that exhibit satisfactory out-of-sample performance. We also show
that this approach outperforms the conventional equal-weights (1/N) asset
allocation strategy and other optimization formulations based on historical
data only.
"
2302.07935,2024-12-17,Market-Based Probability of Stock Returns,"  This paper describes the dependence of market-based statistical moments of
returns on statistical moments and correlations of the current and past trade
values. We use Markowitz's definition of value weighted return of a portfolio
as the definition of market-based average return of trades during the averaging
period. Then we derive the dependence of market-based volatility and higher
statistical moments of returns on statistical moments, volatilities, and
correlations of the current and past trade values. We derive the approximations
of the characteristic function and the probability of returns by a finite
number q of market-based statistical moments. To forecast market-based average
and volatility of returns at horizon T, one should predict the first two
statistical moments and correlation of current and past trade values at the
same horizon. We discuss the economic reasons that limit the number of
predicted statistical moments of returns by the first two. That limits the
accuracy of the forecasts of probability of returns by the accuracy of the
Gaussian approximations. To improve the reliability of large macroeconomic and
market models like BlackRock's Aladdin, JP Morgan, and the U.S. Fed., the
developers should use market-based statistical moments of returns.
"
2302.08208,2023-02-17,"A Look at Financial Dependencies by Means of Econophysics and Financial
  Economics","  This is a review about financial dependencies which merges efforts in
econophysics and financial economics during the last few years. We focus on the
most relevant contributions to the analysis of asset markets' dependencies,
especially correlational studies, which in our opinion are beneficial for
researchers in both fields. In econophysics, these dependencies can be modeled
to describe financial markets as evolving complex networks. In particular we
show that a useful way to describe dependencies is by means of information
filtering networks that are able to retrieve relevant and meaningful
information in complex financial data sets. In financial economics these
dependencies can describe asset comovement and spill-overs. In particular,
several models are presented that show how network and factor model approaches
are related to modeling of multivariate volatility and asset returns
respectively. Finally, we sketch out how these studies can inspire future
research and how they contribute to support researchers in both fields to find
a better and a stronger common language.
"
2302.08731,2023-02-20,"Optimal management of DB pension fund under both underfunded and
  overfunded cases","  This paper investigates the optimal management of an aggregated defined
benefit pension plan in a stochastic environment. The interest rate follows the
Ornstein-Uhlenbeck model, the benefits follow the geometric Brownian motion
while the contribution rate is determined by the spread method of fund
amortization. The pension manager invests in the financial market with three
assets: cash, bond and stock. Regardless of the initial status of the plan, we
suppose that the pension fund may become underfunded or overfunded in the
planning horizon. The optimization goal of the manager is to maximize the
expected utility in the overfunded region minus the weighted solvency risk in
the underfunded region. By introducing an auxiliary process and related
equivalent optimization problems and using the martingale method, the optimal
wealth process, optimal portfolio and efficient frontier are obtained under
four cases (high tolerance towards solvency risk, low tolerance towards
solvency risk, a specific lower bound, and high lower bound). Moreover, we also
obtain the probabilities that the optimal terminal wealth falls in the
overfunded and underfunded regions. At last, we present numerical analyses to
illustrate the manager's economic behaviors.
"
2302.08829,2024-06-27,"Great year, bad Sharpe? A note on the joint distribution of performance
  and risk-adjusted return","  Returns distributions are heavy-tailed across asset classes. In this note, I
examine the implications of this well-known stylized fact for the joint
statistics of performance (absolute return) and Sharpe ratio (risk-adjusted
return). Using both synthetic and real data, I show that, all other things
being equal, the investments with the best in-sample performance are never
associated with the best in-sample Sharpe ratios (and vice versa). This
counter-intuitive effect is unrelated to the risk-return tradeoff familiar from
portfolio theory: it is, rather, a consequence of asymptotic correlations
between the sample mean and sample standard deviation of heavy-tailed
variables. In addition to its large sample noise, this non-monotonic
association of the Sharpe ratio with performance puts into question its status
as the gold standard metric of investment quality.
"
2302.09382,2024-05-14,"Co-trading networks for modeling dynamic interdependency structures and
  estimating high-dimensional covariances in US equity markets","  The time proximity of trades across stocks reveals interesting topological
structures of the equity market in the United States. In this article, we
investigate how such concurrent cross-stock trading behaviors, which we denote
as co-trading, shape the market structures and affect stock price co-movements.
By leveraging a co-trading-based pairwise similarity measure, we propose a
novel method to construct dynamic networks of stocks. Our empirical studies
employ high-frequency limit order book data from 2017-01-03 to 2019-12-09. By
applying spectral clustering on co-trading networks, we uncover economically
meaningful clusters of stocks. Beyond the static Global Industry Classification
Standard (GICS) sectors, our data-driven clusters capture the time evolution of
the dependency among stocks. Furthermore, we demonstrate statistically
significant positive relations between low-latency co-trading and return
covariance. With the aid of co-trading networks, we develop a robust estimator
for high-dimensional covariance matrix, which yields superior economic value on
portfolio allocation. The mean-variance portfolios based on our covariance
estimates achieve both lower volatility and higher Sharpe ratios than standard
benchmarks.
"
2302.10175,2023-12-08,"Spatio-Temporal Momentum: Jointly Learning Time-Series and
  Cross-Sectional Strategies","  We introduce Spatio-Temporal Momentum strategies, a class of models that
unify both time-series and cross-sectional momentum strategies by trading
assets based on their cross-sectional momentum features over time. While both
time-series and cross-sectional momentum strategies are designed to
systematically capture momentum risk premia, these strategies are regarded as
distinct implementations and do not consider the concurrent relationship and
predictability between temporal and cross-sectional momentum features of
different assets. We model spatio-temporal momentum with neural networks of
varying complexities and demonstrate that a simple neural network with only a
single fully connected layer learns to simultaneously generate trading signals
for all assets in a portfolio by incorporating both their time-series and
cross-sectional momentum features. Backtesting on portfolios of 46
actively-traded US equities and 12 equity index futures contracts, we
demonstrate that the model is able to retain its performance over benchmarks in
the presence of high transaction costs of up to 5-10 basis points. In
particular, we find that the model when coupled with least absolute shrinkage
and turnover regularization results in the best performance over various
transaction cost scenarios.
"
2302.10573,2023-02-22,"Convex scalarizations of the mean-variance-skewness-kurtosis problem in
  portfolio selection","  We consider the multi-objective mean-variance-skewness-kurtosis (MVSK)
problem in portfolio selection, with and without shorting and leverage.
Additionally, we define a sparse variant of MVSK where feasible portfolios have
supports contained in a chosen class of sets. To find the MVSK problem's Pareto
front, we linearly scalarize the four objectives of MVSK into a scalar-valued
degree four polynomial $F_{\lambda}$ depending on some hyper-parameter $\lambda
\in \Delta^4$. As one of our main results, we identify a set of
hyper-parameters for which $F_{\lambda}$ is convex over the probability simplex
(or over the cube). By exploiting the convexity and neatness of the
scalarization, we can compute part of the Pareto front. We compute an optimizer
of the scalarization $F_{\lambda}$ for each $\lambda$ in a grid sampling of
$\Delta^4$. To see each optimizer's quality, we plot scaled portfolio objective
values against hyper-parameters. Doing so, we reveal a sub-set of optimizers
that provide a superior trade-off among the four objectives in MVSK.
"
2302.11652,2023-04-21,"Complexity-Approximation Trade-offs in Exchange Mechanisms: AMMs vs.
  LOBs","  This paper presents a general framework for the design and analysis of
exchange mechanisms between two assets that unifies and enables comparisons
between the two dominant paradigms for exchange, constant function market
markers (CFMMs) and limit order books (LOBs). In our framework, each liquidity
provider (LP) submits to the exchange a downward-sloping demand curve,
specifying the quantity of the risky asset it wishes to hold at each price; the
exchange buys and sells the risky asset so as to satisfy the aggregate
submitted demand. In general, such a mechanism is budget-balanced and enables
price discovery. Different exchange mechanisms correspond to different
restrictions on the set of acceptable demand curves. The primary goal of this
paper is to formalize an approximation-complexity trade-off that pervades the
design of exchange mechanisms. For example, CFMMs give up expressiveness in
favor of simplicity: the aggregate demand curve of the LPs can be described
using constant space, but most demand curves cannot be well approximated by any
function in the corresponding single-dimensional family. LOBs, intuitively,
make the opposite trade-off: any downward-slowing demand curve can be well
approximated by a collection of limit orders, but the space needed to describe
the state of a LOB can be large. This paper introduces a general measure of
{\em exchange complexity}, defined by the minimal set of basis functions that
generate, through their conical hull, all of the demand functions allowed by an
exchange. With this complexity measure in place, we investigate the design of
{\em optimally expressive} exchange mechanisms, meaning the lowest complexity
mechanisms that allow for arbitrary downward-sloping demand curves to be well
approximated. As a case study, we interpret the complexity-approximation
trade-offs in the widely-used Uniswap v3 AMM through the lens of our framework.
"
2302.11729,2023-04-21,Factor Exposure Heterogeneity in Green and Brown Stocks,"  Using the peer-exposure ratio, we explore the factor exposure heterogeneity
in green and brown stocks. By looking at peer groups of S&P 500 index firms
over 2014-2020 based on their greenhouse gas emission levels, we find that, on
average, green stocks exhibit less factor exposure heterogeneity than brown
stocks for most of the traditional equity factors but the value factor. Hence,
investment managers shifting their investments from brown stocks to green
stocks have less room to differentiate themselves regarding their factor
exposures. Finally, we find that factor exposure heterogeneity has increased
for green stocks compared to earlier periods.
"
2302.13245,2023-02-28,Physical Momentum in the Indian Stock Market,"  Our study focuses on determining the presence of abnormal returns for
physical momentum portfolios in the context of the Indian market. The physical
momentum portfolios, comprising stocks from the NSE 500, are constructed for
the daily, weekly, monthly, and yearly timescales. In the aforementioned
timescales, we empirically evaluate the historical returns and varied risk
profiles of these portfolios for the years 2014-2021. It has been observed that
the best-performing physical momentum portfolios from each of the four
timescales achieved higher returns and better risk measures when compared to
the benchmark NIFTY 50 portfolio. We further find that the high-frequency daily
time scale exhibits the strongest reversal in the physical momentum effect,
wherein the portfolio yielded a 16-fold profit over the initial investment.
"
2302.13646,2023-02-28,A Tale of Tail Covariances (and Diversified Tails),"  This paper deals with tail diversification in financial time series through
the concept of statistical independence by way of differential entropy and
mutual information. By using moments as contrast functions to isolate the tails
of the return distributions, we recover the tail covariance matrix, a specific
two-dimensional slice of the mixed moment tensor, as a key driver of tail
diversification.
  We further explore the links between the moment contrast approach and the
original entropy formulation, and show an example of in- and out-of-sample
diversification on a broad stock universe.
"
2302.13979,2023-02-28,"Wasserstein-Kelly Portfolios: A Robust Data-Driven Solution to Optimize
  Portfolio Growth","  We introduce a robust variant of the Kelly portfolio optimization model,
called the Wasserstein-Kelly portfolio optimization. Our model, taking a
Wasserstein distributionally robust optimization (DRO) formulation, addresses
the fundamental issue of estimation error in Kelly portfolio optimization by
defining a ``ball"" of distributions close to the empirical return distribution
using the Wasserstein metric and seeking a robust log-optimal portfolio against
the worst-case distribution from the Wasserstein ball. Enhancing the Kelly
portfolio using Wasserstein DRO is a natural step to take, given many
successful applications of the latter in areas such as machine learning for
generating robust data-driven solutions. However, naive application of
Wasserstein DRO to the growth-optimal portfolio problem can lead to several
issues, which we resolve through careful modelling. Our proposed model is both
practically motivated and efficiently solvable as a convex program. Using
empirical financial data, our numerical study demonstrates that the
Wasserstein-Kelly portfolio can outperform the Kelly portfolio in out-of-sample
testing across multiple performance metrics and exhibits greater stability.
"
2302.13994,2023-02-28,Gambling the World Away: Myopic Investors,"  Myopic investors are locally rational decision-makers but globally
irrational. Their suboptimal portfolios lag the market. As a consequence, other
market participants are provided with profit opportunities. Not subterfuge but
constrained optimisation leads to disparities. Four overlapping examples are
given. The first case centres on the difference between local and global
optimisers and their respective Kelly fractions, the second on isolated versus
combined optimisation, the third on the distinction between qualitative and
quantitative investor, the fourth on the non-commutative nature of information
and the resulting asymmetries.
"
2303.01167,2023-03-03,Robust portfolio selection under Recovery Average Value at Risk,"  We study mean-risk optimal portfolio problems where risk is measured by
Recovery Average Value at Risk, a prominent example in the class of recovery
risk measures. We establish existence results in the situation where the joint
distribution of portfolio assets is known as well as in the situation where it
is uncertain and only assumed to belong to a set of mixtures of benchmark
distributions (mixture uncertainty) or to a cloud around a benchmark
distribution (box uncertainty). The comparison with the classical Average Value
at Risk shows that portfolio selection under its recovery version enables
financial institutions to exert better control on the recovery on liabilities
while still allowing for tractable computations.
"
2303.01485,2023-03-03,Bayesian Optimization of ESG Financial Investments,"  Financial experts and analysts seek to predict the variability of financial
markets. In particular, the correct prediction of this variability ensures
investors successful investments. However, there has been a big trend in
finance in the last years, which are the ESG criteria. Concretely, ESG
(Economic, Social and Governance) criteria have become more significant in
finance due to the growing importance of investments being socially
responsible, and because of the financial impact companies suffer when not
complying with them. Consequently, creating a stock portfolio should not only
take into account its performance but compliance with ESG criteria. Hence, this
paper combines mathematical modelling, with ESG and finance. In more detail, we
use Bayesian optimization (BO), a sequential state-of-the-art design strategy
to optimize black-boxes with unknown analytical and costly-to compute
expressions, to maximize the performance of a stock portfolio under the
presence of ESG criteria soft constraints incorporated to the objective
function. In an illustrative experiment, we use the Sharpe ratio, that takes
into consideration the portfolio returns and its variance, in other words, it
balances the trade-off between maximizing returns and minimizing risks. In the
present work, ESG criteria have been divided into fourteen independent
categories used in a linear combination to estimate a firm total ESG score.
Most importantly, our presented approach would scale to alternative black-box
methods of estimating the performance and ESG compliance of the stock
portfolio. In particular, this research has opened the door to many new
research lines, as it has proved that a portfolio can be optimized using a BO
that takes into consideration financial performance and the accomplishment of
ESG criteria.
"
2303.01855,2024-06-04,"An adaptive volatility method for probabilistic forecasting and its
  application to the M6 financial forecasting competition","  In this paper, we address the problem of probabilistic forecasting using an
adaptive volatility method rooted in classical time-varying volatility models
and leveraging online stochastic optimization algorithms. These principles were
successfully applied in the M6 forecasting competition under the team named
AdaGaussMC. Our approach takes a unique path by embracing the Efficient Market
Hypothesis (EMH) instead of trying to beat the market directly. We focus on
evaluating the efficient market, emphasizing the importance of online
forecasting in adapting to the dynamic nature of financial markets. The three
key points of our approach are: (a) apply the univariate time-varying
volatility model AdaVol, (b) obtain probabilistic forecasts of future returns,
and (c) optimize the competition metrics using stochastic gradient-based
algorithms. We contend that the simplicity of our approach contributes to its
robustness and consistency. Remarkably, our performance in the M6 competition
resulted in an overall 7th ranking, with a noteworthy 5th position in the
forecasting task. This achievement, considering the perceived simplicity of our
approach, underscores the efficacy of our adaptive volatility method in the
realm of probabilistic forecasting.
"
2303.02298,2023-03-07,"Continuous-Time Path-Dependent Exploratory Mean-Variance Portfolio
  Construction","  In this paper, we present an extended exploratory continuous-time
mean-variance framework for portfolio management. Our strategy involves a new
clustering method based on simulated annealing, which allows for more practical
asset selection. Additionally, we consider past wealth evolution when
constructing the mean-variance portfolio. We found that our strategy
effectively learns from the past and performs well in practice.
"
2303.02303,2023-03-07,"Electricity Virtual Bidding Strategy Via Entropy-Regularized Stochastic
  Control Method","  We propose a virtual bidding strategy by modeling the price differences
between the day-ahead market and the real-time market as Brownian motion with
drift, where the drift rate and volatility are functions of meteorological
variables. We then transform the virtual bidding problem into a mean-variance
portfolio management problem, where we approach the mean-variance portfolio
management problem by using the exploratory mean-variance portfolio management
framework
"
2303.05654,2023-03-13,The Financial Market of Indices of Socioeconomic Wellbeing,"  The financial industry should be involved in mitigating the risk of downturns
in the financial wellbeing indices around the world by implementing
well-developed financial tools such as insurance instruments on the underlying
wellbeing indices. We define a new quantitative measure of the wellbeing of a
country's population for those countries using the world development indicators
provided by the World Bank. We monetize the indices of socioeconomic wellbeing,
which serve as ""risky assets,"" and consequently develop a global financial
market for them, which serves as a ""market of indices of socioeconomic
wellbeing."" Then, we compare the wellbeing of different countries using
financial econometric analysis and dynamic asset pricing theory. We provide the
optimal portfolio weight composition along with the efficient frontiers of the
wellbeing socioeconomic indices with different risk-return measures. We derive
insurance instruments, such as put options, which allow the financial industry
to monitor, manage, and trade these indices, creating the funds for insurance
against adverse movements of those indices. Our findings should help financial
institutions to incorporate socioeconomic issues as an additional dimension to
their ""two-dimensional"" risk-return adjusted optimal financial portfolios.
"
2303.07158,2024-05-20,Uniform Pessimistic Risk and its Optimal Portfolio,"  The optimal allocation of assets has been widely discussed with the
theoretical analysis of risk measures, and pessimism is one of the most
attractive approaches beyond the conventional optimal portfolio model. The
$\alpha$-risk plays a crucial role in deriving a broad class of pessimistic
optimal portfolios. However, estimating an optimal portfolio assessed by a
pessimistic risk is still challenging due to the absence of a computationally
tractable model. In this study, we propose an integral of $\alpha$-risk called
the \textit{uniform pessimistic risk} and the computational algorithm to obtain
an optimal portfolio based on the risk. Further, we investigate the theoretical
properties of the proposed risk in view of three different approaches: multiple
quantile regression, the proper scoring rule, and distributionally robust
optimization. Real data analysis of three stock datasets (S\&P500, CSI500,
KOSPI200) demonstrates the usefulness of the proposed risk and portfolio model.
"
2303.07244,2023-03-14,"The Stock Price Relationship between Holding Companies and Subsidiaries:
  A Case study of Indonesia Multiholding Companies","  This study aimed to examine the correlation between the stock prices of two
major Indonesian holding companies, MNC Group and Elang Mahkota Teknologi
(Emtek) Group, and their respective subsidiaries as case studies. The data for
the analysis were collected from 2013 to 2022, and Spearman correlation was
used to determine the strength and direction of the relationship between the
stock prices of the holding companies and their subsidiaries. The results of
the analysis revealed that there were varying degrees of correlation between
the stock prices of the holding companies and their subsidiaries. The strongest
positive correlation was observed between BHIT and BMTR, while the weakest
correlations were found between BHIT and IPTV, and BHIT and MSIN. The
correlations were also found to have changed over time, possibly due to market
conditions, company-specific events, or changes in industry sectors.In the case
of Emtek Group, the analysis suggested that EMTK's stock price movements had a
significant impact on the stock prices of its subsidiaries, with varying
strengths of relationships. The negative correlation between EMTK and SCMA over
the entire period suggested an inverse relationship, while positive
correlations with BUKA, AMOR, BBHI, and RSGK indicated a tendency to move in
the same direction as EMTK's stock price. The correlations were found to have
increased over time, possibly due to market conditions and EMTK's ownership
stake in these companies. Overall, the findings of this study suggest that
there is a complex interplay between the stock prices of parent companies and
their subsidiaries, and that there are a variety of factors that can influence
these relationships over time. These findings may be useful for investors in
making informed decisions about their investment portfolios, as changes in the
correlations could impact their portfolio's performance.
"
2303.08462,2023-09-19,"Optimal Investment in Defined Contribution Pension Schemes with Forward
  Utility Preferences","  Optimal investment strategies of an individual worker during the accumulation
phase in the defined contribution pension scheme have been well studied in the
literature. Most of them adopted the classical backward model and approach, but
any pre-specifications of retirement time, preferences, and market environment
models do not often hold in such a prolonged horizon of the pension scheme.
Pre-commitment to ensure the time-consistency of an optimal investment strategy
derived from the backward model and approach leads the supposedly optimal
strategy to be sub-optimal in the actual realizations. This paper revisits the
optimal investment problem for the worker during the accumulation phase in the
defined contribution pension scheme, via the forward preferences, in which an
environment-adapting strategy is able to hold optimality and time-consistency
together. Stochastic partial differential equation representation for the
worker's forward preferences is illustrated. This paper constructs two of the
forward utility preferences and solves the corresponding optimal investment
strategies, in the cases of initial power and exponential utility functions.
"
2303.08521,2024-02-22,Optimal investment in ambiguous financial markets with learning,"  We consider the classical multi-asset Merton investment problem under drift
uncertainty, i.e. the asset price dynamics are given by geometric Brownian
motions with constant but unknown drift coefficients. The investor assumes a
prior drift distribution and is able to learn by observing the asset prize
realizations during the investment horizon. While the solution of an expected
utility maximizing investor with constant relative risk aversion (CRRA) is well
known, we consider the optimization problem under risk and ambiguity
preferences by means of the KMM (Klibanoff et al. (2005)) approach. Here, the
investor maximizes a double certainty equivalent. The inner certainty
equivalent is for given drift coefficient, the outer is based on a drift
distribution. Assuming also a CRRA type ambiguity function, it turns out that
the optimal strategy can be stated in terms of the solution without ambiguity
preferences but an adjusted drift distribution. To the best of our knowledge an
explicit solution method in this setting is new. We rely on some duality
theorems to prove our statements.
  Based on our theoretical results, we are able to shed light on the impact of
the prior drift distribution as well as the consequences of ambiguity
preferences via the transfer to an adjusted drift distribution, i.e. we are
able to explain the interaction of risk and ambiguity preferences. We compare
our results with the ones in a pre-commitment setup where the investor is
restricted to deterministic strategies. It turns out that (under risk and
ambiguity aversion) an infinite investment horizon implies in both cases a
maximin decision rule, i.e. the investor follows the worst (best) Merton
fraction (over all realizations of it) if she is more (less) risk averse than a
log-investor. We illustrate our findings with an extensive numerical study.
"
2303.09835,2023-03-20,"Portfolio Optimization with Allocation Constraints and Stochastic Factor
  Market Dynamics","  We study the expected utility portfolio optimization problem in an incomplete
financial market where the risky asset dynamics depend on stochastic factors
and the portfolio allocation is constrained to lie within a given convex set.
We employ fundamental duality results from real constrained optimization to
formally derive a dual representation of the associated HJB PDE. Using this
representation, we provide a condition on the market dynamics and the
allocation constraints, which ensures that the solution to the HJB PDE is
exponentially affine and separable. This condition is used to derive an
explicit expression for the optimal allocation-constrained portfolio up to a
deterministic minimizer and the solution to a system of Riccati ODEs in a
market with CIR volatility and in a market with multi-factor OU short rate.
"
2303.11013,2023-03-21,"Venture Capital Portfolio Construction and the Main Factors Impacting
  the Optimal Strategy","  The optimal portfolio size for a venture capital (VC) fund is a topic often
debated, but there is no consensus on the best strategy. This is because it is
a function of many factors. It is not easy to find a general formula that can
be applied to all situations, and it largely depends on the goal of the fund.
In this report, we will go through the different factors step by step, studying
how they affect fund returns and the optimal portfolio size, starting with some
basic assumptions and then increasing the complexity of the model.
"
2303.12209,2023-03-29,Portfolio Optimization with Relative Tail Risk,"  This paper proposes analytic forms of portfolio CoVaR and CoCVaR on the
normal tempered stable market model. Since CoCVaR captures the relative risk of
the portfolio with respect to a benchmark return, we apply it to the relative
portfolio optimization. Moreover, we derive analytic forms for the marginal
contribution to CoVaR and the marginal contribution to CoCVaR. We discuss the
Monte-Carlo simulation method to calculate CoCVaR and the marginal
contributions of CoVaR and CoCVaR. As the empirical illustration, we show
relative portfolio optimization with thirty stocks under the distress condition
of the Dow Jones Industrial Average. Finally, we perform the risk budgeting
method to reduce the CoVaR and CoCVaR of the portfolio based on the marginal
contributions to CoVaR and CoCVaR.
"
2303.12751,2023-11-13,A Unified Framework for Fast Large-Scale Portfolio Optimization,"  We introduce a unified framework for rapid, large-scale portfolio
optimization that incorporates both shrinkage and regularization techniques.
This framework addresses multiple objectives, including minimum variance,
mean-variance, and the maximum Sharpe ratio, and also adapts to various
portfolio weight constraints. For each optimization scenario, we detail the
translation into the corresponding quadratic programming (QP) problem and then
integrate these solutions into a new open-source Python library. Using 50 years
of return data from US mid to large-sized companies, and 33 distinct
firm-specific characteristics, we utilize our framework to assess the
out-of-sample monthly rebalanced portfolio performance of widely-adopted
covariance matrix estimators and factor models, examining both daily and
monthly returns. These estimators include the sample covariance matrix, linear
and nonlinear shrinkage estimators, and factor portfolios based on Asset
Pricing (AP) Trees, Principal Component Analysis (PCA), Risk Premium PCA
(RP-PCA), and Instrumented PCA (IPCA). Our findings emphasize that AP-Trees and
PCA-based factor models consistently outperform all other approaches in
out-of-sample portfolio performance. Finally, we develop new l1 and l2
regularizations of factor portfolio norms which not only elevate the portfolio
performance of AP-Trees and PCA-based factor models but they have a potential
to reduce an excessive turnover and transaction costs often associated with
these models.
"
2303.13282,2023-03-24,"Accurate solution of the Index Tracking problem with a hybrid simulated
  annealing algorithm","  An actively managed portfolio almost never beats the market in the long term.
Thus, many investors often resort to passively managed portfolios whose aim is
to follow a certain financial index. The task of building such passive
portfolios aiming also to minimize the transaction costs is called Index
Tracking (IT), where the goal is to track the index by holding only a small
subset of assets in the index. As such, it is an NP-hard problem and becomes
unfeasible to solve exactly for indices with more than 100 assets. In this
work, we present a novel hybrid simulated annealing method that can efficiently
solve the IT problem for large indices and is flexible enough to adapt to
financially relevant constraints. By tracking the S&P-500 index between the
years 2011 and 2018 we show that our algorithm is capable of finding optimal
solutions in the in-sample period of past returns and can be tuned to provide
optimal returns in the out-of-sample period of future returns. Finally, we
focus on the task of holding an IT portfolio during one year and rebalancing
the portfolio every month. Here, our hybrid simulated annealing algorithm is
capable of producing financially optimal portfolios already for small subsets
of assets and using reasonable computational resources, making it an
appropriate tool for financial managers.
"
2303.14533,2024-09-27,The Elasticity of Quantitative Investment,"  What is the demand elasticity of statistical arbitrageurs that invest
according to the advice of modern cross-sectional asset pricing models?
Thirteen models from the literature exhibit strikingly inelastic demand, in
contrast to classical models that rely on statistical arbitrageurs to create
elastic market demand for assets. This inelasticity arises from the difficulty
of trading against price changes. A quantitative equilibrium model shows that
aggregate demand remains inelastic even with these statistical arbitrageurs in
the market.
"
2303.15830,2023-04-12,"Mean-variance hybrid portfolio optimization with quantile-based risk
  measure","  This paper addresses the importance of incorporating various risk measures in
portfolio management and proposes a dynamic hybrid portfolio optimization model
that combines the spectral risk measure and the Value-at-Risk in the
mean-variance formulation. By utilizing the quantile optimization technique and
martingale representation, we offer a solution framework for these issues and
also develop a closed-form portfolio policy when all market parameters are
deterministic. Our hybrid model outperforms the classical continuous-time
mean-variance portfolio policy by allocating a higher position of the risky
asset in favorable market states and a less risky asset in unfavorable market
states. This desirable property leads to promising numerical experiment
results, including improved Sortino ratio and reduced downside risk compared to
the benchmark models.
"
2303.17266,2023-03-31,Coskewness under dependence uncertainty,"  We study the impact of dependence uncertainty on the expectation of the
product of $d$ random variables, $\mathbb{E}(X_1X_2\cdots X_d)$ when $X_i \sim
F_i$ for all~$i$. Under some conditions on the $F_i$, explicit sharp bounds are
obtained and a numerical method is provided to approximate them for arbitrary
choices of the $F_i$. The results are applied to assess the impact of
dependence uncertainty on coskewness. In this regard, we introduce a novel
notion of ""standardized rank coskewness,"" which is invariant under strictly
increasing transformations and takes values in $[-1,\ 1]$.
"
2304.02362,2023-04-06,"A network-based strategy of price correlations for optimal
  cryptocurrency portfolios","  A cryptocurrency is a digital asset maintained by a decentralised system
using cryptography. Investors in this emerging digital market are exploring the
profitability potential of portfolios in place of single coins. Portfolios are
particularly useful given that price forecasting in such a volatile market is
challenging. The crypto market is a self-organised complex system where the
complex inter-dependencies between the cryptocurrencies may be exploited to
understand the market dynamics and build efficient portfolios. In this letter,
we use network methods to identify highly decorrelated cryptocurrencies to
create diversified portfolios using the Markowitz Portfolio Theory agnostic to
future market behaviour. The performance of our network-based portfolios is
optimal with 46 coins and superior to benchmarks up to an investment horizon of
14 days, reaching up to 1,066% average expected return within 1 day, with
reasonable associated risks. We also show that popular cryptocurrencies are
typically not included in the optimal portfolios. Past price correlations
reduce risk and may improve the performance of crypto portfolios in comparison
to methodologies based exclusively on price auto-correlations. Short-term
crypto investments may be competitive to traditional high-risk investments such
as the stock market or commodity market but call for caution given the high
variability of prices.
"
2304.05297,2023-05-26,"Neural Network Approach to Portfolio Optimization with Leverage
  Constraints:a Case Study on High Inflation Investment","  Motivated by the current global high inflation scenario, we aim to discover a
dynamic multi-period allocation strategy to optimally outperform a passive
benchmark while adhering to a bounded leverage limit. To this end, we formulate
an optimal control problem to outperform a benchmark portfolio throughout the
investment horizon. Assuming the asset prices follow the jump-diffusion model
during high inflation periods, we first establish a closed-form solution for
the optimal strategy that outperforms a passive strategy under the cumulative
quadratic tracking difference (CD) objective, assuming continuous trading and
no bankruptcy. To obtain strategies under the bounded leverage constraint among
other realistic constraints, we then propose a novel leverage-feasible neural
network (LFNN) to represent control, which converts the original constrained
optimization problem into an unconstrained optimization problem that is
computationally feasible with standard optimization methods. We establish
mathematically that the LFNN approximation can yield a solution that is
arbitrarily close to the solution of the original optimal control problem with
bounded leverage. We further apply the LFNN approach to a four-asset investment
scenario with bootstrap resampled asset returns from the filtered high
inflation regime data. The LFNN strategy is shown to consistently outperform
the passive benchmark strategy by about 200 bps (median annualized return),
with a greater than 90% probability of outperforming the benchmark at the end
of the investment horizon.
"
2304.05900,2023-04-13,Managing Portfolio for Maximizing Alpha and Minimizing Beta,"  Portfolio management is an essential component of investment strategy that
aims to maximize returns while minimizing risk. This paper explores several
portfolio management strategies, including asset allocation, diversification,
active management, and risk management, and their importance in optimizing
portfolio performance. These strategies are examined individually and in
combination to demonstrate how they can help investors maximize alpha and
minimize beta. Asset allocation is the process of dividing a portfolio among
different asset classes to achieve the desired level of risk and return.
Diversification involves spreading investments across different securities and
sectors to minimize the impact of individual security or sector-specific risks.
Active management involves security selection and risk management techniques to
generate excess returns while minimizing losses. Risk management strategies,
such as stop-loss orders and options strategies, aim to minimize losses in
adverse market conditions. The importance of combining these strategies for
optimizing portfolio performance is emphasized in this paper. The proper
implementation of these strategies can help investors achieve their investment
goals over the long-term, while minimizing exposure to risks. A call to action
for investors to utilize portfolio management strategies to maximize alpha and
minimize beta is also provided.
"
2304.06466,2024-02-22,"Market-Based ""Actual"" Returns of Investors","  We describe how the market-based average and volatility of the ""actual""
return, which the investors gain within their market sales, depend on the
statistical moments, volatilities, and correlations of the current and past
market trade values. We describe three successive approximations. First, we
derive the dependence of the market-based average and volatility of a single
sale return on market trade statistical moments determined by multiple
purchases in the past. Then, we describe the dependence of average and
volatility of return that a single investor gains during the ""trading day.""
Finally, we derive the market-based average and volatility of return of
different investors during the ""trading day"" as a function of volatilities and
correlations of market trade values. That highlights the distribution of the
""actual"" return of market trade and can serve as a benchmark for ""purchasing""
investors.
"
2304.06859,2023-11-21,A Natural Copula,"  Copulas are widely used in financial economics as well as in other areas of
applied mathematics. Yet, there is much arbitrariness in their choice. The
author proposes ""a natural copula"" concept, which minimizes Wasserstein
distance between distributions in some space, in which both these distributions
are embedded. Transport properties and hydrodynamic interpretation are
discussed with two examples of distributions of financial significance. A
natural copula can be parsimoniously estimated by the methods of linear
programming.
"
2304.06938,2023-07-17,Robust utility maximization with intractable claims,"  We study a continuous-time expected utility maximization problem in which the
investor at maturity receives the value of a contingent claim in addition to
the investment payoff from the financial market. The investor knows nothing
about the claim other than its probability distribution, hence an ``intractable
claim''. In view of the lack of necessary information about the claim, we
consider a robust formulation to maximize her utility in the worst scenario. We
apply the quantile formulation to solve the problem, expressing the quantile
function of the optimal terminal investment income as the solution of certain
variational inequalities of ordinary differential equations and obtaining the
resulting optimal trading strategy. In the case of an exponential utility, the
problem reduces to a (non-robust) rank--dependent utility maximization with
probability distortion whose solution is available in the literature. The
results can also be used to determine the utility indifference price of the
intractable claim.
"
2304.07672,2023-04-18,"Optimal Investment and Consumption Strategies with General and Linear
  Transaction Costs under CRRA Utility","  Transaction costs play a critical role in asset allocation and consumption
strategies in portfolio management. We apply the methods of dynamic programming
and singular perturbation expansion to derive the closed-form leading solutions
to this problem for small transaction costs with arbitrary transaction cost
structure by maximizing the expected CRRA (constant relative risk aversion)
utility function for this problem. We also discuss in detail the case which
consists of both fixed and proportional transaction costs.
"
2304.08910,2023-11-06,"On the Separation of Estimation and Control in Risk-Sensitive Investment
  Problems under Incomplete Observation","  A typical approach to tackle stochastic control problems with partial
observation is to separate the control and estimation tasks. However, it is
well known that this separation generally fails to deliver an actual optimal
solution for risk-sensitive control problems. This paper investigates the
separability of a general class of risk-sensitive investment management
problems when a finite-dimensional filter exists. We show that the
corresponding separated problem, where instead of the unobserved quantities,
one considers their conditional filter distribution given the observations, is
strictly equivalent to the original control problem. We widen the applicability
of the so-called Modified Zakai Equation (MZE) for the study of the separated
problem and prove that the MZE simplifies to a PDE in our approach.
Furthermore, we derive criteria for separability. We do not solve the separated
control problem but note that the existence of a finite-dimensional filter
leads to a finite state space for the separated problem. Hence, the difficulty
is equivalent to solving a complete observation risk-sensitive problem. Our
results have implications for existing risk-sensitive investment management
models with partial observations in that they establish their separability.
Their implications for future research on new applications is mainly to provide
conditions to ensure separability.
"
2304.10802,2025-04-11,An extended Merton problem with relaxed benchmark tracking,"  This paper studies a Merton's optimal portfolio and consumption problem in an
extended formulation by incorporating the benchmark tracking on the wealth
process. We consider a tracking formulation such that the wealth process
compensated by a fictitious capital injection outperforms the benchmark at all
times. The fund manager aims to maximize the expected utility of consumption
deducted by the cost of the capital injection, where the latter term can also
be interpreted as the expected largest shortfall of the wealth with reference
to the benchmark. By considering an auxiliary state process, we formulate an
equivalent stochastic control problem with state reflections at zero. For
general utility functions and It\^o diffusion benchmark process, we develop a
convex duality theorem, new to the literature, to the auxiliary stochastic
control problem with state reflections in which the dual process also exhibits
reflections from above. For CRRA utility and geometric Brownian motion
benchmark process, we further derive the optimal portfolio and consumption in
feedback form using the new duality theorem, allowing us to discuss some
interesting financial implications induced by the additional risk-taking from
the capital injection and the goal of tracking.
"
2304.11856,2023-04-25,"Portfolio Optimization using Predictive Auxiliary Classifier Generative
  Adversarial Networks with Measuring Uncertainty","  In financial engineering, portfolio optimization has been of consistent
interest. Portfolio optimization is a process of modulating asset distributions
to maximize expected returns and minimize risks. To obtain the expected
returns, deep learning models have been explored in recent years. However, due
to the deterministic nature of the models, it is difficult to consider the risk
of portfolios because conventional deep learning models do not know how
reliable their predictions can be. To address this limitation, this paper
proposes a probabilistic model, namely predictive auxiliary classifier
generative adversarial networks (PredACGAN). The proposed PredACGAN utilizes
the characteristic of the ACGAN framework in which the output of the generator
forms a distribution. While ACGAN has not been employed for predictive models
and is generally utilized for image sample generation, this paper proposes a
method to use the ACGAN structure for a probabilistic and predictive model.
Additionally, an algorithm to use the risk measurement obtained by PredACGAN is
proposed. In the algorithm, the assets that are predicted to be at high risk
are eliminated from the investment universe at the rebalancing moment.
Therefore, PredACGAN considers both return and risk to optimize portfolios. The
proposed algorithm and PredACGAN have been evaluated with daily close price
data of S&P 500 from 1990 to 2020. Experimental scenarios are assumed to
rebalance the portfolios monthly according to predictions and risk measures
with PredACGAN. As a result, a portfolio using PredACGAN exhibits 9.123% yearly
returns and a Sharpe ratio of 1.054, while a portfolio without considering risk
measures shows 1.024% yearly returns and a Sharpe ratio of 0.236 in the same
scenario. Also, the maximum drawdown of the proposed portfolio is lower than
the portfolio without PredACGAN.
"
2305.01642,2023-05-03,"Construct sparse portfolio with mutual fund's favourite stocks in China
  A share market","  Unlike developed market, some emerging markets are dominated by retail and
unprofessional trading. China A share market is a good and fitting example in
last 20 years. Meanwhile, lots of research show professional investor in China
A share market continuously generate excess return compare with total market
index. Specifically, this excess return mostly come from stock selectivity
ability instead of market timing. However for some reason such as fund capacity
limit, fund manager change or market regional switch, it is very hard to find a
fund could continuously beat market. Therefore, in order to get excess return
from mutual fund industry, we use quantitative way to build the sparse
portfolio that take advantage of favorite stocks by mutual fund in China A
market. Firstly we do the analysis about favourite stocks by mutual fund and
compare the different method to construct our portfolio. Then we build a sparse
stock portfolio with constraint on both individual stock and industry exposure
using portfolio optimizer to closely track the partial equity funds index
930950.CSI with median 0.985 correlation. This problem is much more difficult
than tracking full information index or traditional ETF as higher turnover of
mutual fund, just first 10 holding of mutual fund available and fund report
updated quarterly with 15 days delay. Finally we build another low risk and
balanced sparse portfolio that consistently outperform benchmark 930950.CSI.
"
2305.04748,2023-05-09,A greedy algorithm for habit formation under multiplicative utility,"  We consider the problem of optimizing lifetime consumption under a habit
formation model, both with and without an exogenous pension. Unlike much of the
existing literature, we apply a power utility to the ratio of consumption to
habit, rather than to their difference. The martingale/duality method becomes
intractable in this setting, so we develop a greedy version of this method that
is solvable using Monte Carlo simulation. We investigate the behaviour of the
greedy solution, and explore what parameter values make the greedy solution a
good approximation to the optimal one.
"
2305.04801,2023-05-09,"Financial Hedging and Risk Compression, A journey from linear regression
  to neural network","  Finding the hedge ratios for a portfolio and risk compression is the same
mathematical problem. Traditionally, regression is used for this purpose.
However, regression has its own limitations. For example, in a regression
model, we can't use highly correlated independent variables due to
multicollinearity issue and instability in the results. A regression model
cannot also consider the cost of hedging in the hedge ratios estimation. We
have introduced several methods that address the linear regression limitation
while achieving better performance. These models, in general, fall into two
categories: Regularization Techniques and Common Factor Analyses. In
regularization techniques, we minimize the variance of hedged portfolio profit
and loss (PnL) and the hedge ratio sizes, which helps reduce the cost of
hedging. The regularization techniques methods could also consider the cost of
hedging as a function of the cost of funding, market condition, and liquidity.
In common factor analyses, we first map variables into common factors and then
find the hedge ratios so that the hedged portfolio doesn't have any exposure to
the factors. We can use linear or nonlinear factors construction. We are
introducing a modified beta variational autoencoder that constructs common
factors nonlinearly to compute hedges. Finally, we introduce a comparison
method and generate numerical results for an example.
"
2305.05663,2023-05-10,Proofs that the Gerber Statistic is Positive Semidefinite,"  In this brief note, we prove that both forms of the Gerber statistic
introduced in Gerber et al. (2022) are positive semi-definite.
"
2305.06704,2023-09-20,Robust Detection of Lead-Lag Relationships in Lagged Multi-Factor Models,"  In multivariate time series systems, key insights can be obtained by
discovering lead-lag relationships inherent in the data, which refer to the
dependence between two time series shifted in time relative to one another, and
which can be leveraged for the purposes of control, forecasting or clustering.
We develop a clustering-driven methodology for robust detection of lead-lag
relationships in lagged multi-factor models. Within our framework, the
envisioned pipeline takes as input a set of time series, and creates an
enlarged universe of extracted subsequence time series from each input time
series, via a sliding window approach. This is then followed by an application
of various clustering techniques, (such as k-means++ and spectral clustering),
employing a variety of pairwise similarity measures, including nonlinear ones.
Once the clusters have been extracted, lead-lag estimates across clusters are
robustly aggregated to enhance the identification of the consistent
relationships in the original universe. We establish connections to the
multireference alignment problem for both the homogeneous and heterogeneous
settings. Since multivariate time series are ubiquitous in a wide range of
domains, we demonstrate that our method is not only able to robustly detect
lead-lag relationships in financial markets, but can also yield insightful
results when applied to an environmental data set.
"
2305.08056,2023-05-16,"Hybrid Quantum Algorithms integrating QAOA, Penalty Dephasing and Zeno
  Effect for Solving Binary Optimization Problems with Multiple Constraints","  When tackling binary optimization problems using quantum algorithms, the
conventional Ising representation and Quantum Approximate Optimization
Algorithm (QAOA) encounter difficulties in efficiently handling errors for
large-scale problems involving multiple constraints. To address these
challenges, this paper presents a hybrid framework that combines the use of
standard Ising Hamiltonians to solve a subset of the constraints, while
employing non-Ising formulations to represent and address the remaining
constraints. The resolution of these non-Ising constraints is achieved through
either penalty dephasing or the quantum Zeno effect. This innovative approach
leads to a collection of quantum circuits with adaptable structures, depending
on the chosen representation for each constraint. Furthermore, this paper
introduces a novel technique that utilizes the quantum Zeno effect by
frequently measuring the constraint flag, enabling the resolution of any
optimization constraint. Theoretical properties of these algorithms are
discussed, and their performance in addressing practical aircraft loading
problems is highly promising, showcasing significant potential for a wide range
of industrial applications.
"
2305.08530,2023-11-14,Portfolio Optimization Rules beyond the Mean-Variance Approach,"  In this paper, we revisit the relationship between investors' utility
functions and portfolio allocation rules. We derive portfolio allocation rules
for asymmetric Laplace distributed $ALD(\mu,\sigma,\kappa)$ returns and compare
them with the mean-variance approach, which is based on Gaussian returns. We
reveal that in the limit of small $\frac{\mu}{\sigma}$, the Markowitz
contribution is accompanied by a skewness term. We also obtain the allocation
rules when the expected return is a random normal variable in an average and
worst-case scenarios, which allows us to take into account uncertainty of the
predicted returns. An optimal worst-case scenario solution smoothly
approximates between equal weights and minimum variance portfolio, presenting
an attractive convex alternative to the risk parity portfolio. We address the
issue of handling singular covariance matrices by imposing conditional
independence structure on the precision matrix directly. Finally, utilizing a
microscopic portfolio model with random drift and analytical expression for the
expected utility function with log-normal distributed cross-sectional returns,
we demonstrate the influence of model parameters on portfolio construction.
This comprehensive approach enhances allocation weight stability, mitigates
instabilities associated with the mean-variance approach, and can prove
valuable for both short-term traders and long-term investors.
"
2305.08740,2023-05-16,"Temporal and Heterogeneous Graph Neural Network for Financial Time
  Series Prediction","  The price movement prediction of stock market has been a classical yet
challenging problem, with the attention of both economists and computer
scientists. In recent years, graph neural network has significantly improved
the prediction performance by employing deep learning on company relations.
However, existing relation graphs are usually constructed by handcraft human
labeling or nature language processing, which are suffering from heavy resource
requirement and low accuracy. Besides, they cannot effectively response to the
dynamic changes in relation graphs. Therefore, in this paper, we propose a
temporal and heterogeneous graph neural network-based (THGNN) approach to learn
the dynamic relations among price movements in financial time series. In
particular, we first generate the company relation graph for each trading day
according to their historic price. Then we leverage a transformer encoder to
encode the price movement information into temporal representations. Afterward,
we propose a heterogeneous graph attention network to jointly optimize the
embeddings of the financial time series data by transformer encoder and infer
the probability of target movements. Finally, we conduct extensive experiments
on the stock market in the United States and China. The results demonstrate the
effectiveness and superior performance of our proposed methods compared with
state-of-the-art baselines. Moreover, we also deploy the proposed THGNN in a
real-world quantitative algorithm trading system, the accumulated portfolio
return obtained by our method significantly outperforms other baselines.
"
2305.09046,2025-05-22,Convex optimization over a probability simplex,"  We propose a new iteration scheme, the Cauchy-Simplex, to optimize convex
problems over the probability simplex $\{w\in\mathbb{R}^n\ |\ \sum_i w_i=1\
\textrm{and}\ w_i\geq0\}$. Specifically, we map the simplex to the positive
quadrant of a unit sphere, envisage gradient descent in latent variables, and
map the result back in a way that only depends on the simplex variable.
Moreover, proving rigorous convergence results in this formulation leads
inherently to tools from information theory (e.g., cross-entropy and KL
divergence). Each iteration of the Cauchy-Simplex consists of simple
operations, making it well-suited for high-dimensional problems. In continuous
time, we prove that $f(x_T)-f(x^*) = {O}(1/T)$ for differentiable real-valued
convex functions, where $T$ is the number of time steps and $w^*$ is the
optimal solution. Numerical experiments of projection onto convex hulls show
faster convergence than similar algorithms. Finally, we apply our algorithm to
online learning problems and prove the convergence of the average regret for
(1) Prediction with expert advice and (2) Universal Portfolios.
"
2305.11319,2024-11-01,Risk Budgeting Allocation for Dynamic Risk Measures,"  We define and develop an approach for risk budgeting allocation - a risk
diversification portfolio strategy - where risk is measured using a dynamic
time-consistent risk measure. For this, we introduce a notion of dynamic risk
contributions that generalise the classical Euler contributions and which allow
us to obtain dynamic risk contributions in a recursive manner. We prove that,
for the class of coherent dynamic distortion risk measures, the risk allocation
problem may be recast as a sequence of strictly convex optimisation problems.
Moreover, we show that self-financing dynamic risk budgeting strategies with
initial wealth of 1 are scaled versions of the solution of the sequence of
convex optimisation problems. Furthermore, we develop an actor-critic approach,
leveraging the elicitability of dynamic risk measures, to solve for risk
budgeting strategies using deep learning.
"
2305.12364,2023-05-23,Machine Learning for Socially Responsible Portfolio Optimisation,"  Socially responsible investors build investment portfolios intending to
incite social and environmental advancement alongside a financial return.
Although Mean-Variance (MV) models successfully generate the highest possible
return based on an investor's risk tolerance, MV models do not make provisions
for additional constraints relevant to socially responsible (SR) investors. In
response to this problem, the MV model must consider Environmental, Social, and
Governance (ESG) scores in optimisation. Based on the prominent MV model, this
study implements portfolio optimisation for socially responsible investors. The
amended MV model allows SR investors to enter markets with competitive SR
portfolios despite facing a trade-off between their investment Sharpe Ratio and
the average ESG score of the portfolio.
"
2305.12826,2023-05-23,"A Simulation Package in VBA to Support Finance Students for Constructing
  Optimal Portfolios","  This paper introduces a software component created in Visual Basic for
Applications (VBA) that can be applied for creating an optimal portfolio using
two different methods. The first method is the seminal approach of Markowitz
that is based on finding budget shares via the minimization of the variance of
the underlying portfolio. The second method is developed by El-Khatib and
Hatemi-J, which combines risk and return directly in the optimization problem
and yields budget shares that lead to maximizing the risk adjusted return of
the portfolio. This approach is consistent with the expectation of rational
investors since these investors consider both risk and return as the
fundamental basis for selection of the investment assets. Our package offers
another advantage that is usually neglected in the literature, which is the
number of assets that should be included in the portfolio. The common practice
is to assume that the number of assets is given exogenously when the portfolio
is constructed. However, the current software component constructs all possible
combinations and thus the investor can figure out empirically which portfolio
is the best one among all portfolios considered. The software is consumer
friendly via a graphical user interface. An application is also provided to
demonstrate how the software can be used using real-time series data for
several assets.
"
2305.14604,2023-05-25,Automated Market Making and Arbitrage Profits in the Presence of Fees,"  We consider the impact of trading fees on the profits of arbitrageurs trading
against an automated marker marker (AMM) or, equivalently, on the adverse
selection incurred by liquidity providers due to arbitrage. We extend the model
of Milionis et al. [2022] for a general class of two asset AMMs to both
introduce fees and discrete Poisson block generation times. In our setting, we
are able to compute the expected instantaneous rate of arbitrage profit in
closed form. When the fees are low, in the fast block asymptotic regime, the
impact of fees takes a particularly simple form: fees simply scale down
arbitrage profits by the fraction of time that an arriving arbitrageur finds a
profitable trade.
"
2305.16152,2023-06-21,"Mean-variance dynamic portfolio allocation with transaction costs: a
  Wiener chaos expansion approach","  This paper studies the multi-period mean-variance portfolio allocation
problem with transaction costs. Many methods have been proposed these last
years to challenge the famous uni-period Markowitz strategy.But these methods
cannot integrate transaction costs or become computationally heavy and hardly
applicable. In this paper, we try to tackle this allocation problem by
proposing an innovative approach which relies on representing the set of
admissible portfolios by a finite dimensional Wiener chaos expansion. This
numerical method is able to find an optimal strategy for the allocation problem
subject to transaction costs. To complete the study, the link between optimal
portfolios submitted to transaction costs and the underlying risk aversion is
investigated. Then a competitive and compliant benchmark based on the
sequential uni-period Markowitz strategy is built to highlight the efficiency
of our approach.
"
2305.16364,2024-02-13,E2EAI: End-to-End Deep Learning Framework for Active Investing,"  Active investing aims to construct a portfolio of assets that are believed to
be relatively profitable in the markets, with one popular method being to
construct a portfolio via factor-based strategies. In recent years, there have
been increasing efforts to apply deep learning to pursue ""deep factors'' with
more active returns or promising pipelines for asset trends prediction.
However, the question of how to construct an active investment portfolio via an
end-to-end deep learning framework (E2E) is still open and rarely addressed in
existing works. In this paper, we are the first to propose an E2E that covers
almost the entire process of factor investing through factor selection, factor
combination, stock selection, and portfolio construction. Extensive experiments
on real stock market data demonstrate the effectiveness of our end-to-end deep
leaning framework in active investing.
"
2305.16632,2023-05-29,"Causality between investor sentiment and the shares return on the
  Moroccan and Tunisian financial markets","  This paper aims to test the relationship between investor sentiment and the
profitability of stocks listed on two emergent financial markets, the Moroccan
and Tunisian ones. Two indirect measures of investor sentiment are used, SENT
and ARMS. These sentiment indicators show that there is an important
relationship between the stocks returns and investor sentiment. Indeed, the
results of modeling investor sentiment by past observations show that sentiment
has weak memory; on the other hand, series of changes in sentiment have
significant memory. The results of the Granger causality test between stock
return and investor sentiment show us that profitability causes investor
sentiment and not the other way around for the two financial markets
studied.Thanks to four autoregressive relationships estimated between investor
sentiment, change in sentiment, stock return and change in stock return, we
find firstly that the returns predict the changes in sentiments which confirms
with our hypothesis and secondly, the variation in profitability negatively
affects investor sentiment.We conclude that whatever sentiment measure is used
there is a positive and significant relationship between investor sentiment and
profitability, but sentiment cannot be predicted from our various variables.
"
2305.16712,2023-05-29,"Green portfolio optimization: A scenario analysis and stress testing
  based novel approach for sustainable investing in the paradigm Indian markets","  In this article, we present a novel approach for the construction of an
environment-friendly green portfolio using the ESG ratings, and application of
the modern portfolio theory to present what we call as the ``green efficient
frontier'' (wherein the environmental score is included as a third dimension to
the traditional mean-variance framework). Based on the prevailing action levels
and policies, as well as additional market information, scenario analyses and
stress testing are conducted to anticipate the future performance of the green
portfolio in varying circumstances. The performance of the green portfolio is
evaluated against the market returns in order to highlight the importance of
sustainable investing and recognizing climate risk as a significant risk factor
in financial analysis.
"
2305.17523,2023-05-30,"A Comparative Analysis of Portfolio Optimization Using Mean-Variance,
  Hierarchical Risk Parity, and Reinforcement Learning Approaches on the Indian
  Stock Market","  This paper presents a comparative analysis of the performances of three
portfolio optimization approaches. Three approaches of portfolio optimization
that are considered in this work are the mean-variance portfolio (MVP),
hierarchical risk parity (HRP) portfolio, and reinforcement learning-based
portfolio. The portfolios are trained and tested over several stock data and
their performances are compared on their annual returns, annual risks, and
Sharpe ratios. In the reinforcement learning-based portfolio design approach,
the deep Q learning technique has been utilized. Due to the large number of
possible states, the construction of the Q-table is done using a deep neural
network. The historical prices of the 50 premier stocks from the Indian stock
market, known as the NIFTY50 stocks, and several stocks from 10 important
sectors of the Indian stock market are used to create the environment for
training the agent.
"
2305.17881,2023-05-30,Integrating Different Informations for Portfolio Selection,"  Following the idea of Bayesian learning via Gaussian mixture model, we
organically combine the backward-looking information contained in the
historical data and the forward-looking information implied by the market
portfolio, which is affected by heterogeneous expectations and noisy trading
behavior. The proposed combined estimation adaptively harmonizes these two
types of information based on the degree of market efficiency and responds
quickly at turning points of the market. Both simulation experiments and a
global empirical test confirm that the approach is a flexible and robust
forecasting tool and is applicable to various capital markets with different
degrees of efficiency.
"
2305.18136,2023-06-27,Exponential Utility Maximization in a Discrete Time Gaussian Framework,"  The aim of this short note is to present a solution to the discrete time
exponential utility maximization problem in a case where the underlying asset
has a multivariate normal distribution. In addition to the usual setting
considered in Mathematical Finance, we also consider an investor who is
informed about the risky asset's price changes with a delay. Our method of
solution is based on the theory developed in [4] and guessing the optimal
portfolio.
"
2306.01660,2023-06-06,"A systematic literature review on solution approaches for the index
  tracking problem in the last decade","  The passive management approach offers conservative investors a way to reduce
risk concerning the market. This investment strategy aims at replicating a
specific index, such as the NASDAQ Composite or the FTSE100 index. The problem
is that buying all the index's assets incurs high rebalancing costs, and this
harms future returns. The index tracking problem concerns building a portfolio
that follows a specific benchmark with fewer transaction costs. Since a subset
of assets is required to solve the index problem this class of problems is
NP-hard, and in the past years, researchers have been studying solution
approaches to obtain tracking portfolios more practically. This work brings an
analysis, spanning the last decade, of the advances in mathematical approaches
for index tracking. The systematic literature review covered important issues,
such as the most relevant research areas, solution methods, and model
structures. Special attention was given to the exploration and analysis of
metaheuristics applied to the index tracking problem.
"
2306.02764,2023-06-06,"Optimal Market Making in the Chinese Stock Market: A Stochastic Control
  and Scenario Analysis","  Market making plays a crucial role in providing liquidity and maintaining
stability in financial markets, making it an essential component of
well-functioning capital markets. Despite its importance, there is limited
research on market making in the Chinese stock market, which is one of the
largest and most rapidly growing markets globally. To address this gap, we
employ an optimal market making framework with an exponential CARA-type
(Constant Absolute Risk Aversion) utility function that accounts for various
market conditions, such as price drift, volatility, and stamp duty, and is
capable of describing 3 major risks (i.e., inventory, execution and adverse
selection risks) in market making practice, and provide an in-depth
quantitative and scenario analysis of market making in the Chinese stock
market. Our numerical experiments explore the impact of volatility on the
market maker's inventory. Furthermore, we find that the stamp duty rate is a
critical factor in market making, with a negative impact on both the profit of
the market maker and the liquidity of the market. Additionally, our analysis
emphasizes the significance of accurately estimating stock drift for managing
inventory and adverse selection risks effectively and enhancing profit for the
market maker. These findings offer valuable insights for both market makers and
policymakers in the Chinese stock market and provide directions for further
research in designing effective market making strategies and policies.
"
2306.02848,2024-02-13,"HireVAE: An Online and Adaptive Factor Model Based on Hierarchical and
  Regime-Switch VAE","  Factor model is a fundamental investment tool in quantitative investment,
which can be empowered by deep learning to become more flexible and efficient
in practical complicated investing situations. However, it is still an open
question to build a factor model that can conduct stock prediction in an online
and adaptive setting, where the model can adapt itself to match the current
market regime identified based on only point-in-time market information. To
tackle this problem, we propose the first deep learning based online and
adaptive factor model, HireVAE, at the core of which is a hierarchical latent
space that embeds the underlying relationship between the market situation and
stock-wise latent factors, so that HireVAE can effectively estimate useful
latent factors given only historical market information and subsequently
predict accurate stock returns. Across four commonly used real stock market
benchmarks, the proposed HireVAE demonstrate superior performance in terms of
active returns over previous methods, verifying the potential of such online
and adaptive factor model.
"
2306.05568,2024-04-08,Maximally Machine-Learnable Portfolios,"  When it comes to stock returns, any form of predictability can bolster
risk-adjusted profitability. We develop a collaborative machine learning
algorithm that optimizes portfolio weights so that the resulting synthetic
security is maximally predictable. Precisely, we introduce MACE, a multivariate
extension of Alternating Conditional Expectations that achieves the
aforementioned goal by wielding a Random Forest on one side of the equation,
and a constrained Ridge Regression on the other. There are two key improvements
with respect to Lo and MacKinlay's original maximally predictable portfolio
approach. First, it accommodates for any (nonlinear) forecasting algorithm and
predictor set. Second, it handles large portfolios. We conduct exercises at the
daily and monthly frequency and report significant increases in predictability
and profitability using very little conditioning information. Interestingly,
predictability is found in bad as well as good times, and MACE successfully
navigates the debacle of 2022.
"
2306.05667,2025-03-10,Random matrix theory and nested clustered portfolios on Mexican markets,"  This work aims to deal with the optimal allocation instability problem of
Markowitz's modern portfolio theory in high dimensionality. We propose a
combined strategy that considers covariance matrix estimators from Random
Matrix Theory~(RMT) and the machine learning allocation methodology known as
Nested Clustered Optimization~(NCO). The latter methodology is modified and
reformulated in terms of the spectral clustering algorithm and Minimum Spanning
Tree~(MST) to solve internal problems inherent to the original proposal.
Markowitz's classical mean-variance allocation and the modified NCO machine
learning approach are tested on financial instruments listed on the Mexican
Stock Exchange~(BMV) in a moving window analysis from 2018 to 2022. The
modified NCO algorithm achieves stable allocations by incorporating RMT
covariance estimators. In particular, the allocation weights are positive, and
their absolute value adds up to the total capital without considering explicit
restrictions in the formulation. Our results suggest that can be avoided the
risky \emph{short position} investment strategy by means of RMT inference and
statistical learning techniques.
"
2306.07013,2023-06-13,"Combining Reinforcement Learning and Barrier Functions for Adaptive Risk
  Management in Portfolio Optimization","  Reinforcement learning (RL) based investment strategies have been widely
adopted in portfolio management (PM) in recent years. Nevertheless, most
RL-based approaches may often emphasize on pursuing returns while ignoring the
risks of the underlying trading strategies that may potentially lead to great
losses especially under high market volatility. Therefore, a risk-manageable PM
investment framework integrating both RL and barrier functions (BF) is proposed
to carefully balance the needs for high returns and acceptable risk exposure in
PM applications. Up to our understanding, this work represents the first
attempt to combine BF and RL for financial applications. While the involved RL
approach may aggressively search for more profitable trading strategies, the
BF-based risk controller will continuously monitor the market states to
dynamically adjust the investment portfolio as a controllable measure for
avoiding potential losses particularly in downtrend markets. Additionally, two
adaptive mechanisms are provided to dynamically adjust the impact of risk
controllers such that the proposed framework can be flexibly adapted to uptrend
and downtrend markets. The empirical results of our proposed framework clearly
reveal such advantages against most well-known RL-based approaches on
real-world data sets. More importantly, our proposed framework shed lights on
many possible directions for future investigation.
"
2306.07928,2023-06-14,"Optimizing Investment Strategies with Lazy Factor and Probability
  Weighting: A Price Portfolio Forecasting and Mean-Variance Model with
  Transaction Costs Approach","  Market traders often engage in the frequent transaction of volatile assets to
optimize their total return. In this study, we introduce a novel investment
strategy model, anchored on the 'lazy factor.' Our approach bifurcates into a
Price Portfolio Forecasting Model and a Mean-Variance Model with Transaction
Costs, utilizing probability weights as the coefficients of laziness factors.
The Price Portfolio Forecasting Model, leveraging the EXPMA Mean Method, plots
the long-term price trend line and forecasts future price movements,
incorporating the tangent slope and rate of change. For short-term investments,
we apply the ARIMA Model to predict ensuing prices. The Mean-Variance Model
with Transaction Costs employs the Monte Carlo Method to formulate the feasible
region. To strike an optimal balance between risk and return, equal probability
weights are incorporated as coefficients of the laziness factor. To assess the
efficacy of this combined strategy, we executed extensive experiments on a
specified dataset. Our findings underscore the model's adaptability and
generalizability, indicating its potential to transform investment strategies.
"
2306.08105,2023-06-16,Model-Free Market Risk Hedging Using Crowding Networks,"  Crowding is widely regarded as one of the most important risk factors in
designing portfolio strategies. In this paper, we analyze stock crowding using
network analysis of fund holdings, which is used to compute crowding scores for
stocks. These scores are used to construct costless long-short portfolios,
computed in a distribution-free (model-free) way and without using any
numerical optimization, with desirable properties of hedge portfolios. More
specifically, these long-short portfolios provide protection for both small and
large market price fluctuations, due to their negative correlation with the
market and positive convexity as a function of market returns. By adding our
long-short portfolio to a baseline portfolio such as a traditional 60/40
portfolio, our method provides an alternative way to hedge portfolio risk
including tail risk, which does not require costly option-based strategies or
complex numerical optimization. The total cost of such hedging amounts to the
total cost of rebalancing the hedge portfolio.
"
2306.08809,2023-06-16,"Optimal Portfolio Execution in a Regime-switching Market with Non-linear
  Impact Costs: Combining Dynamic Program and Neural Network","  Optimal execution of a portfolio have been a challenging problem for
institutional investors. Traders face the trade-off between average trading
price and uncertainty, and traditional methods suffer from the curse of
dimensionality. Here, we propose a four-step numerical framework for the
optimal portfolio execution problem where multiple market regimes exist, with
the underlying regime switching based on a Markov process. The market impact
costs are modelled with a temporary part and a permanent part, where the former
affects only the current trade while the latter persists. Our approach accepts
impact cost functions in generic forms. First, we calculate the approximated
orthogonal portfolios based on estimated impact cost functions; second, we
employ dynamic program to learn the optimal selling schedule of each
approximated orthogonal portfolio; third, weights of a neural network are
pre-trained with the strategy suggested by previous step; last, we train the
neural network to optimize on the original trading model. In our experiment of
a 10-asset liquidation example with quadratic impact costs, the proposed
combined method provides promising selling strategy for both CRRA (constant
relative risk aversion) and mean-variance objectives. The running time is
linear in the number of risky assets in the portfolio as well as in the number
of trading periods. Possible improvements in running time are discussed for
potential large-scale usages.
"
2306.09421,2023-06-19,"FLAIR: A Metric for Liquidity Provider Competitiveness in Automated
  Market Makers","  This paper aims to enhance the understanding of liquidity provider (LP)
returns in automated market makers (AMMs). LPs face market risk as well as
adverse selection due to risky asset holdings in the pool that they provide
liquidity to and the informational asymmetry between informed traders
(arbitrageurs) and AMMs. Loss-versus-rebalancing (LVR) quantifies the adverse
selection cost (Milionis et al., 2022a), and is a popular metric to evaluate
the flow toxicity to an AMM. However, individual LP returns are critically
affected by another factor orthogonal to the above: the competitiveness among
LPs. This work introduces a novel metric for LP competitiveness, called FLAIR
(short for fee liquidity-adjusted instantaneous returns), that aims to
supplement LVR in assessments of LP performance to capture the dynamic behavior
of LPs in a pool. Our metric reflects the characteristics of fee
return-on-capital, and differentiates active liquidity provisioning strategies
in AMMs. To illustrate how both flow toxicity, accounting for the
sophistication of the counterparty of LPs, as well as LP competitiveness,
accounting for the sophistication of the competition among LPs, affect
individual LP returns, we propose a quadrant interpretation where all of these
characteristics may be readily visualized. We examine LP competitiveness in an
ex-post fashion, and show example cases in all of which our metric confirms the
expected nuances and intuition of competitiveness among LPs. FLAIR has
particular merit in empirical analyses, and is able to better inform practical
assessments of AMM pools.
"
2306.10950,2024-01-17,"Benchmarking Robustness of Deep Reinforcement Learning approaches to
  Online Portfolio Management","  Deep Reinforcement Learning approaches to Online Portfolio Selection have
grown in popularity in recent years. The sensitive nature of training
Reinforcement Learning agents implies a need for extensive efforts in market
representation, behavior objectives, and training processes, which have often
been lacking in previous works. We propose a training and evaluation process to
assess the performance of classical DRL algorithms for portfolio management. We
found that most Deep Reinforcement Learning algorithms were not robust, with
strategies generalizing poorly and degrading quickly during backtesting.
"
2306.11158,2023-11-08,"Mind the Cap! -- Constrained Portfolio Optimisation in Heston's
  Stochastic Volatility Model","  We consider a portfolio optimisation problem for a utility-maximising
investor who faces convex constraints on his portfolio allocation in Heston's
stochastic volatility model. We apply the duality methods developed in previous
work to obtain a closed-form expression for the optimal portfolio allocation.
In doing so, we observe that allocation constraints impact the optimal
constrained portfolio allocation in a fundamentally different way in Heston's
stochastic volatility model than in the Black Scholes model. In particular, the
optimal constrained portfolio may be different from the naive capped portfolio,
which caps off the optimal unconstrained portfolio at the boundaries of the
constraints. Despite this difference, we illustrate by way of a numerical
analysis that in most realistic scenarios the capped portfolio leads to slim
annual wealth equivalent losses compared to the optimal constrained portfolio.
During a financial crisis, however, a capped solution might lead to compelling
annual wealth equivalent losses.
"
2306.12639,2023-06-23,"Efficient Solution of Portfolio Optimization Problems via Dimension
  Reduction and Sparsification","  The Markowitz mean-variance portfolio optimization model aims to balance
expected return and risk when investing. However, there is a significant
limitation when solving large portfolio optimization problems efficiently: the
large and dense covariance matrix. Since portfolio performance can be
potentially improved by considering a wider range of investments, it is
imperative to be able to solve large portfolio optimization problems
efficiently, typically in microseconds. We propose dimension reduction and
increased sparsity as remedies for the covariance matrix. The size reduction is
based on predictions from machine learning techniques and the solution to a
linear programming problem. We find that using the efficient frontier from the
linear formulation is much better at predicting the assets on the Markowitz
efficient frontier, compared to the predictions from neural networks. Reducing
the covariance matrix based on these predictions decreases both runtime and
total iterations. We also present a technique to sparsify the covariance matrix
such that it preserves positive semi-definiteness, which improves runtime per
iteration. The methods we discuss all achieved similar portfolio expected risk
and return as we would obtain from a full dense covariance matrix but with
improved optimizer performance.
"
2306.13343,2023-10-30,Optimal Investment with Stochastic Interest Rates and Ambiguity,"  This paper studies dynamic asset allocation with interest rate risk and
several sources of ambiguity. The market consists of a risk-free asset, a
zero-coupon bond (both determined by a Vasicek model), and a stock. There is
ambiguity about the risk premia, the volatilities, and the correlation. The
investor's preferences display both risk aversion and ambiguity aversion. The
optimal investment problem admits a closed-form solution. The solution shows
that the ambiguity only affects the speculative motives of the investor,
representing a hedge against the ambiguity, but not the hedging of interest
rate risk. An implementation of the optimal investment strategy shows that
ambiguity aversion helps to tame the highly leveraged portfolios neglecting
ambiguity and leads to strategies that are more in line with popular investment
advice.
"
2306.13661,2023-06-29,"Constructing Time-Series Momentum Portfolios with Deep Multi-Task
  Learning","  A diversified risk-adjusted time-series momentum (TSMOM) portfolio can
deliver substantial abnormal returns and offer some degree of tail risk
protection during extreme market events. The performance of existing TSMOM
strategies, however, relies not only on the quality of the momentum signal but
also on the efficacy of the volatility estimator. Yet many of the existing
studies have always considered these two factors to be independent. Inspired by
recent progress in Multi-Task Learning (MTL), we present a new approach using
MTL in a deep neural network architecture that jointly learns portfolio
construction and various auxiliary tasks related to volatility, such as
forecasting realized volatility as measured by different volatility estimators.
Through backtesting from January 2000 to December 2020 on a diversified
portfolio of continuous futures contracts, we demonstrate that even after
accounting for transaction costs of up to 3 basis points, our approach
outperforms existing TSMOM strategies. Moreover, experiments confirm that
adding auxiliary tasks indeed boosts the portfolio's performance. These
findings demonstrate that MTL can be a powerful tool in finance.
"
2306.15807,2024-02-20,"Liquidity Premium, Liquidity-Adjusted Return and Volatility, and Extreme
  Liquidity","  We establish innovative liquidity premium measures, and construct
liquidity-adjusted return and volatility to model assets with extreme
liquidity, represented by a portfolio of selected crypto assets, and upon which
we develop a set of liquidity-adjusted ARMA-GARCH/EGARCH models. We demonstrate
that these models produce superior predictability at extreme liquidity to their
traditional counterparts. We provide empirical support by comparing the
performances of a series of Mean Variance portfolios.
"
2306.16563,2023-11-22,Using Monte Carlo Methods for Retirement Simulations,"  Retirement prediction helps individuals and institutions make informed
financial, lifestyle, and workforce decisions based on estimated retirement
portfolios. This paper attempts to predict retirement using Monte Carlo
simulations, allowing one to probabilistically account for a range of
possibilities. The authors propose a model to predict the values of the
investment accounts IRA and 401(k) through the simulation of inflation rates,
interest rates, and other pertinent factors. They provide a user case study to
discuss the implications of the proposed model.
"
2307.00459,2023-07-04,"Principal Component Analysis and Hidden Markov Model for Forecasting
  Stock Returns","  This paper presents a method for predicting stock returns using principal
component analysis (PCA) and the hidden Markov model (HMM) and tests the
results of trading stocks based on this approach. Principal component analysis
is applied to the covariance matrix of stock returns for companies listed in
the S&P 500 index, and interpreting principal components as factor returns, we
apply the HMM model on them. Then we use the transition probability matrix and
state conditional means to forecast the factors returns. Reverting the factor
returns forecasts to stock returns using eigenvectors, we obtain forecasts for
the stock returns. We find that, with the right hyperparameters, our model
yields a strategy that outperforms the buy-and-hold strategy in terms of the
annualized Sharpe ratio.
"
2307.01599,2023-07-06,"A Scalable Reinforcement Learning-based System Using On-Chain Data for
  Cryptocurrency Portfolio Management","  On-chain data (metrics) of blockchain networks, akin to company fundamentals,
provide crucial and comprehensive insights into the networks. Despite their
informative nature, on-chain data have not been utilized in reinforcement
learning (RL)-based systems for cryptocurrency (crypto) portfolio management
(PM). An intriguing subject is the extent to which the utilization of on-chain
data can enhance an RL-based system's return performance compared to baselines.
Therefore, in this study, we propose CryptoRLPM, a novel RL-based system
incorporating on-chain data for end-to-end crypto PM. CryptoRLPM consists of
five units, spanning from information comprehension to trading order execution.
In CryptoRLPM, the on-chain data are tested and specified for each crypto to
solve the issue of ineffectiveness of metrics. Moreover, the scalable nature of
CryptoRLPM allows changes in the portfolios' cryptos at any time. Backtesting
results on three portfolios indicate that CryptoRLPM outperforms all the
baselines in terms of accumulated rate of return (ARR), daily rate of return
(DRR), and Sortino ratio (SR). Particularly, when compared to Bitcoin,
CryptoRLPM enhances the ARR, DRR, and SR by at least 83.14%, 0.5603%, and
2.1767 respectively.
"
2307.01719,2023-07-13,MOPO-LSI: A User Guide,"  MOPO-LSI is an open-source Multi-Objective Portfolio Optimization Library for
Sustainable Investments. This document provides a user guide for MOPO-LSI
version 1.0, including problem setup, workflow and the hyper-parameters in
configurations.
"
2307.03391,2024-05-02,On Unified Adaptive Portfolio Management,"  This paper introduces a unified framework for adaptive portfolio management,
integrating dynamic Black-Litterman (BL) optimization with the general factor
model, Elastic Net regression, and mean-variance portfolio optimization, which
allows us to generate investors views and mitigate potential estimation errors
systematically. Specifically, we propose an innovative dynamic sliding window
algorithm to respond to the constantly changing market conditions. This
algorithm allows for the flexible window size adjustment based on market
volatility, generating robust estimates for factor modeling, time-varying BL
estimations, and optimal portfolio weights. Through extensive ten-year
empirical studies using the top 100 capitalized assets in the S&P 500 index,
accounting for turnover transaction costs, we demonstrate that this combined
approach leads to computational advantages and promising trading performances.
"
2307.04045,2023-07-11,"Time-limited Metaheuristics for Cardinality-constrained Portfolio
  Optimisation","  A financial portfolio contains assets that offer a return with a certain
level of risk. To maximise returns or minimise risk, the portfolio must be
optimised - the ideal combination of optimal quantities of assets must be
found. The number of possible combinations is vast. Furthermore, to make the
problem realistic, constraints can be imposed on the number of assets held in
the portfolio and the maximum proportion of the portfolio that can be allocated
to an asset. This problem is unsolvable using quadratic programming, which
means that the optimal solution cannot be calculated. A group of algorithms,
called metaheuristics, can find near-optimal solutions in a practical computing
time. These algorithms have been successfully used in constrained portfolio
optimisation. However, in past studies the computation time of metaheuristics
is not limited, which means that the results differ in both quality and
computation time, and cannot be easily compared. This study proposes a
different way of testing metaheuristics, limiting their computation time to a
certain duration, yielding results that differ only in quality. Given that in
some use cases the priority is the quality of the solution and in others the
speed, time limits of 1, 5 and 25 seconds were tested. Three metaheuristics -
simulated annealing, tabu search, and genetic algorithm - were evaluated on
five sets of historical market data with different numbers of assets. Although
the metaheuristics could not find a competitive solution in 1 second, simulated
annealing found a near-optimal solution in 5 seconds in all but one dataset.
The lowest quality solutions were obtained by genetic algorithm.
"
2307.04754,2023-10-10,Action-State Dependent Dynamic Model Selection,"  A model among many may only be best under certain states of the world.
Switching from a model to another can also be costly. Finding a procedure to
dynamically choose a model in these circumstances requires to solve a complex
estimation procedure and a dynamic programming problem. A Reinforcement
learning algorithm is used to approximate and estimate from the data the
optimal solution to this dynamic programming problem. The algorithm is shown to
consistently estimate the optimal policy that may choose different models based
on a set of covariates. A typical example is the one of switching between
different portfolio models under rebalancing costs, using macroeconomic
information. Using a set of macroeconomic variables and price data, an
empirical application to the aforementioned portfolio problem shows superior
performance to choosing the best portfolio model with hindsight.
"
2307.04953,2023-07-18,Measuring Cause-Effect with the Variability of the Largest Eigenvalue,"  We present a method to test and monitor structural relationships between time
variables. The distribution of the first eigenvalue for lagged correlation
matrices (Tracy-Widom distribution) is used to test structural time
relationships between variables against the alternative hypothesis
(Independence). This distribution studies the asymptotic dynamics of the
largest eigenvalue as a function of the lag in lagged correlation matrices. By
analyzing the time series of the standard deviation of the greatest eigenvalue
for $2\times 2$ correlation matrices with different lags we can analyze
deviations from the Tracy-Widom distribution to test structural relationships
between these two time variables. These relationships can be related to
causality. We use the standard deviation of the explanatory power of the first
eigenvalue at different lags as a proxy for testing and monitoring structural
causal relationships. The method is applied to analyse causal dependencies
between daily monetary flows in a retail brokerage business allowing to control
for liquidity risks.
"
2307.05048,2023-07-12,Portfolio Optimization: A Comparative Study,"  Portfolio optimization has been an area that has attracted considerable
attention from the financial research community. Designing a profitable
portfolio is a challenging task involving precise forecasting of future stock
returns and risks. This chapter presents a comparative study of three portfolio
design approaches, the mean-variance portfolio (MVP), hierarchical risk parity
(HRP)-based portfolio, and autoencoder-based portfolio. These three approaches
to portfolio design are applied to the historical prices of stocks chosen from
ten thematic sectors listed on the National Stock Exchange (NSE) of India. The
portfolios are designed using the stock price data from January 1, 2018, to
December 31, 2021, and their performances are tested on the out-of-sample data
from January 1, 2022, to December 31, 2022. Extensive results are analyzed on
the performance of the portfolios. It is observed that the performance of the
MVP portfolio is the best on the out-of-sample data for the risk-adjusted
returns. However, the autoencoder portfolios outperformed their counterparts on
annual returns.
"
2307.07694,2023-08-01,"Evaluation of Deep Reinforcement Learning Algorithms for Portfolio
  Optimisation","  We evaluate benchmark deep reinforcement learning (DRL) algorithms on the
task of portfolio optimisation under a simulator. The simulator is based on
correlated geometric Brownian motion (GBM) with the Bertsimas-Lo (BL) market
impact model. Using the Kelly criterion (log utility) as the objective, we can
analytically derive the optimal policy without market impact and use it as an
upper bound to measure performance when including market impact. We found that
the off-policy algorithms DDPG, TD3 and SAC were unable to learn the right Q
function due to the noisy rewards and therefore perform poorly. The on-policy
algorithms PPO and A2C, with the use of generalised advantage estimation (GAE),
were able to deal with the noise and derive a close to optimal policy. The
clipping variant of PPO was found to be important in preventing the policy from
deviating from the optimal once converged. In a more challenging environment
where we have regime changes in the GBM parameters, we found that PPO, combined
with a hidden Markov model (HMM) to learn and predict the regime context, is
able to learn different policies adapted to each regime. Overall, we find that
the sample complexity of these algorithms is too high, requiring more than 2m
steps to learn a good policy in the simplest setting, which is equivalent to
almost 8,000 years of daily prices.
"
2307.07811,2023-07-18,Generative Meta-Learning Robust Quality-Diversity Portfolio,"  This paper proposes a novel meta-learning approach to optimize a robust
portfolio ensemble. The method uses a deep generative model to generate diverse
and high-quality sub-portfolios combined to form the ensemble portfolio. The
generative model consists of a convolutional layer, a stateful LSTM module, and
a dense network. During training, the model takes a randomly sampled batch of
Gaussian noise and outputs a population of solutions, which are then evaluated
using the objective function of the problem. The weights of the model are
updated using a gradient-based optimizer. The convolutional layer transforms
the noise into a desired distribution in latent space, while the LSTM module
adds dependence between generations. The dense network decodes the population
of solutions. The proposed method balances maximizing the performance of the
sub-portfolios with minimizing their maximum correlation, resulting in a robust
ensemble portfolio against systematic shocks. The approach was effective in
experiments where stochastic rewards were present. Moreover, the results (Fig.
1) demonstrated that the ensemble portfolio obtained by taking the average of
the generated sub-portfolio weights was robust and generalized well. The
proposed method can be applied to problems where diversity is desired among
co-optimized solutions for a robust ensemble. The source-codes and the dataset
are in the supplementary material.
"
2307.09332,2023-07-19,Company2Vec -- German Company Embeddings based on Corporate Websites,"  With Company2Vec, the paper proposes a novel application in representation
learning. The model analyzes business activities from unstructured company
website data using Word2Vec and dimensionality reduction. Company2Vec maintains
semantic language structures and thus creates efficient company embeddings in
fine-granular industries. These semantic embeddings can be used for various
applications in banking. Direct relations between companies and words allow
semantic business analytics (e.g. top-n words for a company). Furthermore,
industry prediction is presented as a supervised learning application and
evaluation method. The vectorized structure of the embeddings allows measuring
companies similarities with the cosine distance. Company2Vec hence offers a
more fine-grained comparison of companies than the standard industry labels
(NACE). This property is relevant for unsupervised learning tasks, such as
clustering. An alternative industry segmentation is shown with k-means
clustering on the company embeddings. Finally, this paper proposes three
algorithms for (1) firm-centric, (2) industry-centric and (3) portfolio-centric
peer-firm identification.
"
2307.09631,2023-07-20,Deep Reinforcement Learning for ESG financial portfolio management,"  This paper investigates the application of Deep Reinforcement Learning (DRL)
for Environment, Social, and Governance (ESG) financial portfolio management,
with a specific focus on the potential benefits of ESG score-based market
regulation. We leveraged an Advantage Actor-Critic (A2C) agent and conducted
our experiments using environments encoded within the OpenAI Gym, adapted from
the FinRL platform. The study includes a comparative analysis of DRL agent
performance under standard Dow Jones Industrial Average (DJIA) market
conditions and a scenario where returns are regulated in line with company ESG
scores. In the ESG-regulated market, grants were proportionally allotted to
portfolios based on their returns and ESG scores, while taxes were assigned to
portfolios below the mean ESG score of the index. The results intriguingly
reveal that the DRL agent within the ESG-regulated market outperforms the
standard DJIA market setup. Furthermore, we considered the inclusion of ESG
variables in the agent state space, and compared this with scenarios where such
data were excluded. This comparison adds to the understanding of the role of
ESG factors in portfolio management decision-making. We also analyze the
behaviour of the DRL agent in IBEX 35 and NASDAQ-100 indexes. Both the A2C and
Proximal Policy Optimization (PPO) algorithms were applied to these additional
markets, providing a broader perspective on the generalization of our findings.
This work contributes to the evolving field of ESG investing, suggesting that
market regulation based on ESG scoring can potentially improve DRL-based
portfolio management, with significant implications for sustainable investing
strategies.
"
2307.11919,2024-02-28,Discrete time optimal investment under model uncertainty,"  We study a robust utility maximization problem in a general discrete-time
frictionless market under quasi-sure no-arbitrage. The investor is assumed to
have a random and concave utility function defined on the whole real-line. She
also faces model ambiguity on her beliefs about the market, which is modeled
through a set of priors. We prove the existence of an optimal investment
strategy using only primal methods. For that we assume classical assumptions on
the market and on the random utility function as asymptotic elasticity
constraints. Most of our other assumptions are stated on a prior-by-prior basis
and correspond to generally accepted assumptions in the literature on markets
without ambiguity. We also propose a general setting including utility
functions with benchmark for which our assumptions are easily checked.
"
2307.12161,2023-07-25,"Unraveling the Trade-off between Sustainability and Returns: A
  Multivariate Utility Analysis","  This paper proposes an expected multivariate utility analysis for ESG
investors in which green stocks, brown stocks, and a market index are modeled
in a one-factor, CAPM-type structure. This setting allows investors to
accommodate their preferences for green investments according to proper risk
aversion levels. We find closed-form solutions for optimal allocations, wealth
and value functions. As by-products, we first demonstrate that investors do not
need to reduce their pecuniary satisfaction in order to increase green
investments. Secondly, we propose a parameterization to capture investors'
preferences for green assets over brown or market assets, independent of
performance. The paper uses the RepRisk Rating of U.S. stocks from 2010 to 2020
to select companies that are representative of various ESG ratings. Our
empirical analysis reveals drastic increases in wealth allocation toward
high-rated ESG stocks for ESG-sensitive investors; this holds even as the
overall level of pecuniary satisfaction is kept unchanged.
"
2307.13422,2023-08-21,"VolTS: A Volatility-based Trading System to forecast Stock Markets Trend
  using Statistics and Machine Learning","  Volatility-based trading strategies have attracted a lot of attention in
financial markets due to their ability to capture opportunities for profit from
market dynamics. In this article, we propose a new volatility-based trading
strategy that combines statistical analysis with machine learning techniques to
forecast stock markets trend.
  The method consists of several steps including, data exploration, correlation
and autocorrelation analysis, technical indicator use, application of
hypothesis tests and statistical models, and use of variable selection
algorithms. In particular, we use the k-means++ clustering algorithm to group
the mean volatility of the nine largest stocks in the NYSE and NasdaqGS
markets. The resulting clusters are the basis for identifying relationships
between stocks based on their volatility behaviour. Next, we use the Granger
Causality Test on the clustered dataset with mid-volatility to determine the
predictive power of a stock over another stock. By identifying stocks with
strong predictive relationships, we establish a trading strategy in which the
stock acting as a reliable predictor becomes a trend indicator to determine the
buy, sell, and hold of target stock trades.
  Through extensive backtesting and performance evaluation, we find the
reliability and robustness of our volatility-based trading strategy. The
results suggest that our approach effectively captures profitable trading
opportunities by leveraging the predictive power of volatility clusters, and
Granger causality relationships between stocks.
  The proposed strategy offers valuable insights and practical implications to
investors and market participants who seek to improve their trading decisions
and capitalize on market trends. It provides valuable insights and practical
implications for market participants looking to.
"
2307.13501,2023-07-26,Deep Reinforcement Learning for Robust Goal-Based Wealth Management,"  Goal-based investing is an approach to wealth management that prioritizes
achieving specific financial goals. It is naturally formulated as a sequential
decision-making problem as it requires choosing the appropriate investment
until a goal is achieved. Consequently, reinforcement learning, a machine
learning technique appropriate for sequential decision-making, offers a
promising path for optimizing these investment strategies. In this paper, a
novel approach for robust goal-based wealth management based on deep
reinforcement learning is proposed. The experimental results indicate its
superiority over several goal-based wealth management benchmarks on both
simulated and historical market data.
"
2307.13546,2023-07-26,Transfer Learning for Portfolio Optimization,"  In this work, we explore the possibility of utilizing transfer learning
techniques to address the financial portfolio optimization problem. We
introduce a novel concept called ""transfer risk"", within the optimization
framework of transfer learning. A series of numerical experiments are conducted
from three categories: cross-continent transfer, cross-sector transfer, and
cross-frequency transfer. In particular, 1. a strong correlation between the
transfer risk and the overall performance of transfer learning methods is
established, underscoring the significance of transfer risk as a viable
indicator of ""transferability""; 2. transfer risk is shown to provide a
computationally efficient way to identify appropriate source tasks in transfer
learning, enhancing the efficiency and effectiveness of the transfer learning
approach; 3. additionally, the numerical experiments offer valuable new
insights for portfolio management across these different settings.
"
2307.13807,2023-07-27,"Sports Betting: an application of neural networks and modern portfolio
  theory to the English Premier League","  This paper presents a novel approach for optimizing betting strategies in
sports gambling by integrating Von Neumann-Morgenstern Expected Utility Theory,
deep learning techniques, and advanced formulations of the Kelly Criterion. By
combining neural network models with portfolio optimization, our method
achieved remarkable profits of 135.8% relative to the initial wealth during the
latter half of the 20/21 season of the English Premier League. We explore
complete and restricted strategies, evaluating their performance, risk
management, and diversification. A deep neural network model is developed to
forecast match outcomes, addressing challenges such as limited variables. Our
research provides valuable insights and practical applications in the field of
sports betting and predictive modeling.
"
2308.01305,2023-08-03,A quantum double-or-nothing game: The Kelly Criterion for Spins,"  A sequence of spin-1/2 particles polarised in one of two possible directions
is presented to an experimenter, who can wager in a double-or-nothing game on
the outcomes of measurements in freely chosen polarisation directions. Wealth
is accrued through astute betting. As information is gained from the stream of
particles, the measurement directions are progressively adjusted, and the
portfolio growth rate is raised. The optimal quantum strategy is determined
numerically and shown to differ from the classical strategy, which is
associated with the Kelly criterion. The paper contributes to the development
of quantum finance, as aspects of portfolio optimisation are extended to the
quantum realm.
"
2308.02049,2024-07-01,"Portfolio Optimization in a Market with Hidden Gaussian Drift and
  Randomly Arriving Expert Opinions: Modeling and Theoretical Results","  This paper investigates the optimal selection of portfolios for power utility
maximizing investors in a financial market where stock returns depend on a
hidden Gaussian mean reverting drift process. Information on the drift is
obtained from returns and expert opinions in the form of noisy signals about
the current state of the drift arriving randomly over time. The arrival dates
are modeled as the jump times of a homogeneous Poisson process. Applying Kalman
filter techniques we derive estimates of the hidden drift which are described
by the conditional mean and covariance of the drift given the observations. The
utility maximization problem is solved with dynamic programming methods. We
derive the associated dynamic programming equation and study regularization
arguments for a rigorous mathematical justification.
"
2308.02820,2024-11-19,Reinforcement Learning for Financial Index Tracking,"  We propose the first discrete-time infinite-horizon dynamic formulation of
the financial index tracking problem under both return-based tracking error and
value-based tracking error. The formulation overcomes the limitations of
existing models by incorporating the intertemporal dynamics of market
information variables not limited to prices, allowing exact calculation of
transaction costs, accounting for the tradeoff between overall tracking error
and transaction costs, allowing effective use of data in a long time period,
etc. The formulation also allows novel decision variables of cash injection or
withdraw. We propose to solve the portfolio rebalancing equation using a Banach
fixed point iteration, which allows to accurately calculate the transaction
costs specified as nonlinear functions of trading volumes in practice. We
propose an extension of deep reinforcement learning (RL) method to solve the
dynamic formulation. Our RL method resolves the issue of data limitation
resulting from the availability of a single sample path of financial data by a
novel training scheme. A comprehensive empirical study based on a 17-year-long
testing set demonstrates that the proposed method outperforms a benchmark
method in terms of tracking accuracy and has the potential for earning extra
profit through cash withdraw strategy.
"
2308.04769,2024-01-10,"Correlation-diversified portfolio construction by finding maximum
  independent set in large-scale market graph","  Correlation-diversified portfolios can be constructed by finding the maximum
independent sets (MISs) in market graphs with edges corresponding to
correlations between two stocks. The computational complexity to find the MIS
increases exponentially as the size of the market graph increases, making the
MIS selection in a large-scale market graph difficult. Here we construct a
diversified portfolio by solving the MIS problem for a large-scale market graph
with a combinatorial optimization solver (an Ising machine) based on a
quantum-inspired algorithm called simulated bifurcation (SB) and investigate
the investment performance of the constructed portfolio using long-term
historical market data. Comparisons using stock universes of various sizes
[TOPIX 100, Nikkei 225, TOPIX 1000, and TOPIX (including approximately 2,000
constituents)] show that the SB-based solver outperforms conventional MIS
solvers in terms of computation-time and solution-accuracy. By using the
SB-based solver, we optimized the parameters of a MIS portfolio strategy
through iteration of the backcast simulation that calculates the performance of
the MIS portfolio strategy based on a large-scale universe covering more than
1,700 Japanese stocks for a long period of 10 years. It has been found that the
best MIS portfolio strategy (Sharpe ratio = 1.16, annualized return/risk =
16.3%/14.0%) outperforms the major indices such as TOPIX (0.66, 10.0%/15.2%)
and MSCI Japan Minimum Volatility Index (0.64, 7.7%/12.1%) for the period from
2013 to 2023.
"
2308.05200,2023-08-11,SmartDCA superiority,"  Dollar-Cost Averaging (DCA) is a widely used technique to mitigate volatility
in long-term investments of appreciating assets. However, the inefficiency of
DCA arises from fixing the investment amount regardless of market conditions.
In this paper, we present a more efficient approach that we name SmartDCA,
which consists in adjusting asset purchases based on price levels. The
simplicity of SmartDCA allows for rigorous mathematical analysis, enabling us
to establish its superiority through the application of Cauchy-Schwartz
inequality and Lehmer means. We further extend our analysis to what we refer to
as $\rho$-SmartDCA, where the invested amount is raised to the power of $\rho$.
We demonstrate that higher values of $\rho$ lead to enhanced performance.
However, this approach may result in unbounded investments. To address this
concern, we introduce a bounded version of SmartDCA, taking advantage of two
novel mean definitions that we name quasi-Lehmer means. The bounded SmartDCA is
specifically designed to retain its superiority to DCA. To support our claims,
we provide rigorous mathematical proofs and conduct numerical analyses across
various scenarios. The performance gain of different SmartDCA alternatives is
compared against DCA using data from S\&P500 and Bitcoin. The results
consistently demonstrate that all SmartDCA variations yield higher long-term
investment returns compared to DCA.
"
2308.06260,2023-08-14,ChatGPT-based Investment Portfolio Selection,"  In this paper, we explore potential uses of generative AI models, such as
ChatGPT, for investment portfolio selection. Trusting investment advice from
Generative Pre-Trained Transformer (GPT) models is a challenge due to model
""hallucinations"", necessitating careful verification and validation of the
output. Therefore, we take an alternative approach. We use ChatGPT to obtain a
universe of stocks from S&P500 market index that are potentially attractive for
investing. Subsequently, we compared various portfolio optimization strategies
that utilized this AI-generated trading universe, evaluating those against
quantitative portfolio optimization models as well as comparing to some of the
popular investment funds. Our findings indicate that ChatGPT is effective in
stock selection but may not perform as well in assigning optimal weights to
stocks within the portfolio. But when stocks selection by ChatGPT is combined
with established portfolio optimization models, we achieve even better results.
By blending strengths of AI-generated stock selection with advanced
quantitative optimization techniques, we observed the potential for more robust
and favorable investment outcomes, suggesting a hybrid approach for more
effective and reliable investment decision-making in the future.
"
2308.07763,2023-11-08,Online Universal Dirichlet Factor Portfolios,"  We revisit the online portfolio allocation problem and propose universal
portfolios that use factor weighing to produce portfolios that out-perform
uniform dirichlet allocation schemes. We show a few analytical results on the
lower bounds of portfolio growth when the returns are known to follow a factor
model. We also show analytically that factor weighted dirichlet sampled
portfolios dominate the wealth generated by uniformly sampled dirichlet
portfolios. We corroborate our analytical results with empirical studies on
equity markets that are known to be driven by factors.
"
2308.07944,2023-08-17,Portfolio Selection via Topological Data Analysis,"  Portfolio management is an essential part of investment decision-making.
However, traditional methods often fail to deliver reasonable performance. This
problem stems from the inability of these methods to account for the unique
characteristics of multivariate time series data from stock markets. We present
a two-stage method for constructing an investment portfolio of common stocks.
The method involves the generation of time series representations followed by
their subsequent clustering. Our approach utilizes features based on
Topological Data Analysis (TDA) for the generation of representations, allowing
us to elucidate the topological structure within the data. Experimental results
show that our proposed system outperforms other methods. This superior
performance is consistent over different time frames, suggesting the viability
of TDA as a powerful tool for portfolio selection.
"
2308.09264,2023-11-27,"Black-Litterman, Bayesian Shrinkage, and Factor Models in Portfolio
  Selection: You Can Have It All","  Mean-variance analysis is widely used in portfolio management to identify the
best portfolio that makes an optimal trade-off between expected return and
volatility. Yet, this method has its limitations, notably its vulnerability to
estimation errors and its reliance on historical data. While shrinkage
estimators and factor models have been introduced to improve estimation
accuracy through bias-variance trade-offs, and the Black-Litterman model has
been developed to integrate investor opinions, a unified framework combining
three approaches has been lacking. Our study debuts a Bayesian blueprint that
fuses shrinkage estimation with view inclusion, conceptualizing both as
Bayesian updates. This model is then applied within the context of the
Fama-French approach factor models, thereby integrating the advantages of each
methodology. Finally, through a comprehensive empirical study in the US equity
market spanning a decade, we show that the model outperforms both the simple
$1/N$ portfolio and the optimal portfolios based on sample estimators.
"
2308.10039,2023-08-22,Do We Price Happiness? Evidence from Korean Stock Market,"  This study explores the potential of internet search volume data,
specifically Google Trends, as an indicator for cross-sectional stock returns.
Unlike previous studies, our research specifically investigates the search
volume of the topic 'happiness' and its impact on stock returns in the aspect
of risk pricing rather than as sentiment measurement. Empirical results
indicate that this 'happiness' search exposure (HSE) can explain future
returns, particularly for big and value firms. This suggests that HSE might be
a reflection of a firm's ability to produce goods or services that meet
societal utility needs. Our findings have significant implications for
institutional investors seeking to leverage HSE-based strategies for
outperformance. Additionally, our research suggests that, when selected
judiciously, some search topics on Google Trends can be related to risks that
impact stock prices.
"
2308.10556,2023-09-06,"D-TIPO: Deep time-inconsistent portfolio optimization with stocks and
  options","  In this paper, we propose a machine learning algorithm for time-inconsistent
portfolio optimization. The proposed algorithm builds upon neural network based
trading schemes, in which the asset allocation at each time point is determined
by a a neural network. The loss function is given by an empirical version of
the objective function of the portfolio optimization problem. Moreover, various
trading constraints are naturally fulfilled by choosing appropriate activation
functions in the output layers of the neural networks. Besides this, our main
contribution is to add options to the portfolio of risky assets and a risk-free
bond and using additional neural networks to determine the amount allocated
into the options as well as their strike prices.
  We consider objective functions more in line with the rational preference of
an investor than the classical mean-variance, apply realistic trading
constraints and model the assets with a correlated jump-diffusion SDE. With an
incomplete market and a more involved objective function, we show that it is
beneficial to add options to the portfolio. Moreover, it is shown that adding
options leads to a more constant stock allocation with less demand for drastic
re-allocations.
"
2308.11202,2023-08-23,Analysis of Optimal Portfolio Management Using Hierarchical Clustering,"  Portfolio optimization is a task that investors use to determine the best
allocations for their investments, and fund managers implement computational
models to help guide their decisions. While one of the most common portfolio
optimization models in the industry is the Markowitz Model, practitioners
recognize limitations in its framework that lead to suboptimal out-of-sample
performance and unrealistic allocations. In this study, I refine the Markowitz
Model by incorporating machine learning to improve portfolio performance. By
using a hierarchical clustering-based approach, I am able to enhance portfolio
performance on a risk-adjusted basis compared to the Markowitz Model, across
various market factors.
"
2308.11294,2023-08-25,Network Momentum across Asset Classes,"  We investigate the concept of network momentum, a novel trading signal
derived from momentum spillover across assets. Initially observed within the
confines of pairwise economic and fundamental ties, such as the stock-bond
connection of the same company and stocks linked through supply-demand chains,
momentum spillover implies a propagation of momentum risk premium from one
asset to another. The similarity of momentum risk premium, exemplified by
co-movement patterns, has been spotted across multiple asset classes including
commodities, equities, bonds and currencies. However, studying the network
effect of momentum spillover across these classes has been challenging due to a
lack of readily available common characteristics or economic ties beyond the
company level. In this paper, we explore the interconnections of momentum
features across a diverse range of 64 continuous future contracts spanning
these four classes. We utilise a linear and interpretable graph learning model
with minimal assumptions to reveal the intricacies of the momentum spillover
network. By leveraging the learned networks, we construct a network momentum
strategy that exhibits a Sharpe ratio of 1.5 and an annual return of 22%, after
volatility scaling, from 2000 to 2022. This paper pioneers the examination of
momentum spillover across multiple asset classes using only pricing data,
presents a multi-asset investment strategy based on network momentum, and
underscores the effectiveness of this strategy through robust empirical
analysis.
"
2308.12212,2023-08-25,Learning to Learn Financial Networks for Optimising Momentum Strategies,"  Network momentum provides a novel type of risk premium, which exploits the
interconnections among assets in a financial network to predict future returns.
However, the current process of constructing financial networks relies heavily
on expensive databases and financial expertise, limiting accessibility for
small-sized and academic institutions. Furthermore, the traditional approach
treats network construction and portfolio optimisation as separate tasks,
potentially hindering optimal portfolio performance. To address these
challenges, we propose L2GMOM, an end-to-end machine learning framework that
simultaneously learns financial networks and optimises trading signals for
network momentum strategies. The model of L2GMOM is a neural network with a
highly interpretable forward propagation architecture, which is derived from
algorithm unrolling. The L2GMOM is flexible and can be trained with diverse
loss functions for portfolio performance, e.g. the negative Sharpe ratio.
Backtesting on 64 continuous future contracts demonstrates a significant
improvement in portfolio profitability and risk control, with a Sharpe ratio of
1.74 across a 20-year period.
"
2308.15135,2023-08-31,"Signature Trading: A Path-Dependent Extension of the Mean-Variance
  Framework with Exogenous Signals","  In this article we introduce a portfolio optimisation framework, in which the
use of rough path signatures (Lyons, 1998) provides a novel method of
incorporating path-dependencies in the joint signal-asset dynamics, naturally
extending traditional factor models, while keeping the resulting formulas
lightweight and easily interpretable. We achieve this by representing a trading
strategy as a linear functional applied to the signature of a path (which we
refer to as ""Signature Trading"" or ""Sig-Trading""). This allows the modeller to
efficiently encode the evolution of past time-series observations into the
optimisation problem. In particular, we derive a concise formulation of the
dynamic mean-variance criterion alongside an explicit solution in our setting,
which naturally incorporates a drawdown control in the optimal strategy over a
finite time horizon. Secondly, we draw parallels between classical portfolio
stategies and Sig-Trading strategies and explain how the latter leads to a
pathwise extension of the classical setting via the ""Signature Efficient
Frontier"". Finally, we give examples when trading under an exogenous signal as
well as examples for momentum and pair-trading strategies, demonstrated both on
synthetic and market data. Our framework combines the best of both worlds
between classical theory (whose appeal lies in clear and concise formulae) and
between modern, flexible data-driven methods that can handle more realistic
datasets. The advantage of the added flexibility of the latter is that one can
bypass common issues such as the accumulation of heteroskedastic and asymmetric
residuals during the optimisation phase. Overall, Sig-Trading combines the
flexibility of data-driven methods without compromising on the clarity of the
classical theory and our presented results provide a compelling toolbox that
yields superior results for a large class of trading strategies.
"
2308.15384,2023-09-01,Hedging Forecast Combinations With an Application to the Random Forest,"  This papers proposes a generic, high-level methodology for generating
forecast combinations that would deliver the optimal linearly combined forecast
in terms of the mean-squared forecast error if one had access to two population
quantities: the mean vector and the covariance matrix of the vector of
individual forecast errors. We point out that this problem is identical to a
mean-variance portfolio construction problem, in which portfolio weights
correspond to forecast combination weights. We allow negative forecast weights
and interpret such weights as hedging over and under estimation risks across
estimators. This interpretation follows directly as an implication of the
portfolio analogy. We demonstrate our method's improved out-of-sample
performance relative to standard methods in combining tree forecasts to form
weighted random forests in 14 data sets.
"
2309.00025,2023-09-04,"New general dependence measures: construction, estimation and
  application to high-frequency stock returns","  We propose a set of dependence measures that are non-linear, local, invariant
to a wide range of transformations on the marginals, can show tail and risk
asymmetries, are always well-defined, are easy to estimate and can be used on
any dataset. We propose a nonparametric estimator and prove its consistency and
asymptotic normality. Thereby we significantly improve on existing (extreme)
dependence measures used in asset pricing and statistics. To show practical
utility, we use these measures on high-frequency stock return data around
market distress events such as the 2010 Flash Crash and during the GFC.
Contrary to ubiquitously used correlations we find that our measures clearly
show tail asymmetry, non-linearity, lack of diversification and endogenous
buildup of risks present during these distress events. Additionally, our
measures anticipate large (joint) losses during the Flash Crash while also
anticipating the bounce back and flagging the subsequent market fragility. Our
findings have implications for risk management, portfolio construction and
hedging at any frequency.
"
2309.01363,2023-09-06,"Mutual Information Maximizing Quantum Generative Adversarial Network and
  Its Applications in Finance","  One of the most promising applications in the era of NISQ (Noisy
Intermediate-Scale Quantum) computing is quantum machine learning. Quantum
machine learning offers significant quantum advantages over classical machine
learning across various domains. Specifically, generative adversarial networks
have been recognized for their potential utility in diverse fields such as
image generation, finance, and probability distribution modeling. However,
these networks necessitate solutions for inherent challenges like mode
collapse. In this study, we capitalize on the concept that the estimation of
mutual information between high-dimensional continuous random variables can be
achieved through gradient descent using neural networks. We introduce a novel
approach named InfoQGAN, which employs the Mutual Information Neural Estimator
(MINE) within the framework of quantum generative adversarial networks to
tackle the mode collapse issue. Furthermore, we elaborate on how this approach
can be applied to a financial scenario, specifically addressing the problem of
generating portfolio return distributions through dynamic asset allocation.
This illustrates the potential practical applicability of InfoQGAN in
real-world contexts.
"
2309.01936,2023-09-06,"Optimal Management of DC Pension Plan with Inflation Risk and Tail VaR
  Constraint","  This paper investigates an optimal investment problem under the tail Value at
Risk (tail VaR, also known as expected shortfall, conditional VaR, average VaR)
and portfolio insurance constraints confronted by a defined-contribution
pension member. The member's aim is to maximize the expected utility from the
terminal wealth exceeding the minimum guarantee by investing his wealth in a
cash bond, an inflation-linked bond and a stock. Due to the presence of the
tail VaR constraint, the problem cannot be tackled by standard control tools.
We apply the Lagrange method along with quantile optimization techniques to
solve the problem. Through delicate analysis, the optimal investment output in
closed-form and optimal investment strategy are derived. A numerical analysis
is also provided to show how the constraints impact the optimal investment
output and strategy.
"
2309.03736,2023-09-08,"TradingGPT: Multi-Agent System with Layered Memory and Distinct
  Characters for Enhanced Financial Trading Performance","  Large Language Models (LLMs), prominently highlighted by the recent evolution
in the Generative Pre-trained Transformers (GPT) series, have displayed
significant prowess across various domains, such as aiding in healthcare
diagnostics and curating analytical business reports. The efficacy of GPTs lies
in their ability to decode human instructions, achieved through comprehensively
processing historical inputs as an entirety within their memory system. Yet,
the memory processing of GPTs does not precisely emulate the hierarchical
nature of human memory. This can result in LLMs struggling to prioritize
immediate and critical tasks efficiently. To bridge this gap, we introduce an
innovative LLM multi-agent framework endowed with layered memories. We assert
that this framework is well-suited for stock and fund trading, where the
extraction of highly relevant insights from hierarchical financial data is
imperative to inform trading decisions. Within this framework, one agent
organizes memory into three distinct layers, each governed by a custom decay
mechanism, aligning more closely with human cognitive processes. Agents can
also engage in inter-agent debate. In financial trading contexts, LLMs serve as
the decision core for trading agents, leveraging their layered memory system to
integrate multi-source historical actions and market insights. This equips them
to navigate financial changes, formulate strategies, and debate with peer
agents about investment decisions. Another standout feature of our approach is
to equip agents with individualized trading traits, enhancing memory diversity
and decision robustness. These sophisticated designs boost the system's
responsiveness to historical trades and real-time market signals, ensuring
superior automated trading accuracy.
"
2309.05003,2024-09-10,"Multidimensional indefinite stochastic Riccati equations and zero-sum
  stochastic linear-quadratic differential games with non-Markovian regime
  switching","  This paper is concerned with zero-sum stochastic linear-quadratic
differential games in a regime switching model. The coefficients of the games
depend on the underlying noises, so it is a non-Markovian regime switching
model. Based on the solutions of a new kind of multidimensional indefinite
stochastic Riccati equation (SRE) and a multidimensional linear backward
stochastic differential equation (BSDE) with unbounded coefficients, we provide
closed-loop optimal feedback control-strategy pairs for the two players. The
main contribution of this paper, which is of great importance in its own right
from the BSDE theory point of view, is to prove the existence and uniqueness of
the solution to the new kind of SRE. Notably, the first component of the
solution (as a process) is capable of taking positive and negative values
simultaneously. For homogeneous systems, we obtain the optimal feedback
control-strategy pairs under general closed convex cone control constraints.
Finally, these results are applied to portfolio selection games with full or
partial no-shorting constraint in a regime switching market with random
coefficients.
"
2309.05926,2023-09-13,"SCOP: Schrodinger Control Optimal Planning for Goal-Based Wealth
  Management","  We consider the problem of optimization of contributions of a financial
planner such as a working individual towards a financial goal such as
retirement. The objective of the planner is to find an optimal and feasible
schedule of periodic installments to an investment portfolio set up towards the
goal. Because portfolio returns are random, the practical version of the
problem amounts to finding an optimal contribution scheme such that the goal is
satisfied at a given confidence level. This paper suggests a semi-analytical
approach to a continuous-time version of this problem based on a controlled
backward Kolmogorov equation (BKE) which describes the tail probability of the
terminal wealth given a contribution policy. The controlled BKE is solved
semi-analytically by reducing it to a controlled Schrodinger equation and
solving the latter using an algebraic method. Numerically, our approach amounts
to finding semi-analytical solutions simultaneously for all values of control
parameters on a small grid, and then using the standard two-dimensional spline
interpolation to simultaneously represent all satisficing solutions of the
original plan optimization problem. Rather than being a point in the space of
control variables, satisficing solutions form continuous contour lines
(efficient frontiers) in this space.
"
2309.06353,2023-09-13,"The Conundrum of the Pension System in India: A Comprehensive study in
  the context of India's Growth Story","  India is the largest democracy in the world and has recently surpassed China
to be the highest-populated country, with an estimated 1.425 billion
(approximately 18% of the world population). Moreover, India's elderly
population is projected to increase to 138 million by 2035. Indian economy is
already reeling under the pressure of exorbitant pension liabilities of the
government for existing pensioners. As such, India has introduced a National
Pension System (NPS), which is a Defined Contribution Scheme for employees
joining government service on or after 1st January 2004, bidding adieu to the
age-old, tried and tested Old Pension System (OPS) which is a Direct Benefit
Scheme, in vogue in India since the British Raj. This is an epoch-making move
by the government as it seeks to inculcate Disciplined Saving among the people
while significantly reducing the government burden by reducing the Pension
Liabilities of the Central and State Governments. This paper aims to analyse
various features and intricacies of the NPS and address the claims of various
stakeholders like the Central Government, State Government, Employees,
Pensioners, etc. In light of the above, and taking cognisance of the fact that
many states such as Rajasthan, Chattisgarh, Jharkhand, etc, have exited the NPS
scheme and have sought back their share of NPS employee and employer
contribution, this study is relevant to address the current economic and fiscal
issues of India to propel towards the ambitious goal of becoming a $ 5 trillion
dollar economy by 2025.
  Keywords: Old Pension Scheme (OPS), National Pension System (NPS), Direct
Benefit Scheme, Defined Contribution Scheme, Pension Liabilities.
"
2309.07667,2023-12-22,Profit and loss attribution: An empirical study,"  The profit and loss (p&l) attrition for each business year into different
risk or risk factors (e.g., interest rates, credit spreads, foreign exchange
rate etc.) is a regulatory requirement, e.g., under Solvency 2. Three different
decomposition principles are prevalent: one-at-a-time (OAT), sequential
updating (SU) and average sequential updating (ASU) decompositions. In this
research, using financial market data from 2003 to 2022, we demonstrate that
the OAT decomposition can generate significant unexplained p&l and that the SU
decompositions depends significantly on the order or labeling of the risk
factors. On the basis of an investment in a foreign stock, we further explain
that the SU decomposition is not able to identify all relevant risk factors.
This potentially effects the hedging strategy of the portfolio manager. In
conclusion, we suggest to use the ASU decomposition in practice.
"
2309.10152,2024-03-19,"Sparse Index Tracking: Simultaneous Asset Selection and Capital
  Allocation via $\ell_0$-Constrained Portfolio","  Sparse index tracking is a prominent passive portfolio management strategy
that constructs a sparse portfolio to track a financial index. A sparse
portfolio is preferable to a full portfolio in terms of reducing transaction
costs and avoiding illiquid assets. To achieve portfolio sparsity, conventional
studies have utilized $\ell_p$-norm regularizations as a continuous surrogate
of the $\ell_0$-norm regularization. Although these formulations can construct
sparse portfolios, their practical application is challenging due to the
intricate and time-consuming process of tuning parameters to define the precise
upper limit of assets in the portfolio. In this paper, we propose a new problem
formulation of sparse index tracking using an $\ell_0$-norm constraint that
enables easy control of the upper bound on the number of assets in the
portfolio. Moreover, our approach offers a choice between constraints on
portfolio and turnover sparsity, further reducing transaction costs by limiting
asset updates at each rebalancing interval. Furthermore, we develop an
efficient algorithm for solving this problem based on a primal-dual splitting
method. Finally, we illustrate the effectiveness of the proposed method through
experiments on the S&P500 and Russell3000 index datasets.
"
2309.10546,2023-09-20,"Mean Absolute Directional Loss as a New Loss Function for Machine
  Learning Problems in Algorithmic Investment Strategies","  This paper investigates the issue of an adequate loss function in the
optimization of machine learning models used in the forecasting of financial
time series for the purpose of algorithmic investment strategies (AIS)
construction. We propose the Mean Absolute Directional Loss (MADL) function,
solving important problems of classical forecast error functions in extracting
information from forecasts to create efficient buy/sell signals in algorithmic
investment strategies. Finally, based on the data from two different asset
classes (cryptocurrencies: Bitcoin and commodities: Crude Oil), we show that
the new loss function enables us to select better hyperparameters for the LSTM
model and obtain more efficient investment strategies, with regard to
risk-adjusted return metrics on the out-of-sample data.
"
2309.11693,2023-09-22,Doubly Robust Mean-CVaR Portfolio,"  In this study, we address the challenge of portfolio optimization, a critical
aspect of managing investment risks and maximizing returns. The mean-CVaR
portfolio is considered a promising method due to today's unstable financial
market crises like the COVID-19 pandemic. It incorporates expected returns into
the CVaR, which considers the expected value of losses exceeding a specified
probability level. However, the instability associated with the input parameter
changes and estimation errors can deteriorate portfolio performance. Therefore
in this study, we propose a Doubly Robust mean-CVaR Portfolio refined approach
to the mean-CVaR portfolio optimization. Our method can solve the instability
problem to simultaneously optimize the multiple levels of CVaRs and define
uncertainty sets for the mean parameter to perform robust optimization.
Theoretically, the proposed method can be formulated as a second-order cone
programming problem which is the same formulation as traditional mean-variance
portfolio optimization. In addition, we derive an estimation error bound of the
proposed method for the finite-sample case. Finally, experiments with benchmark
and real market data show that our proposed method exhibits better performance
compared to existing portfolio optimization strategies.
"
2309.13696,2023-09-26,"Performance Evaluation of Equal-Weight Portfolio and Optimum Risk
  Portfolio on Indian Stocks","  Designing an optimum portfolio for allocating suitable weights to its
constituent assets so that the return and risk associated with the portfolio
are optimized is a computationally hard problem. The seminal work of Markowitz
that attempted to solve the problem by estimating the future returns of the
stocks is found to perform sub-optimally on real-world stock market data. This
is because the estimation task becomes extremely challenging due to the
stochastic and volatile nature of stock prices. This work illustrates three
approaches to portfolio design minimizing the risk, optimizing the risk, and
assigning equal weights to the stocks of a portfolio. Thirteen critical sectors
listed on the National Stock Exchange (NSE) of India are first chosen. Three
portfolios are designed following the above approaches choosing the top ten
stocks from each sector based on their free-float market capitalization. The
portfolios are designed using the historical prices of the stocks from Jan 1,
2017, to Dec 31, 2022. The portfolios are evaluated on the stock price data
from Jan 1, 2022, to Dec 31, 2022. The performances of the portfolios are
compared, and the portfolio yielding the higher return for each sector is
identified.
"
2309.15640,2023-09-28,"Hedging Properties of Algorithmic Investment Strategies using Long
  Short-Term Memory and Time Series models for Equity Indices","  This paper proposes a novel approach to hedging portfolios of risky assets
when financial markets are affected by financial turmoils. We introduce a
completely novel approach to diversification activity not on the level of
single assets but on the level of ensemble algorithmic investment strategies
(AIS) built based on the prices of these assets. We employ four types of
diverse theoretical models (LSTM - Long Short-Term Memory, ARIMA-GARCH -
Autoregressive Integrated Moving Average - Generalized Autoregressive
Conditional Heteroskedasticity, momentum, and contrarian) to generate price
forecasts, which are then used to produce investment signals in single and
complex AIS. In such a way, we are able to verify the diversification potential
of different types of investment strategies consisting of various assets
(energy commodities, precious metals, cryptocurrencies, or soft commodities) in
hedging ensemble AIS built for equity indices (S&P 500 index). Empirical data
used in this study cover the period between 2004 and 2022. Our main conclusion
is that LSTM-based strategies outperform the other models and that the best
diversifier for the AIS built for the S&P 500 index is the AIS built for
Bitcoin. Finally, we test the LSTM model for a higher frequency of data (1
hour). We conclude that it outperforms the results obtained using daily data.
"
2309.15767,2023-09-28,Implementing portfolio risk management and hedging in practice,"  In academic literature portfolio risk management and hedging are often versed
in the language of stochastic control and Hamilton--Jacobi--Bellman~(HJB)
equations in continuous time. In practice the continuous-time framework of
stochastic control may be undesirable for various business reasons. In this
work we present a straightforward approach for thinking of cross-asset
portfolio risk management and hedging, providing some implementation details,
while rarely venturing outside the convex optimisation setting of (approximate)
quadratic programming~(QP). We pay particular attention to the correspondence
between the economic concepts and their mathematical representations; the
abstractions enabling us to handle multiple asset classes and risk models at
once; the dimensional analysis of the resulting equations; and the assumptions
inherent in our derivations. We demonstrate how to solve the resulting QPs with
CVXOPT.
"
2309.16679,2023-10-25,"Leveraging Deep Learning and Online Source Sentiment for Financial
  Portfolio Management","  Financial portfolio management describes the task of distributing funds and
conducting trading operations on a set of financial assets, such as stocks,
index funds, foreign exchange or cryptocurrencies, aiming to maximize the
profit while minimizing the loss incurred by said operations. Deep Learning
(DL) methods have been consistently excelling at various tasks and automated
financial trading is one of the most complex one of those. This paper aims to
provide insight into various DL methods for financial trading, under both the
supervised and reinforcement learning schemes. At the same time, taking into
consideration sentiment information regarding the traded assets, we discuss and
demonstrate their usefulness through corresponding research studies. Finally,
we discuss commonly found problems in training such financial agents and equip
the reader with the necessary knowledge to avoid these problems and apply the
discussed methods in practice.
"
2309.16888,2024-06-17,Beyond Gut Feel: Using Time Series Transformers to Find Investment Gems,"  This paper addresses the growing application of data-driven approaches within
the Private Equity (PE) industry, particularly in sourcing investment targets
(i.e., companies) for Venture Capital (VC) and Growth Capital (GC). We present
a comprehensive review of the relevant approaches and propose a novel approach
leveraging a Transformer-based Multivariate Time Series Classifier (TMTSC) for
predicting the success likelihood of any candidate company. The objective of
our research is to optimize sourcing performance for VC and GC investments by
formally defining the sourcing problem as a multivariate time series
classification task. We consecutively introduce the key components of our
implementation which collectively contribute to the successful application of
TMTSC in VC/GC sourcing: input features, model architecture, optimization
target, and investor-centric data processing. Our extensive experiments on two
real-world investment tasks, benchmarked towards three popular baselines,
demonstrate the effectiveness of our approach in improving decision making
within the VC and GC industry.
"
2310.00553,2025-05-13,Robust Asset-Liability Management,"  How should financial institutions hedge their balance sheets against interest
rate risk when managing long-term assets and liabilities? We address this
question by proposing a bond portfolio solution based on ambiguity-averse
preferences, which generalizes classical immunization and accommodates
arbitrary liability structures, portfolio constraints, and interest rate
perturbations. In a further extension, we show that the optimal portfolio can
be computed as a simple generalized least squares problem, making the solution
both transparent and computationally efficient. The resulting portfolio also
reduces leverage by implicitly regularizing the portfolio weights, which
enhances out-of-sample performance. Numerical evaluations using both empirical
and simulated yield curves from a no-arbitrage term structure model support the
feasibility and accuracy of our approach relative to existing methods.
"
2310.00747,2025-01-09,"NoxTrader: LSTM-Based Stock Return Momentum Prediction for Quantitative
  Trading","  We introduce NoxTrader, a sophisticated system designed for portfolio
construction and trading execution with the primary objective of achieving
profitable outcomes in the stock market, specifically aiming to generate
moderate to long-term profits. The underlying learning process of NoxTrader is
rooted in the assimilation of valuable insights derived from historical trading
data, particularly focusing on time-series analysis due to the nature of the
dataset employed. In our approach, we utilize price and volume data of US stock
market for feature engineering to generate effective features, including Return
Momentum, Week Price Momentum, and Month Price Momentum. We choose the Long
Short-Term Memory (LSTM)model to capture continuous price trends and implement
dynamic model updates during the trading execution process, enabling the model
to continuously adapt to the current market trends. Notably, we have developed
a comprehensive trading backtesting system - NoxTrader, which allows us to
manage portfolios based on predictive scores and utilize custom evaluation
metrics to conduct a thorough assessment of our trading performance. Our
rigorous feature engineering and careful selection of prediction targets enable
us to generate prediction data with an impressive correlation range between
0.65 and 0.75. Finally, we monitor the dispersion of our prediction data and
perform a comparative analysis against actual market data. Through the use of
filtering techniques, we improved the initial -60% investment return to 325%.
"
2310.01319,2023-10-03,"CAD: Clustering And Deep Reinforcement Learning Based Multi-Period
  Portfolio Management Strategy","  In this paper, we present a novel trading strategy that integrates
reinforcement learning methods with clustering techniques for portfolio
management in multi-period trading. Specifically, we leverage the clustering
method to categorize stocks into various clusters based on their financial
indices. Subsequently, we utilize the algorithm Asynchronous Advantage
Actor-Critic to determine the trading actions for stocks within each cluster.
Finally, we employ the algorithm DDPG to generate the portfolio weight vector,
which decides the amount of stocks to buy, sell, or hold according to the
trading actions of different clusters. To the best of our knowledge, our
approach is the first to combine clustering methods and reinforcement learning
methods for portfolio management in the context of multi-period trading.
  Our proposed strategy is evaluated using a series of back-tests on four
datasets, comprising a of 800 stocks, obtained from the Shanghai Stock Exchange
and National Association of Securities Deal Automated Quotations sources. Our
results demonstrate that our approach outperforms conventional portfolio
management techniques, such as the Robust Median Reversion strategy, Passive
Aggressive Median Reversion Strategy, and several machine learning methods,
across various metrics. In our back-test experiments, our proposed strategy
yields an average return of 151% over 360 trading periods with 800 stocks,
compared to the highest return of 124% achieved by other techniques over
identical trading periods and stocks.
"
2310.02014,2023-10-04,Utility-based acceptability indices,"  In this short paper we introduce a new class of performance measures based on
certainty equivalents defined via scaled utility functions. We analyse their
properties, show that the corresponding portfolio optimization problem is
well-posed under generic conditions, and analyse the link between portfolio
dynamics, benchmark process, and utility function choice in the long-run
setting.
"
2310.02084,2023-10-04,Robust Long-Term Growth Rate of Expected Utility for Leveraged ETFs,"  This paper analyzes the robust long-term growth rate of expected utility and
expected return from holding a leveraged exchange-traded fund (LETF). When the
Markovian model parameters in the reference asset are uncertain, the robust
long-term growth rate is derived by analyzing the worst-case parameters among
an uncertainty set. We compute the growth rate and describe the optimal
leverage ratio maximizing the robust long-term growth rate. To achieve this,
the worst-case parameters are analyzed by the comparison principle, and the
growth rate of the worst-case is computed using the martingale extraction
method. The robust long-term growth rates are obtained explicitly under a
number of models for the reference asset, including the geometric Brownian
motion (GBM), Cox--Ingersoll--Ross (CIR), 3/2, and Heston and 3/2 stochastic
volatility models. Additionally, we demonstrate the impact of stochastic
interest rates, such as the Vasicek and inverse GARCH short rate models. This
paper is an extended work of \citet{Leung2017}.
"
2310.02163,2025-01-07,Navigating Uncertainty in ESG Investing,"  The widespread confusion among investors regarding Environmental, Social, and
Governance (ESG) rankings assigned by rating agencies has underscored a
critical issue in sustainable investing. To address this uncertainty, our
research has devised methods that not only recognize this ambiguity but also
offer tailored investment strategies for different investor profiles. By
developing ESG ensemble strategies and integrating ESG scores into a
Reinforcement Learning (RL) model, we aim to optimize portfolios that cater to
both financial returns and ESG-focused outcomes. Additionally, by proposing the
Double-Mean-Variance model, we classify three types of investors based on their
risk preferences. We also introduce ESG-adjusted Capital Asset Pricing Models
(CAPMs) to assess the performance of these optimized portfolios. Ultimately,
our comprehensive approach provides investors with tools to navigate the
inherent ambiguities of ESG ratings, facilitating more informed investment
decisions.
"
2310.02322,2024-10-08,Signature Methods in Stochastic Portfolio Theory,"  In the context of stochastic portfolio theory we introduce a novel class of
portfolios which we call linear path-functional portfolios. These are
portfolios which are determined by certain transformations of linear functions
of a collections of feature maps that are non-anticipative path functionals of
an underlying semimartingale. As main example for such feature maps we consider
the signature of the (ranked) market weights. We prove that these portfolios
are universal in the sense that every continuous, possibly path-dependent,
portfolio function of the market weights can be uniformly approximated by
signature portfolios. We also show that signature portfolios can approximate
the growth-optimal portfolio in several classes of non-Markovian market models
arbitrarily well and illustrate numerically that the trained signature
portfolios are remarkably close to the theoretical growth-optimal portfolios.
Besides these universality features, the main numerical advantage lies in the
fact that several optimization tasks like maximizing (expected) logarithmic
wealth or mean-variance optimization within the class of linear path-functional
portfolios reduce to a convex quadratic optimization problem, thus making it
computationally highly tractable. We apply our method also to real market data
based on several indices. Our results point towards out-performance on the
considered out-of-sample data, also in the presence of transaction costs.
"
2310.04280,2023-10-31,Multi-Industry Simplex : A Probabilistic Extension of GICS,"  Accurate industry classification is a critical tool for many asset management
applications. While the current industry gold-standard GICS (Global Industry
Classification Standard) has proven to be reliable and robust in many settings,
it has limitations that cannot be ignored. Fundamentally, GICS is a
single-industry model, in which every firm is assigned to exactly one group -
regardless of how diversified that firm may be. This approach breaks down for
large conglomerates like Amazon, which have risk exposure spread out across
multiple sectors. We attempt to overcome these limitations by developing MIS
(Multi-Industry Simplex), a probabilistic model that can flexibly assign a firm
to as many industries as can be supported by the data. In particular, we
utilize topic modeling, an natural language processing approach that utilizes
business descriptions to extract and identify corresponding industries. Each
identified industry comes with a relevance probability, allowing for high
interpretability and easy auditing, circumventing the black-box nature of
alternative machine learning approaches. We describe this model in detail and
provide two use-cases that are relevant to asset management - thematic
portfolios and nearest neighbor identification. While our approach has
limitations of its own, we demonstrate the viability of probabilistic industry
classification and hope to inspire future research in this field.
"
2310.04536,2023-10-10,"Improving Portfolio Performance Using a Novel Method for Predicting
  Financial Regimes","  This work extends a previous work in regime detection, which allowed trading
positions to be profitably adjusted when a new regime was detected, to ex ante
prediction of regimes, leading to substantial performance improvements over the
earlier model, over all three asset classes considered (equities, commodities,
and foreign exchange), over a test period of four years. The proposed new model
is also benchmarked over this same period against a hidden Markov model, the
most popular current model for financial regime prediction, and against an
appropriate index benchmark for each asset class, in the case of the
commodities model having a test period cost-adjusted cumulative return over
four times higher than that expected from the index. Notably, the proposed
model makes use of a contrarian trading strategy, not uncommon in the financial
industry but relatively unexplored in machine learning models. The model also
makes use of frequent short positions, something not always desirable to
investors due to issues of both financial risk and ethics; however, it is
discussed how further work could remove this reliance on shorting and allow the
construction of a long-only version of the model.
"
2310.07052,2025-01-17,"Uses of Sub-sample Estimates to Reduce Errors in Stochastic Optimization
  Models","  Optimization software enables the solution of problems with millions of
variables and associated parameters. These parameters are, however, often
uncertain and represented with an analytical description of the parameter's
distribution or with some form of sample. With large numbers of such
parameters, optimization of the resulting model is often driven by
mis-specifications or extreme sample characteristics, resulting in solutions
that are far from a true optimum. This paper describes how asymptotic
convergence results may not be useful in large-scale problems and how the
optimization of problems based on sub-sample estimates may achieve improved
results over models using full-sample solution estimates. A motivating example
and numerical results from a portfolio optimization problem demonstrate the
potential improvement. A theoretical analysis also provides insight into the
structure of problems where sub-sample optimization may be most beneficial.
"
2310.07692,2024-04-22,Risk valuation of quanto derivatives on temperature and electricity,"  This paper develops a coupled model for day-ahead electricity prices and
average daily temperature which allows to model quanto weather and energy
derivatives. These products have gained on popularity as they enable to hedge
against both volumetric and price risks. Electricity day-ahead prices and
average daily temperatures are modelled through non homogeneous
Ornstein-Uhlenbeck processes driven by a Brownian motion and a Normal Inverse
Gaussian L\'evy process, which allows to include dependence between them. A
Conditional Least Square method is developed to estimate the different
parameters of the model and used on real data. Then, explicit and semi-explicit
formulas are obtained for derivatives including quanto options and compared
with Monte Carlo simulations. Last, we develop explicit formulas to hedge
statically single and double sided quanto options by a portfolio of electricity
options and temperature options (CDD or HDD).
"
2310.08284,2023-10-13,"Statistical arbitrage portfolio construction based on preference
  relations","  Statistical arbitrage methods identify mispricings in securities with the
goal of building portfolios which are weakly correlated with the market. In
pairs trading, an arbitrage opportunity is identified by observing relative
price movements between a pair of two securities. By simultaneously observing
multiple pairs, one can exploit different arbitrage opportunities and increase
the performance of such methods. However, the use of a large number of pairs is
difficult due to the increased probability of contradictory trade signals among
different pairs. In this paper, we propose a novel portfolio construction
method based on preference relation graphs, which can reconcile contradictory
pairs trading signals across multiple security pairs. The proposed approach
enables joint exploitation of arbitrage opportunities among a large number of
securities. Experimental results using three decades of historical returns of
roughly 500 stocks from the S\&P 500 index show that the portfolios based on
preference relations exhibit robust returns even with high transaction costs,
and that their performance improves with the number of securities considered.
"
2310.09578,2023-10-17,Sparse Index Tracking via Topological Learning,"  In this research, we introduce a novel methodology for the index tracking
problem with sparse portfolios by leveraging topological data analysis (TDA).
Utilizing persistence homology to measure the riskiness of assets, we introduce
a topological method for data-driven learning of the parameters for
regularization terms. Specifically, the Vietoris-Rips filtration method is
utilized to capture the intricate topological features of asset movements,
providing a robust framework for portfolio tracking. Our approach has the
advantage of accommodating both $\ell_1$ and $\ell_2$ penalty terms without the
requirement for expensive estimation procedures. We empirically validate the
performance of our methodology against state-of-the-art sparse index tracking
techniques, such as Elastic-Net and SLOPE, using a dataset that covers 23 years
of S&P500 index and its constituent data. Our out-of-sample results show that
this computationally efficient technique surpasses conventional methods across
risk metrics, risk-adjusted performance, and trading expenses in varied market
conditions. Furthermore, in turbulent markets, it not only maintains but also
enhances tracking performance.
"
2310.10500,2024-03-29,"Few-Shot Learning Patterns in Financial Time-Series for Trend-Following
  Strategies","  Forecasting models for systematic trading strategies do not adapt quickly
when financial market conditions rapidly change, as was seen in the advent of
the COVID-19 pandemic in 2020, causing many forecasting models to take
loss-making positions. To deal with such situations, we propose a novel
time-series trend-following forecaster that can quickly adapt to new market
conditions, referred to as regimes. We leverage recent developments from the
deep learning community and use few-shot learning. We propose the Cross
Attentive Time-Series Trend Network -- X-Trend -- which takes positions
attending over a context set of financial time-series regimes. X-Trend
transfers trends from similar patterns in the context set to make forecasts,
then subsequently takes positions for a new distinct target regime. By quickly
adapting to new financial regimes, X-Trend increases Sharpe ratio by 18.9% over
a neural forecaster and 10-fold over a conventional Time-series Momentum
strategy during the turbulent market period from 2018 to 2023. Our strategy
recovers twice as quickly from the COVID-19 drawdown compared to the
neural-forecaster. X-Trend can also take zero-shot positions on novel unseen
financial assets obtaining a 5-fold Sharpe ratio increase versus a neural
time-series trend forecaster over the same period. Furthermore, the
cross-attention mechanism allows us to interpret the relationship between
forecasts and patterns in the context set.
"
2310.10760,2023-10-18,"Towards reducing hallucination in extracting information from financial
  reports using Large Language Models","  For a financial analyst, the question and answer (Q\&A) segment of the
company financial report is a crucial piece of information for various analysis
and investment decisions. However, extracting valuable insights from the Q\&A
section has posed considerable challenges as the conventional methods such as
detailed reading and note-taking lack scalability and are susceptible to human
errors, and Optical Character Recognition (OCR) and similar techniques
encounter difficulties in accurately processing unstructured transcript text,
often missing subtle linguistic nuances that drive investor decisions. Here, we
demonstrate the utilization of Large Language Models (LLMs) to efficiently and
rapidly extract information from earnings report transcripts while ensuring
high accuracy transforming the extraction process as well as reducing
hallucination by combining retrieval-augmented generation technique as well as
metadata. We evaluate the outcomes of various LLMs with and without using our
proposed approach based on various objective metrics for evaluating Q\&A
systems, and empirically demonstrate superiority of our method.
"
2310.11023,2025-04-18,Robust Trading in a Generalized Lattice Market,"  This paper introduces a novel robust trading paradigm, called
\textit{multi-double linear policies}, situated within a \textit{generalized}
lattice market. Distinctively, our framework departs from most existing robust
trading strategies, which are predominantly limited to single or paired assets
and typically embed asset correlation within the trading strategy itself,
rather than as an inherent characteristic of the market. Our generalized
lattice market model incorporates both serially correlated returns and asset
correlation through a conditional probabilistic model. In the nominal case,
where the parameters of the model are known, we demonstrate that the proposed
policies ensure survivability and probabilistic positivity. We then derive an
analytic expression for the worst-case expected gain-loss and prove sufficient
conditions that the proposed policies can maintain a \textit{positive expected
profits}, even within a seemingly nonprofitable symmetric lattice market. When
the parameters are unknown and require estimation, we show that the parameter
space of the lattice model forms a convex polyhedron, and we present an
efficient estimation method using a constrained least-squares method. These
theoretical findings are strengthened by extensive empirical studies using data
from the top 30 companies within the S\&P 500 index, substantiating the
efficacy of the generalized model and the robustness of the proposed policies
in sustaining the positive expected profit and providing downside risk
protection.
"
2310.11987,2023-10-19,"A Framework for Treating Model Uncertainty in the Asset Liability
  Management Problem","  The problem of asset liability management (ALM) is a classic problem of the
financial mathematics and of great interest for the banking institutions and
insurance companies. Several formulations of this problem under various model
settings have been studied under the Mean-Variance (MV) principle perspective.
In this paper, the ALM problem is revisited under the context of model
uncertainty in the one-stage framework. In practice, uncertainty issues appear
to several aspects of the problem, e.g. liability process characteristics,
market conditions, inflation rates, inside information effects, etc. A
framework relying on the notion of the Wasserstein barycenter is presented
which is able to treat robustly this type of ambiguities by appropriate
handling the various information sources (models) and appropriately
reformulating the relevant decision making problem. The proposed framework can
be applied to a number of different model settings leading to the selection of
investment portfolios that remain robust to the various uncertainties appearing
in the market. The paper is concluded with a numerical experiment for a static
version of the ALM problem, employing standard modelling approaches,
illustrating the capabilities of the proposed method with very satisfactory
results in retrieving the true optimal strategy even in high noise cases.
"
2310.12333,2023-10-20,Black-Litterman Asset Allocation under Hidden Truncation Distribution,"  In this paper, we study the Black-Litterman (BL) asset allocation model
(Black and Litterman, 1990) under the hidden truncation skew-normal
distribution (Arnold and Beaver, 2000). In particular, when returns are assumed
to follow this skew normal distribution, we show that the posterior returns,
after incorporating views, are also skew normal. By using Simaan three moments
risk model (Simaan, 1993), we could then obtain the optimal portfolio.
Empirical data show that the optimal portfolio obtained this way has less risk
compared to an optimal portfolio of the classical BL model and that they become
more negatively skewed as the expected returns of portfolios increase, which
suggests that the investors trade a negative skewness for a higher expected
return. We also observe a negative relation between portfolio volatility and
portfolio skewness. This observation suggests that investors may be making a
trade-off, opting for lower volatility in exchange for higher skewness, or vice
versa. This trade-off indicates that stocks with significant price declines
tend to exhibit increased volatility.
"
2310.14320,2023-10-24,Analysis of the RMM-01 Market Maker,"  Constant function market makers(CFMMS) are a popular market design for
decentralized exchanges(DEX). Liquidity providers(LPs) supply the CFMMs with
assets to enable trades. In exchange for providing this liquidity, an LP
receives a token that replicates a payoff determined by the trading function
used by the CFMM. In this paper, we study a time-dependent CFMM called RMM-01.
The trading function for RMM-01 is chosen such that LPs recover the payoff of a
Black--Scholes priced covered call. First, we introduce the general framework
for CFMMs. After, we analyze the pricing properties of RMM-01. This includes
the cost of price manipulation and the corresponding implications on arbitrage.
Our first primary contribution is from examining the time-varying price
properties of RMM-01 and determining parameter bounds when RMM-01 has a more
stable price than Uniswap. Finally, we discuss combining lending protocols with
RMM-01 to achieve other option payoffs which is our other primary contribution.
"
2310.14748,2023-10-30,"A Comparative Study of Portfolio Optimization Methods for the Indian
  Stock Market","  This chapter presents a comparative study of the three portfolio optimization
methods, MVP, HRP, and HERC, on the Indian stock market, particularly focusing
on the stocks chosen from 15 sectors listed on the National Stock Exchange of
India. The top stocks of each cluster are identified based on their free-float
market capitalization from the report of the NSE published on July 1, 2022 (NSE
Website). For each sector, three portfolios are designed on stock prices from
July 1, 2019, to June 30, 2022, following three portfolio optimization
approaches. The portfolios are tested over the period from July 1, 2022, to
June 30, 2023. For the evaluation of the performances of the portfolios, three
metrics are used. These three metrics are cumulative returns, annual
volatilities, and Sharpe ratios. For each sector, the portfolios that yield the
highest cumulative return, the lowest volatility, and the maximum Sharpe Ratio
over the training and the test periods are identified.
"
2310.14881,2023-10-24,Topological Portfolio Selection and Optimization,"  Modern portfolio optimization is centered around creating a low-risk
portfolio with extensive asset diversification. Following the seminal work of
Markowitz, optimal asset allocation can be computed using a constrained
optimization model based on empirical covariance. However, covariance is
typically estimated from historical lookback observations, and it is prone to
noise and may inadequately represent future market behavior. As a remedy,
information filtering networks from network science can be used to mitigate the
noise in empirical covariance estimation, and therefore, can bring added value
to the portfolio construction process. In this paper, we propose the use of the
Statistically Robust Information Filtering Network (SR-IFN) which leverages the
bootstrapping techniques to eliminate unnecessary edges during the network
formation and enhances the network's noise reduction capability further. We
apply SR-IFN to index component stock pools in the US, UK, and China to assess
its effectiveness. The SR-IFN network is partially disconnected with isolated
nodes representing lesser-correlated assets, facilitating the selection of
peripheral, diversified and higher-performing portfolios. Further optimization
of performance can be achieved by inversely proportioning asset weights to
their centrality based on the resultant network.
"
2310.19023,2023-10-31,Optimal fees in hedge funds with first-loss compensation,"  Hedge fund managers with the first-loss scheme charge a management fee, a
performance fee and guarantee to cover a certain amount of investors' potential
losses. We study how parties can choose a mutually preferred first-loss scheme
in a hedge fund with the manager's first-loss deposit and investors' assets
segregated. For that, we solve the manager's non-concave utility maximization
problem, calculate Pareto optimal first-loss schemes and maximize a decision
criterion on this set. The traditional 2% management and 20% performance fees
are found to be not Pareto optimal, neither are common first-loss fee
arrangements. The preferred first-loss coverage guarantee is increasing as the
investor's risk-aversion or the interest rate increases. It decreases as the
manager's risk-aversion or the market price of risk increases. The more risk
averse the investor or the higher the interest rate, the larger is the
preferred performance fee. The preferred fee schemes significantly decrease the
fund's volatility.
"
2311.01692,2023-11-06,Benchmark Beating with the Increasing Convex Order,"  In this paper we model benchmark beating with the increasing convex order
(ICX order). The mean constraint in the mean-variance theory of portfolio
selection can be regarded as beating a constant. We then investigate the
problem of minimizing the variance of a portfolio with ICX order constraints,
based on which we also study the problem of beating-performance-variance
efficient portfolios. The optimal and efficient portfolios are all worked out
in closed form for complete markets.
"
2311.02088,2023-11-07,"Combining Deep Learning on Order Books with Reinforcement Learning for
  Profitable Trading","  High-frequency trading is prevalent, where automated decisions must be made
quickly to take advantage of price imbalances and patterns in price action that
forecast near-future movements. While many algorithms have been explored and
tested, analytical methods fail to harness the whole nature of the market
environment by focusing on a limited domain. With the evergrowing machine
learning field, many large-scale end-to-end studies on raw data have been
successfully employed to increase the domain scope for profitable trading but
are very difficult to replicate. Combining deep learning on the order books
with reinforcement learning is one way of breaking down large-scale end-to-end
learning into more manageable and lightweight components for reproducibility,
suitable for retail trading.
  The following work focuses on forecasting returns across multiple horizons
using order flow imbalance and training three temporal-difference learning
models for five financial instruments to provide trading signals. The
instruments used are two foreign exchange pairs (GBPUSD and EURUSD), two
indices (DE40 and FTSE100), and one commodity (XAUUSD). The performances of
these 15 agents are evaluated through backtesting simulation, and successful
models proceed through to forward testing on a retail trading platform. The
results prove potential but require further minimal modifications for
consistently profitable trading to fully handle retail trading costs, slippage,
and spread fluctuation.
"
2311.04475,2023-11-09,Portfolio Construction using Black-Litterman Model and Factors,"  This paper presents a portfolio construction process, including mainly two
parts, Factors Selection and Weight Allocations. For the factors selection
part, We have chosen 20 factors by considering three aspects, the global
market, different assets class, and stock idiosyncratic characteristics. Each
factor is proxied by a corresponding ETF. Then, we would apply several weight
allocation methods to those factors, including two fixed weight allocation
methods, three optimisation methods, and a Black-Litterman model. In addition,
we would also fit a Deep Learning model for generating views periodically and
incorporating views with the prior to achieve dynamically updated weights by
using the Black-Litterman model. In the end, the robustness checking shows how
weights change with respect to time evolving and variance increasing. Results
using shrinkage variance are provided to alleviate the impacts of
representativeness of historical data, but there sadly has little impact.
Overall, the model by using the Deep Learning plus Black-Litterman model
results outperform the portfolio by other weight allocation schemes, even
though further improvement and robustness checking should be performed.
"
2311.04946,2023-11-10,"Causal Inference on Investment Constraints and Non-stationarity in
  Dynamic Portfolio Optimization through Reinforcement Learning","  In this study, we have developed a dynamic asset allocation investment
strategy using reinforcement learning techniques. To begin with, we have
addressed the crucial issue of incorporating non-stationarity of financial time
series data into reinforcement learning algorithms, which is a significant
implementation in the application of reinforcement learning in investment
strategies. Our findings highlight the significance of introducing certain
variables such as regime change in the environment setting to enhance the
prediction accuracy. Furthermore, the application of reinforcement learning in
investment strategies provides a remarkable advantage of setting the
optimization problem flexibly. This enables the integration of practical
constraints faced by investors into the algorithm, resulting in efficient
optimization. Our study has categorized the investment strategy formulation
conditions into three main categories, including performance measurement
indicators, portfolio management rules, and other constraints. We have
evaluated the impact of incorporating these conditions into the environment and
rewards in a reinforcement learning framework and examined how they influence
investment behavior.
"
2311.05781,2023-11-13,Optimal dividend strategies for a catastrophe insurer,"  In this paper we study the problem of optimally paying out dividends from an
insurance portfolio, when the criterion is to maximize the expected discounted
dividends over the lifetime of the company and the portfolio contains claims
due to natural catastrophes, modelled by a shot-noise Cox claim number process.
The optimal value function of the resulting two-dimensional stochastic control
problem is shown to be the smallest viscosity supersolution of a corresponding
Hamilton-Jacobi-Bellman equation, and we prove that it can be uniformly
approximated through a discretization of the space of the free surplus of the
portfolio and the current claim intensity level. We implement the resulting
numerical scheme to identify optimal dividend strategies for such a natural
catastrophe insurer, and it is shown that the nature of the barrier and band
strategies known from the classical models with constant Poisson claim
intensity carry over in a certain way to this more general situation, leading
to action and non-action regions for the dividend payments as a function of the
current surplus and intensity level. We also discuss some interpretations in
terms of upward potential for shareholders when including a catastrophe sector
in the portfolio.
"
2311.06519,2024-02-26,Portfolio diversification with varying investor abilities,"  We introduce new mathematical methods to study the optimal portfolio size of
investment portfolios over time, considering investors with varying skill
levels. First, we explore the benefit of portfolio diversification on an annual
basis for poor, average and strong investors defined by the 10th, 50th and 90th
percentiles of risk-adjusted returns, respectively. Second, we conduct a
thorough regression experiment examining quantiles of risk-adjusted returns as
a function of portfolio size across investor ability, testing for trends and
curvature within these functions. Finally, we study the optimal portfolio size
for poor, average and strong investors in a continuously temporal manner using
more than 20 years of data. We show that strong investors should hold
concentrated portfolios, poor investors should hold diversified portfolios;
average investors have a less obvious distribution with the optimal number
varying materially over time.
"
2311.06665,2024-10-22,Withdrawal Success Optimization,"  For $n$ assets and discrete-time rebalancing, the probability to complete a
given schedule of investments and withdrawals is maximized over progressively
measurable portfolio weight functions. Applications consider two assets, namely
the S&P Composite Index and an inflation-protected bond. The maximum
probability and optimal portfolio weight functions are computed for annually
rebalanced schedules involving an arbitrary initial investment and then equal
annual withdrawals over the remainder of the time period. Applications also
consider annually rebalanced schedules that start with dollar cost averaging
(equal annual investments) and then shift to equal annual withdrawals. Results
indicate noticeable improvements in the probability to complete a given
schedule when optimal portfolio weights are used instead of constant portfolio
weights like the standard of keeping 90% in the S&P Composite Index and 10% in
inflation-protected bonds.
"
2311.06745,2023-11-15,Dynamic portfolio selection for nonlinear law-dependent preferences,"  This paper addresses the portfolio selection problem for nonlinear
law-dependent preferences in continuous time, which inherently exhibit time
inconsistency. Employing the method of stochastic maximum principle, we
establish verification theorems for equilibrium strategies, accommodating both
random market coefficients and incomplete markets. We derive the first-order
condition (FOC) for the equilibrium strategies, using a notion of functional
derivatives with respect to probability distributions. Then, with the help of
the FOC we obtain the equilibrium strategies in closed form for two classes of
implicitly defined preferences: CRRA and CARA betweenness preferences, with
deterministic market coefficients. Finally, to show applications of our
theoretical results to problems with random market coefficients, we examine the
weighted utility. We reveal that the equilibrium strategy can be described by a
coupled system of Quadratic Backward Stochastic Differential Equations
(QBSDEs). The well-posedness of this system is generally open but is
established under the special structures of our problem.
"
2311.07478,2023-11-14,Optimal portfolio allocation with uncertain covariance matrix,"  In this paper, we explore the portfolio allocation problem involving an
uncertain covariance matrix. We calculate the expected value of the Constant
Absolute Risk Aversion (CARA) utility function, marginalized over a
distribution of covariance matrices. We show that marginalization introduces a
logarithmic dependence on risk, as opposed to the linear dependence assumed in
the mean-variance approach. Additionally, it leads to a decrease in the
allocation level for higher uncertainties. Our proposed method extends the
mean-variance approach by considering the uncertainty associated with future
covariance matrices and expected returns, which is important for practical
applications.
"
2311.10713,2023-11-21,Diversifying an Index,"  In July 2023, Nasdaq announced a `Special Rebalance' of the Nasdaq-100 index
to reduce the index weights of its large constituents. A rebalance as suggested
currently by Nasdaq index methodology may have several undesirable effects.
These effects can be avoided by a different, but simple rebalancing strategy.
Such rebalancing is easily computable and guarantees (a) that the maximum
overall index weight does not increase through the rebalancing and (b) that the
order of index weights is preserved.
"
2311.10801,2024-02-28,"Reinforcement Learning with Maskable Stock Representation for Portfolio
  Management in Customizable Stock Pools","  Portfolio management (PM) is a fundamental financial trading task, which
explores the optimal periodical reallocation of capitals into different stocks
to pursue long-term profits. Reinforcement learning (RL) has recently shown its
potential to train profitable agents for PM through interacting with financial
markets. However, existing work mostly focuses on fixed stock pools, which is
inconsistent with investors' practical demand. Specifically, the target stock
pool of different investors varies dramatically due to their discrepancy on
market states and individual investors may temporally adjust stocks they desire
to trade (e.g., adding one popular stocks), which lead to customizable stock
pools (CSPs). Existing RL methods require to retrain RL agents even with a tiny
change of the stock pool, which leads to high computational cost and unstable
performance. To tackle this challenge, we propose EarnMore, a rEinforcement
leARNing framework with Maskable stOck REpresentation to handle PM with CSPs
through one-shot training in a global stock pool (GSP). Specifically, we first
introduce a mechanism to mask out the representation of the stocks outside the
target pool. Second, we learn meaningful stock representations through a
self-supervised masking and reconstruction process. Third, a re-weighting
mechanism is designed to make the portfolio concentrate on favorable stocks and
neglect the stocks outside the target pool. Through extensive experiments on 8
subset stock pools of the US stock market, we demonstrate that EarnMore
significantly outperforms 14 state-of-the-art baselines in terms of 6 popular
financial metrics with over 40% improvement on profit.
"
2311.12169,2023-11-22,Optimal Retirement Choice under Age-dependent Force of Mortality,"  This paper examines the retirement decision, optimal investment, and
consumption strategies under an age-dependent force of mortality. We formulate
the optimization problem as a combined stochastic control and optimal stopping
problem with a random time horizon, featuring three state variables: wealth,
labor income, and force of mortality. To address this problem, we transform it
into its dual form, which is a finite time horizon, three-dimensional
degenerate optimal stopping problem with interconnected dynamics. We establish
the existence of an optimal retirement boundary that splits the state space
into continuation and stopping regions. Regularity of the optimal stopping
value function is derived and the boundary is proved to be Lipschitz
continuous, and it is characterized as the unique solution to a nonlinear
integral equation, which we compute numerically. In the original coordinates,
the agent thus retires whenever her wealth exceeds an age-, labor income- and
mortality-dependent transformed version of the optimal stopping boundary. We
also provide numerical illustrations of the optimal strategies, including the
sensitivities of the optimal retirement boundary concerning the relevant
model's parameters.
"
2311.12183,2024-04-11,Optimal Transport Divergences induced by Scoring Functions,"  We employ scoring functions, used in statistics for eliciting risk
functionals, as cost functions in the Monge-Kantorovich (MK) optimal transport
problem. This gives raise to a rich variety of novel asymmetric MK divergences,
which subsume the family of Bregman-Wasserstein divergences. We show that for
distributions on the real line, the comonotonic coupling is optimal for the
majority of the new divergences. Specifically, we derive the optimal coupling
of the MK divergences induced by functionals including the mean, generalised
quantiles, expectiles, and shortfall measures. Furthermore, we show that while
any elicitable law-invariant coherent risk measure gives raise to infinitely
many MK divergences, the comonotonic coupling is simultaneously optimal.
  The novel MK divergences, which can be efficiently calculated, open an array
of applications in robust stochastic optimisation. We derive sharp bounds on
distortion risk measures under a Bregman-Wasserstein divergence constraint, and
solve for cost-efficient payoffs under benchmark constraints.
"
2311.12450,2024-03-15,Hedging carbon risk with a network approach,"  Sustainable investing refers to the integration of environmental and social
aspects in investors' decisions. We propose a novel methodology based on the
Triangulated Maximally Filtered Graph and node2vec algorithms to construct an
hedging portfolio for climate risk, represented by various risk factors, among
which the CO2 and the ESG ones. The CO2 factor is strongly correlated
consistently over time with the Utility sector, which is the most carbon
intensive in the S&P 500 index. Conversely, identifying a group of sectors
linked to the ESG factor proves challenging. As a consequence, while it is
possible to obtain an efficient hedging portfolio strategy with our methodology
for the carbon factor, the same cannot be achieved for the ESG one. The ESG
scores appears to be an indicator too broadly defined for market applications.
These results support the idea that bank capital requirements should take into
account carbon risk.
"
2311.12517,2023-12-20,"Optimal Portfolio with Ratio Type Periodic Evaluation under
  Short-Selling Prohibition","  This paper studies some unconventional utility maximization problems when the
ratio type relative portfolio performance is periodically evaluated over an
infinite horizon. Meanwhile, the agent is prohibited from short-selling stocks.
Our goal is to understand the impact of the periodic reward structure on the
long-run constrained portfolio strategy. For power and logarithmic utilities,
we can reformulate the original problem into an auxiliary one-period
optimization problem. To cope with the auxiliary problem with no short-selling,
the dual control problem is introduced and studied, which gives the
characterization of the candidate optimal portfolio within one period. With the
help of the results from the auxiliary problem, the value function and the
optimal constrained portfolio for the original problem with periodic evaluation
can be derived and verified, allowing us to discuss some financial implications
under the new performance paradigm.
"
2311.13326,2024-01-17,"Curriculum Learning and Imitation Learning for Model-free Control on
  Financial Time-series","  Curriculum learning and imitation learning have been leveraged extensively in
the robotics domain. However, minimal research has been done on leveraging
these ideas on control tasks over highly stochastic time-series data. Here, we
theoretically and empirically explore these approaches in a representative
control task over complex time-series data. We implement the fundamental ideas
of curriculum learning via data augmentation, while imitation learning is
implemented via policy distillation from an oracle. Our findings reveal that
curriculum learning should be considered a novel direction in improving
control-task performance over complex time-series. Our ample random-seed
out-sample empirics and ablation studies are highly encouraging for curriculum
learning for time-series control. These findings are especially encouraging as
we tune all overlapping hyperparameters on the baseline -- giving an advantage
to the baseline. On the other hand, we find that imitation learning should be
used with caution.
"
2311.13564,2024-06-21,High order universal portfolios,"  The Cover universal portfolio (UP from now on) has many interesting
theoretical and numerical properties and was investigated for a long time.
Building on it, we explore what happens when we add this UP to the market as a
new synthetic asset and construct by recurrence higher order UPs. We
investigate some important theoretical properties of the high order UPs and
show in particular that they are indeed different from the Cover UP and are
capable to break the time permutation invariance. We show that under some
perturbation regime the second high order UP has better Sharp ratio than the
standard UP and briefly investigate arbitrage opportunities thus created.
Numerical experiences on a benchmark from the literature confirm that high
order UPs improve Cover's UP performances.
"
2311.14318,2024-11-01,"On optimal tracking portfolio in incomplete markets: The reinforcement
  learning approach","  This paper studies an infinite horizon optimal tracking portfolio problem
using capital injection in incomplete market models. The benchmark process is
modelled by a geometric Brownian motion with zero drift driven by some
unhedgeable risk. The relaxed tracking formulation is adopted where the fund
account compensated by the injected capital needs to outperform the benchmark
process at any time, and the goal is to minimize the cost of the discounted
total capital injection. When model parameters are known, we formulate the
equivalent auxiliary control problem with reflected state dynamics, for which
the classical solution of the HJB equation with Neumann boundary condition is
obtained explicitly. When model parameters are unknown, we introduce the
exploratory formulation for the auxiliary control problem with entropy
regularization and develop the continuous-time q-learning algorithm in models
of reflected diffusion processes. In some illustrative numerical example, we
show the satisfactory performance of the q-learning algorithm.
"
2311.15247,2023-11-28,"Information Content of Financial Youtube Channel: Case Study of 3PROTV
  and Korean Stock Market","  We investigate the information content of 3PROTV, a south Korean financial
youtube channel. In our sample we found evidence for the hypothesis that the
channel have information content on stock selection, but only on negative
sentiment. Positively mentioned stock had pre-announcement spike followed by
steep fall in stock price around announcement period. Negatively mentioned
stock started underperforming around the announcement period, with
underreaction dynamics in post-announcement period. In the area of market
timing, we found that change of sentimental tone of 3PROTV than its historical
average predicts the lead value of Korean market portfolio return. Its
predictive power cannot be explained by future change in news sentiment, future
short term interest rate, and future liquidity risk.
"
2311.15635,2024-12-25,"Discretization of continuous-time arbitrage strategies in financial
  markets with fractional Brownian motion","  This study evaluates the practical usefulness of continuous-time arbitrage
strategies designed to exploit serial correlation in fractional financial
markets. Specifically, we revisit the strategies of Shiryaev (1998) and Salopek
(1998) and transfer them to a real-world setting by distretizing their dynamics
and introducing transaction costs. In Monte Carlo simulations with various
market and trading parameter settings as well as a formal analysis of
discretization error, we show that both are promising with respect to terminal
portfolio values and loss probabilities. These features and complementary
sparsity make them worth serious consideration in the toolkit of quantitative
investors.
"
2311.16204,2023-11-29,Planning for the Efficient Updating of Mutual Fund Portfolios,"  Once there is a decision of rebalancing or updating a portfolio of funds, the
process of changing the current portfolio to the target one, involves a set of
transactions that are susceptible of being optimized. This is particularly
relevant when managers have to handle the implications of different types of
instruments. In this work we present linear programming and heuristic search
approaches that produce plans for executing the update. The evaluation of our
proposals shows cost improvements over the compared based strategy. The models
can be easily extended to other realistic scenarios in which a holistic
portfolio management is required
"
2312.00033,2023-12-04,DeFi Security: Turning The Weakest Link Into The Strongest Attraction,"  The primary innovation we pioneer -- focused on blockchain information
security -- is called the Safe-House. The Safe-House is badly needed since
there are many ongoing hacks and security concerns in the DeFi space right now.
The Safe-House is a piece of engineering sophistication that utilizes existing
blockchain principles to bring about greater security when customer assets are
moved around. The Safe-House logic is easily implemented as smart contracts on
any decentralized system. The amount of funds at risk from both internal and
external parties -- and hence the maximum one time loss -- is guaranteed to
stay within the specified limits based on cryptographic fundamentals.
  To improve the safety of the Safe-House even further, we adapt the one time
password (OPT) concept to operate using blockchain technology. Well suited to
blockchain cryptographic nuances, our secondary advancement can be termed the
one time next time password (OTNTP) mechanism. The OTNTP is designed to
complement the Safe-House making it even more safe.
  We provide a detailed threat assessment model -- discussing the risks faced
by DeFi protocols and the specific risks that apply to blockchain fund
management -- and give technical arguments regarding how these threats can be
overcome in a robust manner. We discuss how the Safe-House can participate with
other external yield generation protocols in a secure way. We provide reasons
for why the Safe-House increases safety without sacrificing the efficiency of
operation. We start with a high level intuitive description of the landscape,
the corresponding problems and our solutions. We then supplement this overview
with detailed discussions including the corresponding mathematical formulations
and pointers for technological implementation. This approach ensures that the
article is accessible to a broad audience.
"
2312.00202,2024-01-09,Investigate The ESG Score Methodology,"  Whether the Refinitiv provide a reliable and trusted methodology in the
process of aggregating 10 category scores to overall score?
"
2312.01668,2023-12-05,Optimal dividend payout with path-dependent drawdown constraint,"  This paper studies an optimal dividend payout problem with drawdown
constraint in a Brownian motion model, where the dividend payout rate must be
no less than a fixed proportion of its historical running maximum. It is a
stochastic control problem, where the admissible control depends on its past
values, thus is path-dependent. The related Hamilton-Jacobi-Bellman equation
turns out to be a new type of two-dimensional variational inequality with
gradient constraint, which has only been studied by viscosity solution
technique in the literature. In this paper, we use delicate PDE methods to
obtain a strong solution. Different from the viscosity solution, based on our
solution, we succeed in deriving an optimal feedback payout strategy, which is
expressed in terms of two free boundaries and the running maximum surplus
process. Furthermore, we have obtained many properties of the value function
and the free boundaries such as the boundedness, continuity etc. Numerical
examples are presented as well to verify our theoretical results and give some
new but not proved financial insights.
"
2312.02943,2023-12-24,"Striking the Balance: Life Insurance Timing and Asset Allocation in
  Financial Planning","  This paper investigates the consumption and investment decisions of an
individual facing uncertain lifespan and stochastic labor income within a
Black-Scholes market framework. A key aspect of our study involves the agent's
option to choose when to acquire life insurance for bequest purposes. We
examine two scenarios: one with a fixed bequest amount and another with a
controlled bequest amount. Applying duality theory and addressing free-boundary
problems, we analytically solve both cases, and provide explicit expressions
for value functions and optimal strategies in both cases. In the first
scenario, where the bequest amount is fixed, distinct outcomes emerge based on
different levels of risk aversion parameter $\gamma$: (i) the optimal time for
life insurance purchase occurs when the agent's wealth surpasses a critical
threshold if $\gamma \in (0,1)$, or (ii) life insurance should be acquired
immediately if $\gamma>1$. In contrast, in the second scenario with a
controlled bequest amount, regardless of $\gamma$ values, immediate life
insurance purchase proves to be optimal.
"
2312.03294,2023-12-07,"A General Framework for Portfolio Construction Based on Generative
  Models of Asset Returns","  In this paper, we present an integrated approach to portfolio construction
and optimization, leveraging high-performance computing capabilities. We first
explore diverse pairings of generative model forecasts and objective functions
used for portfolio optimization, which are evaluated using
performance-attribution models based on LASSO. We illustrate our approach using
extensive simulations of crypto-currency portfolios, and we show that the
portfolios constructed using the vine-copula generative model and the
Sharpe-ratio objective function consistently outperform. To accommodate a wide
array of investment strategies, we further investigate portfolio blending and
propose a general framework for evaluating and combining investment strategies.
We employ an extension of the multi-armed bandit framework and use value models
and policy models to construct eclectic blended portfolios based on past
performance. We consider similarity and optimality measures for value models
and employ probability-matching (""blending"") and a greedy algorithm
(""switching"") for policy models. The eclectic portfolios are also evaluated
using LASSO models. We show that the value model utilizing cosine similarity
and logit optimality consistently delivers robust superior performances. The
extent of outperformance by eclectic portfolios over their benchmarks
significantly surpasses that achieved by individual generative model-based
portfolios over their respective benchmarks.
"
2312.05169,2023-12-11,Onflow: an online portfolio allocation algorithm,"  We introduce Onflow, a reinforcement learning technique that enables online
optimization of portfolio allocation policies based on gradient flows. We
devise dynamic allocations of an investment portfolio to maximize its expected
log return while taking into account transaction fees. The portfolio allocation
is parameterized through a softmax function, and at each time step, the
gradient flow method leads to an ordinary differential equation whose solutions
correspond to the updated allocations. This algorithm belongs to the large
class of stochastic optimization procedures; we measure its efficiency by
comparing our results to the mathematical theoretical values in a log-normal
framework and to standard benchmarks from the 'old NYSE' dataset. For
log-normal assets, the strategy learned by Onflow, with transaction costs at
zero, mimics Markowitz's optimal portfolio and thus the best possible asset
allocation strategy. Numerical experiments from the 'old NYSE' dataset show
that Onflow leads to dynamic asset allocation strategies whose performances
are: a) comparable to benchmark strategies such as Cover's Universal Portfolio
or Helmbold et al. ""multiplicative updates"" approach when transaction costs are
zero, and b) better than previous procedures when transaction costs are high.
Onflow can even remain efficient in regimes where other dynamical allocation
techniques do not work anymore. Therefore, as far as tested, Onflow appears to
be a promising dynamic portfolio management strategy based on observed prices
only and without any assumption on the laws of distributions of the underlying
assets' returns. In particular it could avoid model risk when building a
trading strategy.
"
2312.07733,2023-12-14,Least-Cost Structuring of 24/7 Carbon-Free Electricity Procurements,"  We consider the construction of renewable portfolios targeting specified
carbon-free (CFE) hourly performance scores. We work in a probabilistic
framework that uses a collection of simulation scenarios and imposes
probability constraints on achieving the desired CFE score. In our approach
there is a fixed set of available CFE generators and a given load customer who
seeks to minimize annual procurement costs. We illustrate results using a
realistic dataset of jointly calibrated solar and wind assets, and compare
different approaches to handling multiple loads.
"
2312.09707,2023-12-18,A return-diversification approach to portfolio selection,"  In this paper, we propose a general bi-objective model for portfolio
selection, aiming to maximize both a diversification measure and the portfolio
expected return. Within this general framework, we focus on maximizing a
diversification measure recently proposed by Choueifaty and Coignard for the
case of volatility as a risk measure. We first show that the maximum
diversification approach is actually equivalent to the Risk Parity approach
using volatility under the assumption of equicorrelated assets. Then, we extend
the maximum diversification approach formulated for general risk measures.
Finally, we provide explicit formulations of our bi-objective model for
different risk measures, such as volatility, Mean Absolute Deviation,
Conditional Value-at-Risk, and Expectiles, and we present extensive
out-of-sample performance results for the portfolios obtained with our model.
The empirical analysis, based on five real-world data sets, shows that the
return-diversification approach provides portfolios that tend to outperform the
strategies based only on a diversification method or on the classical
risk-return approach.
"
2312.10739,2023-12-19,Managing ESG Ratings Disagreement in Sustainable Portfolio Selection,"  Sustainable Investing identifies the approach of investors whose aim is
twofold: on the one hand, they want to achieve the best compromise between
portfolio risk and return, but they also want to take into account the
sustainability of their investment, assessed through some Environmental,
Social, and Governance (ESG) criteria. The inclusion of sustainable goals in
the portfolio selection process may have an actual impact on financial
portfolio performance. ESG indices provided by the rating agencies are
generally considered good proxies for the performance in sustainability of an
investment, as well as, appropriate measures for Socially Responsible
Investments (SRI) in the market. In this framework of analysis, the lack of
alignment between ratings provided by different agencies is a crucial issue
that inevitably undermines the robustness and reliability of these evaluation
measures. In fact, the ESG rating disagreement may produce conflicting
information, implying a difficulty for the investor in the portfolio ESG
evaluation. This may cause underestimation or overestimation of the market
opportunities for a sustainable investment. In this paper, we deal with a
multi-criteria portfolio selection problem taking into account risk, return,
and ESG criteria. For the ESG evaluation of the securities in the market, we
consider more than one agency and propose a new approach to overcome the
problem related to the disagreement between the ESG ratings by different
agencies. We propose a nonlinear optimization model for our three-criteria
portfolio selection problem. We show that it can be reformulated as an
equivalent convex quadratic program by exploiting a technique known in the
literature as the k-sum optimization strategy. An extensive empirical analysis
of the performance of this model is provided on real-world financial data sets.
"
2312.10749,2023-12-19,"A new behavioral model for portfolio selection using the
  Half-Full/Half-Empty approach","  We focus on a behavioral model, that has been recently proposed in the
literature, whose rational can be traced back to the Half-Full/Half-Empty glass
metaphor. More precisely, we generalize the Half-Full/Half-Empty approach to
the context of positive and negative lotteries and give financial and
behavioral interpretations of the Half-Full/Half-Empty parameters. We develop a
portfolio selection model based on the Half-Full/Half-Empty strategy, resulting
in a nonconvex optimization problem, which, nonetheless, is proven to be
equivalent to an alternative Mixed-Integer Linear Programming formulation. By
means of the ensuing empirical analysis, based on three real-world datasets,
the Half-Full/Half-Empty model is shown to be very versatile by appropriately
varying its parameters, and to provide portfolios displaying promising
performances in terms of risk and profitability, compared with Prospect Theory,
risk minimization approaches and Equally-Weighted portfolios.
"
2312.11132,2024-05-28,Asset and Factor Risk Budgeting: A Balanced Approach,"  Portfolio optimization methods have evolved significantly since Markowitz
introduced the mean-variance framework in 1952. While the theoretical appeal of
this approach is undeniable, its practical implementation poses important
challenges, primarily revolving around the intricate task of estimating
expected returns. As a result, practitioners and scholars have explored
alternative methods that prioritize risk management and diversification. One
such approach is Risk Budgeting, where portfolio risk is allocated among assets
according to predefined risk budgets. The effectiveness of Risk Budgeting in
achieving true diversification can, however, be questioned, given that asset
returns are often influenced by a small number of risk factors. From this
perspective, one question arises: is it possible to allocate risk at the factor
level using the Risk Budgeting approach? First, we introduce a comprehensive
framework to address this question by introducing risk measures directly
associated with risk factor exposures and demonstrating the desirable
mathematical properties of these risk measures, making them suitable for
optimization. Then, we propose a novel framework to find portfolios that
effectively balance the risk contributions from both assets and factors.
Leveraging standard stochastic algorithms, our framework enables the use of a
wide range of risk measures to construct diversified portfolios.
"
2312.11797,2025-05-09,Data-Driven Merton's Strategies via Policy Randomization,"  We study Merton's expected utility maximization problem in an incomplete
market, characterized by a factor process in addition to the stock price
process, where all the model primitives are unknown. The agent under
consideration is a price taker who has access only to the stock and factor
value processes and the instantaneous volatility. We propose an auxiliary
problem in which the agent can invoke policy randomization according to a
specific class of Gaussian distributions, and prove that the mean of its
optimal Gaussian policy solves the original Merton problem. With randomized
policies, we are in the realm of continuous-time reinforcement learning (RL)
recently developed in Wang et al. (2020) and Jia and Zhou (2022a, 2022b, 2023),
enabling us to solve the auxiliary problem in a data-driven way without having
to estimate the model primitives. Specifically, we establish a policy
improvement theorem based on which we design both online and offline
actor-critic RL algorithms for learning Merton's strategies. A key insight from
this study is that RL in general and policy randomization in particular are
useful beyond the purpose for exploration -- they can be employed as a
technical tool to solve a problem that cannot be otherwise solved by mere
deterministic policies. At last, we carry out both simulation and empirical
studies in a stochastic volatility environment to demonstrate the decisive
outperformance of the devised RL algorithms in comparison to the conventional
model-based, plug-in method.
"
2312.13057,2024-11-27,"Cross-Currency Heath-Jarrow-Morton Framework in the Multiple-Curve
  Setting","  We provide a general HJM framework for forward contracts written on abstract
market indices with arbitrary fixing and payment adjustments, and featuring
collateralization in any currency denominations. In view of this, we first
provide a thorough study of cross-currency markets in the presence of
collateral and incompleteness. Then we give a general treatment of collateral
dislocations by describing the instantaneous cross-currency basis spreads by
means of HJM models, for which we derive appropriate drift conditions. The
framework obtained allows us to simultaneously cover forward-looking risky IBOR
rates, such as EURIBOR, and backward-looking rates based on overnight rates,
such as SOFR. Due to the discrepancies in market conventions of different
currency areas created by the benchmark transition, this is pivotal for
describing portfolios of interest-rate products that are denominated in
multiple currencies. As an example of contract simultaneously depending on all
the risk factors that we describe within our framework, we treat cross-currency
swaps using our proposed abstract indices.
"
2312.13719,2024-07-09,Market-Adaptive Ratio for Portfolio Management,"  Traditional risk-adjusted returns, such as the Treynor, Sharpe, Sortino, and
Information ratios, have been pivotal in portfolio asset allocation, focusing
on minimizing risk while maximizing profit. Nevertheless, these metrics often
fail to account for the distinct characteristics of bull and bear markets,
leading to sub-optimal investment decisions. This paper introduces a novel
approach called the Market-adaptive Ratio, which was designed to adjust risk
preferences dynamically in response to market conditions. By integrating the
$\rho$ parameter, which differentiates between bull and bear markets, this new
ratio enables a more adaptive portfolio management strategy. The $\rho$
parameter is derived from historical data and implemented within a
reinforcement learning framework, allowing the method to learn and optimize
portfolio allocations based on prevailing market trends. Empirical analysis
showed that the Market-adaptive Ratio outperformed the Sharpe Ratio by
providing more robust risk-adjusted returns tailored to the specific market
environment. This advance enhances portfolio performance by aligning investment
strategies with the inherent dynamics of bull and bear markets, optimizing risk
and return outcomes.
"
2312.14203,2023-12-25,Shai: A large language model for asset management,"  This paper introduces ""Shai"" a 10B level large language model specifically
designed for the asset management industry, built upon an open-source
foundational model. With continuous pre-training and fine-tuning using a
targeted corpus, Shai demonstrates enhanced performance in tasks relevant to
its domain, outperforming baseline models. Our research includes the
development of an innovative evaluation framework, which integrates
professional qualification exams, tailored tasks, open-ended question
answering, and safety assessments, to comprehensively assess Shai's
capabilities. Furthermore, we discuss the challenges and implications of
utilizing large language models like GPT-4 for performance assessment in asset
management, suggesting a combination of automated evaluation and human
judgment. Shai's development, showcasing the potential and versatility of
10B-level large language models in the financial sector with significant
performance and modest computational requirements, hopes to provide practical
insights and methodologies to assist industry peers in their similar endeavors.
"
2312.15385,2023-12-27,Discrete-Time Mean-Variance Strategy Based on Reinforcement Learning,"  This paper studies a discrete-time mean-variance model based on reinforcement
learning. Compared with its continuous-time counterpart in \cite{zhou2020mv},
the discrete-time model makes more general assumptions about the asset's return
distribution. Using entropy to measure the cost of exploration, we derive the
optimal investment strategy, whose density function is also Gaussian type.
Additionally, we design the corresponding reinforcement learning algorithm.
Both simulation experiments and empirical analysis indicate that our
discrete-time model exhibits better applicability when analyzing real-world
data than the continuous-time model.
"
2312.16448,2023-12-29,Randomized Signature Methods in Optimal Portfolio Selection,"  We present convincing empirical results on the application of Randomized
Signature Methods for non-linear, non-parametric drift estimation for a
multi-variate financial market. Even though drift estimation is notoriously ill
defined due to small signal to noise ratio, one can still try to learn optimal
non-linear maps from data to future returns for the purposes of portfolio
optimization. Randomized Signatures, in contrast to classical signatures, allow
for high dimensional market dimension and provide features on the same scale.
We do not contribute to the theory of Randomized Signatures here, but rather
present our empirical findings on portfolio selection in real world settings
including real market data and transaction costs.
"
2401.00001,2024-01-02,Sector Rotation by Factor Model and Fundamental Analysis,"  This study presents an analytical approach to sector rotation, leveraging
both factor models and fundamental metrics. We initiate with a systematic
classification of sectors, followed by an empirical investigation into their
returns. Through factor analysis, the paper underscores the significance of
momentum and short-term reversion in dictating sectoral shifts. A subsequent
in-depth fundamental analysis evaluates metrics such as PE, PB, EV-to-EBITDA,
Dividend Yield, among others. Our primary contribution lies in developing a
predictive framework based on these fundamental indicators. The constructed
models, post rigorous training, exhibit noteworthy predictive capabilities. The
findings furnish a nuanced understanding of sector rotation strategies, with
implications for asset management and portfolio construction in the financial
domain.
"
2401.00103,2024-01-02,"Representation of forward performance criteria with random endowment via
  FBSDE and application to forward optimized certainty equivalent","  We extend the notion of forward performance criteria to settings with random
endowment in incomplete markets. Building on these results, we introduce and
develop the novel concept of forward optimized certainty equivalent (forward
OCE), which offers a genuinely dynamic valuation mechanism that accommodates
progressively adaptive market model updates, stochastic risk preferences, and
incoming claims with arbitrary maturities.
  In parallel, we develop a new methodology to analyze the emerging stochastic
optimization problems by directly studying the candidate optimal control
processes for both the primal and dual problems. Specifically, we derive two
new systems of forward-backward stochastic differential equations (FBSDEs) and
establish necessary and sufficient conditions for optimality, and various
equivalences between the two problems. This new approach is general and
complements the existing one based on backward stochastic partial differential
equations (backward SPDEs) for the related value functions. We, also, consider
representative examples for both forward performance criteria with random
endowment and forward OCE, and for the case of exponential criteria, we
investigate the connection between forward OCE and forward entropic risk
measures.
"
2401.00188,2024-01-02,Enhancing CVaR portfolio optimisation performance with GAM factor models,"  We propose a discrete-time econometric model that combines autoregressive
filters with factor regressions to predict stock returns for portfolio
optimisation purposes. In particular, we test both robust linear regressions
and general additive models on two different investment universes composed of
the Dow Jones Industrial Average and the Standard & Poor's 500 indexes, and we
compare the out-of-sample performances of mean-CVaR optimal portfolios over a
horizon of six years. The results show a substantial improvement in portfolio
performances when the factor model is estimated with general additive models.
"
2401.00507,2024-01-02,"Optimization of portfolios with cryptocurrencies: Markowitz and
  GARCH-Copula model approach","  The growing interest in cryptocurrencies has drawn the attention of the
financial world to this innovative medium of exchange. This study aims to
explore the impact of cryptocurrencies on portfolio performance. We conduct our
analysis retrospectively, assessing the performance achieved within a specific
time frame by three distinct portfolios: one consisting solely of equities,
bonds, and commodities; another composed exclusively of cryptocurrencies; and a
third, which combines both 'traditional' assets and the best-performing
cryptocurrency from the second portfolio.To achieve this, we employ the classic
variance-covariance approach, utilizing the GARCH-Copula and GARCH-Vine Copula
methods to calculate the risk structure. The optimal asset weights within the
optimized portfolios are determined through the Markowitz optimization problem.
Our analysis predominantly reveals that the portfolio comprising both
cryptocurrency and traditional assets exhibits a higher Sharpe ratio from a
retrospective viewpoint and demonstrates more stable performances from a
prospective perspective. We also provide an explanation for our choice of
portfolio optimization based on the Markowitz approach rather than CVaR and ES.
"
2401.00949,2024-02-01,A Portfolio's Common Causal Conditional Risk-neutral PDE,"  Portfolio's optimal drivers for diversification are common causes of the
constituents' correlations. A closed-form formula for the conditional
probability of the portfolio given its optimal common drivers is presented,
with each pair constituent-common driver joint distribution modelled by
Gaussian copulas. A conditional risk-neutral PDE is obtained for this
conditional probability as a system of copulas' PDEs, allowing for dynamical
risk management of a portfolio as shown in the experiments. Implied conditional
portfolio volatilities and implied weights are new risk metrics that can be
dynamically monitored from the PDEs or obtained from their solution.
"
2401.00970,2024-02-07,Almost Perfect Shadow Prices,"  Shadow prices simplify the derivation of optimal trading strategies in
markets with transaction costs by transferring optimization into a more
tractable, frictionless market. This paper establishes that a na\""ive shadow
price Ansatz for maximizing long term returns given average volatility yields a
strategy that is, for small bid-ask-spreads, asymptotically optimal at third
order. Considering the second-order impact of transaction costs, such a
strategy is essentially optimal. However, for risk aversion different from one,
we devise alternative strategies that outperform the shadow market at fourth
order. Finally, it is shown that the risk-neutral objective rules out the
existence of shadow prices.
"
2401.02601,2024-01-08,"Constrained Max Drawdown: a Fast and Robust Portfolio Optimization
  Approach","  We propose an alternative linearization to the classical Markowitz quadratic
portfolio optimization model, based on maximum drawdown. This model, which
minimizes maximum portfolio drawdown, is particularly appealing during times of
financial distress, like during the COVID-19 pandemic. In addition, we will
present a Mixed-Integer Linear Programming variation of our new model that,
based on our out-of-sample results and sensitivity analysis, delivers a more
profitable and robust solution with a 200 times faster solving time compared to
the standard Markowitz quadratic formulation.
"
2401.05080,2024-01-11,Markowitz Portfolio Construction at Seventy,"  More than seventy years ago Harry Markowitz formulated portfolio construction
as an optimization problem that trades off expected return and risk, defined as
the standard deviation of the portfolio returns. Since then the method has been
extended to include many practical constraints and objective terms, such as
transaction cost or leverage limits. Despite several criticisms of Markowitz's
method, for example its sensitivity to poor forecasts of the return statistics,
it has become the dominant quantitative method for portfolio construction in
practice. In this article we describe an extension of Markowitz's method that
addresses many practical effects and gracefully handles the uncertainty
inherent in return statistics forecasting. Like Markowitz's original
formulation, the extension is also a convex optimization problem, which can be
solved with high reliability and speed.
"
2401.05264,2024-01-11,"Comparison of Markowitz Model and Single-Index Model on Portfolio
  Selection of Malaysian Stocks","  Our article is focused on the application of Markowitz Portfolio Theory and
the Single Index Model on 10-year historical monthly return data for 10 stocks
included in FTSE Bursa Malaysia KLCI, which is also our market index, as well
as a risk-free asset which is the monthly fixed deposit rate. We will calculate
the minimum variance portfolio and maximum Sharpe portfolio for both the
Markowitz model and Single Index model subject to five different constraints,
with the results presented in the form of tables and graphs such that
comparisons between the different models and constraints can be made. We hope
this article will help provide useful information for future investors who are
interested in the Malaysian stock market and would like to construct an
efficient investment portfolio. Keywords: Markowitz Portfolio Theory, Single
Index Model, FTSE Bursa Malaysia KLCI, Efficient Portfolio
"
2401.07183,2024-07-16,"Optimal Investment with Herd Behaviour Using Rational Decision
  Decomposition","  In this paper, we study the optimal investment problem considering the herd
behaviour between two agents, including one leading expert and one following
agent whose decisions are influenced by those of the leading expert. In the
objective functional of the optimal investment problem, we introduce the
average deviation term to measure the distance between the two agents'
decisions and use the variational method to find its analytical solution. To
theoretically analyze the impact of the following agent's herd behaviour on
his/her decision, we decompose his/her optimal decision into a convex linear
combination of the two agents' rational decisions, which we call the rational
decision decomposition. Furthermore, we define the weight function in the
rational decision decomposition as the following agent's investment opinion to
measure the preference of his/her own rational decision over that of the
leading expert. We use the investment opinion to quantitatively analyze the
impact of the herd behaviour, the following agent's initial wealth, the excess
return, and the volatility of the risky asset on the optimal decision. We
validate our analyses through numerical experiments on real stock data. This
study is crucial to understanding investors' herd behaviour in decision-making
and designing effective mechanisms to guide their decisions.
"
2401.08323,2024-03-05,Dynamic portfolio selection under generalized disappointment aversion,"  This paper addresses the continuous-time portfolio selection problem under
generalized disappointment aversion (GDA). The implicit definition of the
certainty equivalent within GDA preferences introduces time inconsistency to
this problem. We provide the sufficient and necessary condition for a strategy
to be an equilibrium by a fully nonlinear integral equation. Investigating the
existence and uniqueness of the solution to the integral equation, we establish
the existence and uniqueness of the equilibrium. Our findings indicate that
under disappointment aversion preferences, non-participation in the stock
market is the unique equilibrium. The semi-analytical equilibrium strategies
obtained under the constant relative risk aversion utility functions reveal
that, under GDA preferences, the investment proportion in the stock market
consistently remains smaller than the investment proportion under classical
expected utility theory. The numerical analysis shows that the equilibrium
strategy's monotonicity concerning the two parameters of GDA preference aligns
with the monotonicity of the degree of risk aversion.
"
2401.12669,2024-01-24,"New approximate stochastic dominance approaches for Enhanced Indexation
  models","  In this paper, we discuss portfolio selection strategies for Enhanced
Indexation (EI), which are based on stochastic dominance relations. The goal is
to select portfolios that stochastically dominate a given benchmark but that,
at the same time, must generate some excess return with respect to a benchmark
index. To achieve this goal, we propose a new methodology that selects
portfolios using the ordered weighted average (OWA) operator, which generalizes
previous approaches based on minimax selection rules and still leads to solving
linear programming models. We also introduce a new type of approximate
stochastic dominance rule and show that it implies the almost Second-order
Stochastic Dominance (SSD) criterion proposed by Lizyayev and Ruszczynski
(2012). We prove that our EI model based on OWA selects portfolios that
dominate a given benchmark through this new form of stochastic dominance
criterion. We test the performance of the obtained portfolios in an extensive
empirical analysis based on real-world datasets. The computational results show
that our proposed approach outperforms several SSD-based strategies widely used
in the literature, as well as the global minimum variance portfolio.
"
2401.14672,2024-01-29,"Optimal portfolio under ratio-type periodic evaluation in incomplete
  markets with stochastic factors","  This paper studies a type of periodic utility maximization for portfolio
management in an incomplete market model, where the underlying price diffusion
process depends on some external stochastic factors. The portfolio performance
is periodically evaluated on the relative ratio of two adjacent wealth levels
over an infinite horizon. For both power and logarithmic utilities, we
formulate the auxiliary one-period optimization problems with modified utility
functions, for which we develop the martingale duality approach to establish
the existence of the optimal portfolio processes and the dual minimizers can be
identified as the ""least favorable"" completion of the market. With the help of
the duality results in the auxiliary problems and some fixed point arguments,
we further derive and verify the optimal portfolio processes in a periodic
manner for the original periodic evaluation problems over an infinite horizon.
"
2401.15139,2024-01-31,"FDR-Controlled Portfolio Optimization for Sparse Financial Index
  Tracking","  In high-dimensional data analysis, such as financial index tracking or
biomedical applications, it is crucial to select the few relevant variables
while maintaining control over the false discovery rate (FDR). In these
applications, strong dependencies often exist among the variables (e.g., stock
returns), which can undermine the FDR control property of existing methods like
the model-X knockoff method or the T-Rex selector. To address this issue, we
have expanded the T-Rex framework to accommodate overlapping groups of highly
correlated variables. This is achieved by integrating a nearest neighbors
penalization mechanism into the framework, which provably controls the FDR at
the user-defined target level. A real-world example of sparse index tracking
demonstrates the proposed method's ability to accurately track the S&P 500
index over the past 20 years based on a small number of stocks. An open-source
implementation is provided within the R package TRexSelector on CRAN.
"
2401.16920,2024-12-16,"Sparse Portfolio Selection via Topological Data Analysis based
  Clustering","  This paper uses topological data analysis (TDA) tools and introduces a
data-driven clustering-based stock selection strategy tailored for sparse
portfolio construction. Our asset selection strategy exploits the topological
features of stock price movements to select a subset of topologically similar
(different) assets for a sparse index tracking (Markowitz) portfolio. We
introduce new distance measures, which serve as an input to the clustering
algorithm, on the space of persistence diagrams and landscapes that consider
the time component of a time series. We conduct an empirical analysis on the
S\&P index from 2009 to 2022, including a study on the COVID-19 data to
validate the robustness of our methodology. Our strategy to integrate TDA with
the clustering algorithm significantly enhanced the performance of sparse
portfolios across various performance measures in diverse market scenarios.
"
2402.00515,2024-09-11,"Developing A Multi-Agent and Self-Adaptive Framework with Deep
  Reinforcement Learning for Dynamic Portfolio Risk Management","  Deep or reinforcement learning (RL) approaches have been adapted as reactive
agents to quickly learn and respond with new investment strategies for
portfolio management under the highly turbulent financial market environments
in recent years. In many cases, due to the very complex correlations among
various financial sectors, and the fluctuating trends in different financial
markets, a deep or reinforcement learning based agent can be biased in
maximising the total returns of the newly formulated investment portfolio while
neglecting its potential risks under the turmoil of various market conditions
in the global or regional sectors. Accordingly, a multi-agent and self-adaptive
framework namely the MASA is proposed in which a sophisticated multi-agent
reinforcement learning (RL) approach is adopted through two cooperating and
reactive agents to carefully and dynamically balance the trade-off between the
overall portfolio returns and their potential risks. Besides, a very flexible
and proactive agent as the market observer is integrated into the MASA
framework to provide some additional information on the estimated market trends
as valuable feedbacks for multi-agent RL approach to quickly adapt to the
ever-changing market conditions. The obtained empirical results clearly reveal
the potential strengths of our proposed MASA framework based on the multi-agent
RL approach against many well-known RL-based approaches on the challenging data
sets of the CSI 300, Dow Jones Industrial Average and S&P 500 indexes over the
past 10 years. More importantly, our proposed MASA framework shed lights on
many possible directions for future investigation.
"
2402.01951,2024-09-02,"Sparse spanning portfolios and under-diversification with second-order
  stochastic dominance","  We develop and implement methods for determining whether relaxing sparsity
constraints on portfolios improves the investment opportunity set for
risk-averse investors. We formulate a new estimation procedure for sparse
second-order stochastic spanning based on a greedy algorithm and Linear
Programming. We show the optimal recovery of the sparse solution asymptotically
whether spanning holds or not. From large equity datasets, we estimate the
expected utility loss due to possible under-diversification, and find that
there is no benefit from expanding a sparse opportunity set beyond 45 assets.
The optimal sparse portfolio invests in 10 industry sectors and cuts tail risk
when compared to a sparse mean-variance portfolio. On a rolling-window basis,
the number of assets shrinks to 25 assets in crisis periods, while standard
factor models cannot explain the performance of the sparse portfolios.
"
2402.04775,2024-03-06,Cyber risk and the cross-section of stock returns,"  We extract firms' cyber risk with a machine learning algorithm measuring the
proximity between their disclosures and a dedicated cyber corpus. Our approach
outperforms dictionary methods, uses full disclosure and not devoted-only
sections, and generates a cyber risk measure uncorrelated with other firms'
characteristics. We find that a portfolio of US-listed stocks in the high cyber
risk quantile generates an excess return of 18.72% p.a. Moreover, a long-short
cyber risk portfolio has a significant and positive risk premium of 6.93% p.a.,
robust to all factors' benchmarks. Finally, using a Bayesian asset pricing
method, we show that our cyber risk factor is the essential feature that allows
any multi-factor model to price the cross-section of stock returns.
"
2402.05113,2024-02-09,Portfolio Time Consistency and Utility Weighted Discount Rates,"  Merton portfolio management problem is studied in this paper within a
stochastic volatility, non constant time discount rate, and power utility
framework. This problem is time inconsistent and the way out of this
predicament is to consider the subgame perfect strategies. The later are
characterized through an extended Hamilton Jacobi Bellman (HJB) equation. A
fixed point iteration is employed to solve the extended HJB equation. This is
done in a two stage approach: in a first step the utility weighted discount
rate is introduced and characterized as the fixed point of a certain operator;
in the second step the value function is determined through a linear parabolic
partial differential equation. Numerical experiments explore the effect of the
time discount rate on the subgame perfect and precommitment strategies.
"
2402.05272,2024-09-18,"Downside Risk Reduction Using Regime-Switching Signals: A Statistical
  Jump Model Approach","  This article investigates a regime-switching investment strategy aimed at
mitigating downside risk by reducing market exposure during anticipated
unfavorable market regimes. We highlight the statistical jump model (JM) for
market regime identification, a recently developed robust model that
distinguishes itself from traditional Markov-switching models by enhancing
regime persistence through a jump penalty applied at each state transition. Our
JM utilizes a feature set comprising risk and return measures derived solely
from the return series, with the optimal jump penalty selected through a
time-series cross-validation method that directly optimizes strategy
performance. Our empirical analysis evaluates the realistic out-of-sample
performance of various strategies on major equity indices from the US, Germany,
and Japan from 1990 to 2023, in the presence of transaction costs and trading
delays. The results demonstrate the consistent outperformance of the JM-guided
strategy in reducing risk metrics such as volatility and maximum drawdown, and
enhancing risk-adjusted returns like the Sharpe ratio, when compared to both
hidden Markov model-guided strategy and the buy-and-hold strategy. These
findings underline the enhanced persistence, practicality, and versatility of
strategies utilizing JMs for regime-switching signals.
"
2402.08108,2024-02-14,"Finding Moving-Band Statistical Arbitrages via Convex-Concave
  Optimization","  We propose a new method for finding statistical arbitrages that can contain
more assets than just the traditional pair. We formulate the problem as seeking
a portfolio with the highest volatility, subject to its price remaining in a
band and a leverage limit. This optimization problem is not convex, but can be
approximately solved using the convex-concave procedure, a specific sequential
convex programming method. We show how the method generalizes to finding
moving-band statistical arbitrages, where the price band midpoint varies over
time.
"
2402.08387,2024-02-14,"Portfolio Optimization under Transaction Costs with Recursive
  Preferences","  The Merton investment-consumption problem is fundamental, both in the field
of finance, and in stochastic control. An important extension of the problem
adds transaction costs, which is highly relevant from a financial perspective
but also challenging from a control perspective because the solution now
involves singular control. A further significant extension takes us from
additive utility to stochastic differential utility (SDU), which allows time
preferences and risk preferences to be disentangled.
  In this paper, we study this extended version of the Merton problem with
proportional transaction costs and Epstein-Zin SDU. We fully characterise all
parameter combinations for which the problem is well posed (which may depend on
the level of transaction costs) and provide a full verification argument that
relies on no additional technical assumptions and uses primal methods only. The
case with SDU requires new mathematical techniques as duality methods break
down.
  Even in the special case of (additive) power utility, our arguments are
significantly simpler, more elegant and more far-reaching than the ones in the
extant literature. This means that we can easily analyse aspects of the problem
which previously have been very challenging, including comparative statics,
boundary cases which heretofore have required separate treatment and the
situation beyond the small transaction cost regime. A key and novel idea is to
parametrise consumption and the value function in terms of the shadow fraction
of wealth, which may be of much wider applicability.
"
2402.09194,2024-02-15,"The Boosted Difference of Convex Functions Algorithm for Value-at-Risk
  Constrained Portfolio Optimization","  A highly relevant problem of modern finance is the design of Value-at-Risk
(VaR) optimal portfolios. Due to contemporary financial regulations, banks and
other financial institutions are tied to use the risk measure to control their
credit, market and operational risks. For a portfolio with a discrete return
distribution and finitely many scenarios, a Difference of Convex (DC) functions
representation of the VaR can be derived. Wozabal (2012) showed that this
yields a solution to a VaR constrained Markowitz style portfolio selection
problem using the Difference of Convex Functions Algorithm (DCA). A recent
algorithmic extension is the so-called Boosted Difference of Convex Functions
Algorithm (BDCA) which accelerates the convergence due to an additional line
search step. It has been shown that the BDCA converges linearly for solving
non-smooth quadratic problems with linear inequality constraints. In this
paper, we prove that the linear rate of convergence is also guaranteed for a
piecewise linear objective function with linear equality and inequality
constraints using the Kurdyka-{\L}ojasiewicz property. An extended case study
under consideration of best practices for comparing optimization algorithms
demonstrates the superiority of the BDCA over the DCA for real-world financial
market data. We are able to show that the results of the BDCA are significantly
closer to the efficient frontier compared to the DCA. Due to the open
availability of all data sets and code, this paper further provides a practical
guide for transparent and easily reproducible comparisons of VaR constrained
portfolio selection problems in Python.
"
2402.15387,2024-02-26,Higher order measures of risk and stochastic dominance,"  Higher order risk measures are stochastic optimization problems by design,
and for this reason they enjoy valuable properties in optimization under
uncertainties. They nicely integrate with stochastic optimization problems, as
has been observed by the intriguing concept of the risk quadrangles, for
example. Stochastic dominance is a binary relation for random variables to
compare random outcomes. It is demonstrated that the concepts of higher order
risk measures and stochastic dominance are equivalent, they can be employed to
characterize the other. The paper explores these relations and connects
stochastic orders, higher order risk measures and the risk quadrangle.
Expectiles are employed to exemplify the relations obtained.
"
2402.15588,2024-02-27,Sizing the bets in a focused portfolio,"  The paper provides a mathematical model and a tool for the focused investing
strategy as advocated by Buffett, Munger, and others from this investment
community. The approach presented here assumes that the investor's role is to
think about probabilities of different outcomes for a set of businesses. Based
on these assumptions, the tool calculates the optimal allocation of capital for
each of the investment candidates. The model is based on a generalized Kelly
Criterion with options to provide constraints that ensure: no shorting, limited
use of leverage, providing a maximum limit to the risk of permanent loss of
capital, and maximum individual allocation. The software is applied to an
example portfolio from which certain observations about excessive
diversification are obtained. In addition, the software is made available for
public use.
"
2402.16118,2024-02-27,Finding Near-Optimal Portfolios With Quality-Diversity,"  The majority of standard approaches to financial portfolio optimization (PO)
are based on the mean-variance (MV) framework. Given a risk aversion
coefficient, the MV procedure yields a single portfolio that represents the
optimal trade-off between risk and return. However, the resulting optimal
portfolio is known to be highly sensitive to the input parameters, i.e., the
estimates of the return covariance matrix and the mean return vector. It has
been shown that a more robust and flexible alternative lies in determining the
entire region of near-optimal portfolios. In this paper, we present a novel
approach for finding a diverse set of such portfolios based on
quality-diversity (QD) optimization. More specifically, we employ the
CVT-MAP-Elites algorithm, which is scalable to high-dimensional settings with
potentially hundreds of behavioral descriptors and/or assets. The results
highlight the promising features of QD as a novel tool in PO.
"
2402.16609,2024-02-27,"Combining Transformer based Deep Reinforcement Learning with
  Black-Litterman Model for Portfolio Optimization","  As a model-free algorithm, deep reinforcement learning (DRL) agent learns and
makes decisions by interacting with the environment in an unsupervised way. In
recent years, DRL algorithms have been widely applied by scholars for portfolio
optimization in consecutive trading periods, since the DRL agent can
dynamically adapt to market changes and does not rely on the specification of
the joint dynamics across the assets. However, typical DRL agents for portfolio
optimization cannot learn a policy that is aware of the dynamic correlation
between portfolio asset returns. Since the dynamic correlations among portfolio
assets are crucial in optimizing the portfolio, the lack of such knowledge
makes it difficult for the DRL agent to maximize the return per unit of risk,
especially when the target market permits short selling (i.e., the US stock
market). In this research, we propose a hybrid portfolio optimization model
combining the DRL agent and the Black-Litterman (BL) model to enable the DRL
agent to learn the dynamic correlation between the portfolio asset returns and
implement an efficacious long/short strategy based on the correlation.
Essentially, the DRL agent is trained to learn the policy to apply the BL model
to determine the target portfolio weights. To test our DRL agent, we construct
the portfolio based on all the Dow Jones Industrial Average constitute stocks.
Empirical results of the experiments conducted on real-world United States
stock market data demonstrate that our DRL agent significantly outperforms
various comparison portfolio choice strategies and alternative DRL frameworks
by at least 42% in terms of accumulated return. In terms of the return per unit
of risk, our DRL agent significantly outperforms various comparative portfolio
choice strategies and alternative strategies based on other machine learning
frameworks.
"
2402.17194,2024-02-28,"The Random Forest Model for Analyzing and Forecasting the US Stock
  Market in the Context of Smart Finance","  The stock market is a crucial component of the financial market, playing a
vital role in wealth accumulation for investors, financing costs for listed
companies, and the stable development of the national macroeconomy. Significant
fluctuations in the stock market can damage the interests of stock investors
and cause an imbalance in the industrial structure, which can interfere with
the macro level development of the national economy. The prediction of stock
price trends is a popular research topic in academia. Predicting the three
trends of stock pricesrising, sideways, and falling can assist investors in
making informed decisions about buying, holding, or selling stocks.
Establishing an effective forecasting model for predicting these trends is of
substantial practical importance. This paper evaluates the predictive
performance of random forest models combined with artificial intelligence on a
test set of four stocks using optimal parameters. The evaluation considers both
predictive accuracy and time efficiency.
"
2402.17523,2024-02-28,"Navigating Complexity: Constrained Portfolio Analysis in High Dimensions
  with Tracking Error and Weight Constraints","  This paper analyzes the statistical properties of constrained portfolio
formation in a high dimensional portfolio with a large number of assets.
Namely, we consider portfolios with tracking error constraints, portfolios with
tracking error jointly with weight (equality or inequality) restrictions, and
portfolios with only weight restrictions. Tracking error is the portfolio's
performance measured against a benchmark (an index usually), {\color{black}{and
weight constraints refers to specific allocation of assets within the
portfolio, which often come in the form of regulatory requirement or fund
prospectus.}} We show how these portfolios can be estimated consistently in
large dimensions, even when the number of assets is larger than the time span
of the portfolio. We also provide rate of convergence results for weights of
the constrained portfolio, risk of the constrained portfolio and the Sharpe
Ratio of the constrained portfolio. To achieve those results we use a new
machine learning technique that merges factor models with nodewise regression
in statistics. Simulation results and empirics show very good performance of
our method.
"
2402.17941,2024-02-29,"Neural Networks for Portfolio-Level Risk Management: Portfolio
  Compression, Static Hedging, Counterparty Credit Risk Exposures and Impact on
  Capital Requirement","  In this paper, we present an artificial neural network framework for
portfolio compression of a large portfolio of European options with varying
maturities (target portfolio) by a significantly smaller portfolio of European
options with shorter or same maturity (compressed portfolio), which also
represents a self-replicating static hedge portfolio of the target portfolio.
For the proposed machine learning architecture, which is consummately
interpretable by choice of design, we also define the algorithm to learn model
parameters by providing a parameter initialisation technique and leveraging the
optimisation methodology proposed in Lokeshwar and Jain (2024), which was
initially introduced to price Bermudan options. We demonstrate the convergence
of errors and the iterative evolution of neural network parameters over the
course of optimization process, using selected target portfolio samples for
illustration. We demonstrate through numerical examples that the Exposure
distributions and Exposure profiles (Expected Exposure and Potential Future
Exposure) of the target portfolio and compressed portfolio align closely across
future risk horizons under risk-neutral and real-world scenarios. Additionally,
we benchmark the target portfolio's Financial Greeks (Delta, Gamma, and Vega)
against the compressed portfolio at future time horizons across different
market scenarios generated by Monte-Carlo simulations. Finally, we compare the
regulatory capital requirement under the standardised approach for counterparty
credit risk of the target portfolio against the compressed portfolio and
highlight that the capital requirement for the compact portfolio substantially
reduces.
"
2402.18764,2024-03-01,"An Analytical Approach to (Meta)Relational Models Theory, and its
  Application to Triple Bottom Line (Profit, People, Planet) -- Towards Social
  Relations Portfolio Management","  Investigating the optimal nature of social interactions among generic actors
(e.g., people or firms), aiming to achieve specifically-agreed objectives, has
been the subject of extensive academic research. Using the relational models
theory - comprehensively describing all social interactions among actors as
combinations of only four forms of sociality: communal sharing, authority
ranking, equality matching, and market pricing - the common approach within the
literature revolves around qualitative assessments of the sociality models'
configurations most effective in realizing predefined purposes, at times
supplemented by empirical data. In this treatment, we formulate this question
as a mathematical optimization problem, in order to quantitatively determine
the best possible configurations of sociality forms between dyadic actors which
would optimize their mutually-agreed objectives. For this purpose, we develop
an analytical framework for quantifying the (meta)relational models theory, and
mathematically demonstrate that combining the four sociality forms within a
specific meaningful social interaction inevitably prompts an inherent tension
among them, through a single elementary and universal metarelation. In analogy
with financial portfolio management, we subsequently introduce the concept of
Social Relations Portfolio (SRP) management, and propose a generalizable
procedural methodology capable of quantitatively identifying the efficient SRP
for any objective involving meaningful social relations. As an important
illustration, the methodology is applied to the Triple Bottom Line paradigm to
derive its efficient SRP, guiding practitioners in precisely measuring,
monitoring, reporting and (proactively) steering stakeholder management efforts
regarding Corporate Social Responsibility (CSR) and Environmental, Social and
Governance (ESG) within and / or across organizations.
"
2403.00009,2024-03-04,Randomized Control in Performance Analysis and Empirical Asset Pricing,"  The present article explores the application of randomized control techniques
in empirical asset pricing and performance evaluation. It introduces geometric
random walks, a class of Markov chain Monte Carlo methods, to construct
flexible control groups in the form of random portfolios adhering to investor
constraints. The sampling-based methods enable an exploration of the
relationship between academically studied factor premia and performance in a
practical setting. In an empirical application, the study assesses the
potential to capture premias associated with size, value, quality, and momentum
within a strongly constrained setup, exemplified by the investor guidelines of
the MSCI Diversified Multifactor index. Additionally, the article highlights
issues with the more traditional use case of random portfolios for drawing
inferences in performance evaluation, showcasing challenges related to the
intricacies of high-dimensional geometry.
"
2403.02500,2024-03-06,"RVRAE: A Dynamic Factor Model Based on Variational Recurrent Autoencoder
  for Stock Returns Prediction","  In recent years, the dynamic factor model has emerged as a dominant tool in
economics and finance, particularly for investment strategies. This model
offers improved handling of complex, nonlinear, and noisy market conditions
compared to traditional static factor models. The advancement of machine
learning, especially in dealing with nonlinear data, has further enhanced asset
pricing methodologies. This paper introduces a groundbreaking dynamic factor
model named RVRAE. This model is a probabilistic approach that addresses the
temporal dependencies and noise in market data. RVRAE ingeniously combines the
principles of dynamic factor modeling with the variational recurrent
autoencoder (VRAE) from deep learning. A key feature of RVRAE is its use of a
prior-posterior learning method. This method fine-tunes the model's learning
process by seeking an optimal posterior factor model informed by future data.
Notably, RVRAE is adept at risk modeling in volatile stock markets, estimating
variances from latent space distributions while also predicting returns. Our
empirical tests with real stock market data underscore RVRAE's superior
performance compared to various established baseline methods.
"
2403.02523,2025-03-14,Transformer for Times Series: an Application to the S&P500,"  The transformer models have been extensively used with good results in a wide
area of machine learning applications including Large Language Models and image
generation. Here, we inquire on the applicability of this approach to financial
time series. We first describe the dataset construction for two prototypical
situations: a mean reverting synthetic Ornstein-Uhlenbeck process on one hand
and real S&P500 data on the other hand. Then, we present in detail the proposed
Transformer architecture and finally we discuss some encouraging results. For
the synthetic data we predict rather accurately the next move, and for the
S&P500 we get some interesting results related to quadratic variation and
volatility prediction.
"
2403.10273,2024-03-18,Optimal Portfolio Choice with Cross-Impact Propagators,"  We consider a class of optimal portfolio choice problems in continuous time
where the agent's transactions create both transient cross-impact driven by a
matrix-valued Volterra propagator, as well as temporary price impact. We
formulate this problem as the maximization of a revenue-risk functional, where
the agent also exploits available information on a progressively measurable
price predicting signal. We solve the maximization problem explicitly in terms
of operator resolvents, by reducing the corresponding first order condition to
a coupled system of stochastic Fredholm equations of the second kind and
deriving its solution. We then give sufficient conditions on the matrix-valued
propagator so that the model does not permit price manipulation. We also
provide an implementation of the solutions to the optimal portfolio choice
problem and to the associated optimal execution problem. Our solutions yield
financial insights on the influence of cross-impact on the optimal strategies
and its interplay with alpha decays.
"
2403.10482,2024-03-25,"Can a GPT4-Powered AI Agent Be a Good Enough Performance Attribution
  Analyst?","  Performance attribution analysis, defined as the process of explaining the
drivers of the excess performance of an investment portfolio against a
benchmark, stands as a significant feature of portfolio management and plays a
crucial role in the investment decision-making process, particularly within the
fund management industry. Rooted in a solid financial and mathematical
framework, the importance and methodologies of this analytical technique are
extensively documented across numerous academic research papers and books. The
integration of large language models (LLMs) and AI agents marks a
groundbreaking development in this field. These agents are designed to automate
and enhance the performance attribution analysis by accurately calculating and
analyzing portfolio performances against benchmarks. In this study, we
introduce the application of an AI Agent for a variety of essential performance
attribution tasks, including the analysis of performance drivers and utilizing
LLMs as calculation engine for multi-level attribution analysis and
question-answering (QA) tasks. Leveraging advanced prompt engineering
techniques such as Chain-of-Thought (CoT) and Plan and Solve (PS), and
employing a standard agent framework from LangChain, the research achieves
promising results: it achieves accuracy rates exceeding 93% in analyzing
performance drivers, attains 100% in multi-level attribution calculations, and
surpasses 84% accuracy in QA exercises that simulate official examination
standards. These findings affirm the impactful role of AI agents, prompt
engineering and evaluation in advancing portfolio management processes,
highlighting a significant development in the practical application and
evaluation of Generative AI technologies within the domain.
"
2403.11622,2024-12-12,Asset management with an ESG mandate,"  We investigate the portfolio frontier and risk premia in equilibrium when
institutional investors aim to minimize the tracking error variance under an
ESG score mandate. If a negative ESG premium is priced in the market, this
mandate can reduce portfolio inefficiency when the return over-performance
target is limited. In equilibrium, with asset managers endowed with an ESG
mandate and mean-variance investors, a negative ESG premium arises. A result
that is supported by empirical data. The negative ESG premium is due to the ESG
constraint imposed on institutional investors and is not associated with a risk
factor.
"
2403.14063,2024-03-22,"DiffSTOCK: Probabilistic relational Stock Market Predictions using
  Diffusion Models","  In this work, we propose an approach to generalize denoising diffusion
probabilistic models for stock market predictions and portfolio management.
Present works have demonstrated the efficacy of modeling interstock relations
for market time-series forecasting and utilized Graph-based learning models for
value prediction and portfolio management. Though convincing, these
deterministic approaches still fall short of handling uncertainties i.e., due
to the low signal-to-noise ratio of the financial data, it is quite challenging
to learn effective deterministic models. Since the probabilistic methods have
shown to effectively emulate higher uncertainties for time-series predictions.
To this end, we showcase effective utilisation of Denoising Diffusion
Probabilistic Models (DDPM), to develop an architecture for providing better
market predictions conditioned on the historical financial indicators and
inter-stock relations. Additionally, we also provide a novel deterministic
architecture MaTCHS which uses Masked Relational Transformer(MRT) to exploit
inter-stock relations along with historical stock features. We demonstrate that
our model achieves SOTA performance for movement predication and Portfolio
management.
"
2403.15243,2024-03-25,Robust Utility Optimization via a GAN Approach,"  Robust utility optimization enables an investor to deal with market
uncertainty in a structured way, with the goal of maximizing the worst-case
outcome. In this work, we propose a generative adversarial network (GAN)
approach to (approximately) solve robust utility optimization problems in
general and realistic settings. In particular, we model both the investor and
the market by neural networks (NN) and train them in a mini-max zero-sum game.
This approach is applicable for any continuous utility function and in
realistic market settings with trading costs, where only observable information
of the market can be used. A large empirical study shows the versatile
usability of our method. Whenever an optimal reference strategy is available,
our method performs on par with it and in the (many) settings without known
optimal strategy, our method outperforms all other reference strategies.
Moreover, we can conclude from our study that the trained path-dependent
strategies do not outperform Markovian ones. Lastly, we uncover that our
generative approach for learning optimal, (non-) robust investments under
trading costs generates universally applicable alternatives to well known
asymptotic strategies of idealized settings.
"
2403.16228,2024-03-26,Rank-Dependent Predictable Forward Performance Processes,"  Predictable forward performance processes (PFPPs) are stochastic optimal
control frameworks for an agent who controls a randomly evolving system but can
only prescribe the system dynamics for a short period ahead. This is a common
scenario in which a controlling agent frequently re-calibrates her model. We
introduce a new class of PFPPs based on rank-dependent utility, generalizing
existing models that are based on expected utility theory (EUT). We establish
existence of rank-dependent PFPPs under a conditionally complete market and
exogenous probability distortion functions which are updated periodically. We
show that their construction reduces to solving an integral equation that
generalizes the integral equation obtained under EUT in previous studies. We
then propose a new approach for solving the integral equation via theory of
Volterra equations. We illustrate our result in the special case of
conditionally complete Black-Scholes model.
"
2403.17127,2024-03-27,High-Dimensional Mean-Variance Spanning Tests,"  We introduce a new framework for the mean-variance spanning (MVS) hypothesis
testing. The procedure can be applied to any test-asset dimension and only
requires stationary asset returns and the number of benchmark assets to be
smaller than the number of time periods. It involves individually testing
moment conditions using a robust Student-t statistic based on the batch-mean
method and combining the p-values using the Cauchy combination test.
Simulations demonstrate the superior performance of the test compared to
state-of-the-art approaches. For the empirical application, we look at the
problem of domestic versus international diversification in equities. We find
that the advantages of diversification are influenced by economic conditions
and exhibit cross-country variation. We also highlight that the rejection of
the MVS hypothesis originates from the potential to reduce variance within the
domestic global minimum-variance portfolio.
"
2403.18823,2024-03-29,"Artificial Intelligence-based Analysis of Change in Public Finance
  between US and International Markets","  Public finances are one of the fundamental mechanisms of economic governance
that refer to the financial activities and decisions made by government
entities to fund public services, projects, and operations through assets. In
today's globalized landscape, even subtle shifts in one nation's public debt
landscape can have significant impacts on that of international finances,
necessitating a nuanced understanding of the correlations between international
and national markets to help investors make informed investment decisions.
Therefore, by leveraging the capabilities of artificial intelligence, this
study utilizes neural networks to depict the correlations between US and
International Public Finances and predict the changes in international public
finances based on the changes in US public finances. With the neural network
model achieving a commendable Mean Squared Error (MSE) value of 2.79, it is
able to affirm a discernible correlation and also plot the effect of US market
volatility on international markets. To further test the accuracy and
significance of the model, an economic analysis was conducted that aimed to
correlate the changes seen by the results of the model with historical stock
market changes. This model demonstrates significant potential for investors to
predict changes in international public finances based on signals from US
markets, marking a significant stride in comprehending the intricacies of
global public finances and the role of artificial intelligence in decoding its
multifaceted patterns for practical forecasting.
"
2404.00187,2024-04-02,Portfolio management using graph centralities: Review and comparison,"  We investigate an application of network centrality measures to portfolio
optimization, by generalizing the method in [Pozzi, Di Matteo and Aste,
\emph{Spread of risks across financial markets: better to invest in the
peripheries}, Scientific Reports 3:1665, 2013], that however had significant
limitations with respect to the state of the art in network theory. In this
paper, we systematically compare many possible variants of the originally
proposed method on S\&P 500 stocks. We use daily data from twenty-seven years
as training set and their following year as test set. We thus select the best
network-based methods according to different viewpoints including for instance
the highest Sharpe Ratio and the highest expected return. We give emphasis in
new centrality measures and we also conduct a thorough analysis, which reveals
significantly stronger results compared to those with more traditional methods.
According to our analysis, this graph-theoretical approach to investment can be
used successfully by investors with different investment profiles leading to
high risk-adjusted returns.
"
2404.00825,2024-04-02,"Using Machine Learning to Forecast Market Direction with Efficient
  Frontier Coefficients","  We propose a novel method to improve estimation of asset returns for
portfolio optimization. This approach first performs a monthly directional
market forecast using an online decision tree. The decision tree is trained on
a novel set of features engineered from portfolio theory: the efficient
frontier functional coefficients. Efficient frontiers can be decomposed to
their functional form, a square-root second-order polynomial, and the
coefficients of this function captures the information of all the constituents
that compose the market in the current time period. To make these forecasts
actionable, these directional forecasts are integrated to a portfolio
optimization framework using expected returns conditional on the market
forecast as an estimate for the return vector. This conditional expectation is
calculated using the inverse Mills ratio, and the Capital Asset Pricing Model
is used to translate the market forecast to individual asset forecasts. This
novel method outperforms baseline portfolios, as well as other feature sets
including technical indicators and the Fama-French factors. To empirically
validate the proposed model, we employ a set of market sector ETFs.
"
2404.02582,2024-04-18,Quantum computing approach to realistic ESG-friendly stock portfolios,"  Finding an optimal balance between risk and returns in investment portfolios
is a central challenge in quantitative finance, often addressed through
Markowitz portfolio theory (MPT). While traditional portfolio optimization is
carried out in a continuous fashion, as if stocks could be bought in fractional
increments, practical implementations often resort to approximations, as
fractional stocks are typically not tradeable. While these approximations are
effective for large investment budgets, they deteriorate as budgets decrease.
To alleviate this issue, a discrete Markowitz portfolio theory (DMPT) with
finite budgets and integer stock weights can be formulated, but results in a
non-polynomial (NP)-hard problem. Recent progress in quantum processing units
(QPUs), including quantum annealers, makes solving DMPT problems feasible. Our
study explores portfolio optimization on quantum annealers, establishing a
mapping between continuous and discrete Markowitz portfolio theories. We find
that correctly normalized discrete portfolios converge to continuous solutions
as budgets increase. Our DMPT implementation provides efficient frontier
solutions, outperforming traditional rounding methods, even for moderate
budgets. Responding to the demand for environmentally and socially responsible
investments, we enhance our discrete portfolio optimization with ESG
(environmental, social, governance) ratings for EURO STOXX 50 index stocks. We
introduce a utility function incorporating ESG ratings to balance risk, return,
and ESG-friendliness, and discuss implications for ESG-aware investors.
"
2404.05101,2024-10-24,StockGPT: A GenAI Model for Stock Prediction and Trading,"  This paper introduces StockGPT, an autoregressive ``number'' model trained
and tested on 70 million daily U.S.\ stock returns over nearly 100 years.
Treating each return series as a sequence of tokens, StockGPT automatically
learns the hidden patterns predictive of future returns via its attention
mechanism. On a held-out test sample from 2001 to 2023, daily and monthly
rebalanced long-short portfolios formed from StockGPT predictions yield strong
performance. The StockGPT-based portfolios span momentum and long-/short-term
reversals, eliminating the need for manually crafted price-based strategies,
and yield highly significant alphas against leading stock market factors,
suggesting a novel AI pricing effect. This highlights the immense promise of
generative AI in surpassing human in making complex financial investment
decisions.
"
2404.05372,2024-04-09,"The PEAL Method: a mathematical framework to streamline securitization
  structuring","  Securitization is a financial process where the cash flows of
income-generating assets are sold to institutional investors as securities,
liquidating illiquid assets. This practice presents persistent challenges due
to the absence of a comprehensive mathematical framework for structuring
asset-backed securities. While existing literature provides technical analysis
of credit risk modeling, there remains a need for a definitive framework
detailing the allocation of the inbound cash flows to the outbound positions.
To fill this gap, we introduce the PEAL Method: a 10-step mathematical
framework to streamline the securitization structuring across all time periods.
  The PEAL Method offers a rigorous and versatile approach, allowing
practitioners to structure various types of securitizations, including those
with complex vertical positions. By employing standardized equations, it
facilitates the delineation of payment priorities and enhances risk
characterization for both the asset and the liability sides throughout the
securitization life cycle.
  In addition to its technical contributions, the PEAL Method aims to elevate
industry standards by addressing longstanding challenges in securitization. By
providing detailed information to investors and enabling transparent risk
profile comparisons, it promotes market transparency and enables stronger
regulatory oversight.
  In summary, the PEAL Method represents a significant advancement in
securitization literature, offering a standardized framework for precision and
efficiency in structuring transactions. Its adoption has the potential to drive
innovation and enhance risk management practices in the securitization market.
"
2404.07452,2025-05-06,"RiskLabs: Predicting Financial Risk Using Large Language Model based on
  Multimodal and Multi-Sources Data","  The integration of Artificial Intelligence (AI) techniques, particularly
large language models (LLMs), in finance has garnered increasing academic
attention. Despite progress, existing studies predominantly focus on tasks like
financial text summarization, question-answering, and stock movement prediction
(binary classification), the application of LLMs to financial risk prediction
remains underexplored. Addressing this gap, in this paper, we introduce
RiskLabs, a novel framework that leverages LLMs to analyze and predict
financial risks. RiskLabs uniquely integrates multimodal financial data,
including textual and vocal information from Earnings Conference Calls (ECCs),
market-related time series data, and contextual news data to improve financial
risk prediction. Empirical results demonstrate RiskLabs' effectiveness in
forecasting both market volatility and variance. Through comparative
experiments, we examine the contributions of different data sources to
financial risk assessment and highlight the crucial role of LLMs in this
process. We also discuss the challenges associated with using LLMs for
financial risk prediction and explore the potential of combining them with
multimodal data for this purpose.
"
2404.08935,2024-04-16,"Developing An Attention-Based Ensemble Learning Framework for Financial
  Portfolio Optimisation","  In recent years, deep or reinforcement learning approaches have been applied
to optimise investment portfolios through learning the spatial and temporal
information under the dynamic financial market. Yet in most cases, the existing
approaches may produce biased trading signals based on the conventional price
data due to a lot of market noises, which possibly fails to balance the
investment returns and risks. Accordingly, a multi-agent and self-adaptive
portfolio optimisation framework integrated with attention mechanisms and time
series, namely the MASAAT, is proposed in this work in which multiple trading
agents are created to observe and analyse the price series and directional
change data that recognises the significant changes of asset prices at
different levels of granularity for enhancing the signal-to-noise ratio of
price series. Afterwards, by reconstructing the tokens of financial data in a
sequence, the attention-based cross-sectional analysis module and temporal
analysis module of each agent can effectively capture the correlations between
assets and the dependencies between time points. Besides, a portfolio generator
is integrated into the proposed framework to fuse the spatial-temporal
information and then summarise the portfolios suggested by all trading agents
to produce a newly ensemble portfolio for reducing biased trading actions and
balancing the overall returns and risks. The experimental results clearly
demonstrate that the MASAAT framework achieves impressive enhancement when
compared with many well-known portfolio optimsation approaches on three
challenging data sets of DJIA, S&P 500 and CSI 300. More importantly, our
proposal has potential strengths in many possible applications for future
study.
"
2404.11080,2024-04-18,"Recommender Systems in Financial Trading: Using machine-based conviction
  analysis in an explainable AI investment framework","  Traditionally, assets are selected for inclusion in a portfolio (long or
short) by human analysts. Teams of human portfolio managers (PMs) seek to weigh
and balance these securities using optimisation methods and other portfolio
construction processes. Often, human PMs consider human analyst recommendations
against the backdrop of the analyst's recommendation track record and the
applicability of the analyst to the recommendation they provide. Many firms
regularly ask analysts to provide a ""conviction"" level on their
recommendations. In the eyes of PMs, understanding a human analyst's track
record has typically come down to basic spread sheet tabulation or, at best, a
""virtual portfolio"" paper trading book to keep track of results of
recommendations.
  Analysts' conviction around their recommendations and their ""paper trading""
track record are two crucial workflow components between analysts and portfolio
construction. Many human PMs may not even appreciate that they factor these
data points into their decision-making logic. This chapter explores how
Artificial Intelligence (AI) can be used to replicate these two steps and
bridge the gap between AI data analytics and AI-based portfolio construction
methods. This field of AI is referred to as Recommender Systems (RS). This
chapter will further explore what metadata that RS systems functionally supply
to downstream systems and their features.
"
2404.12598,2024-04-22,"Continuous-time Risk-sensitive Reinforcement Learning via Quadratic
  Variation Penalty","  This paper studies continuous-time risk-sensitive reinforcement learning (RL)
under the entropy-regularized, exploratory diffusion process formulation with
the exponential-form objective. The risk-sensitive objective arises either as
the agent's risk attitude or as a distributionally robust approach against the
model uncertainty. Owing to the martingale perspective in Jia and Zhou (2023)
the risk-sensitive RL problem is shown to be equivalent to ensuring the
martingale property of a process involving both the value function and the
q-function, augmented by an additional penalty term: the quadratic variation of
the value process, capturing the variability of the value-to-go along the
trajectory. This characterization allows for the straightforward adaptation of
existing RL algorithms developed for non-risk-sensitive scenarios to
incorporate risk sensitivity by adding the realized variance of the value
process. Additionally, I highlight that the conventional policy gradient
representation is inadequate for risk-sensitive problems due to the nonlinear
nature of quadratic variation; however, q-learning offers a solution and
extends to infinite horizon settings. Finally, I prove the convergence of the
proposed algorithm for Merton's investment problem and quantify the impact of
temperature parameter on the behavior of the learning procedure. I also conduct
simulation experiments to demonstrate how risk-sensitive RL improves the
finite-sample performance in the linear-quadratic control problem.
"
2404.14252,2024-04-23,On a fundamental statistical edge principle,"  This paper establishes that conditioning the probability of execution of new
orders on the self-generated historical trading information (HTI) of a trading
strategy is a necessary condition for a statistical trading edge. It is shown,
in particular, that, given any trading strategy S that does not use its own
HTI, it is always possible to construct a new strategy S* that yields a
systematically increasing improvement over S in terms of profit and loss (PnL)
by using the self-generated HTI. This holds true under rather general
conditions that are frequently met in practice, and it is proven through a
decision mechanism specifically designed to formally prove this idea.
Simulations and real-world trading evidence are included for validation and
illustration, respectively.
"
2404.18017,2024-07-23,Application of Deep Learning for Factor Timing in Asset Management,"  The paper examines the performance of regression models (OLS linear
regression, Ridge regression, Random Forest, and Fully-connected Neural
Network) on the prediction of CMA (Conservative Minus Aggressive) factor
premium and the performance of factor timing investment with them.
Out-of-sample R-squared shows that more flexible models have better performance
in explaining the variance in factor premium of the unseen period, and the back
testing affirms that the factor timing based on more flexible models tends to
over perform the ones with linear models. However, for flexible models like
neural networks, the optimal weights based on their prediction tend to be
unstable, which can lead to high transaction costs and market impacts. We
verify that tilting down the rebalance frequency according to the historical
optimal rebalancing scheme can help reduce the transaction costs.
"
2404.18184,2024-04-30,Application and practice of AI technology in quantitative investment,"  With the continuous development of artificial intelligence technology, using
machine learning technology to predict market trends may no longer be out of
reach. In recent years, artificial intelligence has become a research hotspot
in the academic circle,and it has been widely used in image recognition,
natural language processing and other fields, and also has a huge impact on the
field of quantitative investment. As an investment method to obtain stable
returns through data analysis, model construction and program trading,
quantitative investment is deeply loved by financial institutions and
investors. At the same time, as an important application field of quantitative
investment, the quantitative investment strategy based on artificial
intelligence technology arises at the historic moment.How to apply artificial
intelligence to quantitative investment, so as to better achieve profit and
risk control, has also become the focus and difficulty of the research. From a
global perspective, inflation in the US and the Federal Reserve are the
concerns of investors, which to some extent affects the direction of global
assets, including the Chinese stock market. This paper studies the application
of AI technology, quantitative investment, and AI technology in quantitative
investment, aiming to provide investors with auxiliary decision-making, reduce
the difficulty of investment analysis, and help them to obtain higher returns.
"
2404.18467,2025-02-11,Diversification for infinite-mean Pareto models without risk aversion,"  We study stochastic dominance between portfolios of independent and
identically distributed (iid) extremely heavy-tailed (i.e., infinite-mean)
Pareto random variables. With the notion of majorization order, we show that a
more diversified portfolio of iid extremely heavy-tailed Pareto random
variables is larger in the sense of first-order stochastic dominance. This
result is further generalized for Pareto random variables caused by triggering
events, random variables with tails being Pareto, bounded Pareto random
variables, and positively dependent Pareto random variables. These results
provide an important implication in investment: Diversification of extremely
heavy-tailed Pareto profits uniformly increases investors' profitability,
leading to a diversification benefit. Remarkably, different from the
finite-mean setting, such a diversification benefit does not depend on the
decision maker's risk aversion.
"
2404.18822,2025-04-17,Dynamic Black-Litterman,"  The Black-Litterman model is a framework for incorporating forward-looking
expert views in a portfolio optimization problem. Existing work focuses almost
exclusively on single-period problems with the forecast horizon matching that
of the investor. We consider a generalization where the investor trades
dynamically and views can be over horizons that differ from the investor. By
exploiting the underlying graphical structure relating the asset prices and
views, we derive the conditional distribution of asset returns when the price
process is geometric Brownian motion, and show that it can be written in terms
of a multi-dimensional Brownian bridge. The components of the Brownian bridge
are dependent one-dimensional Brownian bridges with hitting times that are
determined by the statistics of the price process and views. The new price
process is an affine factor model with the conditional log-price process
playing the role of a vector of factors. We derive an explicit expression for
the optimal dynamic investment policy and analyze the hedging demand for
changes in the new covariate. More generally, the paper shows that Bayesian
graphical models are a natural framework for incorporating complex information
structures in the Black-Litterman model. The connection between Brownian motion
conditional on noisy observations of its terminal value and multi-dimensional
Brownian bridge is novel and of independent interest.
"
2405.00606,2024-05-02,Some properties of Euler capital allocation,"  The paper discusses capital allocation using the Euler formula and focuses on
the risk measures Value-at-Risk (VaR) and Expected shortfall (ES). Some new
results connected to this capital allocation is known. Two examples illustrate
that capital allocation with VaR is not monotonous which may be surprising
since VaR is monotonous. A third example illustrates why the same risk measure
should be used in capital allocation as in the evaluation of the total
portfolio. We show how simulation may be used in order to estimate the expected
Return on risk adjusted capital in the commitment period of an asset. Finally,
we show how Markov chain Monte Carlo may be used in the estimation of the
capital allocation.
"
2405.01598,2024-05-06,Predictive Decision Synthesis for Portfolios: Betting on Better Models,"  We discuss and develop Bayesian dynamic modelling and predictive decision
synthesis for portfolio analysis. The context involves model uncertainty with a
set of candidate models for financial time series with main foci in sequential
learning, forecasting, and recursive decisions for portfolio reinvestments. The
foundational perspective of Bayesian predictive decision synthesis (BPDS)
defines novel, operational analysis and resulting predictive and decision
outcomes. A detailed case study of BPDS in financial forecasting of
international exchange rate time series and portfolio rebalancing, with
resulting BPDS-based decision outcomes compared to traditional Bayesian
analysis, exemplifies and highlights the practical advances achievable under
the expanded, subjective Bayesian approach that BPDS defines.
"
2405.01604,2024-05-06,Portfolio Management using Deep Reinforcement Learning,"  Algorithmic trading or Financial robots have been conquering the stock
markets with their ability to fathom complex statistical trading strategies.
But with the recent development of deep learning technologies, these strategies
are becoming impotent. The DQN and A2C models have previously outperformed
eminent humans in game-playing and robotics. In our work, we propose a
reinforced portfolio manager offering assistance in the allocation of weights
to assets. The environment proffers the manager the freedom to go long and even
short on the assets. The weight allocation advisements are restricted to the
choice of portfolio assets and tested empirically to knock benchmark indices.
The manager performs financial transactions in a postulated liquid market
without any transaction charges. This work provides the conclusion that the
proposed portfolio manager with actions centered on weight allocations can
surpass the risk-adjusted returns of conventional portfolio managers.
"
2405.02302,2024-07-30,"The Democratization of Wealth Management: Hedged Mutual Fund Blockchain
  Protocol","  We develop several innovations to bring the best practices of traditional
investment funds to the blockchain landscape. Specifically, we illustrate how:
1) fund prices can be updated regularly like mutual funds; 2) performance fees
can be charged like hedge funds; 3) mutually hedged blockchain investment funds
can operate with investor protection schemes, such as high water marks; and 4)
measures to offset trading related slippage costs when redemptions happen.
Using our concepts - and blockchain technology - traditional funds can
calculate performance fees in a simplified manner and alleviate several
operational issues. Blockchain can solve many problems for traditional finance,
while tried and tested wealth management techniques can benefit
decentralization, speeding its adoption. We provide detailed steps - including
mathematical formulations and instructive pointers - to implement these ideas
and discuss how our designs overcome several blockchain bottlenecks, making
smart contracts smarter. We provide numerical illustrations of several
scenarios related to our mechanisms.
"
2405.07184,2024-05-14,Trade execution games in a Markovian environment,"  This paper examines a trade execution game for two large traders in a
generalized price impact model. We incorporate a stochastic and sequentially
dependent factor that exogenously affects the market price into financial
markets. Our model accounts for how strategic and environmental uncertainties
affect the large traders' execution strategies. We formulate an expected
utility maximization problem for two large traders as a Markov game model.
Applying the backward induction method of dynamic programming, we provide an
explicit closed-form execution strategy at a Markov perfect equilibrium. Our
theoretical results reveal that the execution strategy generally lies in a
dynamic and non-randomized class; it becomes deterministic if the Markovian
environment is also deterministic. In addition, our simulation-based numerical
experiments suggest that the execution strategy captures various features
observed in financial markets.
"
2405.08047,2024-05-15,Autonomous Sparse Mean-CVaR Portfolio Optimization,"  The $\ell_0$-constrained mean-CVaR model poses a significant challenge due to
its NP-hard nature, typically tackled through combinatorial methods
characterized by high computational demands. From a markedly different
perspective, we propose an innovative autonomous sparse mean-CVaR portfolio
model, capable of approximating the original $\ell_0$-constrained mean-CVaR
model with arbitrary accuracy. The core idea is to convert the $\ell_0$
constraint into an indicator function and subsequently handle it through a
tailed approximation. We then propose a proximal alternating linearized
minimization algorithm, coupled with a nested fixed-point proximity algorithm
(both convergent), to iteratively solve the model. Autonomy in sparsity refers
to retaining a significant portion of assets within the selected asset pool
during adjustments in pool size. Consequently, our framework offers a
theoretically guaranteed approximation of the $\ell_0$-constrained mean-CVaR
model, improving computational efficiency while providing a robust asset
selection scheme.
"
2405.10917,2024-11-12,Is the annualized compounded return of Medallion over 35%?,"  It is a challenge to estimate fund performance by compounded returns.
Arguably, it is incorrect to use yearly returns directly for compounding, with
reported annualized return of above 60% for Medallion for the 31 years up to
2018. We propose an estimation based on fund sizes and trading profits and
obtain a compounded return of 31.8% before fees. Alternatively, we suggest
using the manager's wealth as a proxy and arriving at a compounded growth rate
of 25.6% for Simons for the 33 years up to 2020. We conclude that the
annualized compounded return of Medallion before fees is probably under 35%.
Our findings have implications for correctly estimating fund performance.
"
2405.10920,2024-05-20,Data-generating process and time-series asset pricing,"  We study the data-generating processes for factors expressed in return
differences, which the literature on time-series asset pricing seems to have
overlooked. For the factors' data-generating processes or long-short zero-cost
portfolios, a meaningful definition of returns is impossible; further, the
compounded market factor (MF) significantly underestimates the return
difference between the market and the risk-free rate compounded separately.
Surprisingly, if MF were treated coercively as periodic-rebalancing long-short
(i.e., the same as size and value), Fama-French three-factor (FF3) would be
economically unattractive for lacking compounding and irrelevant for suffering
from the small ""size of an effect."" Otherwise, FF3 might be misspecified if MF
were buy-and-hold long-short. Finally, we show that OLS with net returns for
single-index models leads to inflated alphas, exaggerated t-values, and
overestimated Sharpe ratios (SR); worse, net returns may lead to pathological
alphas and SRs. We propose defining factors (and SRs) with non-difference
compound returns.
"
2405.12991,2024-05-24,"Systematic Comparable Company Analysis and Computation of Cost of Equity
  using Clustering","  Computing cost of equity for private corporations and performing comparable
company analysis (comps) for both public and private corporations is an
integral but tedious and time-consuming task, with important applications
spanning the finance world, from valuations to internal planning. Performing
comps traditionally often times include high ambiguity and subjectivity,
leading to unreliability and inconsistency. In this paper, I will present a
systematic and faster approach to compute cost of equity for private
corporations and perform comps for both public and private corporations using
spectral and agglomerative clustering. This leads to a reduction in the time
required to perform comps by orders of magnitude and entire process being more
consistent and reliable.
"
2405.15833,2024-05-28,DSPO: An End-to-End Framework for Direct Sorted Portfolio Construction,"  In quantitative investment, constructing characteristic-sorted portfolios is
a crucial strategy for asset allocation. Traditional methods transform raw
stock data of varying frequencies into predictive characteristic factors for
asset sorting, often requiring extensive manual design and misalignment between
prediction and optimization goals. To address these challenges, we introduce
Direct Sorted Portfolio Optimization (DSPO), an innovative end-to-end framework
that efficiently processes raw stock data to construct sorted portfolios
directly. DSPO's neural network architecture seamlessly transitions stock data
from input to output while effectively modeling the intra-dependency of
time-steps and inter-dependency among all tradable stocks. Additionally, we
incorporate a novel Monotonical Logistic Regression loss, which directly
maximizes the likelihood of constructing optimal sorted portfolios. To the best
of our knowledge, DSPO is the first method capable of handling market
cross-sections with thousands of tradable stocks fully end-to-end from raw
multi-frequency data. Empirical results demonstrate DSPO's effectiveness,
yielding a RankIC of 10.12\% and an accumulated return of 121.94\% on the New
York Stock Exchange in 2023-2024, and a RankIC of 9.11\% with a return of
108.74\% in other markets during 2021-2022.
"
2405.16336,2024-05-28,Intertemporal Cost-efficient Consumption,"  We aim to provide an intertemporal, cost-efficient consumption model that
extends the consumption optimization inspired by the Distribution Builder, a
tool developed by Sharpe, Johnson, and Goldstein. The Distribution Builder
enables the recovery of investors' risk preferences by allowing them to select
a desired distribution of terminal wealth within their budget constraints.
  This approach differs from the classical portfolio optimization, which
considers the agent's risk aversion modeled by utility functions that are
challenging to measure in practice. Our intertemporal model captures the
dependent structure between consumption periods using copulas. This strategy is
demonstrated using both the Black-Scholes and CEV models.
"
2405.17841,2024-05-30,"Constrained monotone mean--variance investment-reinsurance under the
  Cram\'er--Lundberg model with random coefficients","  This paper studies an optimal investment-reinsurance problem for an insurer
(she) under the Cram\'er--Lundberg model with monotone mean--variance (MMV)
criterion. At any time, the insurer can purchase reinsurance (or acquire new
business) and invest in a security market consisting of a risk-free asset and
multiple risky assets whose excess return rate and volatility rate are allowed
to be random. The trading strategy is subject to a general convex cone
constraint, encompassing no-shorting constraint as a special case. The optimal
investment-reinsurance strategy and optimal value for the MMV problem are
deduced by solving certain backward stochastic differential equations with
jumps. In the literature, it is known that models with MMV criterion and
mean--variance criterion lead to the same optimal strategy and optimal value
when the wealth process is continuous. Our result shows that the conclusion
remains true even if the wealth process has compensated Poisson jumps and the
market coefficients are random.
"
2405.18728,2024-05-30,A Tick-by-Tick Solution for Concentrated Liquidity Provisioning,"  Automated market makers with concentrated liquidity capabilities are
programmable at the tick level. The maximization of earned fees, plus
depreciated reserves, is a convex optimization problem whose vector solution
gives the best provision of liquidity at each tick under a given set of
parameter estimates for swap volume and price volatility. Surprisingly, early
results show that concentrating liquidity around the current price is usually
not the best strategy.
"
2406.00610,2024-06-04,"Portfolio Optimization with Robust Covariance and Conditional
  Value-at-Risk Constraints","  The measure of portfolio risk is an important input of the Markowitz
framework. In this study, we explored various methods to obtain a robust
covariance estimators that are less susceptible to financial data noise. We
evaluated the performance of large-cap portfolio using various forms of Ledoit
Shrinkage Covariance and Robust Gerber Covariance matrix during the period of
2012 to 2022. Out-of-sample performance indicates that robust covariance
estimators can outperform the market capitalization-weighted benchmark
portfolio, particularly during bull markets. The Gerber covariance with
Mean-Absolute-Deviation (MAD) emerged as the top performer. However, robust
estimators do not manage tail risk well under extreme market conditions, for
example, Covid-19 period. When we aim to control for tail risk, we should add
constraint on Conditional Value-at-Risk (CVaR) to make more conservative
decision on risk exposure. Additionally, we incorporated unsupervised
clustering algorithm K-means to the optimization algorithm (i.e. Nested
Clustering Optimization, NCO). It not only helps mitigate numerical instability
of the optimization algorithm, but also contributes to lower drawdown as well.
"
2406.00655,2024-12-30,"Generalized Exponentiated Gradient Algorithms and Their Application to
  On-Line Portfolio Selection","  This paper introduces a novel family of generalized exponentiated gradient
(EG) updates derived from an Alpha-Beta divergence regularization function.
Collectively referred to as EGAB, the proposed updates belong to the category
of multiplicative gradient algorithms for positive data and demonstrate
considerable flexibility by controlling iteration behavior and performance
through three hyperparameters: $\alpha$, $\beta$, and the learning rate $\eta$.
To enforce a unit $l_1$ norm constraint for nonnegative weight vectors within
generalized EGAB algorithms, we develop two slightly distinct approaches. One
method exploits scale-invariant loss functions, while the other relies on
gradient projections onto the feasible domain. As an illustration of their
applicability, we evaluate the proposed updates in addressing the online
portfolio selection problem (OLPS) using gradient-based methods. Here, they not
only offer a unified perspective on the search directions of various OLPS
algorithms (including the standard exponentiated gradient and diverse
mean-reversion strategies), but also facilitate smooth interpolation and
extension of these updates due to the flexibility in hyperparameter selection.
Simulation results confirm that the adaptability of these generalized gradient
updates can effectively enhance the performance for some portfolios,
particularly in scenarios involving transaction costs.
"
2406.01199,2024-06-04,A Geometric Approach To Asset Allocation With Investor Views,"  In this article, a geometric approach to incorporating investor views in
portfolio construction is presented. In particular, the proposed approach
utilizes the notion of generalized Wasserstein barycenter (GWB) to combine the
statistical information about asset returns with investor views to obtain an
updated estimate of the asset drifts and covariance, which are then fed into a
mean-variance optimizer as inputs. Quantitative comparisons of the proposed
geometric approach with the conventional Black-Litterman model (and a closely
related variant) are presented. The proposed geometric approach provides
investors with more flexibility in specifying their confidence in their views
than conventional Black-Litterman model-based approaches. The geometric
approach also rewards the investors more for making correct decisions than
conventional BL based approaches. We provide empirical and theoretical
justifications for our claim.
"
2406.02102,2024-06-05,"Simulation-based approach for Multiproject Scheduling based on composite
  priority rules","  This paper presents a simulation approach to enhance the performance of
heuristics for multi-project scheduling. Unlike other heuristics available in
the literature that use only one priority criterion for resource allocation,
this paper proposes a structured way to sequentially apply more than one
priority criterion for this purpose. By means of simulation, different feasible
schedules are obtained to, therefore, increase the probability of finding the
schedule with the shortest duration. The performance of this simulation
approach was validated with the MPSPLib library, one of the most prominent
libraries for resource-constrained multi-project scheduling. These results
highlight the proposed method as a useful option for addressing limited time
and resources in portfolio management.
"
2406.03652,2025-02-07,"Ensembling Portfolio Strategies for Long-Term Investments: A
  Distribution-Free Preference Framework for Decision-Making and Algorithms","  This paper investigates the problem of ensembling multiple strategies for
sequential portfolios to outperform individual strategies in terms of long-term
wealth. Due to the uncertainty of strategies' performances in the future
market, which are often based on specific models and statistical assumptions,
investors often mitigate risk and enhance robustness by combining multiple
strategies, akin to common approaches in collective learning prediction.
However, the absence of a distribution-free and consistent preference framework
complicates decisions of combination due to the ambiguous objective. To address
this gap, we introduce a novel framework for decision-making in combining
strategies, irrespective of market conditions, by establishing the investor's
preference between decisions and then forming a clear objective. Through this
framework, we propose a combinatorial strategy construction, free from
statistical assumptions, for any scale of component strategies, even infinite,
such that it meets the determined criterion. Finally, we test the proposed
strategy along with its accelerated variant and some other multi-strategies.
The numerical experiments show results in favor of the proposed strategies,
albeit with small tradeoffs in their Sharpe ratios, in which their cumulative
wealths eventually exceed those of the best component strategies while the
accelerated strategy significantly improves performance.
"
2406.03709,2024-06-07,"Mean-variance portfolio selection in jump-diffusion model under
  no-shorting constraint: A viscosity solution approach","  This paper concerns a continuous time mean-variance (MV) portfolio selection
problem in a jump-diffusion financial model with no-shorting trading
constraint. The problem is reduced to two subproblems: solving a stochastic
linear-quadratic (LQ) control problem under control constraint, and finding a
maximal point of a real function. Based on a two-dimensional fully coupled
ordinary differential equation (ODE), we construct an explicit viscosity
solution to the Hamilton-Jacobi-Bellman equation of the constrained LQ problem.
Together with the Meyer-It\^o formula and a verification procedure, we obtain
the optimal feedback controls of the constrained LQ problem and the original MV
problem, which corrects the flawed results in some existing literatures. In
addition, closed-form efficient portfolio and efficient frontier are derived.
In the end, we present several examples where the two-dimensional ODE is
decoupled.
"
2406.06524,2024-11-07,"Gas Fees on the Ethereum Blockchain: From Foundations to Derivatives
  Valuations","  The gas fee, paid for inclusion in the blockchain, is analyzed in two parts.
First, we consider how effort in terms of resources required to process and
store a transaction turns into a gas limit, which, through a fee, comprised of
the base and priority fee in the current version of Ethereum, is converted into
the cost paid by the user. We adhere closely to the Ethereum protocol to
simplify the analysis and to constrain the design choices when considering
multidimensional gas. Second, we assume that the gas price is given deus ex
machina by a fractional Ornstein-Uhlenbeck process and evaluate various
derivatives. These contracts can, for example, mitigate gas cost volatility.
The ability to price and trade forwards besides the existing spot inclusion
into the blockchain could enable users to hedge against future cost
fluctuations. Overall, this paper offers a comprehensive analysis of gas fee
dynamics on the Ethereum blockchain, integrating supply-side constraints with
demand-side modelling to enhance the predictability and stability of
transaction costs.
"
2406.06552,2024-06-12,"Optimizing Sharpe Ratio: Risk-Adjusted Decision-Making in Multi-Armed
  Bandits","  Sharpe Ratio (SR) is a critical parameter in characterizing financial time
series as it jointly considers the reward and the volatility of any
stock/portfolio through its variance. Deriving online algorithms for optimizing
the SR is particularly challenging since even offline policies experience
constant regret with respect to the best expert Even-Dar et al (2006). Thus,
instead of optimizing the usual definition of SR, we optimize regularized
square SR (RSSR). We consider two settings for the RSSR, Regret Minimization
(RM) and Best Arm Identification (BAI). In this regard, we propose a novel
multi-armed bandit (MAB) algorithm for RM called UCB-RSSR for RSSR
maximization. We derive a path-dependent concentration bound for the estimate
of the RSSR. Based on that, we derive the regret guarantees of UCB-RSSR and
show that it evolves as O(log n) for the two-armed bandit case played for a
horizon n. We also consider a fixed budget setting for well-known BAI
algorithms, i.e., sequential halving and successive rejects, and propose SHVV,
SHSR, and SuRSR algorithms. We derive the upper bound for the error probability
of all proposed BAI algorithms. We demonstrate that UCB-RSSR outperforms the
only other known SR optimizing bandit algorithm, U-UCB Cassel et al (2023). We
also establish its efficacy with respect to other benchmarks derived from the
GRA-UCB and MVTS algorithms. We further demonstrate the performance of proposed
BAI algorithms for multiple different setups. Our research highlights that our
proposed algorithms will find extensive applications in risk-aware portfolio
management problems. Consequently, our research highlights that our proposed
algorithms will find extensive applications in risk-aware portfolio management
problems.
"
2406.07200,2024-06-13,A Multi-step Approach for Minimizing Risk in Decentralized Exchanges,"  Decentralized Exchanges are becoming even more predominant in today's
finance. Driven by the need to study this phenomenon from an academic
perspective, the SIAG/FME Code Quest 2023 was announced. Specifically,
participating teams were asked to implement, in Python, the basic functions of
an Automated Market Maker and a liquidity provision strategy in an Automated
Market Maker to minimize the Conditional Value at Risk, a critical measure of
investment risk. As the competition's winning team, we highlight our approach
in this work. In particular, as the dependence of the final return on the
initial wealth distribution is highly non-linear, we cannot use standard ad-hoc
approaches. Additionally, classical minimization techniques would require a
significant computational load due to the cost of the target function. For
these reasons, we propose a three-step approach. In the first step, the target
function is approximated by a Kernel Ridge Regression. Then, the approximating
function is minimized. In the final step, the previously discovered minimum is
utilized as the starting point for directly optimizing the desired target
function. By using this procedure, we can both reduce the computational
complexity and increase the accuracy of the solution. Finally, the overall
computational load is further reduced thanks to an algorithmic trick concerning
the returns simulation and the usage of Cython.
"
2406.07641,2025-04-08,"Interconnected Markets: Exploring the Dynamic Relationship Between BRICS
  Stock Markets and Cryptocurrency","  This study aims to examine the intricate dynamics between BRICS traditional
stock assets and the evolving landscape of cryptocurrencies. Using a
time-varying parameter vector autoregression model (TVP-VAR), we have analyzed
data from the BRICS stock market index, cryptocurrencies, and indicators from
January 6, 2015, to June 29, 2023. The results show that three out of the five
BRICS stock markets serve as primary sources of shocks that subsequently affect
the financial network. The transcontinental (TCI) value derived from the
dynamic conditional connectedness using the TVP-VAR model demonstrates a higher
explanatory power than the static connectedness observed using the standard VAR
model. The discoveries from this study offer valuable insights for
corporations, investors, and regulators concerning systematic risk and
investment strategies.
"
2406.09578,2024-08-19,Dynamic Asset Allocation with Asset-Specific Regime Forecasts,"  This article introduces a novel hybrid regime identification-forecasting
framework designed to enhance multi-asset portfolio construction by integrating
asset-specific regime forecasts. Unlike traditional approaches that focus on
broad economic regimes affecting the entire asset universe, our framework
leverages both unsupervised and supervised learning to generate tailored regime
forecasts for individual assets. Initially, we use the statistical jump model,
a robust unsupervised regime identification model, to derive regime labels for
historical periods, classifying them into bullish or bearish states based on
features extracted from an asset return series. Following this, a supervised
gradient-boosted decision tree classifier is trained to predict these regimes
using a combination of asset-specific return features and cross-asset
macro-features. We apply this framework individually to each asset in our
universe. Subsequently, return and risk forecasts which incorporate these
regime predictions are input into Markowitz mean-variance optimization to
determine optimal asset allocation weights. We demonstrate the efficacy of our
approach through an empirical study on a multi-asset portfolio comprising
twelve risky assets, including global equity, bond, real estate, and commodity
indexes spanning from 1991 to 2023. The results consistently show
outperformance across various portfolio models, including minimum-variance,
mean-variance, and naive-diversified portfolios, highlighting the advantages of
integrating asset-specific regime forecasts into dynamic asset allocation.
"
2406.10465,2024-06-18,"Constrained mean-variance investment-reinsurance under the
  Cram\'er-Lundberg model with random coefficients","  In this paper, we study an optimal mean-variance investment-reinsurance
problem for an insurer (she) under a Cram\'er-Lundberg model with random
coefficients. At any time, the insurer can purchase reinsurance or acquire new
business and invest her surplus in a security market consisting of a risk-free
asset and multiple risky assets, subject to a general convex cone investment
constraint. We reduce the problem to a constrained stochastic linear-quadratic
control problem with jumps whose solution is related to a system of partially
coupled stochastic Riccati equations (SREs). Then we devote ourselves to
establishing the existence and uniqueness of solutions to the SREs by pure
backward stochastic differential equation (BSDE) techniques. We achieve this
with the help of approximation procedure, comparison theorems for BSDEs with
jumps, log transformation and BMO martingales. The efficient
investment-reinsurance strategy and efficient mean-variance frontier are
explicitly given through the solutions of the SREs, which are shown to be a
linear feedback form of the wealth process and a half-line, respectively.
"
2406.10695,2024-06-18,"Statistical arbitrage in multi-pair trading strategy based on graph
  clustering algorithms in US equities market","  The study seeks to develop an effective strategy based on the novel framework
of statistical arbitrage based on graph clustering algorithms. Amalgamation of
quantitative and machine learning methods, including the Kelly criterion, and
an ensemble of machine learning classifiers have been used to improve
risk-adjusted returns and increase immunity to transaction costs over existing
approaches. The study seeks to provide an integrated approach to optimal signal
detection and risk management. As a part of this approach, innovative ways of
optimizing take profit and stop loss functions for daily frequency trading
strategies have been proposed and tested. All of the tested approaches
outperformed appropriate benchmarks. The best combinations of the techniques
and parameters demonstrated significantly better performance metrics than the
relevant benchmarks. The results have been obtained under the assumption of
realistic transaction costs, but are sensitive to changes in some key
parameters.
"
2406.13486,2025-03-12,"Mean-Variance Portfolio Selection in Long-Term Investments with Unknown
  Distribution: Online Estimation, Risk Aversion under Ambiguity, and
  Universality of Algorithms","  The standard approach for constructing a Mean-Variance portfolio involves
estimating parameters for the model using collected samples. However, since the
distribution of future data may not resemble that of the training set, the
out-of-sample performance of the estimated portfolio is worse than one derived
with true parameters, which has prompted several innovations for better
estimation. Instead of treating the data without a timing aspect as in the
common training-backtest approach, this paper adopts a perspective where data
gradually and continuously reveal over time. The original model is recast into
an online learning framework, which is free from any statistical assumptions,
to propose a dynamic strategy of sequential portfolios such that its empirical
utility, Sharpe ratio, and growth rate asymptotically achieve those of the true
portfolio, derived with perfect knowledge of the future data.
  When the distribution of future data follows a normal shape, the growth rate
of wealth is shown to increase by lifting the portfolio along the efficient
frontier through the calibration of risk aversion. Since risk aversion cannot
be appropriately predetermined, another proposed algorithm updates this
coefficient over time, forming a dynamic strategy that approaches the optimal
empirical Sharpe ratio or growth rate associated with the true coefficient. The
performance of these proposed strategies can be universally guaranteed under
stationary stochastic markets. Furthermore, in certain time-reversible
stochastic markets, the so-called Bayesian strategy utilizing true conditional
distributions, based on past market information during investment, does not
perform better than the proposed strategies in terms of empirical utility,
Sharpe ratio, or growth rate, which, in contrast, do not rely on conditional
distributions.
"
2406.17155,2024-06-26,Optimizing Sparse Mean-Reverting Portfolio,"  Mean-reverting behavior of individuals assets is widely known in financial
markets. In fact, we can construct a portfolio that has mean-reverting behavior
and use it in trading strategies to extract profits. In this paper, we show
that we are able to find the optimal weights of stocks to construct portfolio
that has the fastest mean-reverting behavior. We further add minimum variance
and sparsity constraints to the optimization problem and transform into
Semidefinite Programming (SDP) problem to find the optimal weights. Using the
optimal weights, we empirically compare the performance of contrarian
strategies between non-sparse mean-reverting portfolio and sparse
mean-reverting portfolio to argue that the latter provides higher returns when
we take into account of transaction costs.
"
2406.19105,2024-08-13,"Benchmarking M6 Competitors: An Analysis of Financial Metrics and
  Discussion of Incentives","  The M6 Competition assessed the performance of competitors using a ranked
probability score and an information ratio (IR). While these metrics do well at
picking the winners in the competition, crucial questions remain for investors
with longer-term incentives. To address these questions, we compare the
competitors' performance to a number of conventional (long-only) and
alternative indices using standard industry metrics. We apply factor models to
measure the competitors' value-adds above industry-standard benchmarks and find
that competitors with more extreme performance are less dependent on the
benchmarks. We also uncover that most competitors could not generate
significant out-performance compared to randomly selected long-only and
long-short portfolios but did generate out-performance compared to short-only
portfolios. We further introduce two new strategies by picking the competitors
with the best (Superstars) and worst (Superlosers) recent performance and show
that it is challenging to identify skill amongst investment managers. We also
discuss the incentives of winning the competition compared to professional
investors, where investors wish to maximize fees over an extended period of
time.
"
2406.20063,2025-04-03,"Optimal consumption under loss-averse multiplicative habit-formation
  preferences","  This paper studies a loss-averse version of the multiplicative habit
formation preference and the corresponding optimal investment and consumption
strategies over an infinite horizon. The agent's consumption preference is
depicted by a general S-shaped utility function of her consumption-to-habit
ratio. By considering the concave envelope of the S-shaped utility and the
associated dual value function, we provide a thorough analysis of the HJB
equation for the concavified problem via studying a related nonlinear free
boundary problem. Based on established properties of the solution to this free
boundary problem, we obtain the optimal consumption and investment policies in
feedback form. Some new and technical verification arguments are developed to
cope with generality of the utility function. The equivalence between the
original problem and the concavified problem readily follows from the structure
of the feedback controls. We also discuss some quantitative properties of the
optimal policies, complemented by illustrative numerical examples and their
financial implications.
"
2407.00266,2024-07-02,Vector-valued robust stochastic control,"  We study a dynamic stochastic control problem subject to Knightian
uncertainty with multi-objective (vector-valued) criteria. Assuming the
preferences across expected multi-loss vectors are represented by a given, yet
general, preorder, we address the model uncertainty by adopting a robust or
minimax perspective, minimizing expected loss across the worst-case model. For
loss functions taking real (or scalar) values, there is no ambiguity in
interpreting supremum and infimum. In contrast to the scalar case, major
challenges for multi-loss control problems include properly defining and
interpreting the notions of supremum and infimum, and addressing the
non-uniqueness of these suprema and infima. To deal with these, we employ the
notion of an ideal point vector-valued supremum for the robust part of the
problem, while we view the control part as a multi-objective (or vector)
optimization problem. Using a set-valued framework, we derive both a weak and
strong version of the dynamic programming principle (DPP) or Bellman equations
by taking the value function as the collection of all worst expected losses
across all feasible actions. The weak version of Bellman's principle is proved
under minimal assumptions. To establish a stronger version of DPP, we introduce
the rectangularity property with respect to a general preorder. We also further
study a particular, but important, case of component-wise partial order of
vectors, for which we additionally derive DPP under a different set-valued
notion for the value function, the so-called upper image of the multi-objective
problem. Finally, we provide illustrative examples motivated by financial
problems.
  These results will serve as a foundation for addressing time-inconsistent
problems subject to model uncertainty through the lens of a set-valued
framework, as well as for studying multi-portfolio allocation problems under
model uncertainty.
"
2407.00813,2025-04-21,"Liquidity Adjustment in Multivariate Volatility Modeling: Evidence from
  Portfolios of Cryptocurrencies and US Stocks","  We develop a liquidity-sensitive multivariate volatility framework to improve
the estimation of time-varying covariance structures under market frictions. We
introduce two novel portfolio-level liquidity measures, liquidity jump and
liquidity diffusion, which capture magnitude and volatility of liquidity
fluctuation, respectively, and construct liquidity-adjusted return and
volatility that reflect real-time liquidity variability. These
liquidity-adjusted inputs are integrated into a VECM-DCC/ADCC-Bayesian model,
allowing for conditional and posterior covariance estimation under liquidity
stress. Applying this framework to portfolios of cryptocurrencies and US
stocks, we find that traditional models misrepresent volatility and
co-movement, while liquidity-adjusted models yield more stable and
interpretable risk structures, particularly for portfolios of cryptocurrencies.
The findings support the use of liquidity-adjusted multivariate models as
statistically grounded tools for assessing the propagation of portfolio risk
under market frictions, with implications for asset pricing, market
microstructure design, and portfolio management.
"
2407.00887,2024-10-01,Portfolio optimisation: bridging the gap between theory and practice,"  Portfolio optimisation is essential in quantitative investing, but its
implementation faces several practical difficulties. One particular challenge
is converting optimal portfolio weights into real-life trades in the presence
of realistic features, such as transaction costs and integral lots. This is
especially important in automated trading, where the entire process happens
without human intervention.
  Several works in literature have extended portfolio optimisation models to
account for these features. In this paper, we highlight and illustrate
difficulties faced when employing the existing literature in a practical
setting, such as computational intractability, numerical imprecision and
modelling trade-offs. We then propose a two-stage framework as an alternative
approach to address this issue. Its goal is to optimise portfolio weights in
the first stage and to generate realistic trades in the second. Through
extensive computational experiments, we show that our approach not only
mitigates the difficulties discussed above but also can be successfully
employed in a realistic scenario.
  By splitting the problem in two, we are able to incorporate new features
without adding too much complexity to any single model. With this in mind we
model two novel features that are critical to many investment strategies:
first, we integrate two classes of assets, futures contracts and equities, into
a single framework, with an example illustrating how this can help portfolio
managers in enhancing investment strategies. Second, we account for borrowing
costs in short positions, which have so far been neglected in literature but
which significantly impact profits in long/short strategies. Even with these
new features, our two-stage approach still effectively converts optimal
portfolios into actionable trades.
"
2407.01550,2024-07-23,"Quantitative Investment Diversification Strategies via Various Risk
  Models","  This paper focuses on the developing of high-dimensional risk models to
construct portfolios of securities in the US stock exchange. Investors seek to
gain the highest profits and lowest risk in capital markets. We have developed
various risk models and for each model different investment strategies are
tested. Out of sample tests are performed on a long-term horizon from 1970
until 2023.
"
2407.01572,2025-05-16,"Exploring Sectoral Profitability in the Indian Stock Market Using Deep
  Learning","  This paper explores using a deep learning Long Short-Term Memory (LSTM) model
for accurate stock price prediction and its implications for portfolio design.
Despite the efficient market hypothesis suggesting that predicting stock prices
is impossible, recent research has shown the potential of advanced algorithms
and predictive models. The study builds upon existing literature on stock price
prediction methods, emphasizing the shift toward machine learning and deep
learning approaches. Using historical stock prices of 180 stocks across 18
sectors listed on the NSE, India, the LSTM model predicts future prices. These
predictions guide buy/sell decisions for each stock and analyze sector
profitability. The study's main contributions are threefold: introducing an
optimized LSTM model for robust portfolio design, utilizing LSTM predictions
for buy/sell transactions, and insights into sector profitability and
volatility. Results demonstrate the efficacy of the LSTM model in accurately
predicting stock prices and informing investment decisions. By comparing sector
profitability and prediction accuracy, the work provides valuable insights into
the dynamics of the current financial markets in India.
"
2407.02831,2024-07-04,"Robust optimal investment and consumption strategies with portfolio
  constraints and stochastic environment","  We investigate a continuous-time investment-consumption problem with model
uncertainty in a general diffusion-based market with random model coefficients.
We assume that a power utility investor is ambiguity-averse, with the
preference to robustness captured by the homothetic multiplier robust
specification, and the investor's investment and consumption strategies are
constrained to closed convex sets. To solve this constrained robust control
problem, we employ the stochastic Hamilton-Jacobi-Bellman-Isaacs equations,
backward stochastic differential equations, and bounded mean oscillation
martingale theory. Furthermore, we show the investor incurs (non-negative)
utility loss, i.e. the loss in welfare, if model uncertainty is ignored. When
the model coefficients are deterministic, we establish formally the
relationship between the investor's robustness preference and the robust
optimal investment-consumption strategy and the value function, and the impact
of investment and consumption constraints on the investor's robust optimal
investment-consumption strategy and value function. Extensive numerical
experiments highlight the significant impact of ambiguity aversion, consumption
and investment constraints, on the investor's robust optimal
investment-consumption strategy, utility loss, and value function. Key findings
include: 1) short-selling restriction always reduces the investor's utility
loss when model uncertainty is ignored; 2) the effect of consumption
constraints on utility loss is more delicate and relies on the investor's risk
aversion level.
"
2407.04500,2024-07-08,"Longitudinal market structure detection using a dynamic
  modularity-spectral algorithm","  In this paper, we introduce the Dynamic Modularity-Spectral Algorithm
(DynMSA), a novel approach to identify clusters of stocks with high
intra-cluster correlations and low inter-cluster correlations by combining
Random Matrix Theory with modularity optimisation and spectral clustering. The
primary objective is to uncover hidden market structures and find diversifiers
based on return correlations, thereby achieving a more effective risk-reducing
portfolio allocation. We applied DynMSA to constituents of the S&P 500 and
compared the results to sector- and market-based benchmarks. Besides the
conception of this algorithm, our contributions further include implementing a
sector-based calibration for modularity optimisation and a correlation-based
distance function for spectral clustering. Testing revealed that DynMSA
outperforms baseline models in intra- and inter-cluster correlation
differences, particularly over medium-term correlation look-backs. It also
identifies stable clusters and detects regime changes due to exogenous shocks,
such as the COVID-19 pandemic. Portfolios constructed using our clusters showed
higher Sortino and Sharpe ratios, lower downside volatility, reduced maximum
drawdown and higher annualised returns compared to an equally weighted market
benchmark.
"
2407.05912,2024-07-23,"Constructing an Investment Fund through Stock Clustering and Integer
  Programming","  This paper focuses on the application of quantitative portfolio management by
using integer programming and clustering techniques. Investors seek to gain the
highest profits and lowest risk in capital markets. A data-oriented analysis of
US stock universe is used to provide portfolio managers a device to track
different Exchange Traded Funds. As an example, reconstructing of NASDAQ 100
index fund is presented.
"
2407.07100,2024-07-11,Asymptotic methods for transaction costs,"  We propose a general approximation method for determining optimal trading
strategies in markets with proportional transaction costs, with a polynomial
approximation of the residual value function. The method is exemplified by
several problems from optimally tracking benchmarks, hedging the Log contract,
to maximizing utility from terminal wealth. Strategies are also approximated by
practically executable, discrete trades. We identify the necessary trade-off
between trading frequency and trade sizes to have satisfactory agreement with
the theoretically optimal, continuous strategies of infinite activity.
"
2407.08748,2024-07-15,Covariance Matrix Analysis for Optimal Portfolio Selection,"  In portfolio risk minimization, the inverse covariance matrix of returns is
often unknown and has to be estimated in practice. This inverse covariance
matrix also prescribes the hedge trades in which a stock is hedged by all the
other stocks in the portfolio. In practice with finite samples, however,
multicollinearity gives rise to considerable estimation errors, making the
hedge trades too unstable and unreliable for use. By adopting ideas from
current methodologies in the existing literature, we propose 2 new estimators
of the inverse covariance matrix, one which relies only on the l2 norm while
the other utilizes both the l1 and l2 norms. These 2 new estimators are
classified as shrinkage estimators in the literature. Comparing favorably with
other methods (sample-based estimation, equal-weighting, estimation based on
Principal Component Analysis), a portfolio formed on the proposed estimators
achieves substantial out-of-sample risk reduction and improves the
out-of-sample risk-adjusted returns of the portfolio, particularly in
high-dimensional settings. Furthermore, the proposed estimators can still be
computed even in instances where the sample covariance matrix is
ill-conditioned or singular
"
2407.08756,2024-07-15,Examples and Counterexamples of Cost-efficiency in Incomplete Markets,"  We present a number of examples and counterexamples to illustrate the results
on cost-efficiency in an incomplete market obtained in [BS24]. These examples
and counterexamples do not only illustrate the results obtained in [BS24], but
show the limitations of the results and the sharpness of the key assumptions.
In particular, we make use of a simple 3-state model in which we are able to
recover and illustrate all key results of the paper. This example also shows
how our characterization of perfectly cost-efficient claims allows to solve an
expected utility maximization problem in a simple incomplete market (trinomial
model) and recover results from [DS06, Chapter 3], there obtained using
duality.
"
2407.09536,2024-07-16,"The Blockchain Risk Parity Line: Moving From The Efficient Frontier To
  The Final Frontier Of Investments","  We engineer blockchain based risk managed portfolios by creating three funds
with distinct risk and return profiles: 1) Alpha - high risk portfolio; 2) Beta
- mimics the wider market; and 3) Gamma - represents the risk free rate
adjusted to beat inflation. Each of the sub-funds (Alpha, Beta and Gamma)
provides risk parity because the weight of each asset in the corresponding
portfolio is set to be inversely proportional to the risk derived from
investing in that asset. This can be equivalently stated as equal risk
contributions from each asset towards the overall portfolio risk.
  We provide detailed mechanics of combining assets - including mathematical
formulations - to obtain better risk managed portfolios. The descriptions are
intended to show how a risk parity based efficient frontier portfolio
management engine - that caters to different risk appetites of investors by
letting each individual investor select their preferred risk-return combination
- can be created seamlessly on blockchain.
  Any Investor - using decentralized ledger technology - can select their
desired level of risk, or return, and allocate their wealth accordingly among
the sub funds, which balance one another under different market conditions.
This evolution of the risk parity principle - resulting in a mechanism that is
geared to do well under all market cycles - brings more robust performance and
can be termed as conceptual parity.
  We have given several numerical examples that illustrate the various
scenarios that arise when combining Alpha, Beta and Gamma to obtain Parity.
  The final investment frontier is now possible - a modification to the
efficient frontier, thus becoming more than a mere theoretical construct - on
blockchain since anyone from anywhere can participate at anytime to obtain
wealth appreciation based on their financial goals.
"
2407.10175,2024-07-16,"Low Volatility Stock Portfolio Through High Dimensional Bayesian
  Cointegration","  We employ a Bayesian modelling technique for high dimensional cointegration
estimation to construct low volatility portfolios from a large number of
stocks. The proposed Bayesian framework effectively identifies sparse and
important cointegration relationships amongst large baskets of stocks across
various asset spaces, resulting in portfolios with reduced volatility. Such
cointegration relationships persist well over the out-of-sample testing time,
providing practical benefits in portfolio construction and optimization.
Further studies on drawdown and volatility minimization also highlight the
benefits of including cointegrated portfolios as risk management instruments.
"
2407.12150,2024-07-18,"To Trade Or Not To Trade: Cascading Waterfall Round Robin Rebalancing
  Mechanism for Cryptocurrencies","  We have designed an innovative portfolio rebalancing mechanism termed the
Cascading Waterfall Round Robin Mechanism. This algorithmic approach recommends
an ideal size and number of trades for each asset during the periodic
rebalancing process, factoring in the gas fee and slippage. The essence of the
model we have created gives indications regarding whether trades should be made
on individual assets depending on the uncertainty in the micro - asset level
characteristics - and macro - aggregate market factors - environments. In the
hyper-volatile crypto market, our approach to daily rebalancing will benefit
from volatility. Price movements will cause our algorithm to buy assets that
drop in prices and sell as they soar. In fact, the buying and selling happen
only when certain boundaries are crossed in order to weed out any market noise
and ensure sound trade execution. We have provided several numerical examples
to illustrate the steps - including the calculation of several intermediate
variables - of our rebalancing mechanism. The Algorithm we have developed can
be easily applied outside blockchain to investment funds across all asset
classes at any trading frequency and rebalancing duration.
  Shakespeare As A Crypto Trader:
  To Trade Or Not To Trade, that is the Question,
  Whether an Optimizer can Yield the Answer,
  Against the Spikes and Crashes of Markets Gone Wild,
  To Quench One's Thirst before Liquidity Runs Dry,
  Or Wait till the Tide of Momentum turns Mild.
"
2407.13908,2024-07-22,Construction and Hedging of Equity Index Options Portfolios,"  This research presents a comprehensive evaluation of systematic index
option-writing strategies, focusing on S&P500 index options. We compare the
performance of hedging strategies using the Black-Scholes-Merton (BSM) model
and the Variance-Gamma (VG) model, emphasizing varying moneyness levels and
different sizing methods based on delta and the VIX Index. The study employs
1-minute data of S&P500 index options and index quotes spanning from 2018 to
2023. The analysis benchmarks hedged strategies against buy-and-hold and naked
option-writing strategies, with a focus on risk-adjusted performance metrics
including transaction costs. Portfolio delta approximations are derived using
implied volatility for the BSM model and market-calibrated parameters for the
VG model. Key findings reveal that systematic option-writing strategies can
potentially yield superior returns compared to buy-and-hold benchmarks. The BSM
model generally provided better hedging outcomes than the VG model, although
the VG model showed profitability in certain naked strategies as a tool for
position sizing. In terms of rehedging frequency, we found that intraday
hedging in 130-minute intervals provided both reliable protection against
adverse market movements and a satisfactory returns profile.
"
2407.14486,2024-07-22,"Explainable Post hoc Portfolio Management Financial Policy of a Deep
  Reinforcement Learning agent","  Financial portfolio management investment policies computed quantitatively by
modern portfolio theory techniques like the Markowitz model rely on a set on
assumptions that are not supported by data in high volatility markets. Hence,
quantitative researchers are looking for alternative models to tackle this
problem. Concretely, portfolio management is a problem that has been
successfully addressed recently by Deep Reinforcement Learning (DRL)
approaches. In particular, DRL algorithms train an agent by estimating the
distribution of the expected reward of every action performed by an agent given
any financial state in a simulator. However, these methods rely on Deep Neural
Networks model to represent such a distribution, that although they are
universal approximator models, they cannot explain its behaviour, given by a
set of parameters that are not interpretable. Critically, financial investors
policies require predictions to be interpretable, so DRL agents are not suited
to follow a particular policy or explain their actions. In this work, we
developed a novel Explainable Deep Reinforcement Learning (XDRL) approach for
portfolio management, integrating the Proximal Policy Optimization (PPO) with
the model agnostic explainable techniques of feature importance, SHAP and LIME
to enhance transparency in prediction time. By executing our methodology, we
can interpret in prediction time the actions of the agent to assess whether
they follow the requisites of an investment policy or to assess the risk of
following the agent suggestions. To the best of our knowledge, our proposed
approach is the first explainable post hoc portfolio management financial
policy of a DRL agent. We empirically illustrate our methodology by
successfully identifying key features influencing investment decisions, which
demonstrate the ability to explain the agent actions in prediction time.
"
2407.15532,2025-02-05,"Large-scale Time-Varying Portfolio Optimisation using Graph Attention
  Networks","  Apart from assessing individual asset performance, investors in financial
markets also need to consider how a set of firms performs collectively as a
portfolio. Whereas traditional Markowitz-based mean-variance portfolios are
widespread, network-based optimisation techniques offer a more flexible tool to
capture complex interdependencies between asset values. However, most of the
existing studies do not contain firms at risk of default and remove any firms
that drop off indices over a certain time. This is the first study to also
incorporate such firms in portfolio optimisation on a large scale. We propose
and empirically test a novel method that leverages Graph Attention networks
(GATs), a subclass of Graph Neural Networks (GNNs). GNNs, as deep
learning-based models, can exploit network data to uncover nonlinear
relationships. Their ability to handle high-dimensional data and accommodate
customised layers for specific purposes makes them appealing for large-scale
problems such as mid- and small-cap portfolio optimisation. This study utilises
30 years of data on mid-cap firms, creating graphs of firms using distance
correlation and the Triangulated Maximally Filtered Graph approach. These
graphs are the inputs to a GAT model incorporating weight and allocation
constraints and a loss function derived from the Sharpe ratio, thus focusing on
maximising portfolio risk-adjusted returns. This new model is benchmarked
against a network characteristic-based portfolio, a mean variance-based
portfolio, and an equal-weighted portfolio. The results show that the portfolio
produced by the GAT-based model outperforms all benchmarks and is consistently
superior to other strategies over a long period, while also being informative
of market dynamics.
"
2407.16437,2024-07-24,"Multi-Industry Simplex 2.0 : Temporally-Evolving Probabilistic Industry
  Classification","  Accurate industry classification is critical for many areas of portfolio
management, yet the traditional single-industry framework of the Global
Industry Classification Standard (GICS) struggles to comprehensively represent
risk for highly diversified multi-sector conglomerates like Amazon. Previously,
we introduced the Multi-Industry Simplex (MIS), a probabilistic extension of
GICS that utilizes topic modeling, a natural language processing approach.
Although our initial version, MIS-1, was able to improve upon GICS by providing
multi-industry representations, it relied on an overly simple architecture that
required prior knowledge about the number of industries and relied on the
unrealistic assumption that industries are uncorrelated and independent over
time. We improve upon this model with MIS-2, which addresses three key
limitations of MIS-1 : we utilize Bayesian Non-Parametrics to automatically
infer the number of industries from data, we employ Markov Updating to account
for industries that change over time, and we adjust for correlated and
hierarchical industries allowing for both broad and niche industries (similar
to GICS). Further, we provide an out-of-sample test directly comparing MIS-2
and GICS on the basis of future correlation prediction, where we find evidence
that MIS-2 provides a measurable improvement over GICS. MIS-2 provides
portfolio managers with a more robust tool for industry classification,
empowering them to more effectively identify and manage risk, particularly
around multi-sector conglomerates in a rapidly evolving market in which new
industries periodically emerge.
"
2407.16780,2024-07-25,"The Hybrid Forecast of S&P 500 Volatility ensembled from VIX, GARCH and
  LSTM models","  Predicting the S&P 500 index volatility is crucial for investors and
financial analysts as it helps assess market risk and make informed investment
decisions. Volatility represents the level of uncertainty or risk related to
the size of changes in a security's value, making it an essential indicator for
financial planning. This study explores four methods to improve the accuracy of
volatility forecasts for the S&P 500: the established GARCH model, known for
capturing historical volatility patterns; an LSTM network that utilizes past
volatility and log returns; a hybrid LSTM-GARCH model that combines the
strengths of both approaches; and an advanced version of the hybrid model that
also factors in the VIX index to gauge market sentiment. This analysis is based
on a daily dataset that includes S&P 500 and VIX index data, covering the
period from January 3, 2000, to December 21, 2023. Through rigorous testing and
comparison, we found that machine learning approaches, particularly the hybrid
LSTM models, significantly outperform the traditional GARCH model. Including
the VIX index in the hybrid model further enhances its forecasting ability by
incorporating real-time market sentiment. The results of this study offer
valuable insights for achieving more accurate volatility predictions, enabling
better risk management and strategic investment decisions in the volatile
environment of the S&P 500.
"
2407.17645,2024-07-26,Hopfield Networks for Asset Allocation,"  We present the first application of modern Hopfield networks to the problem
of portfolio optimization. We performed an extensive study based on
combinatorial purged cross-validation over several datasets and compared our
results to both traditional and deep-learning-based methods for portfolio
selection. Compared to state-of-the-art deep-learning methods such as
Long-Short Term Memory networks and Transformers, we find that the proposed
approach performs on par or better, while providing faster training times and
better stability. Our results show that Modern Hopfield Networks represent a
promising approach to portfolio optimization, allowing for an efficient,
scalable, and robust solution for asset allocation, risk management, and
dynamic rebalancing.
"
2407.17866,2025-02-24,Financial Statement Analysis with Large Language Models,"  We investigate whether large language models (LLMs) can successfully perform
financial statement analysis in a way similar to a professional human analyst.
We provide standardized and anonymous financial statements to GPT4 and instruct
the model to analyze them to determine the direction of firms' future earnings.
Even without narrative or industry-specific information, the LLM outperforms
financial analysts in its ability to predict earnings changes directionally.
The LLM exhibits a relative advantage over human analysts in situations when
the analysts tend to struggle. Furthermore, we find that the prediction
accuracy of the LLM is on par with a narrowly trained state-of-the-art ML
model. LLM prediction does not stem from its training memory. Instead, we find
that the LLM generates useful narrative insights about a company's future
performance. Lastly, our trading strategies based on GPT's predictions yield a
higher Sharpe ratio and alphas than strategies based on other models. Our
results suggest that LLMs may take a central role in analysis and
decision-making.
"
2407.18103,2024-08-06,"Fine-Tuning Large Language Models for Stock Return Prediction Using
  Newsflow","  Large language models (LLMs) and their fine-tuning techniques have
demonstrated superior performance in various language understanding and
generation tasks. This paper explores fine-tuning LLMs for stock return
forecasting with financial newsflow. In quantitative investing, return
forecasting is fundamental for subsequent tasks like stock picking, portfolio
optimization, etc. We formulate the model to include text representation and
forecasting modules. We propose to compare the encoder-only and decoder-only
LLMs, considering they generate text representations in distinct ways. The
impact of these different representations on forecasting performance remains an
open question. Meanwhile, we compare two simple methods of integrating LLMs'
token-level representations into the forecasting module. The experiments on
real news and investment universes reveal that: (1) aggregated representations
from LLMs' token-level embeddings generally produce return predictions that
enhance the performance of long-only and long-short portfolios; (2) in the
relatively large investment universe, the decoder LLMs-based prediction model
leads to stronger portfolios, whereas in the small universes, there are no
consistent winners. Among the three LLMs studied (DeBERTa, Mistral, Llama),
Mistral performs more robustly across different universes; (3) return
predictions derived from LLMs' text representations are a strong signal for
portfolio construction, outperforming conventional sentiment scores.
"
2407.19190,2025-03-04,"Optimal retirement in presence of stochastic labor income: a free
  boundary approach in an incomplete market","  In this work, we address the optimal retirement problem in the presence of a
stochastic wage, formulated as a free boundary problem. Specifically, we
explore an incomplete market setting where the wage cannot be perfectly hedged
through investments in the risk-free and risky assets that characterize the
financial market.
"
2407.19857,2024-07-30,PO-QA: A Framework for Portfolio Optimization using Quantum Algorithms,"  Portfolio Optimization (PO) is a financial problem aiming to maximize the net
gains while minimizing the risks in a given investment portfolio. The novelty
of Quantum algorithms lies in their acclaimed potential and capability to solve
complex problems given the underlying Quantum Computing (QC) infrastructure.
Utilizing QC's applicable strengths to the finance industry's problems, such as
PO, allows us to solve these problems using quantum-based algorithms such as
Variational Quantum Eigensolver (VQE) and Quantum Approximate Optimization
Algorithm (QAOA). While the Quantum potential for finance is highly impactful,
the architecture and composition of the quantum circuits have not yet been
properly defined as robust financial frameworks/algorithms as state of the art
in present literature for research and design development purposes. In this
work, we propose a novel scalable framework, denoted PO-QA, to systematically
investigate the variation of quantum parameters (such as rotation blocks,
repetitions, and entanglement types) to observe their subtle effect on the
overall performance. In our paper, the performance is measured and dictated by
convergence to similar ground-state energy values for resultant optimal
solutions by each algorithm variation set for QAOA and VQE to the exact
eigensolver (classical solution). Our results provide effective insights into
comprehending PO from the lens of Quantum Machine Learning in terms of
convergence to the classical solution, which is used as a benchmark. This study
paves the way for identifying efficient configurations of quantum circuits for
solving PO and unveiling their inherent inter-relationships.
"
2407.19858,2024-08-27,"AI-Powered Energy Algorithmic Trading: Integrating Hidden Markov Models
  with Neural Networks","  In quantitative finance, machine learning methods are essential for alpha
generation. This study introduces a new approach that combines Hidden Markov
Models (HMM) and neural networks, integrated with Black-Litterman portfolio
optimization. During the COVID period (2019-2022), this dual-model approach
achieved a 83% return with a Sharpe ratio of 0.77. It incorporates two risk
models to enhance risk management, showing efficiency during volatile periods.
The methodology was implemented on the QuantConnect platform, which was chosen
for its robust framework and experimental reproducibility. The system, which
predicts future price movements, includes a three-year warm-up to ensure proper
algorithm function. It targets highly liquid, large-cap energy stocks to ensure
stable and predictable performance while also considering broker payments. The
dual-model alpha system utilizes log returns to select the optimal state based
on the historical performance. It combines state predictions with neural
network outputs, which are based on historical data, to generate trading
signals. This study examined the architecture of the trading system, data
pre-processing, training, and performance. The full code and backtesting data
are available under the QuantConnect terms.
"
2407.19936,2024-07-30,"Risk management in multi-objective portfolio optimization under
  uncertainty","  In portfolio optimization, decision makers face difficulties from
uncertainties inherent in real-world scenarios. These uncertainties
significantly influence portfolio outcomes in both classical and
multi-objective Markowitz models. To address these challenges, our research
explores the power of robust multi-objective optimization. Since portfolio
managers frequently measure their solutions against benchmarks, we enhance the
multi-objective min-regret robustness concept by incorporating these benchmark
comparisons.
  This approach bridges the gap between theoretical models and real-world
investment scenarios, offering portfolio managers more reliable and adaptable
strategies for navigating market uncertainties. Our framework provides a more
nuanced and practical approach to portfolio optimization under real-world
conditions.
"
2407.20352,2024-07-31,Designing Time-Series Models With Hypernetworks & Adversarial Portfolios,"  This article describes the methods that achieved 4th and 6th place in the
forecasting and investment challenges, respectively, of the M6 competition,
ultimately securing the 1st place in the overall duathlon ranking. In the
forecasting challenge, we tested a novel meta-learning model that utilizes
hypernetworks to design a parametric model tailored to a specific family of
forecasting tasks. This approach allowed us to leverage similarities observed
across individual forecasting tasks while also acknowledging potential
heterogeneity in their data generating processes. The model's training can be
directly performed with backpropagation, eliminating the need for reliance on
higher-order derivatives and is equivalent to a simultaneous search over the
space of parametric functions and their optimal parameter values. The proposed
model's capabilities extend beyond M6, demonstrating superiority over
state-of-the-art meta-learning methods in the sinusoidal regression task and
outperforming conventional parametric models on time-series from the M4
competition. In the investment challenge, we adjusted portfolio weights to
induce greater or smaller correlation between our submission and that of other
participants, depending on the current ranking, aiming to maximize the
probability of achieving a good rank.
"
2407.20380,2024-07-31,"Inferring financial stock returns correlation from complex network
  analysis","  Financial stock returns correlations have been studied in the prism of random
matrix theory, to distinguish the signal from the ""noise"". Eigenvalues of the
matrix that are above the rescaled Marchenko Pastur distribution can be
interpreted as collective modes behavior while the modes under are usually
considered as noise. In this analysis we use complex network analysis to
simulate the ""noise"" and the ""market"" component of the return correlations, by
introducing some meaningful correlations in simulated geometric Brownian motion
for the stocks. We find that the returns correlation matrix is dominated by
stocks with high eigenvector centrality and clustering found in the network. We
then use simulated ""market"" random walks to build an optimal portfolio and find
that the overall return performs better than using the historical mean-variance
data, up to 50% on short time scale.
"
2407.21148,2024-08-01,"On the optimal design of a new class of proportional portfolio insurance
  strategies in a jump-diffusion framework","  In this paper, we investigate an optimal investment problem associated with
proportional portfolio insurance (PPI) strategies in the presence of jumps in
the underlying dynamics. PPI strategies enable investors to mitigate downside
risk while still retaining the potential for upside gains. This is achieved by
maintaining an exposure to risky assets proportional to the difference between
the portfolio value and the present value of the guaranteed amount. While PPI
strategies are known to be free of downside risk in diffusion modeling
frameworks with continuous trading, see e.g., Cont and Tankov (2009), real
market applications exhibit a significant non-negligible risk, known as gap
risk, which increases with the multiplier value. The goal of this paper is to
determine the optimal PPI strategy in a setting where gap risk may occur, due
to downward jumps in the asset price dynamics. We consider a loss-averse agent
who aims at maximizing the expected utility of the terminal wealth exceeding a
minimum guarantee. Technically, we model agent's preferences with an S-shaped
utility functions to accommodate the possibility that gap risk occurs, and
address the optimization problem via a generalization of the martingale
approach that turns to be valid under market incompleteness in a jump-diffusion
framework.
"
2407.21791,2024-11-22,Deep Learning for Options Trading: An End-To-End Approach,"  We introduce a novel approach to options trading strategies using a highly
scalable and data-driven machine learning algorithm. In contrast to traditional
approaches that often require specifications of underlying market dynamics or
assumptions on an option pricing model, our models depart fundamentally from
the need for these prerequisites, directly learning non-trivial mappings from
market data to optimal trading signals. Backtesting on more than a decade of
option contracts for equities listed on the S&P 100, we demonstrate that deep
learning models trained according to our end-to-end approach exhibit
significant improvements in risk-adjusted performance over existing rules-based
trading strategies. We find that incorporating turnover regularization into the
models leads to further performance enhancements at prohibitively high levels
of transaction costs.
"
2408.01772,2024-08-06,Investment strategies based on forecasts are (almost) useless,"  Several studies on portfolio construction reveal that sensible strategies
essentially yield the same results as their nonsensical inverted counterparts;
moreover, random portfolios managed by Malkiel's dart-throwing monkey would
outperform the cap-weighted benchmark index. Forecasting the future development
of stock returns is an important aspect of portfolio assessment. Similar to the
ostensible arbitrariness of portfolio selection methods, it is shown that there
is no substantial difference between the performances of ``best'' and
``trivial'' forecasts - even under euphemistic model assumptions on the
underlying price dynamics. A certain significance of a predictor is found only
in the following special case: the best linear unbiased forecast is used, the
planning horizon is small, and a critical relation is not satisfied.
"
2408.03320,2025-02-17,"Hedge Fund Portfolio Construction Using PolyModel Theory and
  iTransformer","  When constructing portfolios, a key problem is that a lot of financial time
series data are sparse, making it challenging to apply machine learning
methods. Polymodel theory can solve this issue and demonstrate superiority in
portfolio construction from various aspects. To implement the PolyModel theory
for constructing a hedge fund portfolio, we begin by identifying an asset pool,
utilizing over 10,000 hedge funds for the past 29 years' data. PolyModel theory
also involves choosing a wide-ranging set of risk factors, which includes
various financial indices, currencies, and commodity prices. This comprehensive
selection mirrors the complexities of the real-world environment. Leveraging on
the PolyModel theory, we create quantitative measures such as Long-term Alpha,
Long-term Ratio, and SVaR. We also use more classical measures like the Sharpe
ratio or Morningstar's MRAR. To enhance the performance of the constructed
portfolio, we also employ the latest deep learning techniques (iTransformer) to
capture the upward trend, while efficiently controlling the downside, using all
the features. The iTransformer model is specifically designed to address the
challenges in high-dimensional time series forecasting and could largely
improve our strategies. More precisely, our strategies achieve better Sharpe
ratio and annualized return. The above process enables us to create multiple
portfolio strategies aiming for high returns and low risks when compared to
various benchmarks.
"
2408.05382,2024-08-13,"Optimizing Portfolio with Two-Sided Transactions and Lending: A
  Reinforcement Learning Framework","  This study presents a Reinforcement Learning (RL)-based portfolio management
model tailored for high-risk environments, addressing the limitations of
traditional RL models and exploiting market opportunities through two-sided
transactions and lending. Our approach integrates a new environmental
formulation with a Profit and Loss (PnL)-based reward function, enhancing the
RL agent's ability in downside risk management and capital optimization. We
implemented the model using the Soft Actor-Critic (SAC) agent with a
Convolutional Neural Network with Multi-Head Attention (CNN-MHA). This setup
effectively manages a diversified 12-crypto asset portfolio in the Binance
perpetual futures market, leveraging USDT for both granting and receiving loans
and rebalancing every 4 hours, utilizing market data from the preceding 48
hours. Tested over two 16-month periods of varying market volatility, the model
significantly outperformed benchmarks, particularly in high-volatility
scenarios, achieving higher return-to-risk ratios and demonstrating robust
profitability. These results confirm the model's effectiveness in leveraging
market dynamics and managing risks in volatile environments like the
cryptocurrency market.
"
2408.07432,2024-08-15,"Portfolio and reinsurance optimization under unknown market price of
  risk","  We investigate the optimal investment-reinsurance problem for insurance
company with partial information on the market price of the risk. Through the
use of filtering techniques we convert the original optimization problem
involving different filtrations, into an equivalent stochastic control problem
under the observation filtration only, the so-called separated problem. The
Markovian structure of the separated problem allows us to apply a classical
approach to stochastic optimization based on the Hamilton-Jacobi-Bellman
equation, and to provide explicit formulas for the value function and the
optimal investment-reinsurance strategy. We finally discuss some comparisons
between the optimal strategies pursued by a partially informed insurer and that
followed by a fully informed insurer, and we evaluate the value of information
using the idea of indifference pricing. These results are also supported by
numerical experiments.
"
2408.07497,2024-08-15,"Predicting the distributions of stock returns around the globe in the
  era of big data and learning","  This paper presents a method for accurately predicting the full distribution
of stock returns, given a comprehensive set of 194 stock characteristics and
market variables. Such distributions, learned from rich data using a machine
learning algorithm, are not constrained by restrictive model assumptions and
allow the exploration of non-Gaussian, heavy-tailed data and their non-linear
interactions. The method uses a two-stage quantile neural network combined with
spline interpolation. The results show that the proposed approach outperforms
alternative models in terms of out-of-sample losses. Furthermore, we show that
the moments derived from such distributions can be useful as alternative
empirical estimates in many cases, including mean estimation and forecasting.
Finally, we examine the relationship between cross-sectional returns and
several distributional characteristics. The results are robust to a wide range
of US and international data.
"
2408.07879,2024-08-16,On Accelerating Large-Scale Robust Portfolio Optimization,"  Solving large-scale robust portfolio optimization problems is challenging due
to the high computational demands associated with an increasing number of
assets, the amount of data considered, and market uncertainty. To address this
issue, we propose an extended supporting hyperplane approximation approach for
efficiently solving a class of distributionally robust portfolio problems for a
general class of additively separable utility functions and polyhedral
ambiguity distribution set, applied to a large-scale set of assets. Our
technique is validated using a large-scale portfolio of the S&P 500 index
constituents, demonstrating robust out-of-sample trading performance. More
importantly, our empirical studies show that this approach significantly
reduces computational time compared to traditional concave Expected Log-Growth
(ELG) optimization, with running times decreasing from several thousand seconds
to just a few. This method provides a scalable and practical solution to
large-scale robust portfolio optimization, addressing both theoretical and
practical challenges.
"
2408.08483,2024-08-19,"Enhancement of price trend trading strategies via image-induced
  importance weights","  We open up the ""black-box"" to identify the predictive general price patterns
in price chart images via the deep learning image analysis techniques. Our
identified price patterns lead to the construction of image-induced importance
(triple-I) weights, which are applied to weighted moving average the existing
price trend trading signals according to their level of importance in
predicting price movements. From an extensive empirical analysis on the Chinese
stock market, we show that the triple-I weighting scheme can significantly
enhance the price trend trading signals for proposing portfolios, with a
thoughtful robustness study in terms of network specifications, image
structures, and stock sizes. Moreover, we demonstrate that the triple-I
weighting scheme is able to propose long-term portfolios from a time-scale
transfer learning, enhance the news-based trading strategies through a
non-technical transfer learning, and increase the overall strength of numerous
trading rules for portfolio selection.
"
2408.10785,2024-08-21,Hedging in Jump Diffusion Model with Transaction Costs,"  We consider the jump-diffusion risky asset model and study its conditional
prediction laws. Next, we explain the conditional least square hedging strategy
and calculate its closed form for the jump-diffusion model, considering the
Black-Scholes framework with interpretations related to investor priorities and
transaction costs. We investigate the explicit form of this result for the
particular case of the European call option under transaction costs and
formulate recursive hedging strategies. Finally, we present a decision tree,
table of values, and figures to support our results.
"
2408.11739,2025-04-01,Network-based diversification of stock and cryptocurrency portfolios,"  Maintaining a balance between returns and volatility is a common strategy for
portfolio diversification, whether investing in traditional equities or digital
assets like cryptocurrencies. One approach for diversification is the
application of community detection or clustering, using a network representing
the relationships between assets. We examine two network representations, one
based on a standard distance matrix based on correlation, and another based on
mutual information. The Louvain and Affinity propagation algorithms were
employed for finding the network communities (clusters) based on annual data.
Furthermore, we examine building assets' co-occurrence networks, where
communities are detected for each month throughout a whole year and then the
links represent how often assets belong to the same community. Portfolios are
then constructed by selecting several assets from each community based on local
properties (degree centrality), global properties (closeness centrality), or
explained variance (Principal component analysis), with three value ranges
(max, med, min), calculated on a maximal spanning tree or a fully connected
community sub-graph. We explored these various strategies on data from the S\&P
500 and the Top 203 cryptocurrencies with a market cap above 2M USD in the
period from Jan 2019 to Sep 2022. Moreover, we study into more details the
periods of the beginning of the COVID-19 outbreak and the start of the war in
Ukraine. The results confirm some of the previous findings already known for
traditional stock markets and provide some further insights, while they reveal
an opposing trend in the crypto-assets market.
"
2408.11740,2024-08-22,"Less is more: AI Decision-Making using Dynamic Deep Neural Networks for
  Short-Term Stock Index Prediction","  In this paper we introduce a multi-agent deep-learning method which trades in
the Futures markets based on the US S&P 500 index. The method (referred to as
Model A) is an innovation founded on existing well-established machine-learning
models which sample market prices and associated derivatives in order to decide
whether the investment should be long/short or closed (zero exposure), on a
day-to-day decision. We compare the predictions with some conventional
machine-learning methods namely, Long Short-Term Memory, Random Forest and
Gradient-Boosted-Trees. Results are benchmarked against a passive model in
which the Futures contracts are held (long) continuously with the same exposure
(level of investment). Historical tests are based on daily daytime trading
carried out over a period of 6 calendar years (2018-23). We find that Model A
outperforms the passive investment in key performance metrics, placing it
within the top quartile performance of US Large Cap active fund managers. Model
A also outperforms the three machine-learning classification comparators over
this period. We observe that Model A is extremely efficient (doing less and
getting more) with an exposure to the market of only 41.95% compared to the
100% market exposure of the passive investment, and thus provides increased
profitability with reduced risk.
"
2408.14476,2024-08-28,A new approach to the theory of optimal income tax,"  The Nobel-price winning Mirrlees' theory of optimal taxation inspired a long
sequence of research on its refinement and enhancement. However, an issue of
concern has been always the fact that, as was shown in many publications, the
optimal schedule in Mirrlees' paradigm of maximising the total utility
(constructed from individually optimised individual ones) usually did not lead
to progressive taxation (contradicting the ethically supported practice in
developed economies), and often even assigned minimal tax rates to the higher
paid strata of society. The first objective of this paper is to support this
conclusion by proving a theorem on optimal tax schedule in (practically most
exploited) piecewise-linear environment under a simplest natural utility
function. The second objective is to suggest a new paradigm for optimal
taxation, where instead of just total average utility maximization one
introduces a standard deviation of utility as a second parameter (in some
analogy with Marcowitz portfolio optimization). We show that this approach
leads to transparent and easy interpreted optimality criteria for income tax.
"
2409.00416,2024-09-04,Betting Against (Bad) Beta,"  Frazzini and Pedersen (2014) Betting Against Beta (BAB) factor is based on
the idea that high beta assets trade at a premium and low beta assets trade at
a discount due to investor funding constraints. However, as argued by Campbell
and Vuolteenaho (2004), beta comes in ""good"" and ""bad"" varieties. While gaining
exposure to low-beta, BAB factors fail to recognize that such a portfolio may
tilt towards bad-beta. We propose a Betting Against Bad Beta factor, built by
double-sorting on beta and bad-beta and find that it improves the overall
performance of BAB strategies though its success relies on proper transaction
cost mitigation.
"
2409.06289,2025-05-22,Automate Strategy Finding with LLM in Quant Investment,"  We present a novel three-stage framework leveraging Large Language Models
(LLMs) within a risk-aware multi-agent system for automate strategy finding in
quantitative finance. Our approach addresses the brittleness of traditional
deep learning models in financial applications by: employing prompt-engineered
LLMs to generate executable alpha factor candidates across diverse financial
data, implementing multimodal agent-based evaluation that filters factors based
on market status, predictive quality while maintaining category balance, and
deploying dynamic weight optimization that adapts to market conditions.
Experimental results demonstrate the robust performance of the strategy in
Chinese & US market regimes compared to established benchmarks. Our work
extends LLMs capabilities to quantitative trading, providing a scalable
architecture for financial signal extraction and portfolio construction. The
overall framework significantly outperforms all benchmarks with 53.17%
cumulative return on SSE50 (Jan 2023 to Jan 2024), demonstrating superior
risk-adjusted performance and downside protection on the market.
"
2409.08426,2024-09-16,"A Deep Reinforcement Learning Framework For Financial Portfolio
  Management","  In this research paper, we investigate into a paper named ""A Deep
Reinforcement Learning Framework for the Financial Portfolio Management
Problem"" [arXiv:1706.10059]. It is a portfolio management problem which is
solved by deep learning techniques. The original paper proposes a
financial-model-free reinforcement learning framework, which consists of the
Ensemble of Identical Independent Evaluators (EIIE) topology, a
Portfolio-Vector Memory (PVM), an Online Stochastic Batch Learning (OSBL)
scheme, and a fully exploiting and explicit reward function. Three different
instants are used to realize this framework, namely a Convolutional Neural
Network (CNN), a basic Recurrent Neural Network (RNN), and a Long Short-Term
Memory (LSTM). The performance is then examined by comparing to a number of
recently reviewed or published portfolio-selection strategies. We have
successfully replicated their implementations and evaluations. Besides, we
further apply this framework in the stock market, instead of the cryptocurrency
market that the original paper uses. The experiment in the cryptocurrency
market is consistent with the original paper, which achieve superior returns.
But it doesn't perform as well when applied in the stock market.
"
2409.08728,2024-09-16,Disentangling the sources of cyber risk premia,"  We use a methodology based on a machine learning algorithm to quantify firms'
cyber risks based on their disclosures and a dedicated cyber corpus. The model
can identify paragraphs related to determined cyber-threat types and
accordingly attribute several related cyber scores to the firm. The cyber
scores are unrelated to other firms' characteristics. Stocks with high cyber
scores significantly outperform other stocks. The long-short cyber risk factors
have positive risk premia, are robust to all factors' benchmarks, and help
price returns. Furthermore, we suggest the market does not distinguish between
different types of cyber risks but instead views them as a single, aggregate
cyber risk.
"
2409.09684,2024-09-17,"Anatomy of Machines for Markowitz: Decision-Focused Learning for
  Mean-Variance Portfolio Optimization","  Markowitz laid the foundation of portfolio theory through the mean-variance
optimization (MVO) framework. However, the effectiveness of MVO is contingent
on the precise estimation of expected returns, variances, and covariances of
asset returns, which are typically uncertain. Machine learning models are
becoming useful in estimating uncertain parameters, and such models are trained
to minimize prediction errors, such as mean squared errors (MSE), which treat
prediction errors uniformly across assets. Recent studies have pointed out that
this approach would lead to suboptimal decisions and proposed Decision-Focused
Learning (DFL) as a solution, integrating prediction and optimization to
improve decision-making outcomes. While studies have shown DFL's potential to
enhance portfolio performance, the detailed mechanisms of how DFL modifies
prediction models for MVO remain unexplored. This study aims to investigate how
DFL adjusts stock return prediction models to optimize decisions in MVO,
addressing the question: ""MSE treats the errors of all assets equally, but how
does DFL reduce errors of different assets differently?"" Answering this will
provide crucial insights into optimal stock return prediction for constructing
efficient portfolios.
"
2409.10096,2025-04-16,Robust Reinforcement Learning with Dynamic Distortion Risk Measures,"  In a reinforcement learning (RL) setting, the agent's optimal strategy
heavily depends on her risk preferences and the underlying model dynamics of
the training environment. These two aspects influence the agent's ability to
make well-informed and time-consistent decisions when facing testing
environments. In this work, we devise a framework to solve robust risk-aware RL
problems where we simultaneously account for environmental uncertainty and risk
with a class of dynamic robust distortion risk measures. Robustness is
introduced by considering all models within a Wasserstein ball around a
reference model. We estimate such dynamic robust risk measures using neural
networks by making use of strictly consistent scoring functions, derive policy
gradient formulae using the quantile representation of distortion risk
measures, and construct an actor-critic algorithm to solve this class of robust
risk-aware RL problems. We demonstrate the performance of our algorithm on a
portfolio allocation example.
"
2409.10301,2024-11-21,"Decomposition Pipeline for Large-Scale Portfolio Optimization with
  Applications to Near-Term Quantum Computing","  Industrially relevant constrained optimization problems, such as portfolio
optimization and portfolio rebalancing, are often intractable or difficult to
solve exactly. In this work, we propose and benchmark a decomposition pipeline
targeting portfolio optimization and rebalancing problems with constraints. The
pipeline decomposes the optimization problem into constrained subproblems,
which are then solved separately and aggregated to give a final result. Our
pipeline includes three main components: preprocessing of correlation matrices
based on random matrix theory, modified spectral clustering based on Newman's
algorithm, and risk rebalancing. Our empirical results show that our pipeline
consistently decomposes real-world portfolio optimization problems into
subproblems with a size reduction of approximately 80%. Since subproblems are
then solved independently, our pipeline drastically reduces the total
computation time for state-of-the-art solvers. Moreover, by decomposing large
problems into several smaller subproblems, the pipeline enables the use of
near-term quantum devices as solvers, providing a path toward practical utility
of quantum computers in portfolio optimization.
"
2409.10543,2025-05-14,"Kullback-Leibler cluster entropy to quantify volatility correlation and
  risk diversity","  The Kullback-Leibler cluster entropy $\mathcal{D_{C}}[P \| Q] $ is evaluated
for the empirical and model probability distributions $P$ and $Q$ of the
clusters formed in the realized volatility time series of five assets (SP\&500,
NASDAQ, DJIA, DAX, FTSEMIB). The Kullback-Leibler functional $\mathcal{D_{C}}[P
\| Q] $ provides complementary perspectives about the stochastic volatility
process compared to the Shannon functional $\mathcal{S_{C}}[P]$. While
$\mathcal{D_{C}}[P \| Q] $ is maximum at the short time scales,
$\mathcal{S_{C}}[P]$ is maximum at the large time scales leading to
complementary optimization criteria tracing back respectively to the maximum
and minimum relative entropy evolution principles. The realized volatility is
modelled as a time-dependent fractional stochastic process characterized by
power-law decaying distributions with positive correlation ($H>1/2$). As a case
study, a multiperiod portfolio built on diversity indexes derived from the
Kullback-Leibler entropy measure of the realized volatility. The portfolio is
robust and exhibits better performances over the horizon periods. A comparison
with the portfolio built either according to the uniform distribution or in the
framework of the Markowitz theory is also reported.
"
2409.10933,2024-10-07,Optimal Investment under the Influence of Decision-changing Imitation,"  Decision-changing imitation is a prevalent phenomenon in financial markets,
where investors imitate others' decision-changing rates when making their own
investment decisions. In this work, we study the optimal investment problem
under the influence of decision-changing imitation involving one leading expert
and one retail investor whose decisions are unilaterally influenced by the
leading expert. In the objective functional of the optimal investment problem,
we propose the integral disparity to quantify the distance between the two
investors' decision-changing rates. Due to the underdetermination of the
optimal investment problem, we first derive its general solution using the
variational method and find the retail investor's optimal decisions under two
special cases of the boundary conditions. We theoretically analyze the
asymptotic properties of the optimal decision as the influence of
decision-changing imitation approaches infinity, and investigate the impact of
decision-changing imitation on the optimal decision. Our analysis is validated
using numerical experiments on real stock data. This study is essential to
comprehend decision-changing imitation and devise effective mechanisms to guide
investors' decisions.
"
2409.11569,2024-09-19,Optimal Investment with Costly Expert Opinions,"  We consider the Merton problem of optimizing expected power utility of
terminal wealth in the case of an unobservable Markov-modulated drift. What
makes the model special is that the agent is allowed to purchase costly expert
opinions of varying quality on the current state of the drift, leading to a
mixed stochastic control problem with regular and impulse controls involving
random consequences. Using ideas from filtering theory, we first embed the
original problem with unobservable drift into a full information problem on a
larger state space. The value function of the full information problem is
characterized as the unique viscosity solution of the dynamic programming PDE.
This characterization is achieved by a new variant of the stochastic Perron's
method, which additionally allows us to show that, in between purchases of
expert opinions, the problem reduces to an exit time control problem which is
known to admit an optimal feedback control. Under the assumption of sufficient
regularity of this feedback map, we are able to construct optimal trading and
expert opinion strategies.
"
2409.12208,2024-09-20,Mitigating Extremal Risks: A Network-Based Portfolio Strategy,"  In financial markets marked by inherent volatility, extreme events can result
in substantial investor losses. This paper proposes a portfolio strategy
designed to mitigate extremal risks. By applying extreme value theory, we
evaluate the extremal dependence between stocks and develop a network model
reflecting these dependencies. We use a threshold-based approach to construct
this complex network and analyze its structural properties. To improve risk
diversification, we utilize the concept of the maximum independent set from
graph theory to develop suitable portfolio strategies. Since finding the
maximum independent set in a given graph is NP-hard, we further partition the
network using either sector-based or community-based approaches. Additionally,
we use value at risk and expected shortfall as specific risk measures and
compare the performance of the proposed portfolios with that of the market
portfolio.
"
2409.13608,2024-11-08,"A Krasnoselskii-Mann Proximity Algorithm for Markowitz Portfolios with
  Adaptive Expected Return Level","  Markowitz's criterion aims to balance expected return and risk when
optimizing the portfolio. The expected return level is usually fixed according
to the risk appetite of an investor, then the risk is minimized at this fixed
return level. However, the investor may not know which return level is suitable
for her/him and the current financial circumstance. It motivates us to find a
novel approach that adaptively optimizes this return level and the portfolio at
the same time. It not only relieves the trouble of deciding the return level
during an investment but also gets more adaptive to the ever-changing financial
market than a subjective return level. In order to solve the new model, we
propose an exact, convergent, and efficient Krasnoselskii-Mann Proximity
Algorithm based on the proximity operator and Krasnoselskii-Mann momentum
technique. Extensive experiments show that the proposed method achieves
significant improvements over state-of-the-art methods in portfolio
optimization. This finding may contribute a new perspective on the relationship
between return and risk in portfolio optimization.
"
2409.14510,2024-09-24,"Crisis Alpha: A High-Performance Trading Algorithm Tested in Market
  Downturns","  Forming quantitative portfolios using statistical risk models presents a
significant challenge for hedge funds and portfolio managers. This research
investigates three distinct statistical risk models to construct quantitative
portfolios of 1,000 floating stocks in the US market. Utilizing five different
investment strategies, these models are tested across four periods,
encompassing the last three major financial crises: The Dot Com Bubble, Global
Financial Crisis, and Covid-19 market downturn. Backtests leverage the CRSP
dataset from January 1990 through December 2023. The results demonstrate that
the proposed models consistently outperformed market excess returns across all
periods. These findings suggest that the developed risk models can serve as
valuable tools for asset managers, aiding in strategic decision-making and risk
management in various economic conditions.
"
2409.18816,2024-09-30,Modern Portfolio Diversification with Arte-Blue Chip Index,"  This paper presents a novel approach to evaluating blue-chip art as a viable
asset class for portfolio diversification. We present the Arte-Blue Chip Index,
an index that tracks 100 top-performing artists based on 81,891 public
transactions from 157 artists across 584 auction houses over the period 1990 to
2024. By comparing blue-chip art price trends with stock market fluctuations,
our index provides insights into the risk and return profile of blue-chip art
investments. Our analysis demonstrates that a 20% allocation of blue-chip art
in a diversified portfolio enhances risk-adjusted returns by around 20%, while
maintaining volatility levels similar to the S&P 500.
"
2409.20397,2024-10-01,"A Framework for the Construction of a Sentiment-Driven Performance
  Index: The Case of DAX40","  We extract the sentiment from german and english news articles on companies
in the DAX40 stock market index and use it to create a sentiment-powered
pendant. Comparing it to existing products which adjust their weights at
pre-defined dates once per month, we show that our index is able to react more
swiftly to sentiment information mined from online news. Over the nearly 6
years we considered, the sentiment index manages to create an annualized return
of 7.51% compared to the 2.13% of the DAX40, while taking transaction costs
into account. In this work, we present the framework we employed to develop
this sentiment index.
"
2410.01378,2024-10-03,"Robust forward investment and consumption under drift and volatility
  uncertainties: A randomization approach","  This paper studies robust forward investment and consumption preferences and
optimal strategies for a risk-averse and ambiguity-averse agent in an
incomplete financial market with drift and volatility uncertainties. We focus
on non-zero volatility and constant relative risk aversion (CRRA) forward
preferences. Given the non-convexity of the Hamiltonian with respect to
uncertain volatilities, we first construct robust randomized forward
preferences through endogenous randomization in an auxiliary market. We derive
the corresponding optimal and robust investment and consumption strategies.
Furthermore, we show that such forward preferences and strategies, developed in
the auxiliary market, remain optimal and robust in the physical market,
offering a comprehensive framework for forward investment and consumption under
model uncertainty.
"
2410.01732,2024-10-10,"Worst-case values of target semi-variances with applications to robust
  portfolio selection","  The expected regret and target semi-variance are two of the most important
risk measures for downside risk. When the distribution of a loss is uncertain,
and only partial information of the loss is known, their worst-case values play
important roles in robust risk management for finance, insurance, and many
other fields. Jagannathan (1977) derived the worst-case expected regrets when
only the mean and variance of a loss are known and the loss is arbitrary,
symmetric, or non-negative. While Chen et al. (2011) obtained the worst-case
target semi-variances under similar conditions but focusing on arbitrary
losses. In this paper, we first complement the study of Chen et al. (2011) on
the worst-case target semi-variances and derive the closed-form expressions for
the worst-case target semi-variance when only the mean and variance of a loss
are known and the loss is symmetric or non-negative. Then, we investigate
worst-case target semi-variances over uncertainty sets that represent
undesirable scenarios faced by an investors. Our methods for deriving these
worst-case values are different from those used in Jagannathan (1977) and Chen
et al. (2011). As applications of the results derived in this paper, we propose
robust portfolio selection methods that minimize the worst-case target
semi-variance of a portfolio loss over different uncertainty sets. To explore
the insights of our robust portfolio selection methods, we conduct numerical
experiments with real financial data and compare our portfolio selection
methods with several existing portfolio selection models related to the models
proposed in this paper.
"
2410.01826,2024-10-04,"Shocks-adaptive Robust Minimum Variance Portfolio for a Large Universe
  of Assets","  This paper proposes a robust, shocks-adaptive portfolio in a
large-dimensional assets universe where the number of assets could be
comparable to or even larger than the sample size. It is well documented that
portfolios based on optimizations are sensitive to outliers in return data. We
deal with outliers by proposing a robust factor model, contributing
methodologically through the development of a robust principal component
analysis (PCA) for factor model estimation and a shrinkage estimation for the
random error covariance matrix. This approach extends the well-regarded
Principal Orthogonal Complement Thresholding (POET) method (Fan et al., 2013),
enabling it to effectively handle heavy tails and sudden shocks in data. The
novelty of the proposed robust method is its adaptiveness to both global and
idiosyncratic shocks, without the need to distinguish them, which is useful in
forming portfolio weights when facing outliers. We develop the theoretical
results of the robust factor model and the robust minimum variance portfolio.
Numerical and empirical results show the superior performance of the new
portfolio.
"
2410.01864,2024-10-04,"Dynamic Portfolio Rebalancing: A Hybrid new Model Using GNNs and
  Pathfinding for Cost Efficiency","  This paper introduces a novel approach to optimizing portfolio rebalancing by
integrating Graph Neural Networks (GNNs) for predicting transaction costs and
Dijkstra's algorithm for identifying cost-efficient rebalancing paths. Using
historical stock data from prominent technology firms, the GNN is trained to
forecast future transaction costs, which are then applied as edge weights in a
financial asset graph. Dijkstra's algorithm is used to find the least costly
path for reallocating capital between assets. Empirical results show that this
hybrid approach significantly reduces transaction costs, offering a powerful
tool for portfolio managers, especially in high-frequency trading environments.
This methodology demonstrates the potential of combining advanced machine
learning techniques with classical optimization algorithms to improve financial
decision-making processes. Future research will explore expanding the asset
universe and incorporating reinforcement learning for continuous portfolio
optimization.
"
2410.02709,2024-10-04,"Cracking the code: Lessons from 15 years of digital health IPOs for the
  era of AI","  Introduction: As digital health evolves, identifying factors that drive
success is crucial. This study examines how reimbursement billing codes affect
the long-term financial performance of digital health companies on U.S. stock
markets, addressing the question: What separates the winners from the rest?
  Methods: We analyzed digital health companies that went public on U.S. stock
exchanges between 2010 and 2021, offering products or services aimed at
improving personal health or disease management within the U.S. market. A
search using Google and existing IPO lists identified eligible companies. They
were categorized based on the presence or absence of billing codes at the time
of their initial public offering (IPO). Key performance indicators, including
Compound Annual Growth Rate (CAGR), relative performance to benchmark indices,
and market capitalization change, were compared using Mann-Whitney U and
Fisher's Exact tests.
  Results: Of the 33 companies analyzed, 15 (45.5%) had billing codes at IPO.
The median IPO price was $17.00, with no significant difference between groups.
Those with billing codes were 25.5 times more likely to achieve a positive
CAGR. Their median market capitalization increased 56.3%, compared to a median
decline of 80.1% for those without billing codes. All five top performers, in
terms of CAGR, had billing codes at IPO, whereas nine of the ten worst
performers lacked them. Companies without billing codes were 16 times more
likely to experience a drop in market capitalization by the study's end.
  Conclusion: Founders, investors, developers and analysts may have
overestimated consumers' willingness to pay out-of-pocket or underestimated
reimbursement complexities. As the sector evolves, especially with AI-driven
solutions, stakeholders should prioritize billing codes to ensure sustainable
growth, financial stability, and maximized investor returns.
"
2410.03552,2024-10-07,"Evaluating Investment Risks in LATAM AI Startups: Ranking of Investment
  Potential and Framework for Valuation","  The growth of the tech startup ecosystem in Latin America (LATAM) is driven
by innovative entrepreneurs addressing market needs across various sectors.
However, these startups encounter unique challenges and risks that require
specific management approaches. This paper explores a case study with the Total
Addressable Market (TAM), Serviceable Available Market (SAM), and Serviceable
Obtainable Market (SOM) metrics within the context of the online food delivery
industry in LATAM, serving as a model for valuing startups using the Discounted
Cash Flow (DCF) method. By analyzing key emerging powers such as Argentina,
Colombia, Uruguay, Costa Rica, Panama, and Ecuador, the study highlights the
potential and profitability of AI-driven startups in the region through the
development of a ranking of emerging powers in Latin America for tech startup
investment. The paper also examines the political, economic, and competitive
risks faced by startups and offers strategic insights on mitigating these risks
to maximize investment returns. Furthermore, the research underscores the value
of diversifying investment portfolios with startups in emerging markets,
emphasizing the opportunities for substantial growth and returns despite
inherent risks.
"
2410.04217,2024-10-10,Improving Portfolio Optimization Results with Bandit Networks,"  In Reinforcement Learning (RL), multi-armed Bandit (MAB) problems have found
applications across diverse domains such as recommender systems, healthcare,
and finance. Traditional MAB algorithms typically assume stationary reward
distributions, which limits their effectiveness in real-world scenarios
characterized by non-stationary dynamics. This paper addresses this limitation
by introducing and evaluating novel Bandit algorithms designed for
non-stationary environments. First, we present the Adaptive Discounted Thompson
Sampling (ADTS) algorithm, which enhances adaptability through relaxed
discounting and sliding window mechanisms to better respond to changes in
reward distributions. We then extend this approach to the Portfolio
Optimization problem by introducing the Combinatorial Adaptive Discounted
Thompson Sampling (CADTS) algorithm, which addresses computational challenges
within Combinatorial Bandits and improves dynamic asset allocation.
Additionally, we propose a novel architecture called Bandit Networks, which
integrates the outputs of ADTS and CADTS, thereby mitigating computational
limitations in stock selection. Through extensive experiments using real
financial market data, we demonstrate the potential of these algorithms and
architectures in adapting to dynamic environments and optimizing
decision-making processes. For instance, the proposed bandit network instances
present superior performance when compared to classic portfolio optimization
approaches, such as capital asset pricing model, equal weights, risk parity,
and Markovitz, with the best network presenting an out-of-sample Sharpe Ratio
20% higher than the best performing classical model.
"
2410.04459,2025-01-22,"Two-fund separation under hyperbolically distributed returns and concave
  utility function","  Portfolio selection problems that optimize expected utility are usually
difficult to solve. If the number of assets in the portfolio is large, such
expected utility maximization problems become even harder to solve numerically.
Therefore, analytical expressions for optimal portfolios are always preferred.
In our work, we study portfolio optimization problems under the expected
utility criterion for a wide range of utility functions, assuming return
vectors follow hyperbolic distributions. Our main result demonstrates that
under this setup, the two-fund monetary separation holds. Specifically, an
individual with any utility function from this broad class will always choose
to hold the same portfolio of risky assets, only adjusting the mix between this
portfolio and a riskless asset based on their initial wealth and the specific
utility function used for decision making. We provide explicit expressions for
this mutual fund of risky assets. As a result, in our economic model, an
individual's optimal portfolio is expressed in closed form as a linear
combination of the riskless asset and the mutual fund of risky assets.
Additionally, we discuss expected utility maximization problems under
exponential utility functions over any domain of the portfolio set. In this
part of our work, we show that the optimal portfolio in any given convex domain
of the portfolio set either lies on the boundary of the domain or is the unique
globally optimal portfolio within the entire domain.
"
2410.05932,2024-11-15,Quantum-Inspired Portfolio Optimization In The QUBO Framework,"  A quantum-inspired optimization approach is proposed to study the portfolio
optimization aimed at selecting an optimal mix of assets based on the
risk-return trade-off to achieve the desired goal in investment. By integrating
conventional approaches with quantum-inspired methods for penalty coefficient
estimation, this approach enables faster and accurate solutions to portfolio
optimization which is validated through experiments using a real-world dataset
of quarterly financial data spanning over ten-year period. In addition, the
proposed preprocessing method of two-stage search further enhances the
effectiveness of our approach, showing the ability to improve computational
efficiency while maintaining solution accuracy through appropriate setting of
parameters. This research contributes to the growing body of literature on
quantum-inspired techniques in finance, demonstrating its potential as a useful
tool for asset allocation and portfolio management.
"
2410.07749,2024-10-11,Optimal mutual insurance against systematic longevity risk,"  We mathematically demonstrate how and what it means for two collective
pension funds to mutually insure one another against systematic longevity risk.
The key equation that facilitates the exchange of insurance is a market
clearing condition. This enables an insurance market to be established even if
the two funds face the same mortality risk, so long as they have different risk
preferences. Provided the preferences of the two funds are not too dissimilar,
insurance provides little benefit, implying the base scheme is effectively
optimal. When preferences vary significantly, insurance can be beneficial.
"
2410.10239,2025-05-19,"Sample Average Approximation for Portfolio Optimization under CVaR
  constraint in an (re)insurance context","  We consider optimal allocation problems with Conditional Value-At-Risk (CVaR)
constraint. We prove, under very mild assumptions, the convergence of the
Sample Average Approximation method (SAA) applied to this problem, and we also
exhibit a convergence rate and discuss the uniqueness of the solution. These
results give (re)insurers a practical solution to portfolio optimization under
market regulatory constraints, i.e. a certain level of risk.
"
2410.11070,2024-10-16,"Aproximaci\'on pr\'actica a los m\'etodos de selecci\'on de portafolios
  de inversi\'on","  This paper explores the practical approach to portfolio selection methods for
investments. The study delves into portfolio theory, discussing concepts such
as expected return, variance, asset correlation, and opportunity sets. It also
presents the efficient frontier and its application in the Markowitz model,
which employs mean-variance optimization techniques. An alternative approach
based on the mean-semivariance model is introduced. This model accounts for the
skewness and kurtosis of the asset return distribution, providing a more
comprehensive view of risk and return. The study also addresses the practical
implementation of these models, including the use of genetic algorithms to
optimize portfolio selection. Additionally, transaction costs and integer
constraints in portfolio optimization are considered, demonstrating the
applicability of the Markowitz model.
  --
  Este documento explorar la aproximaci\'on pr\'actica a los m\'etodos de
selecci\'on de portafolios para inversiones. El estudio profundiza en la
teor\'ia de los portafolios, discutiendo conceptos como el rendimiento
esperado, la varianza, la correlaci\'on entre activos y los conjuntos de
oportunidades. Tambi\'en presenta la frontera eficiente y su aplicaci\'on en el
modelo de Markowitz, que utiliza t\'ecnicas de optimizaci\'on media-varianza.
Se introduce un enfoque alternativo basado en el modelo media-semivarianza.
Este modelo tiene en cuenta la asimetr\'ia y la curtosis de la distribuci\'on
de retornos de los activos, proporcionando una visi\'on m\'as completa de
riesgo y rendimiento. El estudio tambi\'en aborda la implementaci\'on
pr\'actica de estos modelos, incluyendo el uso de algoritmos gen\'eticos para
optimizar la selecci\'on de portafolios. Adem\'as, se consideran los costos de
transacci\'on y las restricciones enteras en la optimizaci\'on del portafolio.
"
2410.14841,2024-10-22,Dynamic Factor Allocation Leveraging Regime-Switching Signals,"  This article explores dynamic factor allocation by analyzing the cyclical
performance of factors through regime analysis. The authors focus on a U.S.
equity investment universe comprising seven long-only indices representing the
market and six style factors: value, size, momentum, quality, low volatility,
and growth. Their approach integrates factor-specific regime inferences of each
factor index's active performance relative to the market into the
Black-Litterman model to construct a fully-invested, long-only multi-factor
portfolio. First, the authors apply the sparse jump model (SJM) to identify
bull and bear market regimes for individual factors, using a feature set based
on risk and return measures from historical factor active returns, as well as
variables reflecting the broader market environment. The regimes identified by
the SJM exhibit enhanced stability and interpretability compared to traditional
methods. A hypothetical single-factor long-short strategy is then used to
assess these regime inferences and fine-tune hyperparameters, resulting in a
positive Sharpe ratio of this strategy across all factors with low correlation
among them. These regime inferences are then incorporated into the
Black-Litterman framework to dynamically adjust allocations among the seven
indices, with an equally weighted (EW) portfolio serving as the benchmark.
Empirical results show that the constructed multi-factor portfolio
significantly improves the information ratio (IR) relative to the market,
raising it from just 0.05 for the EW benchmark to approximately 0.4. When
measured relative to the EW benchmark itself, the dynamic allocation achieves
an IR of around 0.4 to 0.5. The strategy also enhances absolute portfolio
performance across key metrics such as the Sharpe ratio and maximum drawdown.
"
2410.14984,2024-10-22,"Risk Aggregation and Allocation in the Presence of Systematic Risk via
  Stable Laws","  In order to properly manage risk, practitioners must understand the aggregate
risks they are exposed to. Additionally, to properly price policies and
calculate bonuses the relative riskiness of individual business units must be
well understood. Certainly, Insurers and Financiers are interested in the
properties of the sums of the risks they are exposed to and the dependence of
risks therein. Realistic risk models however must account for a variety of
phenomena: ill-defined moments, lack of elliptical dependence structures,
excess kurtosis and highly heterogeneous marginals. Equally important is the
concern over industry-wide systematic risks that can affect multiple business
lines at once. Many techniques of varying sophistication have been developed
with all or some of these problems in mind. We propose a modification to the
classical individual risk model that allows us to model company-wide losses via
the class of Multivariate Stable Distributions. Stable Distributions
incorporate many of the unpleasant features required for a realistic risk model
while maintaining tractable aggregation and dependence results. We additionally
compute the Tail Conditional Expectation of aggregate risks within the model
and the corresponding allocations.
"
2410.16299,2024-10-23,"Financial Performance and Economic Implications of COFCO's Strategic
  Acquisition of Mengniu","  This paper examines the merger and acquisition (M&A) process between COFCO
and Mengniu Dairy, exploring the motivations behind this strategic move and
identifying its key aspects. By analyzing both the financial and non-financial
contributions of Mengniu Dairy to COFCO, this study provides valuable insights
and references for future corporate M&A activities. The theoretical
significance of this research lies in its focus on the relatively underexplored
area of M&A within the dairy industry, particularly in terms of M&A
contributions. Using the COFCO-Mengniu case as a model, the study broadens
current research perspectives by assessing the impact of M&A from financial and
non-financial standpoints, enriching the body of literature on dairy industry
M&As.
"
2410.16333,2025-02-14,Conformal Predictive Portfolio Selection,"  This study examines portfolio selection using predictive models for portfolio
returns. Portfolio selection is a fundamental task in finance, and a variety of
methods have been developed to achieve this goal. For instance, the
mean-variance approach constructs portfolios by balancing the trade-off between
the mean and variance of asset returns, while the quantile-based approach
optimizes portfolios by considering tail risk. These methods often depend on
distributional information estimated from historical data using predictive
models, each of which carries its own uncertainty. To address this, we propose
a framework for predictive portfolio selection via conformal prediction ,
called \emph{Conformal Predictive Portfolio Selection} (CPPS). Our approach
forecasts future portfolio returns, computes the corresponding prediction
intervals, and selects the portfolio of interest based on these intervals. The
framework is flexible and can accommodate a wide range of predictive models,
including autoregressive (AR) models, random forests, and neural networks. We
demonstrate the effectiveness of the CPPS framework by applying it to an AR
model and validate its performance through empirical studies, showing that it
delivers superior returns compared to simpler strategies.
"
2410.17212,2024-10-23,"Neuroevolution Neural Architecture Search for Evolving RNNs in Stock
  Return Prediction and Portfolio Trading","  Stock return forecasting is a major component of numerous finance
applications. Predicted stock returns can be incorporated into portfolio
trading algorithms to make informed buy or sell decisions which can optimize
returns. In such portfolio trading applications, the predictive performance of
a time series forecasting model is crucial. In this work, we propose the use of
the Evolutionary eXploration of Augmenting Memory Models (EXAMM) algorithm to
progressively evolve recurrent neural networks (RNNs) for stock return
predictions. RNNs are evolved independently for each stocks and portfolio
trading decisions are made based on the predicted stock returns. The portfolio
used for testing consists of the 30 companies in the Dow-Jones Index (DJI) with
each stock have the same weight. Results show that using these evolved RNNs and
a simple daily long-short strategy can generate higher returns than both the
DJI index and the S&P 500 Index for both 2022 (bear market) and 2023 (bull
market).
"
2410.18098,2024-10-25,A Case Study of Next Portfolio Prediction for Mutual Funds,"  Mutual funds aim to generate returns above market averages. While predicting
their future portfolio allocations can bring economic advantages, the task
remains challenging and largely unexplored. To fill that gap, this work frames
mutual fund portfolio prediction as a Next Novel Basket Recommendation (NNBR)
task, focusing on predicting novel items in a fund's next portfolio. We create
a comprehensive benchmark dataset using publicly available data and evaluate
the performance of various recommender system models on the NNBR task.
  Our findings reveal that predicting novel items in mutual fund portfolios is
inherently more challenging than predicting the entire portfolio or only
repeated items. While state-of-the-art NBR models are outperformed by simple
heuristics when considering both novel and repeated items together,
autoencoder-based approaches demonstrate superior performance in predicting
only new items.
  The insights gained from this study highlight the importance of considering
domain-specific characteristics when applying recommender systems to mutual
fund portfolio prediction. The performance gap between predicting the entire
portfolio or repeated items and predicting novel items underscores the
complexity of the NNBR task in this domain and the need for continued research
to develop more robust and adaptable models for this critical financial
application.
"
2410.18240,2024-10-25,Periodic portfolio selection with quasi-hyperbolic discounting,"  We introduce an infinite-horizon, continuous-time portfolio selection problem
faced by an agent with periodic S-shaped preference and present bias. The
inclusion of a quasi-hyperbolic discount function leads to time-inconsistency
and we characterize the optimal portfolio for a pre-committing, naive and
sophisticated agent respectively. In the more theoretically challenging problem
with a sophisticated agent, the time-consistent planning strategy can be
formulated as an equilibrium to a static mean field game. Interestingly,
present bias and naivety do not necessarily result in less desirable risk
taking behaviors, while agent's sophistication may lead to excessive leverage
(underinvestement) in the bad (good) states of the world.
"
2410.18432,2025-04-11,Dynamic Investment-Driven Insurance Pricing and Optimal Regulation,"  This paper analyzes the equilibrium of insurance market in a dynamic setting,
focusing on the interaction between insurers' underwriting and investment
strategies. Three possible equilibrium outcomes are identified: a positive
insurance market, a zero insurance market, and market failure. Our findings
reveal why insurers may rationally accept underwriting losses by setting a
negative safety loading while relying on investment profits, particularly when
there is a negative correlation between insurance gains and financial returns.
Additionally, we explore the impact of regulatory frictions, showing that while
imposing a cost on investment can enhance social welfare under certain
conditions, it may not always be necessary.
"
2410.19030,2024-11-19,"Loss Aversion and State-Dependent Linear Utility Functions for Monetary
  Returns","  We present a theory of expected utility with state-dependent linear utility
functions for monetary returns, that incorporates the possibility of
loss-aversion. Our results relate to first order stochastic dominance,
mean-preserving spread, increasing-concave linear utility profiles and risk
aversion. As an application of the expected utility theory developed here, we
analyze the contract that a monopolist would offer in an insurance market that
allowed for partial coverage of loss.
"
2410.20060,2024-10-29,Constrained portfolio optimization in a life-cycle model,"  This paper considers the constrained portfolio optimization in a generalized
life-cycle model. The individual with a stochastic income manages a portfolio
consisting of stocks, a bond, and life insurance to maximize his or her
consumption level, death benefit, and terminal wealth. Meanwhile, the
individual faces a convex-set trading constraint, of which the non-tradeable
asset constraint, no short-selling constraint, and no borrowing constraint are
special cases. Following Cuoco (1997), we build the artificial markets to
derive the dual problem and prove the existence of the original problem. With
additional discussions, we extend his uniformly bounded assumption on the
interest rate to an almost surely finite expectation condition and enlarge his
uniformly bounded assumption on the income process to a bounded expectation
condition. Moreover, we propose a dual control neural network approach to
compute tight lower and upper bounds for the original problem, which can be
utilized in more general cases than the simulation of artificial markets
strategies (SAMS) approach in Bick et al. (2013). Finally, we conclude that
when considering the trading constraints, the individual will reduce his or her
demand for life insurance.
"
2410.20128,2024-10-29,Optimal life insurance and annuity decision under money illusion,"  This paper investigates the optimal consumption, investment, and life
insurance/annuity decisions for a family in an inflationary economy under money
illusion. The family can invest in a financial market that consists of nominal
bonds, inflation-linked bonds, and a stock index. The breadwinner can also
purchase life insurance or annuities that are available continuously. The
family's objective is to maximize the expected utility of a mixture of nominal
and real consumption, as they partially overlook inflation and tend to think in
terms of nominal rather than real monetary values. We formulate this life-cycle
problem as a random horizon utility maximization problem and derive the optimal
strategy. We calibrate our model to the U.S. data and demonstrate that money
illusion increases life insurance demand for young adults and reduces annuity
demand for retirees. Our findings indicate that the money illusion contributes
to the annuity puzzle and highlights the role of financial literacy in an
inflationary environment.
"
2410.20597,2024-10-29,Extracting Alpha from Financial Analyst Networks,"  We investigate the effectiveness of a momentum trading signal based on the
coverage network of financial analysts. This signal builds on the key
information-brokerage role financial sell-side analysts play in modern stock
markets. The baskets of stocks covered by each analyst can be used to construct
a network between firms whose edge weights represent the number of analysts
jointly covering both firms. Although the link between financial analysts
coverage and co-movement of firms' stock prices has been investigated in the
literature, little effort has been made to systematically learn the most
effective combination of signals from firms covered jointly by analysts in
order to benefit from any spillover effect. To fill this gap, we build a
trading strategy which leverages the analyst coverage network using a graph
attention network. More specifically, our model learns to aggregate information
from individual firm features and signals from neighbouring firms in a
node-level forecasting task. We develop a portfolio based on those predictions
which we demonstrate to exhibit an annualized returns of 29.44% and a Sharpe
ratio of 4.06 substantially outperforming market baselines and existing graph
machine learning based frameworks. We further investigate the performance and
robustness of this strategy through extensive empirical analysis. Our paper
represents one of the first attempts in using graph machine learning to extract
actionable knowledge from the analyst coverage network for practical financial
applications.
"
2410.23297,2024-11-01,"Clustering Digital Assets Using Path Signatures: Application to
  Portfolio Construction","  We propose a new way of building portfolios of cryptocurrencies that provide
good diversification properties to investors. First, we seek to filter these
digital assets by creating some clusters based on their path signature. The
goal is to identify similar patterns in the behavior of these highly volatile
assets. Once such clusters have been built, we propose ""optimal"" portfolios by
comparing the performances of such portfolios to a universe of unfiltered
digital assets. Our intuition is that clustering based on path signatures will
make it easier to capture the main trends and features of a group of
cryptocurrencies, and allow parsimonious portfolios that reduce excessive
transaction fees. Empirically, our assumptions seem to be satisfied.
"
2410.23536,2024-11-01,On Cost-Sensitive Distributionally Robust Log-Optimal Portfolio,"  This paper addresses a novel \emph{cost-sensitive} distributionally robust
log-optimal portfolio problem, where the investor faces \emph{ambiguous} return
distributions, and a general convex transaction cost model is incorporated. The
uncertainty in the return distribution is quantified using the
\emph{Wasserstein} metric, which captures distributional ambiguity. We
establish conditions that ensure robustly survivable trades for all
distributions in the Wasserstein ball under convex transaction costs. By
leveraging duality theory, we approximate the infinite-dimensional
distributionally robust optimization problem with a finite convex program,
enabling computational tractability for mid-sized portfolios. Empirical studies
using S\&P 500 data validate our theoretical framework: without transaction
costs, the optimal portfolio converges to an equal-weighted allocation, while
with transaction costs, the portfolio shifts slightly towards the risk-free
asset, reflecting the trade-off between cost considerations and optimal
allocation.
"
2411.03402,2024-11-07,Climate AI for Corporate Decarbonization Metrics Extraction,"  Corporate Greenhouse Gas (GHG) emission targets are important metrics in
sustainable investing [12, 16]. To provide a comprehensive view of company
emission objectives, we propose an approach to source these metrics from
company public disclosures. Without automation, curating these metrics manually
is a labor-intensive process that requires combing through lengthy corporate
sustainability disclosures that often do not follow a standard format.
Furthermore, the resulting dataset needs to be validated thoroughly by Subject
Matter Experts (SMEs), further lengthening the time-to-market. We introduce the
Climate Artificial Intelligence for Corporate Decarbonization Metrics
Extraction (CAI) model and pipeline, a novel approach utilizing Large Language
Models (LLMs) to extract and validate linked metrics from corporate
disclosures. We demonstrate that the process improves data collection
efficiency and accuracy by automating data curation, validation, and metric
scoring from public corporate disclosures. We further show that our results are
agnostic to the choice of LLMs. This framework can be applied broadly to
information extraction from textual data.
"
2411.05807,2024-11-12,"Schur Complementary Allocation: A Unification of Hierarchical Risk
  Parity and Minimum Variance Portfolios","  Despite many attempts to make optimization-based portfolio construction in
the spirit of Markowitz robust and approachable, it is far from universally
adopted. Meanwhile, the collection of more heuristic divide-and-conquer
approaches was revitalized by Lopez de Prado where Hierarchical Risk Parity
(HRP) was introduced. This paper reveals the hidden connection between these
seemingly disparate approaches.
"
2411.06080,2024-11-12,The lexical ratio: A new perspective on portfolio diversification,"  Portfolio diversification, traditionally measured through asset correlations
and volatilitybased metrics, is fundamental to managing financial risk.
However, existing diversification metrics often overlook non-numerical
relationships between assets that can impact portfolio stability, particularly
during market stresses. This paper introduces the lexical ratio (LR), a novel
metric that leverages textual data to capture diversification dimensions absent
in standard approaches. By treating each asset as a unique document composed of
sectorspecific and financial keywords, the LR evaluates portfolio
diversification by distributing these terms across assets, incorporating
entropy-based insights from information theory. We thoroughly analyze LR's
properties, including scale invariance, concavity, and maximality,
demonstrating its theoretical robustness and ability to enhance risk-adjusted
portfolio returns. Using empirical tests on S&P 500 portfolios, we compare LR's
performance to established metrics such as Markowitz's volatility-based
measures and diversification ratios. Our tests reveal LR's superiority in
optimizing portfolio returns, especially under varied market conditions. Our
findings show that LR aligns with conventional metrics and captures unique
diversification aspects, suggesting it is a viable tool for portfolio managers.
"
2411.06566,2024-11-12,A Fully Analog Pipeline for Portfolio Optimization,"  Portfolio optimization is a ubiquitous problem in financial mathematics that
relies on accurate estimates of covariance matrices for asset returns. However,
estimates of pairwise covariance could be better and calculating time-sensitive
optimal portfolios is energy-intensive for digital computers. We present an
energy-efficient, fast, and fully analog pipeline for solving portfolio
optimization problems that overcomes these limitations. The analog paradigm
leverages the fundamental principles of physics to recover accurate optimal
portfolios in a two-step process. Firstly, we utilize equilibrium propagation,
an analog alternative to backpropagation, to train linear autoencoder neural
networks to calculate low-rank covariance matrices. Then, analog continuous
Hopfield networks output the minimum variance portfolio for a given desired
expected return. The entire efficient frontier may then be recovered, and an
optimal portfolio selected based on risk appetite.
"
2411.07949,2024-12-18,"Optimal two-parameter portfolio management strategy with transaction
  costs","  We consider a simplified model for optimizing a single-asset portfolio in the
presence of transaction costs given a signal with a certain autocorrelation and
cross-correlation structure. In our setup, the portfolio manager is given two
one-parameter controls to influence the construction of the portfolio. The
first is a linear filtering parameter that may increase or decrease the level
of autocorrelation in the signal. The second is a numerical threshold that
determines a symmetric ""no-trade"" zone. Portfolio positions are constrained to
a single unit long or a single unit short. These constraints allow us to focus
on the interplay between the signal filtering mechanism and the hysteresis
introduced by the ""no-trade"" zone. We then formulate an optimization problem
where we aim to minimize the frequency of trades subject to a fixed return
level of the portfolio. We show that maintaining a no-trade zone while removing
autocorrelation entirely from the signal yields a locally optimal solution. For
any given ""no-trade"" zone threshold, this locally optimal solution also
achieves the maximum attainable return level, and we derive a quantitative
lower bound for the amount of improvement in terms of the given threshold and
the amount of autocorrelation removed.
"
2411.08864,2025-03-12,Isotropic Correlation Models for the Cross-Section of Equity Returns,"  This note discusses some of the aspects of a model for the covariance of
equity returns based on a simple ""isotropic"" structure in which all pairwise
correlations are taken to be the same value. The effect of the structure on
feasible values for the common correlation of returns and on the ""effective
degrees of freedom"" within the equity cross-section are discussed, as well as
the impact of this constraint on the asymptotic Normality of portfolio returns.
An eigendecomposition of the covariance matrix is presented and used to
partition variance into that from a common ""market"" factor and
""non-diversifiable"" idiosyncratic risk. A empirical analysis of the recent
history of the returns of S&P 500 Index members is presented and compared to
the expectations from both this model and linear factor models. This analysis
supports the isotropic covariance model and does not seem to provide evidence
in support of linear factor models. Analysis of portfolio selection under
isotropic correlation is presented using mean-variance optimization for both
heteroskedastic and homoskedastic cases. Portfolio selection for negative
exponential utility maximizers is also discussed for the general case of
distributions of returns with elliptical symmetry. The fact that idiosyncratic
risk may not be removed by diversification in a model that the data supports
undermines the basic premises of structures such as the C.A.P.M. and A.P.T. If
the cross-section of equity returns is more accurately described by this
structure then an inevitable consequence is that picking stocks is not a
""pointless"" activity, as the returns to residual risk would be non-zero.
"
2411.08967,2024-11-15,"An Analytic Solution for Asset Allocation with a Multivariate Laplace
  Distribution","  In this short note the theory for multivariate asset allocation with
elliptically symmetric distributions of returns, as developed in the author's
prior work, is specialized to the case of returns drawn from a multivariate
Laplace distribution. This analysis delivers a result closely, but not
perfectly, consistent with the conjecture presented in the author's article
Thinking Differently About Asset Allocation. The principal differences are due
to the introduction of a term in the dimensionality of the problem, which was
omitted from the conjectured solution, and a rescaling of the variance due to
varying parameterizations of the univariate Laplace distribution.
"
2411.09899,2024-11-18,"Portfolio Optimization with Feedback Strategies Based on Artificial
  Neural Networks","  With the recent advancements in machine learning (ML), artificial neural
networks (ANN) are starting to play an increasingly important role in
quantitative finance. Dynamic portfolio optimization is among many problems
that have significantly benefited from a wider adoption of deep learning (DL).
While most existing research has primarily focused on how DL can alleviate the
curse of dimensionality when solving the Hamilton-Jacobi-Bellman (HJB)
equation, some very recent developments propose to forego derivation and
solution of HJB in favor of empirical utility maximization over dynamic
allocation strategies expressed through ANN. In addition to being simple and
transparent, this approach is universally applicable, as it is essentially
agnostic about market dynamics. To showcase the method, we apply it to optimal
portfolio allocation between a cash account and the S&P 500 index modeled using
geometric Brownian motion or the Heston model. In both cases, the results are
demonstrated to be on par with those under the theoretical optimal weights
assuming isoelastic utility and real-time rebalancing. A set of R codes for a
broad class of stochastic volatility models are provided as a supplement.
"
2411.12323,2024-11-20,Mirror Descent Algorithms for Risk Budgeting Portfolios,"  This paper introduces and examines numerical approximation schemes for
computing risk budgeting portfolios associated to positive homogeneous and
sub-additive risk measures. We employ Mirror Descent algorithms to determine
the optimal risk budgeting weights in both deterministic and stochastic
settings, establishing convergence along with an explicit non-asymptotic
quantitative rate for the averaged algorithm. A comprehensive numerical
analysis follows, illustrating our theoretical findings across various risk
measures -- including standard deviation, Expected Shortfall, deviation
measures, and Variantiles -- and comparing the performance with that of the
standard stochastic gradient descent method recently proposed in the
literature.
"
2411.13180,2024-11-21,"Investor Sentiment in Asset Pricing Models: A Review of Empirical
  Evidence","  This study conducted a comprehensive review of 71 papers published between
2000 and 2021 that employed various measures of investor sentiment to model
returns. The analysis indicates that higher complexity of sentiment measures
and models improves the coefficient of determination. However, there was
insufficient evidence to support that models incorporating more complex
sentiment measures have better predictive power than those employing simpler
proxies. Additionally, the significance of sentiment varies based on the asset
and time period being analyzed, suggesting that the consensus relying on the BW
index as a sentiment measure may be subject to change.
"
2411.13579,2024-11-22,"Optimal portfolio under ratio-type periodic evaluation in stochastic
  factor models under convex trading constraints","  This paper studies a type of periodic utility maximization problems for
portfolio management in incomplete stochastic factor models with convex trading
constraints. The portfolio performance is periodically evaluated on the
relative ratio of two adjacent wealth levels over an infinite horizon,
featuring the dynamic adjustments in portfolio decision according to past
achievements. Under power utility, we transform the original infinite horizon
optimal control problem into an auxiliary terminal wealth optimization problem
under a modified utility function. To cope with the convex trading constraints,
we further introduce an auxiliary unconstrained optimization problem in a
modified market model and develop the martingale duality approach to establish
the existence of the dual minimizer such that the optimal unconstrained wealth
process can be obtained using the dual representation. With the help of the
duality results in the auxiliary problems, the relationship between the
constrained and unconstrained models as well as some fixed point arguments, we
finally derive and verify the optimal constrained portfolio process in a
periodic manner for the original problem over an infinite horizon.
"
2411.13792,2024-11-22,Multiscale Markowitz,"  Traditional Markowitz portfolio optimization constrains daily portfolio
variance to a target value, optimising returns, Sharpe or variance within this
constraint. However, this approach overlooks the relationship between variance
at different time scales, typically described by $\sigma(\Delta t) \propto
(\Delta t)^{H}$ where $H$ is the Hurst exponent, most of the time assumed to be
\(\frac{1}{2}\). This paper introduces a multifrequency optimization framework
that allows investors to specify target portfolio variance across a range of
frequencies, characterized by a target Hurst exponent $H_{target}$, or optimize
the portfolio at multiple time scales. By incorporating this scaling behavior,
we enable a more nuanced and comprehensive risk management strategy that aligns
with investor preferences at various time scales. This approach effectively
manages portfolio risk across multiple frequencies and adapts to different
market conditions, providing a robust tool for dynamic asset allocation. This
overcomes some of the traditional limitations of Markowitz, when it comes to
dealing with crashes, regime changes, volatility clustering or multifractality
in markets. We illustrate this concept with a toy example and discuss the
practical implementation for assets with varying scaling behaviors.
"
2411.13965,2024-11-22,"Does the square-root price impact law belong to the strict universal
  scalings?: quantitative support by a complete survey of the Tokyo stock
  exchange market","  Universal power laws have been scrutinised in physics and beyond, and a
long-standing debate exists in econophysics regarding the strict universality
of the nonlinear price impact, commonly referred to as the square-root law
(SRL). The SRL posits that the average price impact $I$ follows a power law
with respect to transaction volume $Q$, such that $I(Q) \propto Q^{\delta}$
with $\delta \approx 1/2$. Some researchers argue that the exponent $\delta$
should be system-specific, without universality. Conversely, others contend
that $\delta$ should be exactly $1/2$ for all stocks across all countries,
implying universality. However, resolving this debate requires high-precision
measurements of $\delta$ with errors of around $0.1$ across hundreds of stocks,
which has been extremely challenging due to the scarcity of large microscopic
datasets -- those that enable tracking the trading behaviour of all individual
accounts. Here we conclusively support the universality hypothesis of the SRL
by a complete survey of all trading accounts for all liquid stocks on the Tokyo
Stock Exchange (TSE) over eight years. Using this comprehensive microscopic
dataset, we show that the exponent $\delta$ is equal to $1/2$ within
statistical errors at both the individual stock level and the individual trader
level. Additionally, we rejected two prominent models supporting the
nonuniversality hypothesis: the Gabaix-Gopikrishnan-Plerou-Stanley and the
Farmer-Gerig-Lillo-Waelbroeck models. Our work provides exceptionally
high-precision evidence for the universality hypothesis in social science and
could prove useful in evaluating the price impact by large investors -- an
important topic even among practitioners.
"
2411.14646,2024-11-28,Diversification quotient based on expectiles,"  A diversification quotient (DQ) quantifies diversification in stochastic
portfolio models based on a family of risk measures. We study DQ based on
expectiles, offering a useful alternative to conventional risk measures such as
Value-at-Risk (VaR) and Expected Shortfall (ES). The expectile-based DQ admits
simple formulas and has a natural connection to the Omega ratio. Moreover, the
expectile-based DQ is not affected by small-sample issues faced by VaR-based or
ES-based DQ due to the scarcity of tail data. The expectile-based DQ exhibits
pseudo-convexity in portfolio weights, allowing gradient descent algorithms for
portfolio selection. We show that the corresponding optimization problem can be
efficiently solved using linear programming techniques in real-data
applications. Explicit formulas for DQ based on expectiles are also derived for
elliptical and multivariate regularly varying distribution models. Our findings
enhance the understanding of the DQ's role in financial risk management and
highlight its potential to improve portfolio construction strategies.
"
2411.15712,2024-11-26,Research on Optimal Portfolio Based on Multifractal Features,"  Providing optimal portfolio selection for investors has always been one of
the hot topics in academia. In view of the traditional portfolio model could
not adapt to the actual capital market and can provide erroneous results. This
paper innovatively constructs a mean-detrended cross-correlation portfolio
model (M-DCCP model), This model is designed to embed detrended
cross-correlation between different simultaneously recorded time series in the
presence of nonstationary into the reward-risk criterion. We illustrate the
model's effectiveness by selected five composite indexes (SSE 50, CSI 300, SSE
500, CSI 1000 and CSI 2000) in China A-share market. The empirical results show
that compared with traditional mean-variance portfolio model (M-VP model), the
M-DCCP model is more conducive for investors to construct optimal portfolios
under the different fluctuation exponent preference and time scales preference,
so as to improve portfolio's performance.
"
2411.16569,2024-11-26,Predictive Power of LLMs in Financial Markets,"  Predicting the movement of the stock market and other assets has been
valuable over the past few decades. Knowing how the value of a certain sector
market may move in the future provides much information for investors, as they
use that information to develop strategies to maximize profit or minimize risk.
However, market data are quite noisy, and it is challenging to choose the right
data or the right model to create such predictions. With the rise of large
language models, there are ways to analyze certain data much more efficiently
than before.
  Our goal is to determine whether the GPT model provides more useful
information compared to other traditional transformer models, such as the BERT
model. We shall use data from the Federal Reserve Beige Book, which provides
summaries of economic conditions in different districts in the US. Using such
data, we then employ the LLM's to make predictions on the correlations. Using
these correlations, we then compare the results with well-known strategies and
determine whether knowing the economic conditions improves investment
decisions. We conclude that the Beige Book does contain information regarding
correlations amongst different assets, yet the GPT model has too much
look-ahead bias and that traditional models still triumph.
"
2411.18397,2024-11-28,Optimal payoff under Bregman-Wasserstein divergence constraints,"  We study optimal payoff choice for an expected utility maximizer under the
constraint that their payoff is not allowed to deviate ``too much'' from a
given benchmark. We solve this problem when the deviation is assessed via a
Bregman-Wasserstein (BW) divergence, generated by a convex function $\phi$.
Unlike the Wasserstein distance (i.e., when $\phi(x)=x^2$). The inherent
asymmetry of the BW divergence makes it possible to penalize positive
deviations different than negative ones. As a main contribution, we provide the
optimal payoff in this setting. Numerical examples illustrate that the choice
of $\phi$ allow to better align the payoff choice with the objectives of
investors.
"
2411.18830,2024-12-02,"Double Descent in Portfolio Optimization: Dance between Theoretical
  Sharpe Ratio and Estimation Accuracy","  We study the relationship between model complexity and out-of-sample
performance in the context of mean-variance portfolio optimization.
Representing model complexity by the number of assets, we find that the
performance of low-dimensional models initially improves with complexity but
then declines due to overfitting. As model complexity becomes sufficiently
high, the performance improves with complexity again, resulting in a double
ascent Sharpe ratio curve similar to the double descent phenomenon observed in
artificial intelligence. The underlying mechanisms involve an intricate
interaction between the theoretical Sharpe ratio and estimation accuracy. In
high-dimensional models, the theoretical Sharpe ratio approaches its upper
limit, and the overfitting problem is reduced because there are more parameters
than data restrictions, which allows us to choose well-behaved parameters based
on inductive bias.
"
2411.19285,2024-12-31,"BPQP: A Differentiable Convex Optimization Framework for Efficient
  End-to-End Learning","  Data-driven decision-making processes increasingly utilize end-to-end
learnable deep neural networks to render final decisions. Sometimes, the output
of the forward functions in certain layers is determined by the solutions to
mathematical optimization problems, leading to the emergence of differentiable
optimization layers that permit gradient back-propagation. However, real-world
scenarios often involve large-scale datasets and numerous constraints,
presenting significant challenges. Current methods for differentiating
optimization problems typically rely on implicit differentiation, which
necessitates costly computations on the Jacobian matrices, resulting in low
efficiency. In this paper, we introduce BPQP, a differentiable convex
optimization framework designed for efficient end-to-end learning. To enhance
efficiency, we reformulate the backward pass as a simplified and decoupled
quadratic programming problem by leveraging the structural properties of the
KKT matrix. This reformulation enables the use of first-order optimization
algorithms in calculating the backward pass gradients, allowing our framework
to potentially utilize any state-of-the-art solver. As solver technologies
evolve, BPQP can continuously adapt and improve its efficiency. Extensive
experiments on both simulated and real-world datasets demonstrate that BPQP
achieves a significant improvement in efficiency--typically an order of
magnitude faster in overall execution time compared to other differentiable
optimization layers. Our results not only highlight the efficiency gains of
BPQP but also underscore its superiority over differentiable optimization layer
baselines.
"
2411.19649,2024-12-02,"Dynamic ETF Portfolio Optimization Using enhanced Transformer-Based
  Models for Covariance and Semi-Covariance Prediction(Work in Progress)","  This study explores the use of Transformer-based models to predict both
covariance and semi-covariance matrices for ETF portfolio optimization.
Traditional portfolio optimization techniques often rely on static covariance
estimates or impose strict model assumptions, which may fail to capture the
dynamic and non-linear nature of market fluctuations. Our approach leverages
the power of Transformer models to generate adaptive, real-time predictions of
asset covariances, with a focus on the semi-covariance matrix to account for
downside risk. The semi-covariance matrix emphasizes negative correlations
between assets, offering a more nuanced approach to risk management compared to
traditional methods that treat all volatility equally.
  Through a series of experiments, we demonstrate that Transformer-based
predictions of both covariance and semi-covariance significantly enhance
portfolio performance. Our results show that portfolios optimized using the
semi-covariance matrix outperform those optimized with the standard covariance
matrix, particularly in volatile market conditions. Moreover, the use of the
Sortino ratio, a risk-adjusted performance metric that focuses on downside
risk, further validates the effectiveness of our approach in managing risk
while maximizing returns.
  These findings have important implications for asset managers and investors,
offering a dynamic, data-driven framework for portfolio construction that
adapts more effectively to shifting market conditions. By integrating
Transformer-based models with the semi-covariance matrix for improved risk
management, this research contributes to the growing field of machine learning
in finance and provides valuable insights for optimizing ETF portfolios.
"
2412.00036,2025-02-04,"Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial
  Market Dynamics","  We propose a highly efficient and accurate methodology for generating
synthetic financial market data using a diffusion model approach. The synthetic
data produced by our methodology align closely with observed market data in
several key aspects: (i) they pass the two-sample Cramer - von Mises test for
portfolios of assets, and (ii) Q - Q plots demonstrate consistency across
quantiles, including in the tails, between observed and generated market data.
Moreover, the covariance matrices derived from a large set of synthetic market
data exhibit significantly lower condition numbers compared to the estimated
covariance matrices of the observed data. This property makes them suitable for
use as regularized versions of the latter. For model training, we develop an
efficient and fast algorithm based on numerical integration rather than Monte
Carlo simulations. The methodology is tested on a large set of equity data.
"
2412.03038,2024-12-05,"MILLION: A General Multi-Objective Framework with Controllable Risk for
  Portfolio Management","  Portfolio management is an important yet challenging task in AI for FinTech,
which aims to allocate investors' budgets among different assets to balance the
risk and return of an investment. In this study, we propose a general
Multi-objectIve framework with controLLable rIsk for pOrtfolio maNagement
(MILLION), which consists of two main phases, i.e., return-related maximization
and risk control. Specifically, in the return-related maximization phase, we
introduce two auxiliary objectives, i.e., return rate prediction, and return
rate ranking, combined with portfolio optimization to remit the overfitting
problem and improve the generalization of the trained model to future markets.
Subsequently, in the risk control phase, we propose two methods, i.e.,
portfolio interpolation and portfolio improvement, to achieve fine-grained risk
control and fast risk adaption to a user-specified risk level. For the
portfolio interpolation method, we theoretically prove that the risk can be
perfectly controlled if the to-be-set risk level is in a proper interval. In
addition, we also show that the return rate of the adjusted portfolio after
portfolio interpolation is no less than that of the min-variance optimization,
as long as the model in the reward maximization phase is effective.
Furthermore, the portfolio improvement method can achieve greater return rates
while keeping the same risk level compared to portfolio interpolation.
Extensive experiments are conducted on three real-world datasets. The results
demonstrate the effectiveness and efficiency of the proposed framework.
"
2412.03305,2024-12-05,Turnover of investment portfolio via covariance matrix of returns,"  An investment portfolio consists of $n$ algorithmic trading strategies, which
generate vectors of positions in trading assets. Sign opposite trades
(buy/sell) cross each other as strategies are combined in a portfolio. Then
portfolio turnover becomes a non linear function of strategies turnover. It
rises a problem of effective (quick and precise) portfolio turnover estimation.
Kakushadze and Liew (2014) shows how to estimate turnover via covariance matrix
of returns. We build a mathematical model for such estimations; prove a theorem
which gives a necessary condition for model applicability; suggest new turnover
estimations; check numerically the preciseness of turnover estimations for
algorithmic strategies on USA equity market.
"
2412.04263,2024-12-06,Correlation without Factors in Retail Cryptocurrency Markets,"  A simple model-free and distribution-free statistic, the functional
relationship between the number of ""effective"" degrees of freedom and portfolio
size, or N*(N), is used to discriminate between two alternative models for the
correlation of daily cryptocurrency returns within a retail universe of defined
by the list of tradable assets available to account holders at the Robinhood
brokerage. The average pairwise correlation between daily cryptocurrency
returns is found to be high (of order 60%) and the data collected supports
description of the cross-section of returns by a simple isotropic correlation
model distinct from a decomposition into a linear factor model with additive
noise with high confidence. This description appears to be relatively stable
through time.
"
2412.04490,2024-12-09,M6 Investment Challenge: The Role of Luck and Strategic Considerations,"  This article investigates the influence of luck and strategic considerations
on performance of teams participating in the M6 investment challenge. We find
that there is insufficient evidence to suggest that the extreme Sharpe ratios
observed are beyond what one would expect by chance, given the number of teams,
and thus not necessarily indicative of the possibility of consistently
attaining abnormal returns. Furthermore, we introduce a stylized model of the
competition to derive and analyze a portfolio strategy optimized for attaining
the top rank. The results demonstrate that the task of achieving the top rank
is not necessarily identical to that of attaining the best investment returns
in expectation. It is possible to improve one's chances of winning, even
without the ability to attain abnormal returns, by choosing portfolio weights
adversarially based on the current competition ranking. Empirical analysis of
submitted portfolio weights aligns with this finding.
"
2412.05431,2025-03-25,"Smart leverage? Rethinking the role of Leveraged Exchange Traded Funds
  in constructing portfolios to beat a benchmark","  Leveraged Exchange Traded Funds (LETFs), while extremely controversial in the
literature, remain stubbornly popular with both institutional and retail
investors in practice. While the criticisms of LETFs are certainly valid, we
argue that their potential has been underestimated in the literature due to the
use of very simple investment strategies involving LETFs. In this paper, we
systematically investigate the potential of including a broad stock market
index LETF in long-term, dynamically-optimal investment strategies designed to
maximize the outperformance over standard investment benchmarks in the sense of
the information ratio (IR). Our results exploit the observation that positions
in a LETF deliver call-like payoffs, so that the addition of a LETF to a
portfolio can be a convenient way to add inexpensive leverage while providing
downside protection. Under stylized assumptions, we present and analyze
closed-form IR-optimal investment strategies using either a LETF or
standard/vanilla ETF (VETF) on the same equity index, which provides the
necessary intuition for the potential and benefits of LETFs. In more realistic
settings, we use a neural network-based approach to determine the IR-optimal
strategies, trained on bootstrapped historical data. We find that IR-optimal
strategies with a broad stock market LETF are not only more likely to
outperform the benchmark than IR-optimal strategies derived using the
corresponding VETF, but are able to achieve partial stochastic dominance over
the benchmark and VETF-based strategies in terms of terminal wealth.
"
2412.07688,2024-12-11,A Joint Energy and Differentially-Private Smart Meter Data Market,"  Given the vital role that smart meter data could play in handling uncertainty
in energy markets, data markets have been proposed as a means to enable
increased data access. However, most extant literature considers energy markets
and data markets separately, which ignores the interdependence between them. In
addition, existing data market frameworks rely on a trusted entity to clear the
market. This paper proposes a joint energy and data market focusing on the
day-ahead retailer energy procurement problem with uncertain demand. The
retailer can purchase differentially-private smart meter data from consumers to
reduce uncertainty. The problem is modelled as an integrated forecasting and
optimisation problem providing a means of valuing data directly rather than
valuing forecasts or forecast accuracy. Value is determined by the Wasserstein
distance, enabling privacy to be preserved during the valuation and procurement
process. The value of joint energy and data clearing is highlighted through
numerical case studies using both synthetic and real smart meter data.
"
2412.09394,2024-12-13,"LLMs for Time Series: an Application for Single Stocks and Statistical
  Arbitrage","  Recently, LLMs (Large Language Models) have been adapted for time series
prediction with significant success in pattern recognition. However, the common
belief is that these models are not suitable for predicting financial market
returns, which are known to be almost random. We aim to challenge this
misconception through a counterexample. Specifically, we utilized the Chronos
model from Ansari et al.(2024) and tested both pretrained configurations and
fine-tuned supervised forecasts on the largest American single stocks using
data from Guijarro-Ordonnez et al.(2022). We constructed a long/short
portfolio, and the performance simulation indicates that LLMs can in reality
handle time series that are nearly indistinguishable from noise, demonstrating
an ability to identify inefficiencies amidst randomness and generate alpha.
Finally, we compared these results with those of specialized models and smaller
deep learning models, highlighting significant room for improvement in LLM
performance to further enhance their predictive capabilities.
"
2412.09517,2024-12-13,Geometric Deep Learning for Realized Covariance Matrix Forecasting,"  Traditional methods employed in matrix volatility forecasting often overlook
the inherent Riemannian manifold structure of symmetric positive definite
matrices, treating them as elements of Euclidean space, which can lead to
suboptimal predictive performance. Moreover, they often struggle to handle
high-dimensional matrices. In this paper, we propose a novel approach for
forecasting realized covariance matrices of asset returns using a
Riemannian-geometry-aware deep learning framework. In this way, we account for
the geometric properties of the covariance matrices, including possible
non-linear dynamics and efficient handling of high-dimensionality. Moreover,
building upon a Fr\'echet sample mean of realized covariance matrices, we are
able to extend the HAR model to the matrix-variate. We demonstrate the efficacy
of our approach using daily realized covariance matrices for the 50 most
capitalized companies in the S&P 500 index, showing that our method outperforms
traditional approaches in terms of predictive accuracy.
"
2412.11019,2024-12-17,PolyModel for Hedge Funds' Portfolio Construction Using Machine Learning,"  The domain of hedge fund investments is undergoing significant
transformation, influenced by the rapid expansion of data availability and the
advancement of analytical technologies. This study explores the enhancement of
hedge fund investment performance through the integration of machine learning
techniques, the application of PolyModel feature selection, and the analysis of
fund size. We address three critical questions: (1) the effect of machine
learning on trading performance, (2) the role of PolyModel feature selection in
fund selection and performance, and (3) the comparative reliability of larger
versus smaller funds.
  Our findings offer compelling insights. We observe that while machine
learning techniques enhance cumulative returns, they also increase annual
volatility, indicating variability in performance. PolyModel feature selection
proves to be a robust strategy, with approaches that utilize a comprehensive
set of features for fund selection outperforming more selective methodologies.
Notably, Long-Term Stability (LTS) effectively manages portfolio volatility
while delivering favorable returns. Contrary to popular belief, our results
suggest that larger funds do not consistently yield better investment outcomes,
challenging the assumption of their inherent reliability.
  This research highlights the transformative impact of data-driven approaches
in the hedge fund investment arena and provides valuable implications for
investors and asset managers. By leveraging machine learning and PolyModel
feature selection, investors can enhance portfolio optimization and reassess
the dependability of larger funds, leading to more informed investment
strategies.
"
2412.11575,2024-12-17,Cost-aware Portfolios in a Large Universe of Assets,"  This paper considers the finite horizon portfolio rebalancing problem in
terms of mean-variance optimization, where decisions are made based on current
information on asset returns and transaction costs. The study's novelty is that
the transaction costs are integrated within the optimization problem in a
high-dimensional portfolio setting where the number of assets is larger than
the sample size. We propose portfolio construction and rebalancing models with
nonconvex penalty considering two types of transaction cost, the proportional
transaction cost and the quadratic transaction cost. We establish the desired
theoretical properties under mild regularity conditions. Monte Carlo
simulations and empirical studies using S&P 500 and Russell 2000 stocks show
the satisfactory performance of the proposed portfolio and highlight the
importance of involving the transaction costs when rebalancing a portfolio.
"
2412.12539,2024-12-18,"Hunting Tomorrow's Leaders: Using Machine Learning to Forecast S&P 500
  Additions & Removal","  This study applies machine learning to predict S&P 500 membership changes:
key events that profoundly impact investor behavior and market dynamics.
Quarterly data from WRDS datasets (2013 onwards) was used, incorporating
features such as industry classification, financial data, market data, and
corporate governance indicators. Using a Random Forest model, we achieved a
test F1 score of 0.85, outperforming logistic regression and SVC models. This
research not only showcases the power of machine learning for financial
forecasting but also emphasizes model transparency through SHAP analysis and
feature engineering. The model's real world applicability is demonstrated with
predicted changes for Q3 2023, such as the addition of Uber (UBER) and the
removal of SolarEdge Technologies (SEDG). By incorporating these predictions
into a trading strategy i.e. buying stocks announced for addition and shorting
those marked for removal, we anticipate capturing alpha and enhancing
investment decision making, offering valuable insights into index dynamics
"
2412.12576,2024-12-18,"Market-Neutral Strategies in Mid-Cap Portfolio Management: A Data-Driven
  Approach to Long-Short Equity","  Mid-cap companies, generally valued between \$2 billion and \$10 billion,
provide investors with a well-rounded opportunity between the fluctuation of
small-cap stocks and the stability of large-cap stocks. This research builds
upon the long-short equity approach (e.g., Michaud, 2018; Dimitriu, Alexander,
2002) customized for mid-cap equities, providing steady risk-adjusted returns
yielding a significant Sharpe ratio of 2.132 in test data. Using data from 2013
to 2023, obtained from WRDS and following point-in-time (PIT) compliance, the
approach guarantees clarity and reproducibility. Elements of essential
financial indicators, such as profitability, valuation, and liquidity, were
designed to improve portfolio optimization. Testing historical data across
various markets conditions illustrates the stability and resilience of the
tactic. This study highlights mid-cap stocks as an attractive investment route,
overlooked by most analysts, which combine transparency with superior
performance in managing portfolios.
"
2412.13172,2024-12-18,"Expressions of Market-Based Correlations Between Prices and Returns of
  Two Assets","  This paper derives the expressions of correlations between prices of two
assets, returns of two assets, and price-return correlations of two assets that
depend on statistical moments and correlations of the current values, past
values, and volumes of their market trades. The usual frequency-based
expressions of correlations of time series of prices and returns describe a
partial case of our model when all trade volumes and past trade values are
constant. Such an assumptions are rather far from market reality, and its use
results in excess losses and wrong forecasts. Traders, banks, and funds that
perform multi-million market transactions or manage billion-valued portfolios
should consider the impact of large trade volumes on market prices and returns.
The use of the market-based correlations of prices and returns of two assets is
mandatory for them. The development of macroeconomic models and market
forecasts like those being created by BlackRock's Aladdin, JP Morgan, and the
U.S. Fed., is impossible without the use of market-based correlations of prices
and returns of two assets.
"
2412.14144,2024-12-19,Application of the Kelly Criterion to Prediction Markets,"  Betting markets are gaining in popularity. Mean beliefs generally differ from
prices in prediction markets. Logarithmic utility is employed to study the risk
and return adjustments to prices. Some consequences are described. A modified
payout structure is proposed. A simple asset price model based on flipping
biased coins is investigated. It is shown using the Kullback-Leibler divergence
how the misjudgment of the bias and the miscalculation of the investment
fraction influence the portfolio growth rate.
"
2412.14182,2024-12-20,Uncertainty Quantification in Portfolio Temperature Alignment,"  We present a novel Bayesian framework for quantifying uncertainty in
portfolio temperature alignment models, leveraging the X-Degree Compatibility
(XDC) approach with the scientifically validated Finite Amplitude Impulse
Response (FaIR) climate model. This framework significantly advances the widely
adopted linear approaches that use the Transient Climate Response to Cumulative
CO2 Emissions (TCRE). Developed in collaboration with right{\deg}, one of the
pioneering companies in portfolio temperature alignment, our methodology
addresses key sources of uncertainty, including parameter variability and input
emission data across diverse decarbonization pathways. By employing adaptive
Markov Chain Monte Carlo (MCMC) methods, we provide robust parametric
uncertainty quantification for the FaIR model. To enhance computational
efficiency, we integrate a deep learning-based emulator, enabling near
real-time simulations. Through practical examples, we demonstrate how this
framework improves climate risk management and decision-making in portfolio
construction by treating uncertainty as a critical feature rather than a
constraint. Moreover, our approach identifies the primary sources of
uncertainty, offering valuable insights for future research.
"
2412.14361,2024-12-23,"Refining and Robust Backtesting of A Century of Profitable Industry
  Trends","  We revisit the long-only trend-following strategy presented in A Century of
Profitable Industry Trends by Zarattini and Antonacci, which achieved
exceptional historical performance with an 18.2% annualized return and a Sharpe
Ratio of 1.39. While the results outperformed benchmarks, practical
implementation raises concerns about robustness and evolving market conditions.
This study explores modifications addressing reliance on T-bills, alternative
fallback allocations, and industry exclusions. Despite attempts to enhance
adaptability through momentum signals, parameter optimization, and Walk-Forward
Analysis, results reveal persistent challenges. The results highlight
challenges in adapting historical strategies to modern markets and offer
insights for future trend-following frameworks.
"
2412.15986,2024-12-23,Shifting the yield curve for fixed-income and derivatives portfolios,"  We use granular regulatory data on euro interest rate swap trades between
January 2021 and June 2023 to assess whether derivative positions of Italian
banks can offset losses on their debt securities holdings should interest rates
rise unexpectedly. At the aggregate level of the banking system, we find that a
100-basis-point upward shift of the yield curve increases on average the value
of swaps by 3.65% of Common Equity Tier 1 (CET1), compensating in part for the
losses of 2.64% and 5.98% of CET1 recorded on debt securities valued at fair
value and amortised cost. Variation exists across institutions, with some bank
swap positions playing an offsetting role and some exacerbating bond market
exposures to interest rate risk. Nevertheless, we conclude that, on aggregate,
Italian banks use swaps as hedging instruments to reduce their interest rate
exposures, which improves their ability to cope with the recent tightening of
monetary policy. Finally, we draw on our swap pricing model to conduct an
extensive data quality analysis of the transaction-level information available
to authorities, and we show that the errors in fitting value changes over time
are significantly lower compared to those in fitting the values themselves.
"
2412.16175,2024-12-24,"Mean--Variance Portfolio Selection by Continuous-Time Reinforcement
  Learning: Algorithms, Regret Analysis, and Empirical Study","  We study continuous-time mean--variance portfolio selection in markets where
stock prices are diffusion processes driven by observable factors that are also
diffusion processes yet the coefficients of these processes are unknown. Based
on the recently developed reinforcement learning (RL) theory for diffusion
processes, we present a general data-driven RL algorithm that learns the
pre-committed investment strategy directly without attempting to learn or
estimate the market coefficients. For multi-stock Black--Scholes markets
without factors, we further devise a baseline algorithm and prove its
performance guarantee by deriving a sublinear regret bound in terms of Sharpe
ratio. For performance enhancement and practical implementation, we modify the
baseline algorithm into four variants, and carry out an extensive empirical
study to compare their performance, in terms of a host of common metrics, with
a large number of widely used portfolio allocation strategies on S\&P 500
constituents. The results demonstrate that the continuous-time RL strategies
are consistently among the best especially in a volatile bear market, and
decisively outperform the model-based continuous-time counterparts by
significant margins.
"
2412.17293,2024-12-24,Multimodal Deep Reinforcement Learning for Portfolio Optimization,"  We propose a reinforcement learning (RL) framework that leverages multimodal
data including historical stock prices, sentiment analysis, and topic
embeddings from news articles, to optimize trading strategies for SP100 stocks.
Building upon recent advancements in financial reinforcement learning, we aim
to enhance the state space representation by integrating financial sentiment
data from SEC filings and news headlines and refining the reward function to
better align with portfolio performance metrics. Our methodology includes deep
reinforcement learning with state tensors comprising price data, sentiment
scores, and news embeddings, processed through advanced feature extraction
models like CNNs and RNNs. By benchmarking against traditional portfolio
optimization techniques and advanced strategies, we demonstrate the efficacy of
our approach in delivering superior portfolio performance. Empirical results
showcase the potential of our agent to outperform standard benchmarks,
especially when utilizing combined data sources under profit-based reward
functions.
"
2412.18201,2024-12-25,"Indices of quadratic programs over reproducing kernel Hilbert spaces for
  fun and profit","  We give an abstract perspective on quadratic programming with an eye toward
long portfolio theory geared toward explaining sparsity via maximum principles.
Specifically, in optimal allocation problems, we see that support of an optimal
distribution lies in a variety intersect a kind of distinguished boundary of a
compact subspace to be allocated over. We demonstrate some of its intelligence
by using it to solve mazes and interpret such behavior as the underlying space
trying to understand some hypothetical platonic index for which the capital
asset pricing model holds.
"
2412.18563,2025-02-24,"A Deep Reinforcement Learning Framework for Dynamic Portfolio
  Optimization: Evidence from China's Stock Market","  Artificial intelligence is transforming financial investment decision-making
frameworks, with deep reinforcement learning demonstrating substantial
potential in robo-advisory applications. This paper addresses the limitations
of traditional portfolio optimization methods in dynamic asset weight
adjustment through the development of a deep reinforcement learning-based
dynamic optimization model grounded in practical trading processes. The
research advances two key innovations: first, the introduction of a novel
Sharpe ratio reward function engineered for Actor-Critic deep reinforcement
learning algorithms, which ensures stable convergence during training while
consistently achieving positive average Sharpe ratios; second, the development
of an innovative comprehensive approach to portfolio optimization utilizing
deep reinforcement learning, which significantly enhances model optimization
capability through the integration of random sampling strategies during
training with image-based deep neural network architectures for
multi-dimensional financial time series data processing, average Sharpe ratio
reward functions, and deep reinforcement learning algorithms. The empirical
analysis validates the model using randomly selected constituent stocks from
the CSI 300 Index, benchmarking against established financial econometric
optimization models. Backtesting results demonstrate the model's efficacy in
optimizing portfolio allocation and mitigating investment risk, yielding
superior comprehensive performance metrics.
"
2412.19245,2024-12-30,Sentiment trading with large language models,"  We investigate the efficacy of large language models (LLMs) in sentiment
analysis of U.S. financial news and their potential in predicting stock market
returns. We analyze a dataset comprising 965,375 news articles that span from
January 1, 2010, to June 30, 2023; we focus on the performance of various LLMs,
including BERT, OPT, FINBERT, and the traditional Loughran-McDonald dictionary
model, which has been a dominant methodology in the finance literature. The
study documents a significant association between LLM scores and subsequent
daily stock returns. Specifically, OPT, which is a GPT-3 based LLM, shows the
highest accuracy in sentiment prediction with an accuracy of 74.4%, slightly
ahead of BERT (72.5%) and FINBERT (72.2%). In contrast, the Loughran-McDonald
dictionary model demonstrates considerably lower effectiveness with only 50.1%
accuracy. Regression analyses highlight a robust positive impact of OPT model
scores on next-day stock returns, with coefficients of 0.274 and 0.254 in
different model specifications. BERT and FINBERT also exhibit predictive
relevance, though to a lesser extent. Notably, we do not observe a significant
relationship between the Loughran-McDonald dictionary model scores and stock
returns, challenging the efficacy of this traditional method in the current
financial context. In portfolio performance, the long-short OPT strategy excels
with a Sharpe ratio of 3.05, compared to 2.11 for BERT and 2.07 for FINBERT
long-short strategies. Strategies based on the Loughran-McDonald dictionary
yield the lowest Sharpe ratio of 1.23. Our findings emphasize the superior
performance of advanced LLMs, especially OPT, in financial market prediction
and portfolio management, marking a significant shift in the landscape of
financial analysis tools with implications to financial regulation and policy
analysis.
"
2412.19462,2024-12-30,"Robust and Sparse Portfolio Selection: Quantitative Insights and
  Efficient Algorithms","  We extend the classical mean-variance (MV) framework and propose a robust and
sparse portfolio selection model incorporating an ellipsoidal uncertainty set
to reduce the impact of estimation errors and fixed transaction costs to
penalize over-diversification. In the literature, the MV model under fixed
transaction costs is referred to as the sparse or cardinality-constrained MV
optimization, which is a mixed integer problem and is challenging to solve when
the number of assets is large. We develop an efficient semismooth Newton-based
proximal difference-of-convex algorithm to solve the proposed model and prove
its convergence to at least a local minimizer with a locally linear convergence
rate. We explore properties of the robust and sparse portfolio both
analytically and numerically. In particular, we show that the MV optimization
is indeed a robust procedure as long as an investor makes the proper choice on
the risk-aversion coefficient. We contribute to the literature by proving that
there is a one-to-one correspondence between the risk-aversion coefficient and
the level of robustness. Moreover, we characterize how the number of traded
assets changes with respect to the interaction between the level of uncertainty
on model parameters and the magnitude of transaction cost.
"
2501.01763,2025-01-06,"Quantifying A Firm's AI Engagement: Constructing Objective, Data-Driven,
  AI Stock Indices Using 10-K Filings","  Following an analysis of existing AI-related exchange-traded funds (ETFs), we
reveal the selection criteria for determining which stocks qualify as
AI-related are often opaque and rely on vague phrases and subjective judgments.
This paper proposes a new, objective, data-driven approach using natural
language processing (NLP) techniques to classify AI stocks by analyzing annual
10-K filings from 3,395 NASDAQ-listed firms between 2011 and 2023. This
analysis quantifies each company's engagement with AI through binary indicators
and weighted AI scores based on the frequency and context of AI-related terms.
Using these metrics, we construct four AI stock indices-the Equally Weighted AI
Index (AII), the Size-Weighted AI Index (SAII), and two Time-Discounted AI
Indices (TAII05 and TAII5X)-offering different perspectives on AI investment.
We validate our methodology through an event study on the launch of OpenAI's
ChatGPT, demonstrating that companies with higher AI engagement saw
significantly greater positive abnormal returns, with analyses supporting the
predictive power of our AI measures. Our indices perform on par with or surpass
14 existing AI-themed ETFs and the Nasdaq Composite Index in risk-return
profiles, market responsiveness, and overall performance, achieving higher
average daily returns and risk-adjusted metrics without increased volatility.
These results suggest our NLP-based approach offers a reliable,
market-responsive, and cost-effective alternative to existing AI-related ETF
products. Our innovative methodology can also guide investors, asset managers,
and policymakers in using corporate data to construct other thematic
portfolios, contributing to a more transparent, data-driven, and competitive
approach.
"
2501.03919,2025-05-06,"Multi-Hypothesis Prediction for Portfolio Optimization: A Structured
  Ensemble Learning Approach to Risk Diversification","  This work proposes a unified framework for portfolio allocation, covering
both asset selection and optimization, based on a multiple-hypothesis
predict-then-optimize approach. The portfolio is modeled as a structured
ensemble, where each predictor corresponds to a specific asset or hypothesis.
Structured ensembles formally link predictors' diversity, captured via ensemble
loss decomposition, to out-of-sample risk diversification. A structured data
set of predictor output is constructed with a parametric diversity control,
which influences both the training process and the diversification outcomes.
This data set is used as input for a supervised ensemble model, the target
portfolio of which must align with the ensemble combiner rule implied by the
loss. For squared loss, the arithmetic mean applies, yielding the
equal-weighted portfolio as the optimal target. For asset selection, a novel
method is introduced which prioritizes assets from more diverse predictor sets,
even at the expense of lower average predicted returns, through a
diversity-quality trade-off. This form of diversity is applied before the
portfolio optimization stage and is compatible with a wide range of allocation
techniques. Experiments conducted on the full S&P 500 universe and a data set
of 1.300 global bonds of various types over more than two decades validate the
theoretical framework. Results show that both sources of diversity effectively
extend the boundaries of achievable portfolio diversification, delivering
strong performance across both one-step and multi-step allocation tasks.
"
2501.03938,2025-01-08,In-Sample and Out-of-Sample Sharpe Ratios for Linear Predictive Models,"  We study how much the in-sample performance of trading strategies based on
linear predictive models is reduced out-of-sample due to overfitting. More
specifically, we compute the in- and out-of-sample means and variances of the
corresponding PnLs and use these to derive a closed-form approximation for the
corresponding Sharpe ratios. We find that the out-of-sample ``replication
ratio'' diminishes for complex strategies with many assets and based on many
weak rather than a few strong trading signals, and increases when more training
data is used. The substantial quantitative importance of these effects is
illustrated with an empirical case study for commodity futures following the
methodology of Garleanu-Pedersen.
"
2501.03993,2025-04-24,"Synthetic Data for Portfolios: A Throw of the Dice Will Never Abolish
  Chance","  Simulation methods have always been instrumental in finance, and data-driven
methods with minimal model specification, commonly referred to as generative
models, have attracted increasing attention, especially after the success of
deep learning in a broad range of fields. However, the adoption of these models
in financial applications has not matched the growing interest, probably due to
the unique complexities and challenges of financial markets. This paper
contributes to a deeper understanding of the limitations of generative models,
particularly in portfolio and risk management. To this end, we begin by
presenting theoretical results on the importance of initial sample size, and
point out the potential pitfalls of generating far more data than originally
available. We then highlight the inseparable nature of model development and
the desired uses by touching on a paradox: usual generative models inherently
care less about what is important for constructing portfolios (in particular
the long-short ones). Based on these findings, we propose a pipeline for the
generation of multivariate returns that meets conventional evaluation standards
on a large universe of US equities while being compliant with stylized facts
observed in asset returns and turning around the pitfalls we previously
identified. Moreover, we insist on the need for more accurate evaluation
methods, and suggest, through an example of mean-reversion strategies, a method
designed to identify poor models for a given application based on regurgitative
training, i.e. retraining the model using the data it has itself generated,
which is commonly referred to in statistics as identifiability.
"
2501.04646,2025-01-15,A mixture transition distribution approach to portfolio optimization,"  Understanding the dependencies among financial assets is critical for
portfolio optimization. Traditional approaches based on correlation networks
often fail to capture the nonlinear and directional relationships that exist in
financial markets. In this study, we construct directed and weighted financial
networks using the Mixture Transition Distribution (MTD) model, offering a
richer representation of asset interdependencies. We apply local assortativity
measures--metrics that evaluate how assets connect based on similarities or
differences--to guide portfolio selection and allocation. Using data from the
Dow Jones 30, Euro Stoxx 50, and FTSE 100 indices constituents, we show that
portfolios optimized with network-based assortativity measures consistently
outperform the classical mean-variance framework. Notably, modalities in which
assets with differing characteristics connect enhance diversification and
improve Sharpe ratios. The directed nature of MTD-based networks effectively
captures complex relationships, yielding portfolios with superior risk-adjusted
returns. Our findings highlight the utility of network-based methodologies in
financial decision-making, demonstrating their ability to refine portfolio
optimization strategies. This work thus underscores the potential of leveraging
advanced financial networks to achieve enhanced performance, offering valuable
insights for practitioners and setting a foundation for future research.
"
2501.06275,2025-01-14,"Exploratory Randomization for Discrete-Time Linear Exponential Quadratic
  Gaussian (LEQG) Problem","  We investigate exploratory randomization for an extended
linear-exponential-quadratic-Gaussian (LEQG) control problem in discrete time.
This extended control problem is related to the structure of risk-sensitive
investment management applications. We introduce exploration through a
randomization of the control. Next, we apply the duality between free energy
and relative entropy to reduce the LEQG problem to an equivalent risk-neutral
LQG control problem with an entropy regularization term, see, e.g. Dai Pra et
al. (1996), for which we present a solution approach based on Dynamic
Programming. Our approach, based on the energy-entropy duality may also be
considered as leading to a justification for the use, in the literature, of an
entropy regularization when applying a randomized control.
"
2501.06701,2025-01-22,"Sequential Portfolio Selection under Latent Side Information-Dependence
  Structure: Optimality and Universal Learning Algorithms","  This paper investigates the investment problem of constructing an optimal
no-short sequential portfolio strategy in a market with a latent dependence
structure between asset prices and partly unobservable side information, which
is often high-dimensional. The results demonstrate that a dynamic strategy,
which forms a portfolio based on perfect knowledge of the dependence structure
and full market information over time, may not grow at a higher rate infinitely
often than a constant strategy, which remains invariant over time.
Specifically, if the market is stationary, implying that the dependence
structure is statistically stable, the growth rate of an optimal dynamic
strategy, utilizing the maximum capacity of the entire market information,
almost surely decays over time into an equilibrium state, asymptotically
converging to the growth rate of a constant strategy.
  Technically, this work reassesses the common belief that a constant strategy
only attains the optimal limiting growth rate of dynamic strategies when the
market process is identically and independently distributed. By analyzing the
dynamic log-optimal portfolio strategy as the optimal benchmark in a stationary
market with side information, we show that a random optimal constant strategy
almost surely exists, even when a limiting growth rate for the dynamic strategy
does not. Consequently, two approaches to learning algorithms for portfolio
construction are discussed, demonstrating the safety of removing side
information from the learning process while still guaranteeing an asymptotic
growth rate comparable to that of the optimal dynamic strategy.
"
2501.09911,2025-01-20,"Institutional Adoption and Correlation Dynamics: Bitcoin's Evolving Role
  in Financial Markets","  Bitcoin, widely recognized as the first cryptocurrency, has shown increasing
integration with traditional financial markets, particularly major U.S. equity
indices, amid accelerating institutional adoption. This study examines how
Bitcoin exchange-traded funds and corporate Bitcoin holdings affect
correlations with the Nasdaq 100 and the S&P 500, using rolling-window
correlation, static correlation coefficients, and an event-study framework on
daily data from 2018 to 2025.Correlation levels intensified following key
institutional milestones, with peaks reaching 0.87 in 2024, and they vary
across market regimes. These trends suggest that Bitcoin has transitioned from
an alternative asset toward a more integrated financial instrument, carrying
implications for portfolio diversification, risk management, and systemic
stability. Future research should further investigate regulatory and
macroeconomic factors shaping these evolving relationships.
"
2501.12074,2025-01-23,"Optimizing Portfolio Performance through Clustering and Sharpe
  Ratio-Based Optimization: A Comparative Backtesting Approach","  Optimizing portfolio performance is a fundamental challenge in financial
modeling, requiring the integration of advanced clustering techniques and
data-driven optimization strategies. This paper introduces a comparative
backtesting approach that combines clustering-based portfolio segmentation and
Sharpe ratio-based optimization to enhance investment decision-making. First,
we segment a diverse set of financial assets into clusters based on their
historical log-returns using K-Means clustering. This segmentation enables the
grouping of assets with similar return characteristics, facilitating targeted
portfolio construction. Next, for each cluster, we apply a Sharpe ratio-based
optimization model to derive optimal weights that maximize risk-adjusted
returns. Unlike traditional mean-variance optimization, this approach directly
incorporates the trade-off between returns and volatility, resulting in a more
balanced allocation of resources within each cluster. The proposed framework is
evaluated through a backtesting study using historical data spanning multiple
asset classes. Optimized portfolios for each cluster are constructed and their
cumulative returns are compared over time against a traditional equal-weighted
benchmark portfolio.
"
2501.12397,2025-01-23,"Stochastic Optimal Control of Iron Condor Portfolios for Profitability
  and Risk Management","  Previous research on option strategies has primarily focused on their
behavior near expiration, with limited attention to the transient value process
of the portfolio. In this paper, we formulate Iron Condor portfolio
optimization as a stochastic optimal control problem, examining the impact of
the control process \( u(k_i, \tau) \) on the portfolio's potential
profitability and risk. By assuming the underlying price process as a bounded
martingale within $[K_1, K_2]$, we prove that the portfolio with a strike
structure of $k_1 < k_2 = K_2 < S_t < k_3 = K_3 < k_4$ has a submartingale
value process, which results in the optimal stopping time aligning with the
expiration date $\tau = T$. Moreover, we construct a data generator based on
the Rough Heston model to investigate general scenarios through simulation. The
results show that asymmetric, left-biased Iron Condor portfolios with $\tau =
T$ are optimal in SPX markets, balancing profitability and risk management.
Deep out-of-the-money strategies improve profitability and success rates at the
cost of introducing extreme losses, which can be alleviated by using an optimal
stopping strategy. Except for the left-biased portfolios $\tau$ generally falls
within the range of [50\%,75\%] of total duration. In addition, we validate
these findings through case studies on the actual SPX market, covering bullish,
sideways, and bearish market conditions.
"
2501.12600,2025-02-18,"Pontryagin-Guided Deep Learning for Large-Scale Constrained Dynamic
  Portfolio Choice","  We present a Pontryagin-Guided Direct Policy Optimization (PG-DPO) method for
constrained dynamic portfolio choice - incorporating consumption and
multi-asset investment - that scales to thousands of risky assets. By combining
neural-network controls with Pontryagin's Maximum Principle (PMP), it
circumvents the curse of dimensionality that renders dynamic programming (DP)
grids intractable beyond a handful of assets. Unlike value-based PDE or BSDE
approaches, PG-DPO enforces PMP conditions at each gradient step, naturally
accommodating no-short-selling or borrowing constraints and optional
consumption bounds. A ""one-shot"" variant rapidly computes Pontryagin-optimal
controls after a brief warm-up, leading to substantially higher accuracy than
naive baselines. On modern GPUs, near-optimal solutions often emerge within
just one or two minutes of training. Numerical experiments confirm that, for up
to 1,000 assets, PG-DPO accurately recovers the known closed-form solution in
the unconstrained case and remains tractable under constraints -- far exceeding
the longstanding DP-based limit of around seven assets.
"
2501.12841,2025-01-23,"Can optimal diversification beat the naive 1/N strategy in a highly
  correlated market? Empirical evidence from cryptocurrencies","  This study systematically examines how several alternative approaches
considered affect three aspects that determine portfolio performance (the gross
return, the transaction costs and the portfolio risk). We find that it is
difficult to exploit the possible predictability of asset returns. However, the
predictability of asset return volatility produces obvious economic value,
although in a highly correlated cryptocurrencies market.
"
2501.13901,2025-01-24,"Optimizing Portfolios with Pakistan-Exposed ETFs: Risk and Performance
  Insight","  This study examines the investment landscape of Pakistan as an emerging and
frontier market, focusing on implications for international investors,
particularly those in the United States, through exchange-traded funds (ETFs)
with exposure to Pakistan. The analysis encompasses 30 ETFs with varying
degrees of exposure to Pakistan, covering the period from January 1, 2016, to
February 2024. This research highlights the potential benefits and risks
associated with investing in these ETFs, emphasizing the importance of thorough
risk assessments and portfolio performance comparisons. By providing
descriptive statistics and performance metrics based on historical
optimization, this paper aims to equip investors with the necessary insights to
make informed decisions when optimizing their portfolios with Pakistan-exposed
ETFs. The second part of the paper introduces and assesses dynamic optimization
methodologies. This section is designed to explore the adaptability and
performance metrics of dynamic optimization techniques in comparison with
conventional historical optimization methods. By integrating dynamic
optimization into the investigation, this research aims to offer insights into
the efficacy of these contrasting methodologies in the context of
Pakistan-exposed ETFs. The findings underscore the significance of Pakistan's
market dynamics within the broader context of emerging markets, offering a
pathway for diversification and potential growth in investment strategies.
"
2501.14259,2025-01-27,Optimal Investment under Mutual Strategy Influence among Agents,"  In financial markets, agents often mutually influence each other's investment
strategies and adjust their strategies to align with others. However, there is
limited quantitative study of agents' investment strategies in such scenarios.
In this work, we formulate the optimal investment differential game problem to
study the mutual influence among agents. We derive the analytical solutions for
agents' optimal strategies and propose a fast algorithm to find approximate
solutions with low computational complexity. We theoretically analyze the
impact of mutual influence on agents' optimal strategies and terminal wealth.
When the mutual influence is strong and approaches infinity, we show that
agents' optimal strategies converge to the asymptotic strategy. Furthermore, in
general cases, we prove that agents' optimal strategies are linear combinations
of the asymptotic strategy and their rational strategies without others'
influence. We validate the performance of the fast algorithm and verify the
correctness of our analysis using numerical experiments. This work is crucial
to comprehend mutual influence among agents and design effective mechanisms to
guide their strategies in financial markets.
"
2501.14736,2025-01-28,"NEAT Algorithm-based Stock Trading Strategy with Multiple Technical
  Indicators Resonance","  In this study, we applied the NEAT (NeuroEvolution of Augmenting Topologies)
algorithm to stock trading using multiple technical indicators. Our approach
focused on maximizing earning, avoiding risk, and outperforming the Buy & Hold
strategy. We used progressive training data and a multi-objective fitness
function to guide the evolution of the population towards these objectives. The
results of our study showed that the NEAT model achieved similar returns to the
Buy & Hold strategy, but with lower risk exposure and greater stability. We
also identified some challenges in the training process, including the presence
of a large number of unused nodes and connections in the model architecture. In
future work, it may be worthwhile to explore ways to improve the NEAT algorithm
and apply it to shorter interval data in order to assess the potential impact
on performance.
"
2501.15793,2025-01-28,"Advancing Portfolio Optimization: Adaptive Minimum-Variance Portfolios
  and Minimum Risk Rate Frameworks","  This study presents the Adaptive Minimum-Variance Portfolio (AMVP) framework
and the Adaptive Minimum-Risk Rate (AMRR) metric, innovative tools designed to
optimize portfolios dynamically in volatile and nonstationary financial
markets. Unlike traditional minimum-variance approaches, the AMVP framework
incorporates real-time adaptability through advanced econometric models,
including ARFIMA-FIGARCH processes and non-Gaussian innovations. Empirical
applications on cryptocurrency and equity markets demonstrate the proposed
framework's superior performance in risk reduction and portfolio stability,
particularly during periods of structural market breaks and heightened
volatility. The findings highlight the practical implications of using the AMVP
and AMRR methodologies to address modern investment challenges, offering
actionable insights for portfolio managers navigating uncertain and rapidly
changing market conditions.
"
2501.16659,2025-01-29,"Exploratory Mean-Variance Portfolio Optimization with Regime-Switching
  Market Dynamics","  Considering the continuous-time Mean-Variance (MV) portfolio optimization
problem, we study a regime-switching market setting and apply reinforcement
learning (RL) techniques to assist informed exploration within the control
space. We introduce and solve the Exploratory Mean Variance with Regime
Switching (EMVRS) problem. We also present a Policy Improvement Theorem.
Further, we recognize that the widely applied Temporal Difference (TD) learning
is not adequate for the EMVRS context, hence we consider Orthogonality
Condition (OC) learning, leveraging the martingale property of the induced
optimal value function from the analytical solution to EMVRS. We design a RL
algorithm that has more meaningful parameterization using the market parameters
and propose an updating scheme for each parameter. Our empirical results
demonstrate the superiority of OC learning over TD learning with a clear
convergence of the market parameters towards their corresponding ``grounding
true"" values in a simulated market scenario. In a real market data study, EMVRS
with OC learning outperforms its counterparts with the highest mean and
reasonably low volatility of the annualized portfolio returns.
"
2501.17992,2025-01-31,"Reinforcement-Learning Portfolio Allocation with Dynamic Embedding of
  Market Information","  We develop a portfolio allocation framework that leverages deep learning
techniques to address challenges arising from high-dimensional, non-stationary,
and low-signal-to-noise market information. Our approach includes a dynamic
embedding method that reduces the non-stationary, high-dimensional state space
into a lower-dimensional representation. We design a reinforcement learning
(RL) framework that integrates generative autoencoders and online meta-learning
to dynamically embed market information, enabling the RL agent to focus on the
most impactful parts of the state space for portfolio allocation decisions.
Empirical analysis based on the top 500 U.S. stocks demonstrates that our
framework outperforms common portfolio benchmarks and the predict-then-optimize
(PTO) approach using machine learning, particularly during periods of market
stress. Traditional factor models do not fully explain this superior
performance. The framework's ability to time volatility reduces its market
exposure during turbulent times. Ablation studies confirm the robustness of
this performance across various reinforcement learning algorithms.
Additionally, the embedding and meta-learning techniques effectively manage the
complexities of high-dimensional, noisy, and non-stationary financial data,
enhancing both portfolio performance and risk management.
"
2501.19213,2025-03-19,Testing for the Minimum Mean-Variance Spanning Set,"  This paper explores the estimation and inference of the minimum spanning set
(MSS), the smallest subset of risky assets that spans the mean-variance
efficient frontier of the full asset set. We establish identification
conditions for the MSS and develop a novel procedure for its estimation and
inference. Our theoretical analysis shows that the proposed MSS estimator
covers the true MSS with probability approaching 1 and converges asymptotically
to the true MSS at any desired confidence level, such as 0.95 or 0.99. Monte
Carlo simulations confirm the strong finite-sample performance of the MSS
estimator. We apply our method to evaluate the relative importance of
individual stock momentum and factor momentum strategies, along with a set of
well-established stock return factors. The empirical results highlight factor
momentum, along with several stock momentum and return factors, as key drivers
of mean-variance efficiency. Furthermore, our analysis uncovers the sources of
contribution from these factors and provides a ranking of their relative
importance, offering new insights into their roles in mean-variance analysis.
"
2502.00029,2025-02-05,AlphaSharpe: LLM-Driven Discovery of Robust Risk-Adjusted Metrics,"  Financial metrics like the Sharpe ratio are pivotal in evaluating investment
performance by balancing risk and return. However, traditional metrics often
struggle with robustness and generalization, particularly in dynamic and
volatile market conditions. This paper introduces AlphaSharpe, a novel
framework leveraging large language models (LLMs) to iteratively evolve and
optimize financial metrics to discover enhanced risk-return metrics that
outperform traditional approaches in robustness and correlation with future
performance metrics by employing iterative crossover, mutation, and evaluation.
Key contributions of this work include: (1) a novel use of LLMs to generate and
refine financial metrics with implicit domain-specific knowledge, (2) a scoring
mechanism to ensure that evolved metrics generalize effectively to unseen data,
and (3) an empirical demonstration of 3x predictive power for future
risk-returns, and 2x portfolio performance. Experimental results in a
real-world dataset highlight the superiority of discovered metrics, making them
highly relevant to portfolio managers and financial decision-makers. This
framework not only addresses the limitations of existing metrics but also
showcases the potential of LLMs in advancing financial analytics, paving the
way for informed and robust investment strategies.
"
2502.00415,2025-02-04,MarketSenseAI 2.0: Enhancing Stock Analysis through LLM Agents,"  MarketSenseAI is a novel framework for holistic stock analysis which
leverages Large Language Models (LLMs) to process financial news, historical
prices, company fundamentals and the macroeconomic environment to support
decision making in stock analysis and selection. In this paper, we present the
latest advancements on MarketSenseAI, driven by rapid technological expansion
in LLMs. Through a novel architecture combining Retrieval-Augmented Generation
and LLM agents, the framework processes SEC filings and earnings calls, while
enriching macroeconomic analysis through systematic processing of diverse
institutional reports. We demonstrate a significant improvement in fundamental
analysis accuracy over the previous version. Empirical evaluation on S\&P 100
stocks over two years (2023-2024) shows MarketSenseAI achieving cumulative
returns of 125.9% compared to the index return of 73.5%, while maintaining
comparable risk profiles. Further validation on S\&P 500 stocks during 2024
demonstrates the framework's scalability, delivering a 33.8% higher Sortino
ratio than the market. This work marks a significant advancement in applying
LLM technology to financial analysis, offering insights into the robustness of
LLM-driven investment strategies.
"
2502.00828,2025-02-04,"Decision-informed Neural Networks with Large Language Model Integration
  for Portfolio Optimization","  This paper addresses the critical disconnect between prediction and decision
quality in portfolio optimization by integrating Large Language Models (LLMs)
with decision-focused learning. We demonstrate both theoretically and
empirically that minimizing the prediction error alone leads to suboptimal
portfolio decisions. We aim to exploit the representational power of LLMs for
investment decisions. An attention mechanism processes asset relationships,
temporal dependencies, and macro variables, which are then directly integrated
into a portfolio optimization layer. This enables the model to capture complex
market dynamics and align predictions with the decision objectives. Extensive
experiments on S\&P100 and DOW30 datasets show that our model consistently
outperforms state-of-the-art deep learning models. In addition, gradient-based
analyses show that our model prioritizes the assets most crucial to decision
making, thus mitigating the effects of prediction errors on portfolio
performance. These findings underscore the value of integrating decision
objectives into predictions for more robust and context-aware portfolio
management.
"
2502.02619,2025-02-06,"Regret-Optimized Portfolio Enhancement through Deep Reinforcement
  Learning and Future Looking Rewards","  This paper introduces a novel agent-based approach for enhancing existing
portfolio strategies using Proximal Policy Optimization (PPO). Rather than
focusing solely on traditional portfolio construction, our approach aims to
improve an already high-performing strategy through dynamic rebalancing driven
by PPO and Oracle agents. Our target is to enhance the traditional 60/40
benchmark (60% stocks, 40% bonds) by employing the Regret-based Sharpe reward
function. To address the impact of transaction fee frictions and prevent signal
loss, we develop a transaction cost scheduler. We introduce a future-looking
reward function and employ synthetic data training through a circular block
bootstrap method to facilitate the learning of generalizable allocation
strategies. We focus on two key evaluation measures: return and maximum
drawdown. Given the high stochasticity of financial markets, we train 20
independent agents each period and evaluate their average performance against
the benchmark. Our method not only enhances the performance of the existing
portfolio strategy through strategic rebalancing but also demonstrates strong
results compared to other baselines.
"
2502.06028,2025-02-11,Perpetual Demand Lending Pools,"  Decentralized perpetuals protocols have collectively reached billions of
dollars of daily trading volume, yet are still not serious competitors on the
basis of trading volume with centralized venues such as Binance. One of the
main reasons for this is the high cost of capital for market makers and
sophisticated traders in decentralized settings. Recently, numerous
decentralized finance protocols have been used to improve borrowing costs for
perpetual futures traders. We formalize this class of mechanisms utilized by
protocols such as Jupiter, Hyperliquid, and GMX, which we term~\emph{Perpetual
Demand Lending Pools} (PDLPs). We then formalize a general target weight
mechanism that generalizes what GMX and Jupiter are using in practice. We
explicitly describe pool arbitrage and expected payoffs for arbitrageurs and
liquidity providers within these mechanisms. Using this framework, we show that
under general conditions, PDLPs are easy to delta hedge, partially explaining
the proliferation of live hedged PDLP strategies. Our results suggest
directions to improve capital efficiency in PDLPs via dynamic parametrization.
"
2502.10776,2025-03-12,"A Distillation-based Future-aware Graph Neural Network for Stock Trend
  Prediction","  Stock trend prediction involves forecasting the future price movements by
analyzing historical data and various market indicators. With the advancement
of machine learning, graph neural networks (GNNs) have been extensively
employed in stock prediction due to their powerful capability to capture
spatiotemporal dependencies of stocks. However, despite the efforts of various
GNN stock predictors to enhance predictive performance, the improvements remain
limited, as they focus solely on analyzing historical spatiotemporal
dependencies, overlooking the correlation between historical and future
patterns. In this study, we propose a novel distillation-based future-aware GNN
framework (DishFT-GNN) for stock trend prediction. Specifically, DishFT-GNN
trains a teacher model and a student model, iteratively. The teacher model
learns to capture the correlation between distribution shifts of historical and
future data, which is then utilized as intermediate supervision to guide the
student model to learn future-aware spatiotemporal embeddings for accurate
prediction. Through extensive experiments on two real-world datasets, we verify
the state-of-the-art performance of DishFT-GNN.
"
2502.11052,2025-02-18,"Time-consistent portfolio selection with strictly monotone mean-variance
  preference","  This paper is devoted to time-consistent control problems of portfolio
selection with strictly monotone mean-variance preferences. These preferences
are variational modifications of the conventional mean-variance preferences,
and remain time-inconsistent as in mean-variance optimization problems. To
tackle the time-inconsistency, we study the Nash equilibrium controls of both
the open-loop type and the closed-loop type, and characterize them within a
random parameter setting. The problem is reduced to solving a flow of
forward-backward stochastic differential equations for open-loop equilibria,
and to solving extended Hamilton-Jacobi-Bellman equations for closed-loop
equilibria. In particular, we derive semi-closed-form solutions for these two
types of equilibria under a deterministic parameter setting. Both solutions are
represented by the same function, which is independent of wealth state and
random path. This function can be expressed as the conventional time-consistent
mean-variance portfolio strategy multiplied by a factor greater than one.
Furthermore, we find that the state-independent closed-loop Nash equilibrium
control is a strong equilibrium strategy in a constant parameter setting only
when the interest rate is sufficiently large.
"
2502.11701,2025-02-18,"A Cholesky decomposition-based asset selection heuristic for sparse
  tangent portfolio optimization","  In practice, including large number of assets in mean-variance portfolios can
lead to higher transaction costs and management fees. To address this, one
common approach is to select a smaller subset of assets from the larger pool,
constructing more efficient portfolios. As a solution, we propose a new asset
selection heuristic which generates a pre-defined list of asset candidates
using a surrogate formulation and re-optimizes the cardinality-constrained
tangent portfolio with these selected assets. This method enables faster
optimization and effectively constructs portfolios with fewer assets, as
demonstrated by numerical analyses on historical stock returns. Finally, we
discuss a quantitative metric that can provide a initial assessment of the
performance of the proposed heuristic based on asset covariance.
"
2502.13148,2025-02-20,"Theoretical Frameworks for Integrating Sustainability Factors into
  Institutional Investment Decision-Making","  This paper explores key theoretical frameworks instrumental in understanding
the relationship between sustainability and institutional investment decisions.
The study identifies and analyzes various theories, including Behavioral
Finance Theory, Modern Portfolio Theory, Risk Management Theory, and others, to
explain how sustainability considerations increasingly influence investment
choices. By examining these frameworks, the paper highlights how investors
integrate Environmental, Social, and Governance (ESG) factors to optimize
financial outcomes and align with broader societal goals.
"
2502.13461,2025-02-20,"Tensor dynamic conditional correlation model: A new way to pursuit ""Holy
  Grail of investing""","  Style investing creates asset classes (or the so-called ""styles"") with low
correlations, aligning well with the principle of ""Holy Grail of investing"" in
terms of portfolio selection. The returns of styles naturally form a
tensor-valued time series, which requires new tools for studying the dynamics
of the conditional correlation matrix to facilitate the aforementioned
principle. Towards this goal, we introduce a new tensor dynamic conditional
correlation (TDCC) model, which is based on two novel treatments:
trace-normalization and dimension-normalization. These two normalizations adapt
to the tensor nature of the data, and they are necessary except when the tensor
data reduce to vector data. Moreover, we provide an easy-to-implement
estimation procedure for the TDCC model, and examine its finite sample
performance by simulations. Finally, we assess the usefulness of the TDCC model
in international portfolio selection across ten global markets and in large
portfolio selection for 1800 stocks from the Chinese stock market.
"
2502.17011,2025-02-25,"Predicting Liquidity-Aware Bond Yields using Causal GANs and Deep
  Reinforcement Learning with LLM Evaluation","  Financial bond yield forecasting is challenging due to data scarcity,
nonlinear macroeconomic dependencies, and evolving market conditions. In this
paper, we propose a novel framework that leverages Causal Generative
Adversarial Networks (CausalGANs) and Soft Actor-Critic (SAC) reinforcement
learning (RL) to generate high-fidelity synthetic bond yield data for four
major bond categories (AAA, BAA, US10Y, Junk). By incorporating 12 key
macroeconomic variables, we ensure statistical fidelity by preserving essential
market properties. To transform this market dependent synthetic data into
actionable insights, we employ a finetuned Large Language Model (LLM)
Qwen2.5-7B that generates trading signals (BUY/HOLD/SELL), risk assessments,
and volatility projections. We use automated, human and LLM evaluations, all of
which demonstrate that our framework improves forecasting performance over
existing methods, with statistical validation via predictive accuracy, MAE
evaluation(0.103%), profit/loss evaluation (60% profit rate), LLM evaluation
(3.37/5) and expert assessments scoring 4.67 out of 5. The reinforcement
learning-enhanced synthetic data generation achieves the least Mean Absolute
Error of 0.103, demonstrating its effectiveness in replicating real-world bond
market dynamics. We not only enhance data-driven trading strategies but also
provides a scalable, high-fidelity synthetic financial data pipeline for risk &
volatility management and investment decision-making. This work establishes a
bridge between synthetic data generation, LLM driven financial forecasting, and
language model evaluation, contributing to AI-driven financial decision-making.
"
2502.17915,2025-02-26,"Dynamic Factor Model-Based Multiperiod Mean-Variance Portfolio Selection
  with Portfolio Constraints","  Motivated by practical applications, we explore the constrained multi-period
mean-variance portfolio selection problem within a market characterized by a
dynamic factor model. This model captures predictability in asset returns
driven by state variables and incorporates cone-type portfolio constraints that
are crucial in practice. The model is broad enough to encompass various dynamic
factor frameworks, including practical considerations such as no-short-selling
and cardinality constraints. We derive a semi-analytical optimal solution using
dynamic programming, revealing it as a piecewise linear feedback policy to
wealth, with all factors embedded within the allocation vectors. Additionally,
we demonstrate that the portfolio policies are determined by two specific
stochastic processes resulting from the stochastic optimizations, for which we
provide detailed algorithms. These processes reflect the investor's assessment
of future investment opportunities and play a crucial role in characterizing
the time consistency and efficiency of the optimal policy through the
variance-optimal signed supermartingale measure of the market. We present
numerical examples that illustrate the model's application in various settings.
Using real market data, we investigate how the factors influence portfolio
policies and demonstrate that incorporating the factor structure may enhance
out-of-sample performance.
"
2502.19213,2025-05-21,Framework for asset-liability management with fixed-term securities,"  We consider an optimal investment-consumption problem for a
utility-maximizing investor who has access to assets with different liquidity
and whose consumption rate as well as terminal wealth are subject to
lower-bound constraints. Assuming utility functions that satisfy standard
conditions, we develop a methodology for deriving the optimal strategies in
semi-closed form. Our methodology is based on the generalized martingale
approach and the decomposition of the problem into subproblems. We illustrate
our approach by deriving explicit formulas for agents with power-utility
functions and discuss potential extensions of the proposed framework. In
numerical studies, we substantiate how the parameters of our framework impact
the optimal proportion of initial capital allocated to the illiquid asset, the
monetary value that the investor subjectively assigns to the fixed-term asset,
and the potential of the illiquid asset to increase terminal the terminal value
of liabilities without loss in the investor's expected utility.
"
2503.01099,2025-03-04,A Dynamic Model of Private Asset Allocation,"  We build a state-of-the-art dynamic model of private asset allocation that
considers five key features of private asset markets: (1) the illiquid nature
of private assets, (2) timing lags between capital commitments, capital calls,
and eventual distributions, (3) time-varying business cycle conditions, (4)
serial correlation in observed private asset returns, and (5) regulatory
constraints on certain institutional investors' portfolio choices. We use
cutting-edge machine learning methods to quantify the optimal investment
policies over the life cycle of a fund. Moreover, our model offers regulators a
tool for precisely quantifying the trade-offs when setting risk-based capital
charges.
"
2503.02697,2025-03-05,Consumption-portfolio choice with preferences for liquid assets,"  This paper investigates an infinite horizon, discounted,
consumption-portfolio problem in a market with one bond, one liquid risky
asset, and one illiquid risky asset with proportional transaction costs. We
consider an agent with liquidity preference, modeled by a Cobb-Douglas utility
function that includes the liquid wealth. We analyze the properties of the
value function and divide the solvency region into three regions: the buying
region, the no-trading region, and the selling region, and prove that all three
regions are non-empty. We mathematically characterize and numerically solve the
optimal policy and prove its optimality. Our numerical analysis sheds light on
the impact of various parameters on the optimal policy, and some intuition and
economic insights behind it are also analyzed. We find that liquidity
preference encourages agents to retain more liquid wealth and inhibits
consumption, and may even result in a negative allocation to the illiquid
asset. The liquid risky asset not only affects the location of the three
regions but also has an impact on consumption. However, whether this impact on
consumption is promoted or inhibited depends on the degree of risk aversion of
agents.
"
2503.02722,2025-03-05,"N-player and mean field games among fund managers considering excess
  logarithmic returns","  This paper studies the competition among multiple fund managers with relative
performance over the excess logarithmic return. Fund managers compete with each
other and have expected utility or mean-variance criteria for excess
logarithmic return.
  Each fund manager possesses a unique risky asset, and all fund managers can
also invest in a public risk-free asset and a public risk asset. We construct
both an $n$-player game and a mean field game (MFG) to address the competition
problem under these two criteria. We explicitly define and rigorously solve the
equilibrium and mean field equilibrium (MFE) for each criteria. In the four
models, the excess logarithmic return as the evaluation criterion of the fund
leads to the { allocation fractions} being constant. The introduction of the
public risky asset yields different outcomes, with competition primarily
affecting the investment in public assets, particularly evident in the MFG. We
demonstrate that the MFE of the MFG represents the limit of the $n$-player
game's equilibrium as the competitive scale $n$ approaches infinity. Finally,
the sensitivity analyses of the equilibrium are given.
"
2503.04662,2025-03-07,Risk-aware Trading Portfolio Optimization,"  We investigate portfolio optimization in financial markets from a trading and
risk management perspective. We term this task Risk-Aware Trading Portfolio
Optimization (RATPO), formulate the corresponding optimization problem, and
propose an efficient Risk-Aware Trading Swarm (RATS) algorithm to solve it. The
key elements of RATPO are a generic initial portfolio P, a specific set of
Unique Eligible Instruments (UEIs), their combination into an Eligible
Optimization Strategy (EOS), an objective function, and a set of constraints.
RATS searches for an optimal EOS that, added to P, improves the objective
function repecting the constraints.
  RATS is a specialized Particle Swarm Optimization method that leverages the
parameterization of P in terms of UEIs, enables parallel computation with a
large number of particles, and is fully general with respect to specific
choices of the key elements, which can be customized to encode financial
knowledge and needs of traders and risk managers.
  We showcase two RATPO applications involving a real trading portfolio made of
hundreds of different financial instruments, an objective function combining
both market risk (VaR) and profit&loss measures, constrains on market
sensitivities and UEIs trading costs. In the case of small-sized EOS, RATS
successfully identifies the optimal solution and demonstrates robustness with
respect to hyper-parameters tuning. In the case of large-sized EOS, RATS
markedly improves the portfolio objective value, optimizing risk and capital
charge while respecting risk limits and preserving expected profits.
  Our work bridges the gap between the implementation of effective trading
strategies and compliance with stringent regulatory and economic capital
requirements, allowing a better alignment of business and risk management
objectives.
"
2503.07498,2025-04-03,"Optimal Diversification and Leverage in a Utility-Based Portfolio
  Allocation Approach","  We examine the problem of optimal portfolio allocation within the framework
of utility theory. We apply exponential utility to derive the optimal
diversification strategy and logarithmic utility to determine the optimal
leverage. We enhance existing methodologies by incorporating compound
probability distributions to model the effects of both statistical and
non-stationary uncertainties. Additionally, we extend the maximum expected
utility objective by including the variance of utility in the objective
function, which we term generalized mean-variance. In the case of logarithmic
utility, it provides a natural explanation for the half-Kelly criterion, a
concept widely used by practitioners.
"
2503.08272,2025-03-12,Dynamically optimal portfolios for monotone mean--variance preferences,"  Monotone mean-variance (MMV) utility is the minimal modification of the
classical Markowitz utility that respects rational ordering of investment
opportunities. This paper provides, for the first time, a complete
characterization of optimal dynamic portfolio choice for the MMV utility in
asset price models with independent returns. The task is performed under
minimal assumptions, weaker than the existence of an equivalent martingale
measure and with no restrictions on the moments of asset returns. We interpret
the maximal MMV utility in terms of the monotone Sharpe ratio (MSR) and show
that the global squared MSR arises as the nominal yield from continuously
compounding at the rate equal to the maximal local squared MSR. The paper gives
simple necessary and sufficient conditions for mean-variance (MV) efficient
portfolios to be MMV efficient. Several illustrative examples contrasting the
MV and MMV criteria are provided.
"
2503.09647,2025-04-11,Leveraging LLMS for Top-Down Sector Allocation In Automated Trading,"  This paper introduces a methodology leveraging Large Language Models (LLMs)
for sector-level portfolio allocation through systematic analysis of
macroeconomic conditions and market sentiment. Our framework emphasizes
top-down sector allocation by processing multiple data streams simultaneously,
including policy documents, economic indicators, and sentiment patterns.
Empirical results demonstrate superior risk-adjusted returns compared to
traditional cross momentum strategies, achieving a Sharpe ratio of 2.51 and
portfolio return of 8.79% versus -0.61 and -1.39% respectively. These results
suggest that LLM-based systematic macro analysis presents a viable approach for
enhancing automated portfolio allocation decisions at the sector level.
"
2503.11499,2025-03-24,Tactical Asset Allocation with Macroeconomic Regime Detection,"  This paper extends the tactical asset allocation literature by incorporating
regime modeling using techniques from machine learning. We propose a novel
model that classifies current regimes, forecasts the distribution of future
regimes, and integrates these forecasts with the historical performance of
individual assets to optimize portfolio allocations. Utilizing a macroeconomic
data set from the FRED-MD database, our approach employs a modified k-means
algorithm to ensure consistent regime classification over time. We then
leverage these regime predictions to estimate expected returns and
volatilities, which are subsequently mapped into portfolio allocations using
various sizing schemes. Our method outperforms traditional benchmarks such as
equal-weight, buy-and-hold, and random regime models. Additionally, we are the
first to apply a regime detection model from a large macroeconomic dataset to
tactical asset allocation, demonstrating significant improvements in portfolio
performance. Our work presents several key contributions, including a novel
data-driven regime detection algorithm tailored for uncertainty in forecasted
regimes and applying the FRED-MD data set for tactical asset allocation.
"
2503.12328,2025-03-18,"Hierarchical Minimum Variance Portfolios: A Theoretical and Algorithmic
  Approach","  We introduce a novel approach to portfolio optimization that leverages
hierarchical graph structures and the Schur complement method to systematically
reduce computational complexity while preserving full covariance information.
Inspired by Lopez de Prados hierarchical risk parity and Cottons Schur
complement methods, our framework models the covariance matrix as an
adjacency-like structure of a hierarchical graph. We demonstrate that portfolio
optimization can be recursively reduced across hierarchical levels, allowing
optimal weights to be computed efficiently by inverting only small submatrices
regardless of portfolio size. Moreover, we translate our results into a
recursive algorithm that constructs optimal portfolio allocations. Our results
reveal a transparent and mathematically rigorous connection between classical
Markowitz mean-variance optimization, hierarchical clustering, and the Schur
complement method.
"
2503.13544,2025-03-27,"Semi-Decision-Focused Learning with Deep Ensembles: A Practical
  Framework for Robust Portfolio Optimization","  I propose Semi-Decision-Focused Learning, a practical adaptation of
Decision-Focused Learning for portfolio optimization. Rather than directly
optimizing complex financial metrics, I employ simple target portfolios
(Max-Sortino or One-Hot) and train models with a convex, cross-entropy loss. I
further incorporate Deep Ensemble methods to reduce variance and stabilize
performance. Experiments on two universes (one upward-trending and another
range-bound) show consistent outperformance over baseline portfolios,
demonstrating the effectiveness and robustness of my approach. Code is
available at https://github.com/sDFLwDE/sDFLwDE
"
2503.15186,2025-03-20,"Optimal Data Splitting for Holdout Cross-Validation in Large Covariance
  Matrix Estimation","  Cross-validation is a statistical tool that can be used to improve large
covariance matrix estimation. Although its efficiency is observed in practical
applications, the theoretical reasons behind it remain largely intuitive, with
formal proofs currently lacking. To carry on analytical analysis, we focus on
the holdout method, a single iteration of cross-validation, rather than the
traditional $k$-fold approach. We derive a closed-form expression for the
estimation error when the population matrix follows a white inverse Wishart
distribution, and we observe the optimal train-test split scales as the square
root of the matrix dimension. For general population matrices, we connected the
error to the variance of eigenvalues distribution, but approximations are
necessary. Interestingly, in the high-dimensional asymptotic regime, both the
holdout and $k$-fold cross-validation methods converge to the optimal estimator
when the train-test ratio scales with the square root of the matrix dimension.
"
2503.15534,2025-03-21,"Systemic Risk Management via Maximum Independent Set in Extremal
  Dependence Networks","  The failure of key financial institutions may accelerate risk contagion due
to their interconnections within the system. In this paper, we propose a robust
portfolio strategy to mitigate systemic risks during extreme events. We use the
stock returns of key financial institutions as an indicator of their
performance, apply extreme value theory to assess the extremal dependence among
stocks of financial institutions, and construct a network model based on a
threshold approach that captures extremal dependence. Our analysis reveals
different dependence structures in the Chinese and U.S. financial systems. By
applying the maximum independent set (MIS) from graph theory, we identify a
subset of institutions with minimal extremal dependence, facilitating the
construction of diversified portfolios resilient to risk contagion. We also
compare the performance of our proposed portfolios with that of the market
portfolios in the two economies.
"
2503.15965,2025-03-21,"Practical Portfolio Optimization with Metaheuristics:Pre-assignment
  Constraint and Margin Trading","  Portfolio optimization is a critical area in finance, aiming to maximize
returns while minimizing risk. Metaheuristic algorithms were shown to solve
complex optimization problems efficiently, with Genetic Algorithms and Particle
Swarm Optimization being among the most popular methods. This paper introduces
an innovative approach to portfolio optimization that incorporates
pre-assignment to limit the search space for investor preferences and better
results. Additionally, taking margin trading strategies in account and using a
rare performance ratio to evaluate portfolio efficiency. Through an
illustrative example, this paper demonstrates that the metaheuristic-based
methodology yields superior risk-adjusted returns compared to traditional
benchmarks. The results highlight the potential of metaheuristics with help of
assets filtering in enhancing portfolio performance in terms of risk adjusted
return.
"
2503.17737,2025-03-25,Bayesian Optimization for CVaR-based portfolio optimization,"  Optimal portfolio allocation is often formulated as a constrained risk
problem, where one aims to minimize a risk measure subject to some performance
constraints. This paper presents new Bayesian Optimization algorithms for such
constrained minimization problems, seeking to minimize the conditional
value-at-risk (a computationally intensive risk measure) under a minimum
expected return constraint. The proposed algorithms utilize a new acquisition
function, which drives sampling towards the optimal region. Additionally, a new
two-stage procedure is developed, which significantly reduces the number of
evaluations of the expensive-to-evaluate objective function. The proposed
algorithm's competitive performance is demonstrated through practical examples.
"
2503.18096,2025-03-25,"Informer in Algorithmic Investment Strategies on High Frequency Bitcoin
  Data","  The article investigates the usage of Informer architecture for building
automated trading strategies for high frequency Bitcoin data. Three strategies
using Informer model with different loss functions: Root Mean Squared Error
(RMSE), Generalized Mean Absolute Directional Loss (GMADL) and Quantile loss,
are proposed and evaluated against the Buy and Hold benchmark and two benchmark
strategies based on technical indicators. The evaluation is conducted using
data of various frequencies: 5 minute, 15 minute, and 30 minute intervals, over
the 6 different periods. Although the Informer-based model with Quantile loss
did not outperform the benchmark, two other models achieved better results. The
performance of the model using RMSE loss worsens when used with higher
frequency data while the model that uses novel GMADL loss function is
benefiting from higher frequency data and when trained on 5 minute interval it
beat all the other strategies on most of the testing periods. The primary
contribution of this study is the application and assessment of the RMSE,
GMADL, and Quantile loss functions with the Informer model to forecast future
returns, subsequently using these forecasts to develop automated trading
strategies. The research provides evidence that employing an Informer model
trained with the GMADL loss function can result in superior trading outcomes
compared to the buy-and-hold approach.
"
2503.18199,2025-04-08,Generating realistic metaorders from public data,"  This paper introduces a novel algorithm for generating realistic metaorders
from public trade data, addressing a longstanding challenge in price impact
research that has traditionally relied on proprietary datasets. Our method
effectively recovers all established stylized facts of metaorders impact, such
as the Square Root Law, the concave profile during metaorder execution, and the
post-execution decay. This algorithm not only overcomes the dependence on
proprietary data, a major barrier to research reproducibility, but also enables
the creation of larger and more robust datasets that may increase the quality
of empirical studies. Our findings strongly suggest that average realized
short-term price impact is not due to information revelation (as in the Kyle
framework) but has a mechanical origin which could explain the universality of
the Square Root Law.
"
2503.18609,2025-03-25,"Asset pre-selection for a cardinality constrained index tracking
  portfolio with optional enhancement","  An index tracker is a passive investment reproducing the return and risk of a
market index, an enhanced index tracker offers a return greater than the index.
We consider the selection of a portfolio of given cardinality to track an
index, both without and with enhancement. We divide the problem into two steps
- (1) pre-selection of assets; (2) estimation of weights on the assets chosen.
The eight pre-selection procedures considered use: forward selection (FS) or
backward elimination (BE); implemented using ordinary least squares (OLS) or
least absolute deviation (LAD) regression; with a regression constant (c) or
without (n). The two-step approach avoids the NP-hard problem arising when
asset selection and asset weight computation are combined, leading to the
selection of a cardinality constrained index tracking portfolio by computer
intensive heuristic procedures with many examples in the literature solving for
portfolios of 10 or fewer assets. Avoiding these restrictions, we show that
out-of-sample tracking errors are roughly proportional to 1/sqrt(cardinality).
  We find OLS more effective than LAD; BE marginally more effective than FS;
(n) marginally more effective than (c). For index tracking, both without and
with enhancement, we use BE-OLS(n) in sensitivity analyses on the periods used
for selection and evaluation. For a S&P 500 index tracker, we find that
out-of-sample tracking error, transaction volume and return-risk ratios all
improve as cardinality increases. By contrast for enhanced returns,
cardinalities of the order 10 to 20 are most effective. The S&P 500 data used
from 3/1/2005 to 29/12/2023 is available to researchers.
"
2503.20340,2025-03-27,Relative portfolio optimization via a value at risk based constraint,"  In this paper, we consider $n$ agents who invest in a general financial
market that is free of arbitrage and complete. The aim of each investor is to
maximize her expected utility while ensuring, with a specified probability,
that her terminal wealth exceeds a benchmark defined by her competitors'
performance. This setup introduces an interdependence between agents, leading
to a search for Nash equilibria. In the case of two agents and CRRA utility, we
are able to derive all Nash equilibria in terms of terminal wealth. For $n>2$
agents and logarithmic utility we distinguish two cases. In the first case, the
probabilities in the constraint are small and we can characterize all Nash
equilibria. In the second case, the probabilities are larger and we look for
Nash equilibria in a certain set. We also discuss the impact of the competition
using some numerical examples. As a by-product, we solve some portfolio
optimization problems with probability constraints.
"
2503.20987,2025-03-28,A Causal Perspective of Stock Prediction Models,"  In the realm of stock prediction, machine learning models encounter
considerable obstacles due to the inherent low signal-to-noise ratio and the
nonstationary nature of financial markets. These challenges often result in
spurious correlations and unstable predictive relationships, leading to poor
performance of models when applied to out-of-sample (OOS) domains. To address
these issues, we investigate \textit{Domain Generalization} techniques, with a
particular focus on causal representation learning to improve a prediction
model's generalizability to OOS domains. By leveraging multi-factor models from
econometrics, we introduce a novel error bound that explicitly incorporates
causal relationships. In addition, we present the connection between the
proposed error bound and market nonstationarity. We also develop a
\textit{Causal Discovery} technique to discover invariant feature
representations, which effectively mitigates the proposed error bound, and the
influence of spurious correlations on causal discovery is rigorously examined.
Our theoretical findings are substantiated by numerical results, showcasing the
effectiveness of our approach in enhancing the generalizability of stock
prediction models.
"
2504.02840,2025-04-07,"Statistical applications of the 20/60/20 rule in risk management and
  portfolio optimization","  This paper explores the applications of the 20/60/20 rule-a heuristic method
that segments data into top-performing, average-performing, and underperforming
groups-in mathematical finance. We review the statistical foundations of this
rule and demonstrate its usefulness in risk management and portfolio
optimization. Our study highlights three key applications. First, we apply the
rule to stock market data, showing that it enables effective population
clustering. Second, we introduce a novel, easy-to-implement method for
extracting heavy-tail characteristics in risk management. Third, we integrate
spatial reasoning based on the 20/60/20 rule into portfolio optimization,
enhancing robustness and improving performance. To support our findings, we
develop a new measure for quantifying tail heaviness and employ conditional
statistics to reconstruct the unconditional distribution from the core data
segment. This reconstructed distribution is tested on real financial data to
evaluate whether the 20/60/20 segmentation effectively balances capturing
extreme risks with maintaining the stability of central returns. Our results
offer insights into financial data behavior under heavy-tailed conditions and
demonstrate the potential of the 20/60/20 rule as a complementary tool for
decision-making in finance.
"
2504.02841,2025-04-07,"Dynamic Investment Strategies Through Market Classification and
  Volatility: A Machine Learning Approach","  This study introduces a dynamic investment framework to enhance portfolio
management in volatile markets, offering clear advantages over traditional
static strategies. Evaluates four conventional approaches : equal weighted,
minimum variance, maximum diversification, and equal risk contribution under
dynamic conditions. Using K means clustering, the market is segmented into ten
volatility-based states, with transitions forecasted by a Bayesian Markov
switching model employing Dirichlet priors and Gibbs sampling. This enables
real-time asset allocation adjustments. Tested across two asset sets, the
dynamic portfolio consistently achieves significantly higher risk-adjusted
returns and substantially higher total returns, outperforming most static
methods. By integrating classical optimization with machine learning and
Bayesian techniques, this research provides a robust strategy for optimizing
investment outcomes in unpredictable market environments.
"
2504.05743,2025-04-10,"Causal Portfolio Optimization: Principles and Sensitivity-Based
  Solutions","  Fundamental and necessary principles for achieving efficient portfolio
optimization based on asset and diversification dynamics are presented. The
Commonality Principle is a necessary and sufficient condition for identifying
optimal drivers of a portfolio in terms of its diversification dynamics. The
proof relies on the Reichenbach Common Cause Principle, along with the fact
that the sensitivities of portfolio constituents with respect to the common
causal drivers are themselves causal. A conformal map preserves idiosyncratic
diversification from the unconditional setting while optimizing systematic
diversification on an embedded space of these sensitivities. Causal
methodologies for combinatorial driver selection are presented, such as the use
of Bayesian networks and correlation-based algorithms from Reichenbach's
principle. Limitations of linear models in capturing causality are discussed,
and included for completeness alongside more advanced models such as neural
networks. Portfolio optimization methods are presented that map risk from the
sensitivity space to other risk measures of interest. Finally, the work
introduces a novel risk management framework based on Common Causal Manifolds,
including both theoretical development and experimental validation. The
sensitivity space is predicted along the common causal manifold, which is
modeled as a causal time system. Sensitivities are forecasted using SDEs
calibrated to data previously extracted from neural networks to move along the
manifold via its tangent bundles. An optimization method is then proposed that
accumulates information across future predicted tangent bundles on the common
causal time system manifold. It aggregates sensitivity-based distance metrics
along the trajectory to build a comprehensive sensitivity distance matrix. This
matrix enables trajectory-wide optimal diversification, taking into account
future dynamics.
"
2504.06289,2025-04-10,"On the Efficacy of Shorting Corporate Bonds as a Tail Risk Hedging
  Solution","  United States (US) IG bonds typically trade at modest spreads over US
Treasuries, reflecting the credit risk tied to a corporation's default
potential. During market crises, IG spreads often widen and liquidity tends to
decrease, likely due to increased credit risk (evidenced by higher IG Credit
Default Index spreads) and the necessity for asset holders like mutual funds to
liquidate assets, including IG credits, to manage margin calls, bolster cash
reserves, or meet redemptions. These credit and liquidity premia occur during
market drawdowns and tend to move non-linearly with the market. The research
herein refers to this non-linearity (during periods of drawdown) as downside
convexity, and shows that this market behavior can effectively be captured
through a short position established in IG Exchange Traded Funds (ETFs).
  The following document details the construction of three signals: Momentum,
Liquidity, and Credit, that can be used in combination to signal entries and
exits into short IG positions to hedge a typical active bond portfolio (such as
PIMIX). A dynamic hedge initiates the short when signals jointly correlate and
point to significant future hedged return. The dynamic hedge removes when the
short position's predicted hedged return begins to mean revert. This systematic
hedge largely avoids IG Credit drawdowns, lowers absolute and downside risk,
increases annualised returns and achieves higher Sortino ratios compared to the
benchmark funds. The method is best suited to high carry, high active risk
funds like PIMIX, though it also generalises to more conservative funds similar
to DODIX.
"
2504.07929,2025-04-11,Market-Based Portfolio Selection,"  We show that Markowitz's (1952) decomposition of a portfolio variance as a
quadratic form in the variables of the relative amounts invested into the
securities, which has been the core of classical portfolio theory for more than
70 years, is valid only in the approximation when all trade volumes with all
securities of the portfolio are assumed constant. We derive the market-based
portfolio variance and its decomposition by its securities, which accounts for
the impact of random trade volumes and is a polynomial of the 4th degree in the
variables of the relative amounts invested into the securities. To do that, we
transform the time series of market trades with the securities of the portfolio
and obtain the time series of trades with the portfolio as a single market
security. The time series of market trades determine the market-based means and
variances of prices and returns of the portfolio in the same form as the means
and variances of any market security. The decomposition of the market-based
variance of returns of the portfolio by its securities follows from the
structure of the time series of market trades of the portfolio as a single
security. The market-based decompositions of the portfolio's variances of
prices and returns could help the managers of multi-billion portfolios and the
developers of large market and macroeconomic models like BlackRock's Aladdin,
JP Morgan, and the U.S. Fed adjust their models and forecasts to the reality of
random markets.
"
2504.08085,2025-04-14,"Optimal Investment in Equity and Credit Default Swaps in the Presence of
  Default","  We consider an equity market subject to risk from both unhedgeable shocks and
default. The novelty of our work is that to partially offset default risk,
investors may dynamically trade in a credit default swap (CDS) market. Assuming
investment opportunities are driven by functions of an underlying diffusive
factor process, we identify the certainty equivalent for a constant absolute
risk aversion investor with a semi-linear partial differential equation (PDE)
which has quadratic growth in both the function and gradient coefficients. For
general model specifications, we prove existence of a solution to the PDE which
is also the certainty equivalent. We show the optimal policy in the CDS market
covers not only equity losses upon default (as one would expect), but also
losses due to restricted future trading opportunities. We use our results to
price default dependent claims though the principal of utility indifference,
and we show that provided the underlying equity market is complete absent the
possibility of default, the equity-CDS market is complete accounting for
default. Lastly, through a numerical application, we show the optimal CDS
policies are essentially static (and hence easily implementable) and that
investing in CDS dramatically increases investor indirect utility.
"
2504.08843,2025-04-15,End-to-End Portfolio Optimization with Quantum Annealing,"  With rapid technological progress reshaping the financial industry, quantum
technology plays a critical role in advancing risk management, asset
allocation, and financial strategies. Realizing its full potential requires
overcoming challenges like quantum hardware limits, algorithmic stability, and
implementation barriers. This research explores integrating quantum annealing
with portfolio optimization, highlighting quantum methods' ability to enhance
investment strategy efficiency and speed. Using hybrid quantum-classical
models, the study shows combined approaches effectively handle complex
optimization better than classical methods. Empirical results demonstrate a
portfolio increase of 200,000 Indian Rupees over the benchmark. Additionally,
using rebalancing leads to a portfolio that also surpasses the benchmark value.
"
2504.10914,2025-05-20,Breaking the Trend: How to Avoid Cherry-Picked Signals,"  Our empirical results, illustrated in Fig.5, show an impressive fit with the
pretty complex theoritical Sharpe formula of a Trend following strategy
depending on the parameter of the signal, which was derived by Grebenkov and
Serror (2014). That empirical fit convinces us that a mean-reversion process
with only one time scale is enough to model, in a pretty precise way, the
reality of the trend-following mechanism at the average scale of CTAs and as a
consequence, using only one simple EMA, appears optimal to capture the trend.
As a consequence, using a complex basket of different complex indicators as
signal, do not seem to be so rational or optimal and exposes to the risk of
cherry-picking.
"
2504.11116,2025-05-13,"Breaking the Dimensional Barrier: A Pontryagin-Guided Direct Policy
  Optimization for Continuous-Time Multi-Asset Portfolio","  Solving large-scale, continuous-time portfolio optimization problems
involving numerous assets and state-dependent dynamics has long been challenged
by the curse of dimensionality. Traditional dynamic programming and PDE-based
methods, while rigorous, typically become computationally intractable beyond a
few state variables ($\sim$3-6 limit in prior studies). To overcome this
critical barrier, we introduce the \emph{Pontryagin-Guided Direct Policy
Optimization} (PG-DPO) framework. PG-DPO leverages Pontryagin's Maximum
Principle (PMP) and backpropagation-through-time (BPTT) to directly inform
neural network-based policy learning. A key contribution is our highly
efficient \emph{Projected PG-DPO (P-PGDPO)} variant. This approach uniquely
utilizes BPTT to obtain rapidly stabilizing estimates of the Pontryagin
costates and their crucial derivatives with respect to the state variables.
These estimates are then analytically projected onto the manifold of optimal
controls dictated by PMP's first-order conditions, significantly reducing
training overhead and enhancing accuracy. This enables a breakthrough in
scalability: numerical experiments demonstrate that P-PGDPO successfully
tackles problems with dimensions previously considered far out of reach (up to
50 assets and 10 state variables). Critically, the framework accurately
captures complex intertemporal hedging demands, a feat often elusive for other
methods in high-dimensional settings. P-PGDPO delivers near-optimal policies,
offering a practical and powerful alternative for a broad class of
high-dimensional continuous-time control problems.
"
2504.11881,2025-04-21,"Universal portfolios in continuous time: an approach in pathwise It\^o
  calculus","  We provide a simple and straightforward approach to a continuous-time version
of Cover's universal portfolio strategies within the model-free context of
F\""ollmer's pathwise It\^o calculus. We establish the existence of the
universal portfolio strategy and prove that its portfolio value process is the
average of all values of constant rebalanced strategies. This result relies on
a systematic comparison between two alternative descriptions of self-financing
trading strategies within pathwise It\^o calculus. We moreover provide a
comparison result for the performance and the realized volatility and variance
of constant rebalanced portfolio strategies
"
2504.12266,2025-04-17,Semiparametric Dynamic Copula Models for Portfolio Optimization,"  The mean-variance portfolio model, based on the risk-return trade-off for
optimal asset allocation, remains foundational in portfolio optimization.
However, its reliance on restrictive assumptions about asset return
distributions limits its applicability to real-world data. Parametric copula
structures provide a novel way to overcome these limitations by accounting for
asymmetry, heavy tails, and time-varying dependencies. Existing methods have
been shown to rely on fixed or static dependence structures, thus overlooking
the dynamic nature of the financial market. In this study, a semiparametric
model is proposed that combines non-parametrically estimated copulas with
parametrically estimated marginals to allow all parameters to dynamically
evolve over time. A novel framework was developed that integrates time-varying
dependence modeling with flexible empirical beta copula structures. Marginal
distributions were modeled using the Skewed Generalized T family. This
effectively captures asymmetry and heavy tails and makes the model suitable for
predictive inferences in real world scenarios. Furthermore, the model was
applied to rolling windows of financial returns from the USA, India and Hong
Kong economies to understand the influence of dynamic market conditions. The
approach addresses the limitations of models that rely on parametric
assumptions. By accounting for asymmetry, heavy tails, and cross-correlated
asset prices, the proposed method offers a robust solution for optimizing
diverse portfolios in an interconnected financial market. Through adaptive
modeling, it allows for better management of risk and return across varying
economic conditions, leading to more efficient asset allocation and improved
portfolio performance.
"
2504.13529,2025-04-21,"Risk-aware black-box portfolio construction using Bayesian optimization
  with adaptive weighted Lagrangian estimator","  Existing portfolio management approaches are often black-box models due to
safety and commercial issues in the industry. However, their performance can
vary considerably whenever market conditions or internal trading strategies
change. Furthermore, evaluating these non-transparent systems is expensive,
where certain budgets limit observations of the systems. Therefore, optimizing
performance while controlling the potential risk of these financial systems has
become a critical challenge. This work presents a novel Bayesian optimization
framework to optimize black-box portfolio management models under limited
observations. In conventional Bayesian optimization settings, the objective
function is to maximize the expectation of performance metrics. However, simply
maximizing performance expectations leads to erratic optimization trajectories,
which exacerbate risk accumulation in portfolio management. Meanwhile, this can
lead to misalignment between the target distribution and the actual
distribution of the black-box model. To mitigate this problem, we propose an
adaptive weight Lagrangian estimator considering dual objective, which
incorporates maximizing model performance and minimizing variance of model
observations. Extensive experiments demonstrate the superiority of our approach
over five backtest settings with three black-box stock portfolio management
models. Ablation studies further verify the effectiveness of the proposed
estimator.
"
2504.14345,2025-04-22,"Integrating LLM-Generated Views into Mean-Variance Optimization Using
  the Black-Litterman Model","  Portfolio optimization faces challenges due to the sensitivity in traditional
mean-variance models. The Black-Litterman model mitigates this by integrating
investor views, but defining these views remains difficult. This study explores
the integration of large language models (LLMs) generated views into portfolio
optimization using the Black-Litterman framework. Our method leverages LLMs to
estimate expected stock returns from historical prices and company metadata,
incorporating uncertainty through the variance in predictions. We conduct a
backtest of the LLM-optimized portfolios from June 2024 to February 2025,
rebalancing biweekly using the previous two weeks of price data. As baselines,
we compare against the S&P 500, an equal-weighted portfolio, and a traditional
mean-variance optimized portfolio constructed using the same set of stocks.
Empirical results suggest that different LLMs exhibit varying levels of
predictive optimism and confidence stability, which impact portfolio
performance. The source code and data are available at
https://github.com/youngandbin/LLM-MVO-BLM.
"
2504.15268,2025-05-21,"Beating the Correlation Breakdown: Robust Inference, Flexible Scenarios,
  and Stress Testing for Financial Portfolios","  We live in a multivariate world, and effective modeling of financial
portfolios, including their construction, allocation, forecasting, and risk
analysis, simply is not possible without explicitly modeling the dependence
structure of their assets. Dependence structure can drive portfolio results
more than the combined effects of other parameters in investment and risk
models, but the literature provides relatively little to define the
finite-sample distributions of dependence measures in useable and useful ways
under challenging, real-world financial data conditions. Yet this is exactly
what is needed to make valid inferences about their estimates, and to use these
inferences for essential purposes such as hypothesis testing, dynamic
monitoring, realistic and granular scenario and reverse scenario analyses, and
mitigating the effects of correlation breakdowns during market upheavals. This
work develops a new and straightforward method, Nonparametric Angles-based
Correlation (NAbC), for defining the finite-sample distributions of any
dependence measure whose matrix of pairwise associations is positive definite
(e.g. Pearsons, Kendalls, Spearmans, Tail Dependence Matrix, and others). The
solution remains valid under marginal asset distributions characterized by
notably different and varying degrees of serial correlation, non-stationarity,
heavy-tailedness, and asymmetry. Importantly, NAbCs p-values and confidence
intervals remain analytically consistent at both the matrix level and the
pairwise cell level. Finally, NAbC maintains validity even when selected cells
in the matrix are frozen for a given scenario or stress test, thus enabling
flexible, granular, and realistic scenarios. NAbC stands alone in providing all
of these capabilities simultaneously, and should prove to be a very useful
means by which we can better understand and manage financial portfolios in our
multivariate world.
"
2504.16093,2025-04-24,"Efficient Portfolio Selection through Preference Aggregation with
  Quicksort and the Bradley--Terry Model","  How to allocate limited resources to projects that will yield the greatest
long-term benefits is a problem that often arises in decision-making under
uncertainty. For example, organizations may need to evaluate and select
innovation projects with risky returns. Similarly, when allocating resources to
research projects, funding agencies are tasked with identifying the most
promising proposals based on idiosyncratic criteria. Finally, in participatory
budgeting, a local community may need to select a subset of public projects to
fund. Regardless of context, agents must estimate the uncertain values of a
potentially large number of projects. Developing parsimonious methods to
compare these projects, and aggregating agent evaluations so that the overall
benefit is maximized, are critical in assembling the best project portfolio.
Unlike in standard sorting algorithms, evaluating projects on the basis of
uncertain long-term benefits introduces additional complexities. We propose
comparison rules based on Quicksort and the Bradley--Terry model, which
connects rankings to pairwise ""win"" probabilities. In our model, each agent
determines win probabilities of a pair of projects based on his or her specific
evaluation of the projects' long-term benefit. The win probabilities are then
appropriately aggregated and used to rank projects. Several of the methods we
propose perform better than the two most effective aggregation methods
currently available. Additionally, our methods can be combined with sampling
techniques to significantly reduce the number of pairwise comparisons. We also
discuss how the Bradley--Terry portfolio selection approach can be implemented
in practice.
"
2504.16892,2025-05-07,"Collective Defined Contribution Schemes Without Intergenerational
  Cross-Subsidies","  We present an architecture for managing Collective Defined Contribution (CDC)
schemes. The current approach to UK CDC can be described as shared-indexation,
where the nominal benefit of every member in a scheme receives the same level
of indexation each year. The design of such schemes rely on the use of
approximate discounting methodologies to value liabilities, and this leads to
intergenerational cross-subsidies which can be large and unpredictable. We
present an alternative approach which we call Collective-Drawdown CDC. This
approach does not result in intergenerational cross-subsidies since all pooling
is performed by explicit insurance contracts. It is therefore completely fair.
Moreover, this scheme results in better pension outcomes when compared to
shared-indexation CDC under the same model parameters.
"
2504.17713,2025-04-29,"Target-Date Funds: A State-of-the-Art Review with Policy Applications to
  Chile's Pension Reform","  This review paper explores the evolution and implementation of target-date
funds (TDFs), specifically focusing on their application within the context of
Chile's 2025 pension reform. The introduction of TDFs marks a significant shift
in Chile's pension system, which has traditionally relied on a multifund
structure (essentially a target-risk funds system). We offer a comprehensive
review of the theoretical foundations and practical considerations of TDFs,
highlighting key challenges and opportunities for Chilean regulators and fund
managers. Notably, we recommend that the glide path design should be dynamic,
incorporating adjustments based on total accumulated wealth, with particular
flexibility depending on each investor's risk tolerance. Furthermore, we
propose that the new benchmark for generational funds should feature a wide
deviation band relative to the new benchmark portfolio, which could foster a
market with more investment strategies and better competition among fund
managers, encourage the inclusion of alternative assets, and foster greater
diversification. Lastly, we highlight the need for future work to define a
glide path model that incorporates the theoretical frameworks described,
tailored to the unique parameters of the Chilean pension system. These
recommendations aim to optimize the long-term retirement outcomes for Chilean
workers under the new pension structure.
"
2504.19980,2025-04-29,Deep Declarative Risk Budgeting Portfolios,"  Recent advances in deep learning have spurred the development of end-to-end
frameworks for portfolio optimization that utilize implicit layers. However,
many such implementations are highly sensitive to neural network
initialization, undermining performance consistency. This research introduces a
robust end-to-end framework tailored for risk budgeting portfolios that
effectively reduces sensitivity to initialization. Importantly, this enhanced
stability does not compromise portfolio performance, as our framework
consistently outperforms the risk parity benchmark.
"
2505.01858,2025-05-06,Mean Field Game of Optimal Tracking Portfolio,"  This paper studies the mean field game (MFG) problem arising from a large
population competition in fund management, featuring a new type of relative
performance via the benchmark tracking constraint. In the n-agent model, each
agent can strategically inject capital to ensure that the total wealth
outperforms the benchmark process, which is modeled as a linear combination of
the population's average wealth process and an exogenous market index process.
That is, each agent is concerned about the performance of her competitors
captured by the floor constraint. With a continuum of agents, we formulate the
constrained MFG problem and transform it into an equivalent unconstrained MFG
problem with a reflected state process. We establish the existence of the mean
field equilibrium (MFE) using the PDE approach. Firstly, by applying the dual
transform, the best response control of the representative agent can be
characterized in analytical form in terms of a dual reflected diffusion
process. As a novel contribution, we verify the consistency condition of the
MFE in separated domains with the help of the duality relationship and
properties of the dual process.
"
2505.01962,2025-05-06,"Heterogeneous Trader Responses to Macroeconomic Surprises: Simulating
  Order Flow Dynamics","  Understanding how market participants react to shocks like scheduled
macroeconomic news is crucial for both traders and policymakers. We develop a
calibrated data generation process DGP that embeds four stylized trader
archetypes retail, pension, institutional, and hedge funds into an extended
CAPM augmented by CPI surprises. Each agents order size choice is driven by a
softmax discrete choice rule over small, medium, and large trades, where
utility depends on risk aversion, surprise magnitude, and liquidity. We aim to
analyze each agent's reaction to shocks and Monte Carlo experiments show that
higher information, lower aversion agents take systematically larger positions
and achieve higher average wealth. Retail investors under react on average,
exhibiting smaller allocations and more dispersed outcomes. And ambient
liquidity amplifies the sensitivity of order flow to surprise shocks. Our
framework offers a transparent benchmark for analyzing order flow dynamics
around macro releases and suggests how real time flow data could inform news
impact inference.
"
2505.02185,2025-05-06,Latent Variable Estimation in Bayesian Black-Litterman Models,"  We revisit the Bayesian Black-Litterman (BL) portfolio model and remove its
reliance on subjective investor views. Classical BL requires an investor
""view"": a forecast vector $q$ and its uncertainty matrix $\Omega$ that describe
how much a chosen portfolio should outperform the market. Our key idea is to
treat $(q,\Omega)$ as latent variables and learn them from market data within a
single Bayesian network. Consequently, the resulting posterior estimation
admits closed-form expression, enabling fast inference and stable portfolio
weights. Building on these, we propose two mechanisms to capture how features
interact with returns: shared-latent parametrization and feature-influenced
views; both recover classical BL and Markowitz portfolios as special cases.
Empirically, on 30-year Dow-Jones and 20-year sector-ETF data, we improve
Sharpe ratios by 50% and cut turnover by 55% relative to Markowitz and the
index baselines. This work turns BL into a fully data-driven, view-free, and
coherent Bayesian framework for portfolio optimization.
"
2505.03760,2025-05-08,"Deep Reinforcement Learning for Investor-Specific Portfolio
  Optimization: A Volatility-Guided Asset Selection Approach","  Portfolio optimization requires dynamic allocation of funds by balancing the
risk and return tradeoff under dynamic market conditions. With the recent
advancements in AI, Deep Reinforcement Learning (DRL) has gained prominence in
providing adaptive and scalable strategies for portfolio optimization. However,
the success of these strategies depends not only on their ability to adapt to
market dynamics but also on the careful pre-selection of assets that influence
overall portfolio performance. Incorporating the investor's preference in
pre-selecting assets for a portfolio is essential in refining their investment
strategies. This study proposes a volatility-guided DRL-based portfolio
optimization framework that dynamically constructs portfolios based on
investors' risk profiles. The Generalized Autoregressive Conditional
Heteroscedasticity (GARCH) model is utilized for volatility forecasting of
stocks and categorizes them based on their volatility as aggressive, moderate,
and conservative. The DRL agent is then employed to learn an optimal investment
policy by interacting with the historical market data. The efficacy of the
proposed methodology is established using stocks from the Dow $30$ index. The
proposed investor-specific DRL-based portfolios outperformed the baseline
strategies by generating consistent risk-adjusted returns.
"
2505.05113,2025-05-16,Loss-Versus-Rebalancing under Deterministic and Generalized block-times,"  Although modern blockchains almost universally produce blocks at fixed
intervals, existing models still lack an analytical formula for the
loss-versus-rebalancing (LVR) incurred by Automated Market Makers (AMMs)
liquidity providers in this setting. Leveraging tools from random walk theory,
we derive the following closed-form approximation for the per block per unit of
liquidity expected LVR under constant block time:
  \[ \overline{\mathrm{ARB}}= \frac{\,\sigma_b^{2}}
{\,2+\sqrt{2\pi}\,\gamma/(|\zeta(1/2)|\,\sigma_b)\,}+O\!\bigl(e^{-\mathrm{const}\tfrac{\gamma}{\sigma_b}}\bigr)\;\approx\;
\frac{\sigma_b^{2}}{\,2 + 1.7164\,\gamma/\sigma_b}, \] where $\sigma_b$ is the
intra-block asset volatility, $\gamma$ the AMM spread and $\zeta$ the Riemann
Zeta function. Our large Monte Carlo simulations show that this formula is in
fact quasi-exact across practical parameter ranges.
  Extending our analysis to arbitrary block-time distributions as well, we
demonstrate both that--under every admissible inter-block law--the probability
that a block carries an arbitrage trade converges to a universal limit, and
that only constant block spacing attains the asymptotically minimal LVR. This
shows that constant block intervals provide the best possible protection
against arbitrage for liquidity providers.
"
2505.06383,2025-05-13,"The bias of IID resampled backtests for rolling-window mean-variance
  portfolios","  Backtests on historical data are the basis for practical evaluations of
portfolio selection rules, but their reliability is often limited by reliance
on a single sample path. This can lead to high estimation variance. Resampling
techniques offer a potential solution by increasing the effective sample size,
but can disrupt the temporal ordering inherent in financial data and introduce
significant bias. This paper investigates the critical questions: First, How
large is this bias for Sharpe Ratio estimates?, and then, second: What are its
primary drivers?. We focus on the canonical rolling-window mean-variance
portfolio rule. Our contributions are identifying the bias mechanism, and
providing a practical heuristic for gauging bias severity. We show that the
bias arises from the disruption of train-test dependence linked to the return
auto-covariance structure and derive bounds for the bias which show a strong
dependence on the observable first-lag autocorrelation. Using simulations to
confirm these findings, it is revealed that the resulting Sharpe Ratio bias is
often a fraction of a typical backtest's estimation noise, benefiting from
partial offsetting of component biases. Empirical analysis further illustrates
that differences between IID-resampled and standard backtests align
qualitatively with these drivers. Surprisingly, our results suggest that while
IID resampling can disrupt temporal dependence, its resulting bias can often be
tolerable. However, we highlight the need for structure-preserving resampling
methods.
"
2505.06864,2025-05-13,"NewsNet-SDF: Stochastic Discount Factor Estimation with Pretrained
  Language Model News Embeddings via Adversarial Networks","  Stochastic Discount Factor (SDF) models provide a unified framework for asset
pricing and risk assessment, yet traditional formulations struggle to
incorporate unstructured textual information. We introduce NewsNet-SDF, a novel
deep learning framework that seamlessly integrates pretrained language model
embeddings with financial time series through adversarial networks. Our
multimodal architecture processes financial news using GTE-multilingual models,
extracts temporal patterns from macroeconomic data via LSTM networks, and
normalizes firm characteristics, fusing these heterogeneous information sources
through an innovative adversarial training mechanism. Our dataset encompasses
approximately 2.5 million news articles and 10,000 unique securities,
addressing the computational challenges of processing and aligning text data
with financial time series. Empirical evaluations on U.S. equity data
(1980-2022) demonstrate NewsNet-SDF substantially outperforms alternatives with
a Sharpe ratio of 2.80. The model shows a 471% improvement over CAPM, over 200%
improvement versus traditional SDF implementations, and a 74% reduction in
pricing errors compared to the Fama-French five-factor model. In comprehensive
comparisons, our deep learning approach consistently outperforms traditional,
modern, and other neural asset pricing models across all key metrics. Ablation
studies confirm that text embeddings contribute significantly more to model
performance than macroeconomic features, with news-derived principal components
ranking among the most influential determinants of SDF dynamics. These results
validate the effectiveness of our multimodal deep learning approach in
integrating unstructured text with traditional financial data for more accurate
asset pricing, providing new insights for digital intelligent decision-making
in financial technology.
"
2505.07820,2025-05-13,"Revisiting the Excess Volatility Puzzle Through the Lens of the
  Chiarella Model","  We amend and extend the Chiarella model of financial markets to deal with
arbitrary long-term value drifts in a consistent way. This allows us to improve
upon existing calibration schemes, opening the possibility of calibrating
individual monthly time series instead of classes of time series. The technique
is employed on spot prices of four asset classes from ca. 1800 onward (stock
indices, bonds, commodities, currencies). The so-called fundamental value is a
direct output of the calibration, which allows us to (a) quantify the amount of
excess volatility in these markets, which we find to be large (e.g. a factor
$\approx$ 4 for stock indices) and consistent with previous estimates; and (b)
determine the distribution of mispricings (i.e. the difference between market
price and value), which we find in many cases to be bimodal. Both findings are
strongly at odds with the Efficient Market Hypothesis. We also study in detail
the 'sloppiness' of the calibration, that is, the directions in parameter space
that are weakly constrained by data. The main conclusions of our study are
remarkably consistent across different asset classes, and reinforce the
hypothesis that the medium-term fate of financial markets is determined by a
tug-of-war between trend followers and fundamentalists.
"
2505.10099,2025-05-16,"A Scalable Gradient-Based Optimization Framework for Sparse
  Minimum-Variance Portfolio Selection","  Portfolio optimization involves selecting asset weights to minimize a
risk-reward objective, such as the portfolio variance in the classical
minimum-variance framework. Sparse portfolio selection extends this by imposing
a cardinality constraint: only $k$ assets from a universe of $p$ may be
included. The standard approach models this problem as a mixed-integer
quadratic program and relies on commercial solvers to find the optimal
solution. However, the computational costs of such methods increase
exponentially with $k$ and $p$, making them too slow for problems of even
moderate size. We propose a fast and scalable gradient-based approach that
transforms the combinatorial sparse selection problem into a constrained
continuous optimization task via Boolean relaxation, while preserving
equivalence with the original problem on the set of binary points. Our
algorithm employs a tunable parameter that transmutes the auxiliary objective
from a convex to a concave function. This allows a stable convex starting
point, followed by a controlled path toward a sparse binary solution as the
tuning parameter increases and the objective moves toward concavity. In
practice, our method matches commercial solvers in asset selection for most
instances and, in rare instances, the solution differs by a few assets whilst
showing a negligible error in portfolio variance.
"
2505.15602,2025-05-22,Deep Learning for Continuous-time Stochastic Control with Jumps,"  In this paper, we introduce a model-based deep-learning approach to solve
finite-horizon continuous-time stochastic control problems with jumps. We
iteratively train two neural networks: one to represent the optimal policy and
the other to approximate the value function. Leveraging a continuous-time
version of the dynamic programming principle, we derive two different training
objectives based on the Hamilton-Jacobi-Bellman equation, ensuring that the
networks capture the underlying stochastic dynamics. Empirical evaluations on
different problems illustrate the accuracy and scalability of our approach,
demonstrating its effectiveness in solving complex, high-dimensional stochastic
control tasks.
"
2505.19058,2025-05-27,Distributionally Robust Deep Q-Learning,"  We propose a novel distributionally robust $Q$-learning algorithm for the
non-tabular case accounting for continuous state spaces where the state
transition of the underlying Markov decision process is subject to model
uncertainty. The uncertainty is taken into account by considering the
worst-case transition from a ball around a reference probability measure. To
determine the optimal policy under the worst-case state transition, we solve
the associated non-linear Bellman equation by dualising and regularising the
Bellman operator with the Sinkhorn distance, which is then parameterized with
deep neural networks. This approach allows us to modify the Deep Q-Network
algorithm to optimise for the worst case state transition.
  We illustrate the tractability and effectiveness of our approach through
several applications, including a portfolio optimisation task based on
S\&{P}~500 data.
"
cond-mat/0008069,2008-12-10,Multifractal returns and Hierarchical Portfolio Theory,"  We extend and test empirically the multifractal model of asset returns based
on a multiplicative cascade of volatilities from large to small time scales.
The multifractal description of asset fluctuations is generalized into a
multivariate framework to account simultaneously for correlations across times
scales and between a basket of assets. The reported empirical results show that
this extension is pertinent for financial modelling. The second part of the
paper applies this theory to portfolio optimisation. Our multi-scale
description allows us to characterize the portfolio return distribution at all
time scales simultaneously. The portfolio composition is predicted to change
with the investment time horizon (i.e., the time scale) in a way that can be
fully determined once an adequate measure of risk is chosen. We discuss the use
of the fourth-order cumulant and of utility functions. While the portfolio
volatility can be optimized in some cases for all time horizons, the kurtosis
and higher normalized cumulants cannot be simultaneously optimized. For a fixed
investment horizon, we study in details the influence of the number of periods,
i.e., of the number of rebalancing of the portfolio. For the large risks
quantified by the cumulants of order larger than two, the number of periods has
a non-trivial influence, in contrast with Tobin's result valid in the
mean-variance framework. This theory provides a fundamental framework for the
conflicting optimization involved in the different time horizons and quantifies
systematically the trade-offs for an optimal inter-temporal portfolio
optimization.
"
cond-mat/0009401,2009-10-31,"Empirical properties of the variety of a financial portfolio and the
  single-index model","  We investigate the variety of a portfolio of stocks in normal and extreme
days of market activity. We show that the variety carries information about the
market activity which is not present in the single-index model and we observe
that the variety time evolution is not time reversal around the crash days. We
obtain the theoretical relation between the square variety and the mean return
of the ensemble return distribution predicted by the single-index model. The
single-index model is able to mimic the average behavior of the square variety
but fails in describing quantitatively the relation between the square variety
and the mean return of the ensemble distribution. The difference between
empirical data and theoretical description is more pronounced for large
positive values of the mean return of the ensemble distribution. Other
significant deviations are also observed for extreme negative values of the
mean return.
"
cond-mat/0011280,2008-12-02,The thermodynamics of portfolios,"  We propose a new method of valuation of portfolios and their respective
investing strategies. To this end we define a canonical ensemble of portfolios
that allows to use the formalism thermodynamics.
"
cond-mat/0103020,2008-12-10,"General framework for a portfolio theory with non-Gaussian risks and
  non-linear correlations","  Using a family of modified Weibull distributions, encompassing both
sub-exponentials and super-exponentials, to parameterize the marginal
distributions of asset returns and their natural multivariate generalizations,
we give exact formulas for the tails and for the moments and cumulants of the
distribution of returns of a portfolio make of arbitrary compositions of these
assets. Using combinatorial and hypergeometric functions, we are in particular
able to extend previous results to the case where the exponents of the Weibull
distributions are different from asset to asset and in the presence of
dependence between assets. We treat in details the problem of risk minimization
using two different measures of risks (cumulants and value-at-risk) for a
portfolio made of two assets and compare the theoretical predictions with
direct empirical data. While good agreement is found, the remaining discrepancy
between theory and data stems from the deviations from the Weibull
parameterization for small returns. Our extended formulas enable us to
determine analytically the conditions under which it is possible to ``have your
cake and eat it too'', i.e., to construct a portfolio with both larger return
and smaller ``large risks''.
"
cond-mat/0104305,2010-05-04,Profit Profiles in Correlated Markets,"  We consider a financial market where the asset price follows a fractional
Brownian motion. We introduce a family of investment strategies, and quantify
profit possibilities for both persistent and antipersistant markets.
"
cond-mat/0111537,2009-11-07,Portfolio Optimization and the Random Magnet Problem,"  Diversification of an investment into independently fluctuating assets
reduces its risk. In reality, movement of assets are are mutually correlated
and therefore knowledge of cross--correlations among asset price movements are
of great importance. Our results support the possibility that the problem of
finding an investment in stocks which exposes invested funds to a minimum level
of risk is analogous to the problem of finding the magnetization of a random
magnet. The interactions for this ``random magnet problem'' are given by the
cross-correlation matrix {\bf \sf C} of stock returns. We find that random
matrix theory allows us to make an estimate for {\bf \sf C} which outperforms
the standard estimate in terms of constructing an investment which carries a
minimum level of risk.
"
cond-mat/0202356,2008-12-10,Tail Dependence of Factor Models,"  Using the framework of factor models, we establish the general expression of
the coefficient of tail dependence between the market and a stock (i.e., the
probability that the stock incurs a large loss, assuming that the market has
also undergone a large loss) as a function of the parameters of the underlying
factor model and of the tail parameters of the distributions of the factor and
of the idiosyncratic noise of each stock. Our formula holds for arbitrary
marginal distributions and in addition does not require any parameterization of
the multivariate distributions of the market and stocks. The determination of
the extreme parameter, which is not accessible by a direct statistical
inference, is made possible by the measurement of parameters whose estimation
involves a significant part of the data with sufficient statistics. Our
empirical tests find a good agreement between the calibration of the tail
dependence coefficient and the realized large losses over the period from 1962
to 2000. Nevertheless, a bias is detected which suggests the presence of an
outlier in the form of the crash of October 1987.
"
cond-mat/0203304,2008-12-10,"Self-Financing, Replicating Hedging Strategies, an incomplete
  thermodynamic analogy","  In the theory of riskfree hedges in continuous time finance, one can start
with the delta-hedge and derive the option pricing equation, or one can start
with the replicating, self-financing hedging strategy and derive both the
delta-hedge and the option pricing partial differential equation. Approximately
reversible trading is implicitly assumed in both cases. The option pricing
equation is not restricted to the standard Black-Scholes equation when
nontrivial volatility is assumed, but produces option pricing in agreement with
the empirical distribution for the right choice of volatility in a stochastic
description of fluctuations. The replicating, self-financing hedging strategy
provides us with an incomplete analogy with thermodynamics where liquidity
plays the role of the heat bath, the absence of arbitrage is analgous to
thermal equilibrium, but there is no role played by the entropy of the returns
distribution, which cannot reach a maximum/equilibrium. We emphasize strongly
that the no-arbitrage assumption is not an equilibrium assumption, as is taught
in economics, but provides only an incomplete, very limited analogy with the
idea of thermal equilibrium.
"
cond-mat/0203607,2008-12-02,Portfolio Optimization with Spectral Measures of Risk,"  We study Spectral Measures of Risk from the perspective of portfolio
optimization. We derive exact results which extend to general Spectral Measures
M_phi the Pflug--Rockafellar--Uryasev methodology for the minimization of
alpha--Expected Shortfall. The minimization problem of a spectral measure is
shown to be equivalent to the minimization of a suitable function which
contains additional parameters, but displays analytical properties (piecewise
linearity and convexity in all arguments, absence of sorting subroutines) which
allow for efficient minimization procedures.
  In doing so we also reveal a new picture where the classical risk--reward
problem a la Markowitz (minimizing risks with constrained returns or maximizing
returns with constrained risks) is shown to coincide to the unconstrained
optimization of a single suitable spectral measure. In other words, minimizing
a spectral measure turns out to be already an optimization process itself,
where risk minimization and returns maximization cannot be disentangled from
each other.
"
cond-mat/0205119,2009-11-07,Noisy Covariance Matrices and Portfolio Optimization II,"  Recent studies inspired by results from random matrix theory [1,2,3] found
that covariance matrices determined from empirical financial time series appear
to contain such a high amount of noise that their structure can essentially be
regarded as random. This seems, however, to be in contradiction with the
fundamental role played by covariance matrices in finance, which constitute the
pillars of modern investment theory and have also gained industry-wide
applications in risk management. Our paper is an attempt to resolve this
embarrassing paradox. The key observation is that the effect of noise strongly
depends on the ratio r = n/T, where n is the size of the portfolio and T the
length of the available time series. On the basis of numerical experiments and
analytic results for some toy portfolio models we show that for relatively
large values of r (e.g. 0.6) noise does, indeed, have the pronounced effect
suggested by [1,2,3] and illustrated later by [4,5] in a portfolio optimization
context, while for smaller r (around 0.2 or below), the error due to noise
drops to acceptable levels. Since the length of available time series is for
obvious reasons limited in any practical application, any bound imposed on the
noise-induced error translates into a bound on the size of the portfolio. In a
related set of experiments we find that the effect of noise depends also on
whether the problem arises in asset allocation or in a risk measurement
context: if covariance matrices are used simply for measuring the risk of
portfolios with a fixed composition rather than as inputs to optimization, the
effect of noise on the measured risk may become very small.
"
cond-mat/0207475,2008-12-10,"Multi-Moments Method for Portfolio Management: Generalized Capital Asset
  Pricing Model in Homogeneous and Heterogeneous markets","  We introduce a new set of consistent measures of risks, in terms of the
semi-invariants of pdf's, such that the centered moments and the cumulants of
the portfolio distribution of returns that put more emphasis on the tail the
distributions. We derive generalized efficient frontiers, based on these novel
measures of risks and present the generalized CAPM, both in the cases of
homogeneous and heterogeneous markets. Then, using a family of modified Weibull
distributions, encompassing both sub-exponentials and super-exponentials, to
parameterize the marginal distributions of asset returns and their natural
multivariate generalizations, we offer exact formulas for the moments and
cumulants of the distribution of returns of a portfolio made of an arbitrary
composition of these assets. Using combinatorial and hypergeometric functions,
we are in particular able to extend previous results to the case where the
exponents of the Weibull distributions are different from asset to asset and in
the presence of dependence between assets. In this parameterization, we treat
in details the problem of risk minimization using the cumulants as measures of
risks for a portfolio made of two assets and compare the theoretical
predictions with direct empirical data. Our extended formulas enable us to
determine analytically the conditions under which it is possible to ``have your
cake and eat it too'', i.e., to construct a portfolio with both larger return
and smaller ``large risks''.
"
cond-mat/0210499,2009-11-07,Strategy for investments from Zipf law(s),"  We have applied the Zipf method to extract the $\zeta'$ exponent for seven
financial indices (DAX, FTSE; DJIA, NASDAQ, S&P500; Hang-Seng and Nikkei 225),
after having translated the signals into a text based on two letters. We follow
considerations based on the signal Hurst exponent and the notion of a time
dependent Zipf law and exponent in order to implement two simple investment
strategies for such indices. We show the time dependence of the returns.
"
cond-mat/0211044,2011-06-24,"Growth-Optimal Strategies with Quadratic Friction Over Finite-Time
  Investment Horizons","  We investigate the growth optimal strategy over a finite time horizon for a
stock and bond portfolio in an analytically solvable multiplicative Markovian
market model. We show that the optimal strategy consists in holding the amount
of capital invested in stocks within an interval around an ideal optimal
investment. The size of the holding interval is determined by the intensity of
the transaction costs and the time horizon.
"
cond-mat/0212187,2009-11-07,Risk and Utility in Portfolio Optimization,"  Modern portfolio theory(MPT) addresses the problem of determining the optimum
allocation of investment resources among a set of candidate assets. In the
original mean-variance approach of Markowitz, volatility is taken as a proxy
for risk, conflating uncertainty with risk. There have been many subsequent
attempts to alleviate that weakness which, typically, combine utility and risk.
We present here a modification of MPT based on the inclusion of separate risk
and utility criteria. We define risk as the probability of failure to meet a
pre-established investment goal. We define utility as the expectation of a
utility function with positive and decreasing marginal value as a function of
yield. The emphasis throughout is on long investment horizons for which
risk-free assets do not exist. Analytic results are presented for a Gaussian
probability distribution. Risk-utility relations are explored via empirical
stock-price data, and an illustrative portfolio is optimized using the
empirical data.
"
cond-mat/0212358,2014-10-03,Optimal strategies in collective Parrondo games,"  We present a modification of the so-called Parrondo's paradox where one is
allowed to choose in each turn the game that a large number of individuals
play. It turns out that, by choosing the game which gives the highest average
earnings at each step, one ends up with systematic loses, whereas a periodic or
random sequence of choices yields a steadily increase of the capital. An
explanation of this behavior is given by noting that the short-range
maximization of the returns is ""killing the goose that laid the golden eggs"". A
continuous model displaying similar features is analyzed using dynamic
programming techniques from control theory.
"
cond-mat/0303304,2008-12-10,Investment strategy based on a company growth model,"  We first estimate the average growth of a company's annual income and its
variance by using both real company data and a numerical model which we already
introduced a couple of years ago. Investment strategies expecting for income
growth is evaluated based on the numerical model. Our numerical simulation
suggests the possibility that an investment strategy focusing on the
medium-sized companies gives the best asset growth with relatively low risk.
"
cond-mat/0310503,2009-02-06,The scale-free topology of market investments,"  We propose a network description of large market investments, where both
stocks and shareholders are represented as vertices connected by weighted links
corresponding to shareholdings. In this framework, the in-degree ($k_{in}$) and
the sum of incoming link weights ($v$) of an investor correspond to the number
of assets held (\emph{portfolio diversification}) and to the invested wealth
(\emph{portfolio volume}) respectively. An empirical analysis of three
different real markets reveals that the distributions of both $k_{in}$ and $v$
display power-law tails with exponents $\gamma$ and $\alpha$. Moreover, we find
that $k_{in}$ scales as a power-law function of $v$ with an exponent $\beta$.
Remarkably, despite the values of $\alpha$, $\beta$ and $\gamma$ differ across
the three markets, they are always governed by the scaling relation
$\beta=(1-\alpha)/(1-\gamma)$. We show that these empirical findings can be
reproduced by a recent model relating the emergence of scale-free networks to
an underlying Paretian distribution of `hidden' vertex properties.
"
cond-mat/0404520,2008-12-10,The Feedback Effect of Hedging in Portfolio Optimization,"  In this short note, we will show how to optimize the portfolio of a large
trader whose hedging strategy affects the price of his assets.
"
cond-mat/0501057,2008-12-02,Metaheuristic Approaches to Realistic Portfolio Optimization,"  We investigate the application of two heuristic methods, genetic algorithms
and tabu/scatter search, to the optimisation of realistic portfolios. The model
is based on the classical mean-variance approach, but enhanced with floor and
ceiling constraints, cardinality constraints and nonlinear transaction costs
which include a substantial illiquidity premium.
  It is shown that genetic algorithms can optimise such portfolios effectively
and within reasonable times. This approach also copes easily with extensive
modifications such as the addition of more intricate constraints, discontinuous
variables and more complex objective functions.
  The results indicate that that both floor and ceiling constraints have a
substantial negative impact on portfolio performance and should be examined
critically. Another insight is that nonlinear transaction costs which are
comparable in magnitude to forecast returns will tend to diversify portfolios;
the effect of these costs on portfolio risk is, however, ambiguous, depending
on the degree of diversification required for cost reduction. The number of
assets in a portfolio invariably increases as a result of constraints, costs
and their combination.
  The implementation of cardinality constraints is essential for finding the
best-performing portfolio. The ability of the heuristic method to deal with
cardinality constraints is one of its most powerful features.
"
cond-mat/9707042,2008-12-02,Missing Information and Asset Allocation,"  When the available statistical information is imperfect, it is dangerous to
follow standard optimisation procedures to construct an optimal portfolio,
which usually leads to a strong concentration of the weights on very few
assets. We propose a new way, based on generalised entropies, to ensure a
minimal degree of diversification.
"
cond-mat/9801239,2015-06-25,Dynamical Optimization Theory of a Diversified Portfolio,"  We propose and study a simple model of dynamical redistribution of capital in
a diversified portfolio. We consider a hypothetical situation of a portfolio
composed of N uncorrelated stocks. Each stock price follows a multiplicative
random walk with identical drift and dispersion. The rules of our model
naturally give rise to power law tails in the distribution of capital fractions
invested in different stocks. The exponent of this scale free distribution is
calculated in both discrete and continuous time formalism. It is demonstrated
that the dynamical redistribution strategy results in a larger typical growth
rate of the capital than a static ``buy-and-hold'' strategy. In the large N
limit the typical growth rate is shown to asymptotically approach that of the
expectation value of the stock price. The finite dimensional variant of the
model is shown to describe the partition function of directed polymers in
random media.
"
cond-mat/9801240,2008-12-02,Optimal Investment Strategy for Risky Assets,"  We design an optimal strategy for investment in a portfolio of assets subject
to a multiplicative Brownian motion. The strategy provides the maximal typical
long-term growth rate of investor's capital. We determine the optimal fraction
of capital that an investor should keep in risky assets as well as weights of
different assets in an optimal portfolio. In this approach both average return
and volatility of an asset are relevant indicators determining its optimal
weight. Our results are particularly relevant for very risky assets when
traditional continuous-time Gaussian portfolio theories are no longer
applicable.
"
cond-mat/9802059,2015-06-25,Large deviations and portfolio optimization,"  Risk control and optimal diversification constitute a major focus in the
finance and insurance industries as well as, more or less consciously, in our
everyday life. We present a discussion of the characterization of risks and of
the optimization of portfolios that starts from a simple illustrative model and
ends by a general functional integral formulation. A major theme is that risk,
usually thought one-dimensional in the conventional mean-variance approach, has
to be addressed by the full distribution of losses. Furthermore, the
time-horizon of the investment is shown to play a major role. We show the
importance of accounting for large fluctuations and use the theory of Cram\'er
for large deviations in this context. We first treat a simple model with a
single risky asset that examplifies the distinction between the average return
and the typical return, the role of large deviations in multiplicative
processes, and the different optimal strategies for the investors depending on
their size. We then analyze the case of assets whose price variations are
distributed according to exponential laws, a situation that is found to
describe reasonably well daily price variations. Several portfolio optimization
strategies are presented that aim at controlling large risks. We end by
extending the standard mean-variance portfolio optimization theory, first
within the quasi-Gaussian approximation and then using a general formulation
for non-Gaussian correlated assets in terms of the formalism of functional
integrals developed in the field theory of critical phenomena.
"
cond-mat/9804297,2009-09-25,Optimal Strategies for Prudent Investors,"  We consider a stochastic model of investment on an asset of a stock market
for a prudent investor. She decides to buy permanent goods with a fraction $\a$
of the maximum amount of money owned in her life in order that her economic
level never decreases. The optimal strategy is obtained by maximizing the
exponential growth rate for a fixed $\a$. We derive analytical expressions for
the typical exponential growth rate of the capital and its fluctuations by
solving an one-dimensional random walk with drift.
"
cond-mat/9810091,2008-12-02,Optimal lag in dynamical investments,"  A portfolio of different stocks and a risk-less security whose composition is
dynamically maintained stable by trading shares at any time step leads to a
growth of the capital with a nonrandom rate. This is the key for the theory of
optimal-growth investment formulated by Kelly. In presence of transaction
costs, the optimal composition changes and, more important, it turns out that
the frequency of transactions must be reduced. This simple observation leads to
the definition of an optimal lag between two rearrangement of the portfolio.
This idea is tested against an investment in a risky asset and a risk-less one.
The price of the first is proportional to NYSE composite index while the price
of the second grows according to the American Discount Rate. An application to
a portfolio of many stochastically equivalent securities is also provided.
"
cond-mat/9905050,2009-10-31,On the possibility of optimal investment,"  We analyze the theory of optimal investment in risky assets, developed
recently by Marsili, Maslov and Zhang [Physica A 253 (1998) 403]. When the real
data are used instead of abstract stochastic process, it appears that a
non-trivial investment strategy is rarely possible. We show that non-zero
transaction costs make the applicability of the method even more difficult. We
generalize the method in order to take into account possible correlations in
the asset price.
"
cond-mat/9912330,2008-12-02,Driving Force in Investment,"  We study investment strategy in different models of financial markets, where
the investors cannot reach a perfect knowledge about available assets. The
investor spends a certain effort to get information; this allows him to better
choose the investment strategy, and puts a selective pressure upon assets. The
best strategy is then a compromise between diversification and effort to get
information.
"
math/0207259,2008-12-02,"Maximin setting for investment problems and fixed income management with
  observable but non-predictable parameters","  We study optimal investment problem for a diffusion market consisting of a
finite number of risky assets (for example, bonds, stocks and options). Risky
assets evolution is described by Ito's equation, and the number of risky assets
can be larger than the number of driving Brownian motions. We assume that the
risk-free rate, the appreciation rates and the volatility of the stocks are all
random; they are not necessary adapted to the driving Brownian motion, and
their distributions are unknown, but they are supposed to be currently
observable. Admissible strategies are based on current observations of the
stock prices and the aforementioned parameters. The optimal investment problem
is stated as a problem with a maximin performance criterion. This criterion is
to ensure that a strategy is found such that the minimum of utility over all
distributions of parameters is maximal. Then the maximin problem is solved for
a very general case via solution of a linear parabolic equation.
"
math/0207260,2008-12-02,Optimal portfolio selection and compression in an incomplete market,"  We investigate an optimal investment problem with a general performance
criterion which, in particular, includes discontinuous functions. Prices are
modeled as diffusions and the market is incomplete. We find an explicit
solution for the case of limited diversification of the portfolio, i.e. for the
portfolio compression problem. By this we mean that an admissible strategies
may include no more than m different stocks concurrently, where m may be less
than the total number n of available stocks.
"
math/0208130,2008-12-10,On Bond Portfolio Management,"  This paper describes a new method of bond portfolio optimization based on
stochastic string models of correlation structure in bond returns. The paper
shows how to approximate correlation function of bond returns, compute the
optimal portfolio allocation using Wiener-Hopf factorization, and check whether
a collection of bonds presents arbitrage opportunities.
"
math/0301278,2008-12-10,A theory of bond portfolios,"  We introduce a bond portfolio management theory based on foundations similar
to those of stock portfolio management. A general continuous-time zero-coupon
market is considered. The problem of optimal portfolios of zero-coupon bonds is
solved for general utility functions, under a condition of no-arbitrage in the
zero-coupon market. A mutual fund theorem is proved, in the case of
deterministic volatilities. Explicit expressions are given for the optimal
solutions for several utility functions.
"
math/0302104,2008-12-02,Optimal Convergence Trading,"  This article examines arbitrage investment in a mispriced asset when the
mispricing follows the Ornstein-Uhlenbeck process and a credit-constrained
investor maximizes a generalization of the Kelly criterion. The optimal
differentiable and threshold policies are derived. The optimal differentiable
policy is linear with respect to mispricing and risk-free in the long run. The
optimal threshold policy calls for investing immediately when the mispricing is
greater than zero with the investment amount inversely proportional to the risk
aversion parameter. The investment is risky even in the long run. The results
are consistent with the belief that credit-constrained arbitrageurs should be
risk-neutral if they are to engage in convergence trading.
"
math/0304151,2008-12-02,Optimal Asset Allocation with Asymptotic Criteria,"  Assume (1) asset returns follow a stochastic multi-factor process with
time-varying conditional expectations; (2) investments are linear functions of
factors. This paper calculates asymptotic joint moments of the logarithm of
investor's wealth and the factors. These formulas enable fast computation of a
wide range of investment criteria. The results are illustrated by a numerical
example that shows that the optimal portfolio rules are sensitive to the
specification of the investment criterion.
"
math/0309276,2008-12-02,"Approximation of Multiple Integrals over Hyperboloids with Application
  to a Quadratic Portfolio with Options","  We consider an application involving a financial quadratic portfolio of
options, when the joint underlying log-returns changes with multivariate
elliptic distribution. This motivates the needs for methods for the
approximation of multiple integrals over hyperboloids. A transformation is used
to reduce the hyperboloid integrals to a product of two radial integrals and
two spherical surface integrals. Numerical approximation methods for the
transformed integrals are constructed. The application of these methods is
demonstrated using some financial applications examples.
"
math/0405293,2008-12-10,Optimal investment with random endowments in incomplete markets,"  In this paper, we study the problem of expected utility maximization of an
agent who, in addition to an initial capital, receives random endowments at
maturity. Contrary to previous studies, we treat as the variables of the
optimization problem not only the initial capital but also the number of units
of the random endowments. We show that this approach leads to a dual problem,
whose solution is always attained in the space of random variables. In
particular, this technique does not require the use of finitely additive
measures and the related assumption that the endowments are bounded.
"
math/0407119,2008-12-10,"A Characterization of Hedging Portfolios for Interest Rate Contingent
  Claims","  We consider the problem of hedging a European interest rate contingent claim
with a portfolio of zero-coupon bonds and show that an HJM type Markovian model
driven by an infinite number of sources of randomness does not have some of the
shortcomings found in the classical finite-factor models. Indeed, under natural
conditions on the model, we find that there exists a unique hedging strategy,
and that this strategy has the desirable property that at all times it consists
of bonds with maturities that are less than or equal to the longest maturity of
the bonds underlying the claim.
"
math/0506621,2008-12-02,Optimal long term investment model with memory,"  We consider a financial market model driven by an R^n-valued Gaussian process
with stationary increments which is different from Brownian motion. This
driving noise process consists of $n$ independent components, and each
component has memory described by two parameters. For this market model, we
explicitly solve optimal investment problems. These include (i) Merton's
portfolio optimization problem; (ii) the maximization of growth rate of
expected utility of wealth over the infinite horizon; (iii) the maximization of
the large deviation probability that the wealth grows at a higher rate than a
given benchmark. The estimation of paremeters is also considered.
"
math/0510333,2008-12-10,Optimal Bond Portfolios,"  We aim to construct a general framework for portfolio management in
continuous time, encompassing both stocks and bonds. In these lecture notes we
give an overview of the state of the art of optimal bond portfolios and we
re-visit main results and mathematical constructions introduced in our previous
publications (Ann. Appl. Probab. \textbf{15}, 1260--1305 (2005) and Fin. Stoch.
{\bf9}, 429--452 (2005)).
  A solution of the optimal bond portfolio problem is given for general utility
functions and volatility operator processes, provided that the market price of
risk process has certain Malliavin differentiability properties or is finite
dimensional.
  The text is essentially self-contained.
"
math/0607617,2008-12-10,Computing strategies for achieving acceptability,"  We consider a trader who wants to direct his portfolio towards a set of
acceptable wealths given by a convex risk measure. We propose a black-box
algorithm, whose inputs are the joint law of stock prices and the convex risk
measure, and whose outputs are the numerical values of initial capital
requirement and the functional form of a trading strategy to achieve
acceptability. We also prove optimality of the obtained capital.
"
math/0610224,2008-12-10,"On the two-times differentiability of the value functions in the problem
  of optimal investment in incomplete markets","  We study the two-times differentiability of the value functions of the primal
and dual optimization problems that appear in the setting of expected utility
maximization in incomplete markets. We also study the differentiability of the
solutions to these problems with respect to their initial values. We show that
the key conditions for the results to hold true are that the relative risk
aversion coefficient of the utility function is uniformly bounded away from
zero and infinity, and that the prices of traded securities are sigma-bounded
under the num\'{e}raire given by the optimal wealth process.
"
math/0610749,2008-12-10,"Quadratic BSDEs driven by a continuous martingale and application to
  utility maximization problem","  In this paper, we study a class of quadratic Backward Stochastic Differential
Equations (BSDEs) which arises naturally when studying the problem of utility
maximization with portfolio constraints. We first establish existence and
uniqueness results for such BSDEs and then, we give an application to the
utility maximization problem. Three cases of utility functions will be
discussed: the exponential, power and logarithmic ones.
"
math/0612181,2008-12-10,Utility Maximization in a jump market model,"  In this paper, we consider the classical problem of utility maximization in a
financial market allowing jumps. Assuming that the constraint set is a compact
set, rather than a convex one, we use a dynamic method from which we derive a
specific BSDE. We then aim at showing existence and uniqueness results for the
introduced BSDE. This allows us to give an explicit expression of the value
function and characterize optimal strategies for our problem.
"
math/0702726,2008-12-02,A Portfolio Decomposition Formula,"  This paper derives a portfolio decomposition formula when the agent maximizes
utility of her wealth at some finite planning horizon. The financial market is
complete and consists of multiple risky assets (stocks) plus a risk free asset.
The stocks are modelled as exponential Brownian motions with drift and
volatility being Ito processes. The optimal portfolio has two components: a
myopic component and a hedging one. We show that the myopic component is robust
with respect to stopping times. We employ the Clark-Haussmann formula to derive
portfolio s hedging component.
"
math/0702727,2008-12-02,On Robust Utility Maximization,"  This paper studies the problem of optimal investment in incomplete markets,
robust with respect to stopping times. We work on a Brownian motion framework
and the stopping times are adapted to the Brownian filtration. Robustness can
only be achieved for logartihmic utility, otherwise a cashflow should be added
to the investor s wealth. The cashflow can be decomposed into the sum of an
increasing and a decreasing process. The last one can be viewed as consumption.
The first one is an insurance premium the agent has to pay.
"
math/0703743,2008-12-10,"Implications of contrarian and one-sided strategies for the fair-coin
  game","  We derive some results on contrarian and one-sided strategies by Skeptic for
the fair-coin game in the framework of the game-theoretic probability of Shafer
and Vovk \cite{sv}. In particular, concerning the rate of convergence of the
strong law of large numbers (SLLN), we prove that Skeptic can force that the
convergence has to be slower than or equal to $O(n^{-1/2})$. This is achieved
by a very simple contrarian strategy of Skeptic. This type of result, bounding
the rate of convergence from below, contrasts with more standard results of
bounding the rate of SLLN from above by using momentum strategies. We also
derive a corresponding one-sided result.
"
math/0703823,2008-12-02,Optimizing Venture Capital Investments in a Jump Diffusion Model,"  We study a practical optimization problems for venture capital investments
and/or Research and Development (R&D) investments. The first problem is that,
given the amount of the initial investment and the reward function at the
initial public offering (IPO) market, the venture capitalist wants to maximize
overall discounted cash flows after subtracting subsequent (if needed)
investments. We describe this problem as a mixture of singular stochastic
control and optimal stopping problems and give an explicit solution. The former
corresponds to finding an optimal subsequent investment policy for the purpose
that the value of the investee company stays away from zero. The latter
corresponds to finding an optimal stopping rule in order to maximize the
harvest of their investments. The second kind problem is concerned about
optimal dividend policy. Rather than selling the holding stock, the investor
may extract dividends when it is appropriate. We will find a quasi-explicit
optimal solution to this problem and prove the existence and uniqueness of the
solution and the optimality of the proposed strategy.
"
math/9907160,2008-12-02,Equity Allocation and Portfolio Selection in Insurance,"  A discrete time probabilistic model, for optimal equity allocation and
portfolio selection, is formulated so as to apply to (at least) reinsurance. In
the context of a company with several portfolios (or subsidiaries),
representing both liabilities and assets, it is proved that the model has
solutions respecting constraints on ROE's, ruin probabilities and market shares
currently in practical use. Solutions define global and optimal risk management
strategies of the company. Mathematical existence results and tools, such as
the inversion of the linear part of the Euler-Lagrange equations, developed in
a preceding paper in the context of a simplified model are essential for the
mathematical and numerical construction of solutions of the model.
"
nlin/0205011,2008-12-10,Portfolio Allocation to Corporate Bonds with Correlated Defaults,"  This article deals with the problem of optimal allocation of capital to
corporate bonds in fixed income portfolios when there is the possibility of
correlated defaults. Under fairly general assumptions for the distribution of
the total net assets of a set of firms we show that retaining the first few
moments of the portfolio default loss distribution gives an extremely good
approximation to the full solution of the asset allocation problem. We provide
detailed results on the convergence of the moment expansion. We also provide
explicit results for the inverse problem, i.e. for a given allocation to the
set of risky bonds, what is the average risk premium required to make the
portfolio optimal. Numerous numerical illustrations exhibit the results for
realistic portfolios and utility functions.
"
physics/0504131,2012-10-03,Risk portofolio management under Zipf analysis based strategies,"  A so called Zipf analysis portofolio management technique is introduced in
order to comprehend the risk and returns. Two portofoios are built each from a
well known financial index. The portofolio management is based on two
approaches: one called the ""equally weighted portofolio"", the other the
""confidence parametrized portofolio"". A discussion of the (yearly) expected
return, variance, Sharpe ratio and $\beta$ follows. Optimization levels of high
returns or low risks are found.
"
physics/0505142,2008-12-02,"Measuring sectoral diversification in an asymptotic multi-factor
  framework","  We investigate a multi-factor extension of the asymptotic single risk factor
(ASRF) model that underlies the capital charges of the ""Basel II Accord"". In
this extended model, it is still possible to derive closed-form solutions for
the risk contributions to Value-at-Risk and Expected Shortfall. As an
application of the risk contribution formulae we introduce a new concept for a
diversification measure. The use of this new measure is illustrated by an
example calculated with a two-factor model. The results with this model
indicate that, thanks to dependence on not fully correlated systematic sectors,
there can be a substantial reduction of risk contributions by sectoral
diversification effects.
"
physics/0508104,2008-12-10,Trend followers lose more often than they gain,"  We solve exactly a simple model of trend following strategy, and obtain the
analytical shape of the profit per trade distribution. This distribution is non
trivial and has an option like, asymmetric structure. The degree of asymmetry
depends continuously on the parameters of the strategy and on the volatility of
the traded asset. While the average gain per trade is always exactly zero, the
fraction f of winning trades decreases from f=1/2 for small volatility to f=0
for high volatility, showing that this winning probability does not give any
information on the reliability of the strategy but is indicative of the trading
style.
"
physics/0601166,2008-12-08,How many independent bets are there?,"  The benefits of portfolio diversification is a central tenet implicit to
modern financial theory and practice. Linked to diversification is the notion
of breadth. Breadth is correctly thought of as the number of in- dependent bets
available to an investor. Conventionally applications us- ing breadth
frequently assume only the number of separate bets. There may be a large
discrepancy between these two interpretations. We uti- lize a simple
singular-value decomposition (SVD) and the Keiser-Gutman stopping criterion to
select the integer-valued effective dimensionality of the correlation matrix of
returns. In an emerging market such as South African we document an estimated
breadth that is considerably lower than anticipated. This lack of
diversification may be because of market concentration, exposure to the global
commodity cycle and local currency volatility. We discuss some practical
extensions to a more statistically correct interpretation of market breadth,
and its theoretical implications for both global and domestic investors.
"
physics/0606015,2008-12-02,On the Feasibility of Portfolio Optimization under Expected Shortfall,"  We address the problem of portfolio optimization under the simplest coherent
risk measure, i.e. the expected shortfall. As it is well known, one can map
this problem into a linear programming setting. For some values of the external
parameters, when the available time series is too short, the portfolio
optimization is ill posed because it leads to unbounded positions, infinitely
short on some assets and infinitely long on some others. As first observed by
Kondor and coworkers, this phenomenon is actually a phase transition. We
investigate the nature of this transition by means of a replica approach.
"
physics/0607166,2009-11-13,Kelly Criterion revisited: optimal bets,"  Kelly criterion, that maximizes the expectation value of the logarithm of
wealth for bookmaker bets, gives an advantage over different class of
strategies. We use projective symmetries for a explanation of this fact.
Kelly's approach allows for an interesting financial interpretation of the
Boltzmann/Shannon entropy. A ""no-go"" hypothesis for big investors is suggested.
"
physics/0607175,2009-11-13,The matrix rate of return,"  In this paper we give definitions of matrix rates of return which do not
depend on the choice of basis describing baskets. We give their economic
interpretation. The matrix rate of return describes baskets of arbitrary type
and extends portfolio analysis to the complex variable domain. This allows us
for simultaneous analysis of evolution of baskets parameterized by complex
variables in both continuous and discrete time models.
"
physics/0607236,2009-11-13,"Geometry of Financial Markets -- Towards Information Theory Model of
  Markets","  Most of parameters used to describe states and dynamics of financial market
depend on proportions of the appropriate variables rather than on their actual
values. Therefore, projective geometry seems to be the correct language to
describe the theater of financial activities. We suppose that the object of
interest of agents, called here baskets, form a vector space over the reals. A
portfolio is defined as an equivalence class of baskets containing assets in
the same proportions. Therefore portfolios form a projective space. Cross
ratios, being invariants of projective maps, form key structures in the
proposed model. Quotation with respect to an asset X (i.e. in units of X) are
given by linear maps. Among various types of metrics that have financial
interpretation, the min-max metrics on the space of quotations can be
introduced. This metrics has an interesting interpretation in terms of rates of
return. It can be generalized so that to incorporate a new numerical parameter
(called temperature) that describes agent's lack of knowledge about the state
of the market. In a dual way, a metrics on the space of market quotation is
defined. In addition, one can define an interesting metric structure on the
space of portfolios/quotation that is invariant with respect to hyperbolic
(Lorentz) symmetries of the space of portfolios. The introduced formalism opens
new interesting and possibly fruitful fields of research.
"
physics/0608293,2010-04-27,"Automatic Trading Agent. RMT based Portfolio Theory and Portfolio
  Selection","  Portfolio theory is a very powerful tool in the modern investment theory. It
is helpful in estimating risk of an investor's portfolio, which arises from our
lack of information, uncertainty and incomplete knowledge of reality, which
forbids a perfect prediction of future price changes. Despite of many
advantages this tool is not known and is not widely used among investors on
Warsaw Stock Exchange. The main reason for abandoning this method is a high
level of complexity and immense calculations. The aim of this paper is to
introduce an automatic decision - making system, which allows a single investor
to use such complex methods of Modern Portfolio Theory (MPT). The key tool in
MPT is an analysis of an empirical covariance matrix. This matrix, obtained
from historical data is biased by such a high amount of statistical
uncertainty, that it can be seen as random. By bringing into practice the ideas
of Random Matrix Theory (RMT), the noise is removed or significantly reduced,
so the future risk and return are better estimated and controlled. This
concepts are applied to the Warsaw Stock Exchange Simulator http://gra.onet.pl.
The result of the simulation is 18 % level of gains in comparison for
respective 10 % loss of the Warsaw Stock Exchange main index WIG.
"
